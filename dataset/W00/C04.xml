<?xml version="1.0" encoding="UTF-8"?>
	<volume id="C04">

		<paper id="1033">
			<definition id="0">
				<sentence>Coreference resolution is the process of linking as a cluster1 multiple expressions which refer to the same entities in a document .</sentence>
				<definiendum id="0">Coreference resolution</definiendum>
				<definiens id="0">the process of linking as a cluster1 multiple expressions</definiens>
			</definition>
			<definition id="1">
				<sentence>Here SNP is the token list of NP , which is obtained by applying word stemming , stopword removal and acronym expansion to the original string as described in Yang et al. ( 2004 ) ’s work .</sentence>
				<definiendum id="0">SNP</definiendum>
			</definition>
			<definition id="2">
				<sentence>MRF ( Soon et al. , 2001 ) selects the candidate closest to the anaphor , while BF ( Aone and Bennett , 1995 ; Ng 2The confldence value is obtained by using the smoothed ratio p+1t+2 , where p is the number of positive instances and t is the total number of instances contained in the corresponding leaf node .</sentence>
				<definiendum id="0">MRF</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">the total number of instances contained in the corresponding leaf node</definiens>
			</definition>
			<definition id="3">
				<sentence>NP1 gives a detailed description of the entity .</sentence>
				<definiendum id="0">NP1</definiendum>
				<definiens id="0">gives a detailed description of the entity</definiens>
			</definition>
			<definition id="4">
				<sentence>In both trees , the string-similarity features occur on the top portion , which supports the arguments by ( Strube et al. , 2002 ) and ( Yang et al. , 2004 ) that string-matching is a crucial factor for NP coreference resolution .</sentence>
				<definiendum id="0">string-matching</definiendum>
				<definiens id="0">a crucial factor for NP coreference resolution</definiens>
			</definition>
</paper>

		<paper id="1147">
			<definition id="0">
				<sentence>We treat the corpus as a sequence of terms a121 = a122 a73 a18a70a122a34a123a23a18 a115a107a115a107a115 a18a70a122a70a124 where a125 is the size of the corpus .</sentence>
				<definiendum id="0">a125</definiendum>
				<definiens id="0">the size of the corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Word association is a common test in psychology ( Nelson et al. , 2000 ) , and it consists of a person providing an answer to a stimulus word by giving an associated one in response .</sentence>
				<definiendum id="0">Word association</definiendum>
				<definiens id="0">a common test in psychology ( Nelson et al. , 2000 ) , and it consists of a person providing an answer to a stimulus word by giving an associated one in response</definiens>
			</definition>
</paper>

		<paper id="1158">
			<definition id="0">
				<sentence>log PP = − 1 n summationdisplay k log P ( w k |w k−1 , w k−2 ) This perplexity PP represents the degree that a given word sequence , w 1 w 2 ···w n , matches the knowledge base with which the language model P ( w n |w n−1 , w n−2 ) was trained .</sentence>
				<definiendum id="0">perplexity PP</definiendum>
				<definiens id="0">the degree that a given word sequence</definiens>
			</definition>
			<definition id="1">
				<sentence>Calculation of perplexity : phrases ( their context ) PP RS ( &lt; S &gt; ) Atarashiku ( katta ) 499.57 0.86 ( atarashiku ) katta ( XP ) 2079.83 0.47 ( katta ) XP no ( pasokon ) 105.64 0.99 ( no ) pasokon de ( FAX ) 185.92 0.95 ( de ) FAX kinou wo ( tsukau ) 236.23 0.89 ( wo ) tsukau ni ( sono ) 98.40 0.99 ( ni ) sono ( e ) 1378.72 0.62 ( sono ) e ( ikou ) 144.58 0.96 ( e ) ikou ( &lt; /S &gt; ) 27150.00 0.00 &lt; S &gt; , &lt; /S &gt; denote the beginning and end of a sentence .</sentence>
				<definiendum id="0">Calculation of perplexity : phrases ( their context ) PP RS</definiendum>
			</definition>
			<definition id="2">
				<sentence>The value is defined by the equation , SS ( n , m ) =1− |res ( n ) ∩ res ( m ) | 2 |res ( n ) ||res ( m ) | .</sentence>
				<definiendum id="0">SS</definiendum>
				<definiens id="0">n , m ) =1− |res ( n ) ∩ res ( m ) | 2 |res ( n ) ||res ( m ) |</definiens>
			</definition>
			<definition id="3">
				<sentence>Here , res ( n ) denotes a set of retrieval results for the n-th candidate , and |res ( n ) | denotes the number of elements in the set .</sentence>
				<definiendum id="0">n )</definiendum>
				<definiendum id="1">n ) |</definiendum>
				<definiens id="0">denotes a set of retrieval results for the n-th candidate , and |res</definiens>
				<definiens id="1">the number of elements in the set</definiens>
			</definition>
</paper>

		<paper id="1203">
			<definition id="0">
				<sentence>The platform , named TOY ( Çetinolu 2001 ) , is essentially a big set of predicates in the logic programming language Prolog .</sentence>
				<definiendum id="0">TOY</definiendum>
				<definiens id="0">essentially a big set of predicates in the logic programming language Prolog</definiens>
			</definition>
			<definition id="1">
				<sentence>The semantic representation slot gives a description of the contribution of the morpheme to the meaning of full-size sentences in which it appears : Since the meanings of sentences are represented by predicate logic formulas in our setup , roots contribute “partial” versions of such formulas , with “holes” to be filled by the contributions of the other words of the sentence .</sentence>
				<definiendum id="0">semantic representation slot</definiendum>
				<definiens id="0">gives a description of the contribution of the morpheme to the meaning of full-size sentences in which it appears</definiens>
			</definition>
			<definition id="2">
				<sentence>The morphological component of the platform is a finite state transducer that makes use of the lexicon for traversing the arcs of the diagram ( adopted , with changes , from Kemal Oflazer’s work on Turkish morphology ( Oflazer 1993 ) ) to associate a character string with the list of meaning contributions of its morphemes .</sentence>
				<definiendum id="0">morphological component of the platform</definiendum>
			</definition>
			<definition id="3">
				<sentence>In the Prolog program , existentially quantified expressions like this one have the form some ( X , Restrictor , Scope ) , where X is the quantified variable , and Restrictor and Scope are the two sides of the conjunction ( Covington , 1994 ) some ( X , çocuk ( X ) , some ( Y , zeytin ( Y ) , ye ( EventMarker , X , Y , Location , Time , Goal , Source , Instrument , definite_past , none , positive ) ) ) The successful DCG parsing of a sentence also results in a field being instantiated to a symbol representing the sentence’s mood .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">ye</definiendum>
				<definiens id="0">the quantified variable , and Restrictor and Scope are the two sides of the conjunction</definiens>
				<definiens id="1">Y , Location , Time , Goal , Source , Instrument , definite_past , none , positive ) ) ) The successful DCG parsing of a sentence also results in a field being instantiated to a symbol representing the sentence’s mood</definiens>
			</definition>
			<definition id="4">
				<sentence>Resolving an anaphor is the job of finding out which discourse marker ( unique internal name ) to use for the entity referred to by this phrase in the knowledge base .</sentence>
				<definiendum id="0">Resolving an anaphor</definiendum>
				<definiens id="0">the job of finding out which discourse marker ( unique internal name ) to use for the entity referred to by this phrase in the knowledge base</definiens>
			</definition>
			<definition id="5">
				<sentence>For wh-question sentences , the DCG parser creates formulas in the form of Prolog predicates .</sentence>
				<definiendum id="0">DCG parser</definiendum>
			</definition>
			<definition id="6">
				<sentence>is translated to the formula which ( X , insan ( X ) , some ( Y , zeytin ( Y ) , ye ( Event , X , Y , Loc , Time , Goal , Source , Instrument , definite_past , none , positive ) ) whose form matches the already available logic program which ( Item , Property1Item , Property2Item ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">zeytin ( Y ) , ye ( Event , X , Y , Loc , Time , Goal , Source , Instrument , definite_past , none , positive ) ) whose form matches the already available logic program which ( Item , Property1Item , Property2Item )</definiens>
			</definition>
			<definition id="7">
				<sentence>( Canan is a small child ) Teekkürler , örendim .</sentence>
				<definiendum id="0">Canan</definiendum>
				<definiens id="0">a small child ) Teekkürler , örendim</definiens>
			</definition>
			<definition id="8">
				<sentence>( Kemal is a small child .</sentence>
				<definiendum id="0">Kemal</definiendum>
				<definiens id="0">a small child</definiens>
			</definition>
			<definition id="9">
				<sentence>Natural Language InterfaceTUJA TUJA ( Özcan , eker and Karadeniz 2004 ) is a natural language interface for generating Java source code and creating an object-oriented semantic network .</sentence>
				<definiendum id="0">Natural Language InterfaceTUJA TUJA</definiendum>
				<definiens id="0">a natural language interface for generating Java source code and creating an object-oriented semantic network</definiens>
			</definition>
			<definition id="10">
				<sentence>CYC : A Large-Scale Investment in Knowledge Infrastructure .</sentence>
				<definiendum id="0">CYC</definiendum>
			</definition>
</paper>

		<paper id="1118">
			<definition id="0">
				<sentence>Controlled-Language Authoring Technology ( CLAT ) CLAT has been developed to suit the need of some companies to automatically check their technical texts for general language and company speci c language conventions .</sentence>
				<definiendum id="0">Controlled-Language Authoring Technology ( CLAT ) CLAT</definiendum>
				<definiens id="0">texts for general language and company speci c language conventions</definiens>
			</definition>
			<definition id="1">
				<sentence>The terminology component matches the text against a terminology and abbreviation database where also term variants are detected Figure 1 : The Gendercheck Editor ( Carl et al. , 2004 ) .</sentence>
				<definiendum id="0">terminology component</definiendum>
				<definiens id="0">matches the text against a terminology and abbreviation database where also term variants</definiens>
			</definition>
			<definition id="2">
				<sentence>Grammar control checks the text for grammatical correctness and disambiguates multiple readings .</sentence>
				<definiendum id="0">Grammar control</definiendum>
				<definiens id="0">checks the text for grammatical correctness and disambiguates multiple readings</definiens>
			</definition>
</paper>

		<paper id="1196">
			<definition id="0">
				<sentence>The tutor checks the semantic content of the explanation and provides feedback on its correctness and completeness .</sentence>
				<definiendum id="0">tutor</definiendum>
				<definiens id="0">checks the semantic content of the explanation and provides feedback on its correctness and completeness</definiens>
			</definition>
			<definition id="1">
				<sentence>The chart parser is the main engine of the system .</sentence>
				<definiendum id="0">chart parser</definiendum>
			</definition>
			<definition id="2">
				<sentence>The logics system relies on a model of the domain of discourse , encoded as concepts , relations , and production rules , in the two knowledge bases .</sentence>
				<definiendum id="0">logics system</definiendum>
				<definiens id="0">relies on a model of the domain of discourse , encoded as concepts , relations , and production rules , in the two knowledge bases</definiens>
			</definition>
			<definition id="3">
				<sentence>Production rules perform additional inferences that are harder to encode into concepts and/or relations .</sentence>
				<definiendum id="0">Production rules</definiendum>
				<definiens id="0">perform additional inferences that are harder to encode into concepts and/or relations</definiens>
			</definition>
			<definition id="4">
				<sentence>A set of simplified knowledge base definitions necessary for building its representation , in Loom’s definitional language , is : ( defconcept Configuration : is-primitive ( : and Thing ( : all participant Thing ) ) ) ( defconcept Being &amp; Having : is-primitive ( : and Configuration ( : at-most 2 participant ) ) ) ( defconcept Ascription : is ( : and Being &amp; Having ( : exactly 1 attribuend ) ( : exactly 1 attribute ) ) ( defproduction ascription-production : when ( : detects ( Ascription x ) ) : do ( ( combine-instances ( x attribute ) ( x attribuend ) ) ) ) ( defconcept Geometry-Unit : is ( : and Unit ( : one-of ‘degree ‘radian ‘meter ‘foot ) ) ) ( defconcept Angle-Unit : is ( : and Geometry-Unit ( : one-of ‘degree ‘radian ) ) ) ( defconcept Geometry-Measure : is ( : and Measure ( : the unit Geometry-Unit ) ) ) ( defconcept Angle-Measure : is ( : and Geometry-Measure ( : the unit Angle-Unit ) ) ) ( defconcept Geometry-Object : is-primitive ( : and Spatial ( : all measure Geometry-Measure ) ) ) ( defproperty Right : domain Geometry-Object ) ( defconcept Angle : is-primitive ( : and Geometry-Object ( : the measure Angle-Measure ) ) ) ( defconcept Right-Angle : is ( : and Right Angle ) ) Figure 2 .</sentence>
				<definiendum id="0">) )</definiendum>
				<definiendum id="1">Configuration</definiendum>
				<definiendum id="2">Geometry-Unit (</definiendum>
				<definiendum id="3">Geometry-Measure</definiendum>
				<definiendum id="4">Geometry-Object )</definiendum>
				<definiendum id="5">Geometry-Object</definiendum>
				<definiens id="0">all participant Thing )</definiens>
				<definiens id="1">one-of ‘degree ‘radian ‘meter ‘foot</definiens>
				<definiens id="2">one-of ‘degree ‘radian )</definiens>
				<definiens id="3">the unit Angle-Unit</definiens>
			</definition>
			<definition id="5">
				<sentence>( defconcept Ascription-Location : is ( : and Ascription ( : at-least 1 belongs-to ) ) : implies ( : and ( : relates belongs-to attribuend belongs-to ) ( : relates belongs-to attribute belongs-to ) ) ) ) A similar case is that of using constructs specific to the domain of discourse .</sentence>
				<definiendum id="0">defconcept Ascription-Location</definiendum>
				<definiendum id="1">Ascription</definiendum>
				<definiens id="0">relates belongs-to attribuend belongs-to ) ( : relates belongs-to attribute belongs-to )</definiens>
			</definition>
			<definition id="6">
				<sentence>( tell ( : about being &amp; having-2 ( : create Ascription ) ( attribute sum-1 ) ( attribuend sum-1 ) ) All that is needed to achieve semantic equivalence is a reference resolution mechanism that identifies referents at the semantic level with their antecedents .</sentence>
				<definiendum id="0">Ascription )</definiendum>
			</definition>
			<definition id="7">
				<sentence>( defconcept Sum : is-primitive ( : and Measure ( : all term Measure ) ) ) ( defconcept Object-in-Location : is ( : and Object ( : some location Geometry-Object ) ) : implies Geometry-Object ) Disambiguation The presence of anaphora in students’ explanations results in cases where sentences with different sets of words are semantically equivalent .</sentence>
				<definiendum id="0">) ) ( defconcept Object-in-Location</definiendum>
				<definiens id="0">all term Measure )</definiens>
				<definiens id="1">some location Geometry-Object ) ) : implies Geometry-Object ) Disambiguation The presence of anaphora in students’ explanations results in cases where sentences with different sets of words are semantically equivalent</definiens>
			</definition>
			<definition id="8">
				<sentence>And third , a “weighted overlap” , which takes into account the relative semantic distance between different classes in assessing the match between two sets of categories .</sentence>
				<definiendum id="0">“weighted overlap”</definiendum>
			</definition>
			<definition id="9">
				<sentence>An Effective Meta-cognitive Strategy : Learning by Doing and Explaining with a Computer-Based Cognitive Tutor .</sentence>
				<definiendum id="0">Effective Meta-cognitive Strategy</definiendum>
			</definition>
			<definition id="10">
				<sentence>LCFlex : An efficient robust left-corner parser , User’s manual , University of Pittsburgh .</sentence>
				<definiendum id="0">LCFlex</definiendum>
				<definiens id="0">An efficient robust left-corner parser , User’s manual , University of Pittsburgh</definiens>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>The context-free tree grammars ( CFTGs ) were introduced by W. C. Rounds ( 1970 ) as tree generating systems , the definition of which is a direct generalization of context-free grammars ( CFGs ) from strings to rooted , ordered , labeled trees .</sentence>
				<definiendum id="0">context-free tree grammars ( CFTGs</definiendum>
			</definition>
			<definition id="1">
				<sentence>The rank of a nonterminal is a natural number assigned to each nonterminal by which the number of children of the node labeled by the nonterminal is fixed .</sentence>
				<definiendum id="0">rank of a nonterminal</definiendum>
				<definiens id="0">a natural number assigned to each nonterminal by which the number of children of the node labeled by the nonterminal is fixed</definiens>
			</definition>
			<definition id="2">
				<sentence>TAGs have been widely studied relating them to natural languages , and it was shown that TAGs have the same generative power of string languages as other formalisms for natural languages developed independently such as head grammars , combinatory categorial grammars and linear indexed grammars ( Vijay-Shanker and Weir , 1994 ) .</sentence>
				<definiendum id="0">Vijay-Shanker</definiendum>
				<definiens id="0">natural languages developed independently such as head grammars , combinatory categorial grammars and linear indexed grammars</definiens>
			</definition>
			<definition id="3">
				<sentence>Epsilon-freeness is a restriction on grammars that requires no use of epsilon-rules , that is , rules defined with the empty string .</sentence>
				<definiendum id="0">Epsilon-freeness</definiendum>
				<definiens id="0">the empty string</definiens>
			</definition>
			<definition id="4">
				<sentence>A ranked alphabet is a finite set of symbols in which each symbol is associated with a natural number , called the rank of a symbol .</sentence>
				<definiendum id="0">ranked alphabet</definiendum>
				<definiens id="0">a finite set of symbols in which each symbol is associated with a natural number , called the rank of a symbol</definiens>
			</definition>
			<definition id="5">
				<sentence>The definition of CFTGs is a direct generalization of context-free grammars ( CFGs ) .</sentence>
				<definiendum id="0">CFTGs</definiendum>
				<definiens id="0">a direct generalization of context-free grammars ( CFGs )</definiens>
			</definition>
			<definition id="6">
				<sentence>$ E D % ( D G α β x1 x2 x3 x1 ( 1 ) ( 2 ) ( 3 ) Figure 1 : Trees A context-free tree grammar ( CFTG ) is a fourtuple G = ( N ; ; P ; S ) , where : N and are disjoint ranked alphabets of nonterminals and terminals , respectively .</sentence>
				<definiendum id="0">context-free tree grammar</definiendum>
				<definiens id="0">a fourtuple G = ( N ; ; P ; S ) , where : N and are disjoint ranked alphabets of nonterminals and terminals , respectively</definiens>
			</definition>
			<definition id="7">
				<sentence>An ( n-step ) derivation is a finite sequence of trees 0 ; 1 ; : : : ; n 2 TN [ such that n 0 and tion 0 ; 1 ; : : : ; n , it is writen that 0 Gn ) n or The tree language generated by G is the set L ( G ) = f 2 T j S G ) g. The string language generated by G is LS ( G ) = fyield ( ) j 2 L ( G ) g. Note that LS ( G ) ( 0 f '' g ) .</sentence>
				<definiendum id="0">n-step ) derivation</definiendum>
				<definiens id="0">it is writen that 0 Gn ) n or The tree language generated by G is the set L ( G ) = f 2 T j S G ) g. The string language generated by G is LS ( G ) = fyield ( ) j 2 L ( G ) g. Note that LS ( G ) ( 0 f '' g</definiens>
			</definition>
			<definition id="8">
				<sentence>B ( C ( x ) ) with B ; C 2 E1 is in P , then add A 2 N1 to E1 .</sentence>
				<definiendum id="0">B ( C</definiendum>
				<definiens id="0">( x ) ) with B</definiens>
			</definition>
			<definition id="9">
				<sentence>The set of terminal is 0 = [ fcg , where c is a new symbol of rank 1 .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">a new symbol of rank 1</definiens>
			</definition>
			<definition id="10">
				<sentence>B ( C ) is in P. Therefore , A G ) B ( C ) G ) [ ] and yield ( [ ] ) = yield ( 0 [ 0 ] ) .</sentence>
				<definiendum id="0">B ( C )</definiendum>
				<definiens id="0">in P. Therefore , A G ) B ( C ) G ) [ ] and yield</definiens>
			</definition>
			<definition id="11">
				<sentence>B ( C ( x ) ) is in P. Therefore , A ( x ) G ) B ( C ( x ) ) G ) [ ] and yield ( [ [ `` ] ] ) = yield ( 0 [ 0 ] ) .</sentence>
				<definiendum id="0">B ( C ( x ) )</definiendum>
				<definiens id="0">A ( x ) G ) B ( C ( x ) ) G</definiens>
			</definition>
			<definition id="12">
				<sentence>In the case ( 1 ) , A ( x ) G ) B ( C ( x ) ) G ) [ ] = for some ; 2 T ( X1 ) such that B ( x ) G ) and C ( x ) G ) .</sentence>
				<definiendum id="0">C ( x ) G</definiendum>
				<definiens id="0">A ( x ) G ) B ( C ( x ) ) G</definiens>
			</definition>
</paper>

		<paper id="1181">
			<definition id="0">
				<sentence>The status of the dialogue itself is defined by circumscribed obligations to ground prior utterances , follow up open issues , and advance realworld negotiation ( Larsson and Traum , 2000 ) .</sentence>
				<definiendum id="0">status of the dialogue itself</definiendum>
				<definiens id="0">circumscribed obligations to ground prior utterances , follow up open issues , and advance realworld negotiation</definiens>
			</definition>
			<definition id="1">
				<sentence>This is the interpretation FIGLET builds ; to comply , FIGLET draws the circle an arbitrary but representative possible size .</sentence>
				<definiendum id="0">FIGLET</definiendum>
				<definiens id="0">draws the circle an arbitrary but representative possible size</definiens>
			</definition>
			<definition id="2">
				<sentence>Old standards serve as defaults in interpreting subsequent utterances .</sentence>
				<definiendum id="0">Old standards</definiendum>
				<definiens id="0">serve as defaults in interpreting subsequent utterances</definiens>
			</definition>
			<definition id="3">
				<sentence>In understanding the instruction , FIGLET applies all these contextual constraints simultaneously .</sentence>
				<definiendum id="0">FIGLET</definiendum>
				<definiens id="0">applies all these contextual constraints simultaneously</definiens>
			</definition>
			<definition id="4">
				<sentence>In FIGLET , we record the semantics of user instructions using constraints , or logical conjunctions of open atomic formulas , to represent the contextual requirements that utterances impose ; we view these constraints as presuppositions that speakers make in using the utterance .</sentence>
				<definiendum id="0">presuppositions</definiendum>
				<definiens id="0">the semantics of user instructions using constraints , or logical conjunctions of open atomic formulas , to represent the contextual requirements that utterances impose</definiens>
			</definition>
			<definition id="5">
				<sentence>COLLAGEN : applying collaborative discourse theory to human-computer interaction .</sentence>
				<definiendum id="0">COLLAGEN</definiendum>
				<definiens id="0">applying collaborative discourse theory to human-computer interaction</definiens>
			</definition>
</paper>

		<paper id="1170">
			<definition id="0">
				<sentence>The first part of the response There are no bungalows in Meg`eve is the direct response , which corrects the user false presupposition , while the remainder of the response reflects the cooperative know-how of the responder .</sentence>
				<definiendum id="0">Meg`eve</definiendum>
				<definiens id="0">corrects the user false presupposition , while the remainder of the response reflects the cooperative know-how of the responder</definiens>
			</definition>
			<definition id="1">
				<sentence>Cooperative know-how involves several forms of responses that include relaxations , intensional calculus , expression of restrictions , of warnings and conditional responses ( Benamara et al. 2004 ) .</sentence>
				<definiendum id="0">Cooperative know-how</definiendum>
				<definiens id="0">involves several forms of responses that include relaxations , intensional calculus , expression of restrictions , of warnings and conditional responses</definiens>
			</definition>
			<definition id="2">
				<sentence>Lexicalisation is the operation that associates a word or an expression to a concept .</sentence>
				<definiendum id="0">Lexicalisation</definiendum>
				<definiens id="0">the operation that associates a word or an expression to a concept</definiens>
			</definition>
			<definition id="3">
				<sentence>Our ontology is a synthesis of two existing French ontologies , that we customized : TourinFrance ( www.tourinfrance.net ) and the bilingual ( French and English ) thesaurus of tourism and leisure activities ( www.iztzg.hr/indokibiblioteka/THESAUR.PDF ) which includes 2800 French terms .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">a synthesis of two existing French ontologies , that we customized : TourinFrance ( www.tourinfrance.net ) and the bilingual ( French and English ) thesaurus of tourism and leisure activities ( www.iztzg.hr/indokibiblioteka/THESAUR.PDF ) which includes 2800 French terms</definiens>
			</definition>
			<definition id="4">
				<sentence>cooperative QA corpora To carry out our study , we considered three typical sources of cooperative discourses : Frequently Asked Questions ( FAQ ) , Forums , and email question-answer pairs ( EQAP ) , these latter obtained by sending ourselves emails to relevant services ( e.g. for tourism : tourist offices , airlines , hotels ) .</sentence>
				<definiendum id="0">email question-answer pairs</definiendum>
				<definiens id="0">sources of cooperative discourses : Frequently Asked Questions ( FAQ ) , Forums , and</definiens>
			</definition>
			<definition id="5">
				<sentence>We have the following main subtypes : SUB ( a ) lower-level elements in an ontology ( possibly terminal elements ) , SUB ( b ) focuses on sub-events or sub-activities of the larger event lexicalised in the question , or ( simple ) procedure description instead of the procedure name , and SUB ( c ) subtyping via modification ( official guide , mountain guide ) .</sentence>
				<definiendum id="0">SUB</definiendum>
				<definiendum id="1">SUB</definiendum>
				<definiendum id="2">SUB ( c</definiendum>
				<definiens id="0">a ) lower-level elements in an ontology ( possibly terminal elements )</definiens>
			</definition>
			<definition id="6">
				<sentence>• Generalizations ( GEN ) : their main use is in intensional answers , where generalizations are realized to make the answer more compact .</sentence>
				<definiendum id="0">GEN</definiendum>
				<definiens id="0">their main use is in intensional answers , where generalizations are realized to make the answer more compact</definiens>
			</definition>
			<definition id="7">
				<sentence>Q1-R1 have several layers of lexicalisations : guided tour is a subtype of visit , guided tours at fixed hours 11AM and 3 PM is a subtype of visit hours , while building is a generalization of castle , necessary to allow for the reference to town hall , since building is the least upper bound in the ontology for castle and town hall .</sentence>
				<definiendum id="0">PM</definiendum>
				<definiens id="0">a subtype of visit hours</definiens>
				<definiens id="1">a generalization of castle</definiens>
			</definition>
			<definition id="8">
				<sentence>We basically have four situations : • Focus adequate w.r.t. the response : both subtrees coincide , or ST2 is a proper subtree of ST1 , ( Q : what kind of tourist accommodation in Chamonix ?</sentence>
				<definiendum id="0">ST2</definiendum>
				<definiens id="0">a proper subtree of ST1</definiens>
			</definition>
			<definition id="9">
				<sentence>The reasoning component produces a logical formula , from which the NLG functions ( lexicalisation , but also aggregation and microplanning ) operate .</sentence>
				<definiendum id="0">reasoning component</definiendum>
			</definition>
			<definition id="10">
				<sentence>Minock M , Chu W , Yang H , Chiang K , Chow , G and Larson , C , CoBase : A Scalable and Extensible Cooperative Information System .</sentence>
				<definiendum id="0">CoBase</definiendum>
				<definiens id="0">A Scalable and Extensible Cooperative Information System</definiens>
			</definition>
</paper>

		<paper id="1179">
			<definition id="0">
				<sentence>They define a frame element group ( FEG ) as a set of frame element roles present in a particular sentence .</sentence>
				<definiendum id="0">FEG</definiendum>
				<definiens id="0">a set of frame element roles present in a particular sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>We model the probability of a class c given a vector of features x according to the ME formulation below : ) ] , ( exp [ 1 ) | ( 0 xcf Z xcp ii n i x λ = Σ= Here x Z is normalization constant , ) , ( xcf i is a feature function which maps each class and vector element to a binary value , n is the total number of feature functions , and i λ is a weight for the feature function .</sentence>
				<definiendum id="0">xcf i</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">i λ</definiendum>
				<definiens id="0">a feature function which maps each class and vector element to a binary value</definiens>
				<definiens id="1">the total number of feature functions , and</definiens>
				<definiens id="2">a weight for the feature function</definiens>
			</definition>
			<definition id="2">
				<sentence>• Previous class ( c_n ) : The class information of the n th -previous constituent ( target , frame element , or none ) is used to exploit the dependency between constituents .</sentence>
				<definiendum id="0">Previous class</definiendum>
				<definiens id="0">used to exploit the dependency between constituents</definiens>
			</definition>
			<definition id="3">
				<sentence>x t } ) is a feature function which maps each output and all candidates’ feature sets to a binary value , n is the total number of feature functions , and λ i is the weight for a given feature function .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">λ i</definiendum>
				<definiens id="0">a feature function which maps each output and all candidates’ feature sets to a binary value</definiens>
			</definition>
			<definition id="4">
				<sentence>| ( * ) | ( * ) | ( ) | ( ferpsegfepssegpsrp = where s is a given sentence , seg is a segmentation , fe is a frame element identification , and r is the final semantic role tagging .</sentence>
				<definiendum id="0">s</definiendum>
				<definiendum id="1">seg</definiendum>
				<definiendum id="2">fe</definiendum>
				<definiendum id="3">r</definiendum>
				<definiens id="0">a given sentence</definiens>
				<definiens id="1">a frame element identification</definiens>
			</definition>
			<definition id="5">
				<sentence>Re-ranking : apply ME re-ranking and choose the best one from long lists Final Output Agent ( He ) , Path ( over the balcony ) Fig .</sentence>
				<definiendum id="0">Re-ranking</definiendum>
				<definiens id="0">apply ME re-ranking and choose the best one from long lists Final Output Agent ( He ) , Path ( over the balcony ) Fig</definiens>
			</definition>
			<definition id="6">
				<sentence>Re-ranking performance for test set To improve our re-ranker , more features regarding these problems should be added , and a more principled method to obtain the probability of segmenations , p ( seg ) in Sectioin 5.1 , needs to be investigated .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">needs to be investigated</definiens>
			</definition>
</paper>

		<paper id="1097">
			<definition id="0">
				<sentence>Amalgam has an explicit ordering stage that determines the order of constituents and their daughters .</sentence>
				<definiendum id="0">Amalgam</definiendum>
			</definition>
			<definition id="1">
				<sentence>An ordered tree π contains non-terminal constituents C , each of which is the parent of an ordered sequence of daughters ( 1 , ... , n D D ) , one of which is the head constituent H. 2 Given an ordered tree π , the value of the function _ ( ) unordered tree π is an unordered tree ρ corresponding to π that contains a constituent B for each C in π , such that ( ) ( ) 1 _ ( { , ... , } n unordered set daughters Cdaughters B DD = = again with i HD= for some i in ( ) 1 .</sentence>
				<definiendum id="0">π</definiendum>
				<definiens id="0">the head constituent H. 2 Given an ordered tree π , the value of the function _ ( ) unordered tree</definiens>
				<definiens id="1">an unordered tree ρ corresponding to π that contains a constituent B for each C in π</definiens>
			</definition>
			<definition id="2">
				<sentence>With this extension , a model of Markov 3 A “Markov grammar” is a model of constituent structure that starts at the root of the tree and assigns probability to the expansion of a non-terminal one daughter at a time , rather than as entire productions ( Charniak , 1997 &amp; 2000 ) .</sentence>
				<definiendum id="0">“Markov grammar”</definiendum>
				<definiens id="0">a model of constituent structure that starts at the root of the tree and assigns probability to the expansion of a non-terminal one daughter at a time</definiens>
			</definition>
			<definition id="3">
				<sentence>Free variable j represents an index on unordered daughters in i β , as does k. ( ) ( ) 1 , , , , , , i jjji jj ji k kki k P yes d PDd Pyesd β σψ ψ σψ = =Γ Γ= =Γ ∑ ( 8 ) This turns out to be the decision tree analogue of a Maximum Entropy Markov Model ( MEMM ) ( McCallum et al. , 2000 ) , which we can refer to as a DTMM .</sentence>
				<definiendum id="0">Free variable j</definiendum>
				<definiens id="0">the decision tree analogue of a Maximum Entropy Markov Model ( MEMM )</definiens>
			</definition>
			<definition id="4">
				<sentence>The total score for the hypothesis tree ˆπ is the mean of the per-constituent edit distances .</sentence>
				<definiendum id="0">total score</definiendum>
				<definiens id="0">the mean of the per-constituent edit distances</definiens>
			</definition>
			<definition id="5">
				<sentence>The PTB to DSIF transformation pipeline includes the following stages , inspired by Langkilde-Geary’s ( 2002b ) description : A. Deserialize the tree B. Label heads , according to Charniak’s head labeling rules ( Charniak , 2000 ) C. Remove empty nodes and flatten any remaining empty non-terminals D. Relabel heads to conform more closely to the head conventions of NLPWin E. Label with logical roles , inferred from PTB functional roles F. Flatten to maximal projections of heads ( MPH ) , except in the case of conjunctions G. Flatten non-branching non-terminals H. Perform dictionary look-up and morphological analysis I. Introduce structure for material between paired delimiters and for any coordination not already represented in the PTB J. Remove punctuation K. Remove function words L. Map the head of each maximal projection to a dependency node , and map the head’s modifiers to the first node’s dependents , thereby forming a complete dependency tree .</sentence>
				<definiendum id="0">MPH</definiendum>
				<definiens id="0">the head conventions of NLPWin E. Label with logical roles , inferred from PTB functional roles F. Flatten to maximal projections of heads</definiens>
				<definiens id="1">Remove punctuation K. Remove function words L. Map the head of each maximal projection to a dependency node</definiens>
			</definition>
			<definition id="6">
				<sentence>To train the order models , we use a set of 10,000 sentences drawn from the standard PTB training set , namely sections 02–21 from the Wall Street Journal portion of the PTB ( the full set contains approx .</sentence>
				<definiendum id="0">PTB</definiendum>
				<definiens id="0">the full set contains approx</definiens>
			</definition>
			<definition id="7">
				<sentence>Decision trees are trained for each of five constituent types characterized by their head labels : adjectival , nominal , verbal , conjunctions ( coordinated material ) , and other constituents not already covered .</sentence>
				<definiendum id="0">Decision trees</definiendum>
				<definiens id="0">adjectival , nominal , verbal , conjunctions ( coordinated material )</definiens>
			</definition>
			<definition id="8">
				<sentence>Our DSIF test set consists of the blind test set ( section 23 ) of the WSJ portion of the PTB .</sentence>
				<definiendum id="0">DSIF test set</definiendum>
				<definiens id="0">consists of the blind test set ( section 23 ) of the WSJ portion of the PTB</definiens>
			</definition>
			<definition id="9">
				<sentence>Amalgam : A machine-learned generation module .</sentence>
				<definiendum id="0">Amalgam</definiendum>
				<definiens id="0">A machine-learned generation module</definiens>
			</definition>
</paper>

		<paper id="1164">
			<definition id="0">
				<sentence>On the other hand , multi-lingual ontology is very important for natural language processing , such as machine translation ( MT ) , web mining ( Oyama et al. 2004 ) and cross language information retrieval ( CLIR ) .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">machine translation ( MT ) , web mining ( Oyama et al. 2004 ) and cross language information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>Generally , a multilingual ontology maps the keyword set of one language to another language , or compute the cooccurrence of the words among languages .</sentence>
				<definiendum id="0">multilingual ontology</definiendum>
				<definiens id="0">maps the keyword set of one language to another language</definiens>
			</definition>
			<definition id="2">
				<sentence>The final ontology is a merged version of the original ontologies .</sentence>
				<definiendum id="0">final ontology</definiendum>
			</definition>
			<definition id="3">
				<sentence>The measure is defined as : ( ) ( ) ( ) ( ) [ ] min , , , max0 , 0,1 min , ij ij ij ij LL edLL SM L L LL ⎛⎞ − ⎜⎟ ≡∈ ⎝⎠ ( 1 ) where ( ) SM null denotes the lexicon similarity function , ( ) ed null is the Levensthein edit distance function defined in ( Levensthein .</sentence>
				<definiendum id="0">SM L L LL</definiendum>
				<definiendum id="1">SM null</definiendum>
				<definiens id="0">: ( ) ( ) ( ) ( ) [ ] min , , , max0 , 0,1 min , ij ij ij ij LL edLL</definiens>
			</definition>
			<definition id="4">
				<sentence>This paper defines two measures , taxonomic relation and non-taxonomic relation , as the quantitative metrics to evaluate the ontology .</sentence>
				<definiendum id="0">non-taxonomic relation</definiendum>
				<definiens id="0">the quantitative metrics to evaluate the ontology</definiens>
			</definition>
			<definition id="5">
				<sentence>First , the Sinorama ( Sinorama 2001 ) database is adopted as the bilingual language parallel corpus to compute the conditional probability of the words in WordNet , given the words in HowNet .</sentence>
				<definiendum id="0">Sinorama</definiendum>
				<definiens id="0">the bilingual language parallel corpus to compute the conditional probability of the words in WordNet , given the words in HowNet</definiens>
			</definition>
			<definition id="6">
				<sentence>The purpose of this approach is to increase the relation and structural information coverage by aligning the above two languagedependent ontologies , WordNet and HowNet , with their semantic features .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">to increase the relation and structural information coverage by aligning the above two languagedependent ontologies</definiens>
			</definition>
			<definition id="7">
				<sentence>Synonym pruning is an effective alternative to word sense disambiguation .</sentence>
				<definiendum id="0">Synonym pruning</definiendum>
				<definiens id="0">an effective alternative to word sense disambiguation</definiens>
			</definition>
			<definition id="8">
				<sentence>For the target ontology , the factor vectors for normalization is { } 12345678 , , , , , , , T TTTTTTTT NF nf nf nf nf nf nf nf nf= , and for the benchmark ontology is { } 123456789 , , , , , , , , B BBBBBBBBB NF nfnfnfnfnfnfnfnfnf= where o i nf is the normalization factor for the i-th concept of the ontology O. It is defined as the reciprocal of the frequency in the vertex list set .</sentence>
				<definiendum id="0">i nf</definiendum>
				<definiens id="0">the factor vectors for normalization is { } 12345678 , , , , , , , T TTTTTTTT NF nf nf nf nf nf nf nf nf= , and for the benchmark ontology is { } 123456789 , , , , , , , , B BBBBBBBBB NF nfnfnfnfnfnfnfnfnf= where o</definiens>
			</definition>
			<definition id="9">
				<sentence>m and n are the numbers of the concepts in the vertex lists of the target ontology and the bench mark ontology , respectively .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the numbers of the concepts in the vertex lists of the target ontology and the bench mark ontology</definiens>
			</definition>
			<definition id="10">
				<sentence>The lexicon similarity of set can be defined as the following equation : ( , ) Words defined in the and Words defined in the or j i j i j i B T lexicon s t B T st B T st Sim V V VV VV = ( 12 ) Therefore , the evaluation of the non-taxonomic relation is defined as ( ) 11 , 1 ( , ) j i non taxonomic T B pq B T lexicon s t ij st Sim O O Sim V V pq − == = × ∑∑∑∑ ( 13 ) Using the benchmark ontology and evaluation metrics described in previous sections , the evaluation results are shown in Table 1 .</sentence>
				<definiendum id="0">lexicon similarity of set</definiendum>
				<definiens id="0">the following equation : ( , ) Words defined in the and Words defined in the or j i j i j i B T lexicon s t B T st B T st Sim V V VV VV = ( 12 ) Therefore , the evaluation of the non-taxonomic relation is defined as ( ) 11 , 1 ( , ) j i non taxonomic T B pq B T lexicon s t ij st Sim O O Sim V V pq − == = × ∑∑∑∑ ( 13 ) Using the benchmark ontology and evaluation metrics described in previous sections</definiens>
			</definition>
			<definition id="11">
				<sentence>In this approach , a bilingual ontology is developed from two well established language-dependent knowledge bases , WordNet and HowNet according to the co-occurrence of the words in the parallel bilingual corpus .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">developed from two well established language-dependent knowledge bases</definiens>
			</definition>
</paper>

		<paper id="1129">
			<definition id="0">
				<sentence>SimFinder implements an incremental approach to clustering .</sentence>
				<definiendum id="0">SimFinder</definiendum>
				<definiens id="0">implements an incremental approach to clustering</definiens>
			</definition>
			<definition id="1">
				<sentence>Each line consists of two sentence ids ( P [ sent id ] ) and their simval .</sentence>
				<definiendum id="0">line</definiendum>
				<definiens id="0">consists of two sentence ids ( P [ sent id ] ) and their simval</definiens>
			</definition>
</paper>

		<paper id="1078">
			<definition id="0">
				<sentence>Information Extraction ( IE ) aims to extract specific information items of interest from free or semistructured texts , and pattern rule induction is one of the most common techniques for IE tasks ( Muslea , 1999 ) .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE )</definiendum>
			</definition>
			<definition id="1">
				<sentence>Given a tagged instance , we consider the left and right k chunks around the tagged slot as the context : &lt; c -k &gt; … &lt; c -2 &gt; &lt; c -1 &gt; tagged_slot &lt; c +1 &gt; &lt; c +2 &gt; … &lt; c +k &gt; Here &lt; c i &gt; { i=-k to +k } represents the contextual chunks ( or slots ) of the tagged slot , where k is the number of contextual slots considered .</sentence>
				<definiendum id="0">k</definiendum>
				<definiens id="0">the contextual chunks ( or slots ) of the tagged slot</definiens>
				<definiens id="1">the number of contextual slots considered</definiens>
			</definition>
			<definition id="2">
				<sentence>As a result , we obtain a virtual vector Pa representing the contextual soft pattern rule as : &lt; Slot -k , … , Slot -2 , Slot -1 , Slot 0 , Slot 1 , Slot 2 , … , Slot k : Pa &gt; ( 2 ) where Slot i is a vector of tokens occurring in that slot with their probabilities of occurrence : &lt; ( token i1 , weight i1 ) , ( token i2 , weight i2 ) … .</sentence>
				<definiendum id="0">Slot k</definiendum>
				<definiendum id="1">Slot i</definiendum>
				<definiens id="0">a virtual vector Pa representing the contextual soft pattern rule as : &lt; Slot -k , … , Slot -2 , Slot -1 , Slot 0 , Slot 1</definiens>
			</definition>
			<definition id="3">
				<sentence>( token im , weight im ) : Slot i &gt; ( 3 ) Here , token ij denotes any word , punctuation , syntactic or semantic tag contained in Slot i , and weight ij gives the proportion of occurrences of the j th token to the i th slot .</sentence>
				<definiendum id="0">token ij</definiendum>
				<definiens id="0">any word , punctuation , syntactic or semantic tag contained in Slot i , and weight ij gives the proportion of occurrences of the j th token to the i th slot</definiens>
			</definition>
			<definition id="4">
				<sentence>GRID is a supervised covering algorithm .</sentence>
				<definiendum id="0">GRID</definiendum>
				<definiens id="0">a supervised covering algorithm</definiens>
			</definition>
			<definition id="5">
				<sentence>Given the cluster of training instances for a specific slot type , GRID aligns all the instances according to the central slot ( Slot 0 ) as is done in soft pattern rules .</sentence>
				<definiendum id="0">GRID</definiendum>
				<definiens id="0">aligns all the instances according to the central slot ( Slot 0</definiens>
			</definition>
			<definition id="6">
				<sentence>We use a modified Laplacian expected error ( Soderland , 1999 ) to define the quality of the rule as follows : 17.0 1 ) ) ( ( 21 +×++ + = kkk k k ppn n frLaplacian where p k1 denotes the number of instances covered by rule r k ( f ) in the manually annotated set , and p k2 denotes the number of instances covered by the rule r k ( f ) in the automatically annotated set .</sentence>
				<definiendum id="0">k1</definiendum>
				<definiens id="0">a modified Laplacian expected error ( Soderland , 1999 ) to define the quality of the rule as follows : 17.0 1 ) ) ( ( 21 +×++ + = kkk k k ppn n frLaplacian where p</definiens>
				<definiens id="1">the number of instances covered by rule r k ( f ) in the manually annotated set , and p k2 denotes the number of instances covered by the rule r k ( f ) in the automatically annotated set</definiens>
			</definition>
</paper>

		<paper id="1053">
			<definition id="0">
				<sentence>MultiSemCor is an English/Italian parallel corpus which is being created on the basis of the English SemCor corpus and where the texts are aligned at the word level and semantically annotated with a shared inventory of senses .</sentence>
				<definiendum id="0">MultiSemCor</definiendum>
				<definiens id="0">an English/Italian parallel corpus which is being created on the basis of the English SemCor corpus and where the texts are aligned at the word level and semantically annotated with a shared inventory of senses</definiens>
			</definition>
			<definition id="1">
				<sentence>The word aligner used in the project is KNOWA ( KNOwledge-intensive Word Aligner ) , an English/Italian word aligner , developed at ITC-irst , which relies mostly on information contained in the Collins bilingual dictionary , available in electronic format .</sentence>
				<definiendum id="0">KNOWA</definiendum>
				<definiens id="0">an English/Italian word aligner , developed at ITC-irst , which relies mostly on information contained in the Collins bilingual dictionary , available in electronic format</definiens>
			</definition>
			<definition id="2">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="3">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="4">
				<sentence>( 1998 ) WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="5">
				<sentence>MultiWordNet : developing an aligned multilingual database .</sentence>
				<definiendum id="0">MultiWordNet</definiendum>
				<definiens id="0">developing an aligned multilingual database</definiens>
			</definition>
</paper>

		<paper id="1115">
			<definition id="0">
				<sentence>Mutual information ( MI ) is an informationtheoretic measure of association between two words , widely used in statistical NLP .</sentence>
				<definiendum id="0">Mutual information</definiendum>
				<definiens id="0">an informationtheoretic measure of association between two words</definiens>
			</definition>
			<definition id="1">
				<sentence>Pointwise MI between class c and feature f measures how much information presence of f contains about c : ) ( ) ( ) , ( log ) , ( cPfP cfPcfMI = ( 1 ) Gain Ratio ( GR ) is a normalized variant of Information Gain ( IG ) , introduced into machine learning from information theory ( Quinlan , 1993 ) .</sentence>
				<definiendum id="0">Gain Ratio ( GR )</definiendum>
			</definition>
			<definition id="2">
				<sentence>IG measures the number of bits of information obtained about presence and absence of a class by knowing the presence or absence of the feature1 : ∑ ∑ ∈ ∈ = } , { } , { ) ( ) ( ) , ( log ) , ( ) , ( ccd ffg dPgP dgPdgPcfIG ( 2 ) Gain Ratio aims to overcome one disadvantage of IG which is the fact that IG grows not only with the increase of dependence between f and c , but also with the increase of the entropy of f. That is why features with low entropy receive smaller IG weights although they may be strongly correlated with a class .</sentence>
				<definiendum id="0">IG</definiendum>
				<definiens id="0">measures the number of bits of information obtained about presence and absence of a class by knowing the presence or absence of the feature1 : ∑ ∑ ∈ ∈ = } , { }</definiens>
				<definiens id="1">why features with low entropy receive smaller IG weights although they may be strongly correlated with a class</definiens>
			</definition>
			<definition id="3">
				<sentence>GR removes this factor by normalizing IG by the entropy of the class : ∑ ∈ −= } , { ) ( log ) ( ) , ( ) , ( ffg gPgP cgIGcfGR ( 3 ) Odds Ratio ( OR ) is used in information retrieval to rank documents according to their relevance on the basis of association of their features with a set of positive documents .</sentence>
				<definiendum id="0">GR</definiendum>
				<definiens id="0">removes this factor by normalizing IG by the entropy of the class : ∑ ∈ −= }</definiens>
				<definiens id="1">used in information retrieval to rank documents according to their relevance on the basis of association of their features with a set of positive documents</definiens>
			</definition>
			<definition id="4">
				<sentence>TSL2 is the proportion of instances which possess feature f to the total number of instances in c : | } { | | } | { | ) , ( 2 cn nfcncfTSL ∈ ∈∈= ( 7 ) Table 1 illustrates the 10 highest scored features according to five supervised functions for the class { ambulance , car , bike , coupe , jeep , motorbike , taxi , truck } ( estimated from the BNC cooccurrence data described in Section 4 ) .</sentence>
				<definiendum id="0">TSL2</definiendum>
				<definiens id="0">the proportion of instances which possess feature f to the total number of instances in c : | } { | | } | { |</definiens>
				<definiens id="1">estimated from the BNC cooccurrence data described in Section 4 )</definiens>
			</definition>
			<definition id="5">
				<sentence>Jensen-Shannon Divergence measures the ( dis ) similarity between a train instance n and test instance m as : ) ] || ( ) || ( [ 21 ) , ( , , mnmn avgmDavgnDmnJ += ( 8 ) where D is the Kullback Leibler divergence between two probability distributions x and y : ∑ ∈= Vv yvp xvpxvpyxD ) | ( ) | ( log ) | ( ) || ( ( 9 ) and avgn , m is the average of the distributions of n and m. In testing each weighting method , we experimented with k = 1 , 3 , 5 , 7 , 10 , 15 , 20 , 30 , 50 , 70 , and 100 in order to take into account the fact that feature weighting typically changes the optimal value of k. The results for kNN reported below indicate the highest effectiveness measures obtained among all k in a particular test .</sentence>
				<definiendum id="0">Jensen-Shannon Divergence</definiendum>
				<definiendum id="1">D</definiendum>
				<definiens id="0">measures the ( dis ) similarity between a train instance n and test instance m as : ) ] ||</definiens>
			</definition>
			<definition id="6">
				<sentence>The Naïve Bayes algorithm classifies a test instance m by finding a class c that maximizes p ( c|Vm∈m ) .</sentence>
				<definiendum id="0">Naïve Bayes algorithm</definiendum>
				<definiens id="0">classifies a test instance m by finding a class c that maximizes p ( c|Vm∈m )</definiens>
			</definition>
			<definition id="7">
				<sentence>The Naïve Bayes classifier adopted in the study was the binary independence model , which estimates p ( v|ci ) assuming the binomial distribution of features across classes .</sentence>
				<definiendum id="0">Naïve Bayes classifier</definiendum>
				<definiens id="0">estimates p ( v|ci ) assuming the binomial distribution of features across classes</definiens>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>A dialogue manager provides the decision making at the heart of a spoken dialogue system .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">provides the decision making at the heart of a spoken dialogue system</definiens>
			</definition>
			<definition id="1">
				<sentence>Our DM operates within the DARPA 1 Communicator architecture , which is based on the Galaxy hub – a software router developed by the Spoken Language Systems group at MIT ( www.sls.csail.mit.edu/sls/technologies/galaxy.shtml ) and subsequently released as an open source package in collaboration with the MITRE Corporation ( fofoca.mitre.org ) .</sentence>
				<definiendum id="0">DM</definiendum>
			</definition>
			<definition id="2">
				<sentence>The frames consist of Attribute objects , each of which stores : y the type and elicited value of a single piece of information ( datum ) ; y the confirmation status of the datum ( e.g. new_for_system ) ; y the level to which the datum has been confirmed ( through repetition , or by the user’s affirmative response to a system prompt – the level is represented by a simple numeric ‘peg’ ) ; y and the system intention regarding the datum ( e.g. implicitly confirm new information ; explicitly confirm information that has been negated ; ask the user to specify information that is still required ) ( Heisterkamp and McGlashan , 1996 ) .</sentence>
				<definiendum id="0">frames</definiendum>
				<definiens id="0">consist of Attribute objects , each of which stores : y the type and elicited value of a single piece of information ( datum ) ; y the confirmation status of the datum ( e.g. new_for_system ) ; y the level to which the datum has been confirmed ( through repetition , or by the user’s affirmative response to a system prompt – the level is represented by a simple numeric ‘peg’ ) ; y and the system intention regarding the datum ( e.g. implicitly confirm new information ; explicitly confirm information that has been negated ; ask the user to specify information that is still required )</definiens>
			</definition>
			<definition id="3">
				<sentence>Typically the expert rule sequences will be of one of two kinds : y ‘user-focussed rules’ , which determine the agent’s reaction to particular combinations of information supplied by the user – must the system now ask a follow-up question , must it perform a database look-up , or can it conclude a transaction ?</sentence>
				<definiendum id="0">y ‘user-focussed rules’</definiendum>
				<definiens id="0">determine the agent’s reaction to particular combinations of information supplied by the user</definiens>
			</definition>
			<definition id="4">
				<sentence>-contains a DomainSpotter instances to exercise highlevel control over experts .</sentence>
				<definiendum id="0">DomainSpotter</definiendum>
				<definiens id="0">instances to exercise highlevel control over experts</definiens>
			</definition>
			<definition id="5">
				<sentence>To begin the dialogue , in order to identify the most appropriate ‘handling agent’ , the DomainSpotter supplies each service agent with the output of the semantic parse that represents the user’s utterance .</sentence>
				<definiendum id="0">DomainSpotter</definiendum>
				<definiens id="0">supplies each service agent with the output of the semantic parse that represents the user’s utterance</definiens>
			</definition>
			<definition id="6">
				<sentence>As it attempts to find an initial handling agent , the DomainSpotter considers only service agents ( like AccommodationExpert or CinemaExpert ) and not support agents ( like CreditCardExpert ) .</sentence>
				<definiendum id="0">CinemaExpert</definiendum>
				<definiens id="0">attempts to find an initial handling agent , the DomainSpotter considers only service agents ( like AccommodationExpert or</definiens>
			</definition>
			<definition id="7">
				<sentence>Please wait ... MESSAGE : process accommodation booking MESSAGE : GIVEN AccoType [ HOTEL ] AccoClass [ three-star ] Location [ BELFAST ] DateFrom [ 2004-08-15 ] DateTo [ 2004-08-20 ] MESSAGE : database enquiry initiated The AccommodationExpert uses the generic confirmation strategies that it has inherited from the DiscourseManager to implicitly confirm new values , and it uses its own domain-specific rules to initiate a database lookup that will retrieve names of hotels that match the user’s criteria .</sentence>
				<definiendum id="0">MESSAGE</definiendum>
				<definiendum id="1">AccommodationExpert</definiendum>
				<definiens id="0">uses the generic confirmation strategies that it has inherited from the DiscourseManager to implicitly confirm new values , and it uses its own domain-specific rules to initiate a database lookup that will retrieve names of hotels that match the user’s criteria</definiens>
			</definition>
			<definition id="8">
				<sentence>The Queen’s Communicator : an Object-Oriented Dialogue Manager .</sentence>
				<definiendum id="0">Queen’s Communicator</definiendum>
				<definiens id="0">an Object-Oriented Dialogue Manager</definiens>
			</definition>
</paper>

		<paper id="1150">
			<definition id="0">
				<sentence>OntoLearn is an ontology population method based on text mining and machine learning techniques .</sentence>
				<definiendum id="0">OntoLearn</definiendum>
			</definition>
			<definition id="1">
				<sentence>For example , given the list of complex MWEs securities portfolio , investment portfolio , real-estate portfolio , junk-bond portfolio , diversified portfolio , stock portfolio , bond portfolio , loan portfolio , the following list of term components is created : T= [ security , investment , real-estate , estate , bond , junk-bond , diversified , stock , portfolio , loan ] Relevant pattern types are described by a context free grammar G. An example of rule in G is the following ( S 1 S 2 and S are concepts , i.e. synsets in WordNet ) : Rule Name : gloss+hyperonymy/meronymy ( S 1 , S 2 ) : Def : : SynsetsG∈∃ S 1 gloss  →    S and there is a hyperonymy/meronymy path between S and S 2 For instance , in railways company , the gloss of railway # 1 contains the word organization , and there is an hyperonymy path of length 2 between company # 1 and organization # 1 .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">T= [ security , investment , real-estate , estate , bond , junk-bond , diversified , stock , portfolio , loan ] Relevant pattern types are described by a context free grammar G. An example of rule in G is the following ( S 1 S 2 and</definiens>
			</definition>
			<definition id="2">
				<sentence>The weight function is given by : ) _ 1 ( ) ( ) 1 ( j jjj patternlength patternweight βα += where α j is the weight of rule j in G , and the second addend is a smoothing parameter inversely proportional to the length of the matching pattern ( e.g. 2 in the previous example , since 2 is the minimal length of the rule , and the actual length of the pattern is 3 ) .</sentence>
				<definiendum id="0">weight function</definiendum>
				<definiendum id="1">α j</definiendum>
			</definition>
			<definition id="3">
				<sentence>meeting # 1 use ←    ro om # 1 bond # 2 const _ part ←       market # 1 c om puter # 1 product ←      com pany # 1 We represented training instances as pairs of concepts annotated with the appropriate conceptual relation , e.g. : [ ( computer # 1 , maker # 3 ) , Product ] Each concept is in turn represented by a featurevector where attributes are the concept’s hyperonyms in WordNet , e.g. : ( computer # 1 , maker # 3 ) : ( ( computer # 1 , machine # 1 , device # 1 , instrumentality # 3 ) , ( maker # 3 , business # 1 , enterprise # 2 , organization # 1 ) ) This section provides a quantitative evaluation of OntoLearns main algorithms .</sentence>
				<definiendum id="0">attributes</definiendum>
				<definiens id="0">pairs of concepts annotated with the appropriate conceptual relation</definiens>
			</definition>
			<definition id="4">
				<sentence>Membership provides special advantages , particularly a national reservation system .</sentence>
				<definiendum id="0">Membership</definiendum>
			</definition>
			<definition id="5">
				<sentence>Collocational Information in the FrameNet Database .</sentence>
				<definiendum id="0">Collocational Information</definiendum>
			</definition>
</paper>

		<paper id="1075">
			<definition id="0">
				<sentence>Coreference resolution is the process of determining whether two referring expressions refer to the same entity in the world .</sentence>
				<definiendum id="0">Coreference resolution</definiendum>
				<definiens id="0">the process of determining whether two referring expressions</definiens>
			</definition>
			<definition id="1">
				<sentence>• Agent for predicate nominal coreference If the anaphor is the predicate nominal and the antecedent candidate is the subject , they are coreferential .</sentence>
				<definiendum id="0">candidate</definiendum>
				<definiens id="0">the predicate nominal and the antecedent</definiens>
			</definition>
			<definition id="2">
				<sentence>Anaphora resolution : a multi-strategy approach .</sentence>
				<definiendum id="0">Anaphora resolution</definiendum>
				<definiens id="0">a multi-strategy approach</definiens>
			</definition>
</paper>

		<paper id="1077">
			<definition id="0">
				<sentence>The Text Summarization Challenge ( TSC ) 2 has been held once in one and a half years as part of the NTCIR ( NII-NACSIS Test Collection for IR Systems ) project since 2001 .</sentence>
				<definiendum id="0">Text Summarization Challenge</definiendum>
				<definiens id="0">held once in one and a half years as part of the NTCIR ( NII-NACSIS Test Collection for IR Systems ) project since 2001</definiens>
			</definition>
			<definition id="1">
				<sentence>Precision is the ratio of how many sentences in the system output are included in the set of the corresponding sentences .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio of how many sentences in the system output</definiens>
			</definition>
			<definition id="2">
				<sentence>Precision a70a72a71a73a75a74 ( 1 ) where a76 is the least number of sentences needed to produce the abstract by solving the constraint satisfaction problem and a77 is the number of ‘correct’ sentences in the system output , i.e. , the sentences that are included in the set of corresponding sentences .</sentence>
				<definiendum id="0">a76</definiendum>
				<definiendum id="1">a77</definiendum>
				<definiens id="0">the least number of sentences needed to produce the abstract by solving the constraint satisfaction problem and</definiens>
				<definiens id="1">the number of ‘correct’ sentences in the system output , i.e. , the sentences that are included in the set of corresponding sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>If the system output is “a1a32a2a30a35a67a66a32a1a32a2a8a2a14a66a37a1a6a33a3a66a32a1a32a2a8a78a14a66a37a1a6a34a20a35a68a66a37a1a8a34a32a2 ” , then the Precision is as follows : Precision a70a80a79a81a82a70a82a83a85a84a81a37a81a87a86 a84 ( 2 ) for “a1a32a2a88a66a32a1a32a2a30a35a68a66a37a1a3a2a20a2a14a66a32a1a8a7a67a66a37a1a6a33a3a66a32a1a8a34a20a35 ” , the Precision is as follows : Precision a70 a81 a81 a70a90a89a91a84 ( 3 ) Coverage is an evaluation metric for measuring how close the system output is to the abstract taking into account the redundancy found in the set of sentences in the output .</sentence>
				<definiendum id="0">Coverage</definiendum>
				<definiens id="0">an evaluation metric for measuring how close the system output is to the abstract taking into account the redundancy found in the set of sentences in the output</definiens>
			</definition>
			<definition id="4">
				<sentence>W.C. a70 a147 a134 a130 a117a3a152 a108a110a153a120a108a110a109a6a111a16a111a144a154a155a107a91a108a110a109a6a111 a152 a108 a137 a111a110a148a156a108 a137 a111a158a157 a152 a108a22a159a160a111a110a148a142a108a22a159a160a111a140a157 a152 a108a97a161a53a111a110a148a142a108a97a161a53a111 a74 ( 7 ) where a61a158a46a30a92a12a49 denotes the ranking of the a92 -th sentence of the abstract and a162a163a46a36a61a158a46a36a92a14a49a8a49 is its weight .</sentence>
				<definiendum id="0">a61a158a46a30a92a12a49</definiendum>
				<definiens id="0">the ranking of the a92 -th sentence of the abstract</definiens>
			</definition>
			<definition id="5">
				<sentence>‘Exact match’ is a scoring function that returns one when the summary includes the answer to the question .</sentence>
				<definiendum id="0">‘Exact match’</definiendum>
				<definiens id="0">a scoring function that returns one when the summary includes the answer to the question</definiens>
			</definition>
			<definition id="6">
				<sentence>Stfidfa108a97a189 a134 a111 a70 a190a22a191a91a192 a124 a152 a108a186a193 a74a12a194a106a195 a111 a74 ( 10 ) where a162a57a46a30a59a88a66a32a196a155a179a95a49 is defined as follows : a152 a108a110a193 a74a14a194a197a195 a111 a70 a193a6a198a199a108a110a193 a74a14a194a197a195 a111a125a200a8a201a186a202a37a203 a136 a194 a159 a136 a204 a198a205a108a186a193a12a111 a84 ( 11 ) a59a91a206a207a46a36a59a88a66a37a196a171a179a98a49 is the frequency of word a59 in the document set , a208a23a206a140a46a36a59a88a49 is the document frequency of a59 , and a145a196a155a169a52a145 is the total number of documents in the set .</sentence>
				<definiendum id="0">a208a23a206a140a46a36a59a88a49</definiendum>
				<definiendum id="1">a145a196a155a169a52a145</definiendum>
				<definiens id="0">Stfidfa108a97a189 a134 a111 a70 a190a22a191a91a192 a124 a152 a108a186a193 a74a12a194a106a195 a111 a74 ( 10 ) where a162a57a46a30a59a88a66a32a196a155a179a95a49 is defined as follows : a152 a108a110a193 a74a14a194a197a195 a111 a70 a193a6a198a199a108a110a193 a74a14a194a197a195 a111a125a200a8a201a186a202a37a203 a136 a194 a159 a136 a204 a198a205a108a186a193a12a111 a84 ( 11 ) a59a91a206a207a46a36a59a88a66a37a196a171a179a98a49 is the frequency of word a59 in the document set</definiens>
				<definiens id="1">the document frequency of a59 , and</definiens>
				<definiens id="2">the total number of documents in the set</definiens>
			</definition>
			<definition id="7">
				<sentence>a145 a93 a179a114a145 is the number of sentences in all topics and a219a36a63a20a146a166a46a30a213a207a49 is the pattern length .</sentence>
				<definiendum id="0">a219a36a63a20a146a166a46a30a213a207a49</definiendum>
				<definiens id="0">the number of sentences in all topics and</definiens>
			</definition>
			<definition id="8">
				<sentence>SUMMAC : a text summarization evaluation .</sentence>
				<definiendum id="0">SUMMAC</definiendum>
				<definiens id="0">a text summarization evaluation</definiens>
			</definition>
</paper>

		<paper id="1139">
			<definition id="0">
				<sentence>The separation line ( top right to bottom left ) divides the plot area in a native part ( bottom right ) and a non-native part ( top left ) .</sentence>
				<definiendum id="0">non-native part</definiendum>
				<definiens id="0">top right to bottom left</definiens>
			</definition>
			<definition id="1">
				<sentence>The Freiburg LOB Corpus , informally known as FLOB ( Hundt et al. , 1998 ) is a modern counterpart to the much used Lancaster-Oslo/Bergen Corpus ( LOB ; Johansson , 1978 ) It is a one-million word corpus of written ( educated ) Modern British English .</sentence>
				<definiendum id="0">Freiburg LOB Corpus</definiendum>
				<definiendum id="1">FLOB</definiendum>
				<definiens id="0">a modern counterpart to the much used Lancaster-Oslo/Bergen Corpus ( LOB ; Johansson , 1978 ) It is a one-million word corpus of written ( educated ) Modern British English</definiens>
			</definition>
</paper>

		<paper id="1030">
			<definition id="0">
				<sentence>The translation model links the source language sentence to the target language sentence .</sentence>
				<definiendum id="0">translation model</definiendum>
				<definiens id="0">links the source language sentence to the target language sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The argmax operation denotes the search problem , i.e. the generation of the output sentence in the target language .</sentence>
				<definiendum id="0">argmax operation</definiendum>
				<definiens id="0">the search problem , i.e. the generation of the output sentence in the target language</definiens>
			</definition>
			<definition id="2">
				<sentence>¢Z ( fJ1 ) Here , Z ( fJ1 ) denotes the appropriate normalization constant .</sentence>
				<definiendum id="0">¢Z</definiendum>
				<definiens id="0">the appropriate normalization constant</definiens>
			</definition>
			<definition id="3">
				<sentence>Then , J¢ ( J¢M ) k¢E is an upper bound for the size of the Q-table .</sentence>
				<definiendum id="0">J¢ ( J¢M ) k¢E</definiendum>
				<definiens id="0">an upper bound for the size of the Q-table</definiens>
			</definition>
			<definition id="4">
				<sentence>Here , Qjl ; jr ; eb ; et denotes the probability of the best hypothesis translating the source words from position jl ( left ) to position jr ( right ) which begins with the target language word eb ( bottom ) and ends with the word et ( top ) .</sentence>
				<definiendum id="0">et</definiendum>
				<definiens id="0">the probability of the best hypothesis translating the source words from position jl ( left ) to position jr ( right ) which begins with the target language word eb ( bottom ) and ends with the word et ( top )</definiens>
			</definition>
			<definition id="5">
				<sentence>Here , J is the length of the source sentence and E is the vocabulary size of the target language .</sentence>
				<definiendum id="0">J</definiendum>
				<definiendum id="1">E</definiendum>
				<definiens id="0">the length of the source sentence and</definiens>
				<definiens id="1">the vocabulary size of the target language</definiens>
			</definition>
			<definition id="6">
				<sentence>tor is a binary vector marking the source sentence words that have already been translated ( covered ) .</sentence>
				<definiendum id="0">tor</definiendum>
				<definiens id="0">a binary vector marking the source sentence words that have already been translated ( covered )</definiens>
			</definition>
			<definition id="7">
				<sentence>The PER compares the words in the two sentences ignoring the word order .</sentence>
				<definiendum id="0">PER</definiendum>
				<definiens id="0">compares the words in the two sentences ignoring the word order</definiens>
			</definition>
</paper>

		<paper id="1117">
			<definition id="0">
				<sentence>Medical language presents a unique combination of challenges for language engineering , with a focus on applications such as information retrieval , text mining and information extraction .</sentence>
				<definiendum id="0">Medical language</definiendum>
				<definiens id="0">presents a unique combination of challenges for language engineering</definiens>
			</definition>
			<definition id="1">
				<sentence>As subword equivalence classes abstract away from subtle particularities within and between languages , and reference to them is achieved via a language-independent code system , they form an interlingua characterized by semantic identifiers .</sentence>
				<definiendum id="0">subword equivalence classes</definiendum>
				<definiens id="0">they form an interlingua characterized by semantic identifiers</definiens>
			</definition>
			<definition id="2">
				<sentence>Morpho-Semantic Indexing We briefly outline the lexicographic and semantic aspects of our approach , called Morpho-Semantic Indexing ( henceforth , MSI ) , which translates source documents ( and queries ) into an interlingual representation in which their content is represented by language-independent semantic descriptors .</sentence>
				<definiendum id="0">Morpho-Semantic Indexing</definiendum>
				<definiendum id="1">MSI )</definiendum>
				<definiens id="0">translates source documents ( and queries ) into an interlingual representation in which their content is represented by language-independent semantic descriptors</definiens>
			</definition>
			<definition id="3">
				<sentence>Each lexicon entry is assigned a unique identifier representing one synonymy class , the MORPHOSAURUS identifier ( MID ) , which contains this entry as its unique member .</sentence>
				<definiendum id="0">MORPHOSAURUS identifier</definiendum>
				<definiendum id="1">MID</definiendum>
				<definiens id="0">contains this entry as its unique member</definiens>
			</definition>
			<definition id="4">
				<sentence>First , for each Portuguese lexicon entry ( n = 14,183 stems and invariants , excluding affixes ) , all possible Spanish variant strings were generated based upon the set of string substitution rules .</sentence>
				<definiendum id="0">Portuguese lexicon entry</definiendum>
				<definiens id="0">excluding affixes ) , all possible Spanish variant strings were generated based upon the set of string substitution rules</definiens>
			</definition>
			<definition id="5">
				<sentence>In Unsupervised Lexical Acquisition : Proceedings of the Workshop of the ACL Special Interest Group on the Lexicon ( SIGLEX ) , pages 9–16 .</sentence>
				<definiendum id="0">Unsupervised Lexical Acquisition</definiendum>
				<definiens id="0">Proceedings of the Workshop of the ACL Special Interest Group on the Lexicon</definiens>
			</definition>
</paper>

		<paper id="1074">
			<definition id="0">
				<sentence>The factors used in the algorithms and the algorithms themselves are evaluated on a German corpus annotated with syntactic and coreference information ( Negra ) ( Skut et al. , 1997 ) .</sentence>
				<definiendum id="0">factors</definiendum>
			</definition>
			<definition id="1">
				<sentence>We considered two proposals for orderings of form : preferring pronouns and proper names over other NPs over indefinite NPs ( Tetreault , 2001 ) ( NF ) or preferring pronouns over all other NPs ( Tetreault , 2001 ) ( NP ) .</sentence>
				<definiendum id="0">NF</definiendum>
				<definiens id="0">preferring pronouns and proper names over other NPs over indefinite NPs</definiens>
			</definition>
			<definition id="2">
				<sentence>Anaphora resolution : A multi-strategy approach .</sentence>
				<definiendum id="0">Anaphora resolution</definiendum>
				<definiens id="0">A multi-strategy approach</definiens>
			</definition>
</paper>

		<paper id="1109">
			<definition id="0">
				<sentence>The goal of Information Extraction ( IE ) is to extract structured facts of interest from text and present them in databases or templates .</sentence>
				<definiendum id="0">Information Extraction ( IE )</definiendum>
				<definiens id="0">to extract structured facts of interest from text and present them in databases or templates</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , the FASTUS ( Appelt et al. , 1996 ) and Proteus ( Grishman , 1996 ) systems , which performed well for MUC-6 , used hand-written rules for event patterns .</sentence>
				<definiendum id="0">FASTUS</definiendum>
				<definiens id="0">performed well for MUC-6 , used hand-written rules for event patterns</definiens>
			</definition>
			<definition id="2">
				<sentence>The symbolic learning systems , like AutoSlog ( Riloff , 1993 ) and CRYSTAL ( Fisher et al. , 1996 ) , generated patterns automatically from specific examples ( text segments ) using generalization and predefined pattern templates .</sentence>
				<definiendum id="0">symbolic learning systems</definiendum>
				<definiens id="0">text segments ) using generalization and predefined pattern templates</definiens>
			</definition>
			<definition id="3">
				<sentence>Kernel functions provide a way to compute the similarity between two objects without transforming them into features .</sentence>
				<definiendum id="0">Kernel functions</definiendum>
				<definiens id="0">provide a way to compute the similarity between two objects without transforming them into features</definiens>
			</definition>
			<definition id="4">
				<sentence>GLARF ( Grammatical and Logical Argument Regularization Framework ) [ Meyers et al. , 2001 ] is a hand-coded system that produces comprehensive word dependency graphs from Penn TreeBank-II ( PTB-II ) parse trees to facilitate applications like information extraction .</sentence>
				<definiendum id="0">GLARF</definiendum>
				<definiens id="0">a hand-coded system that produces comprehensive word dependency graphs from Penn TreeBank-II ( PTB-II ) parse trees to facilitate applications like information extraction</definiens>
			</definition>
			<definition id="5">
				<sentence>For a sentence , GLARF outputs depencency triples derived automatically from the GLARF typed feature structures [ Meyers et al. , 2001 ] .</sentence>
				<definiendum id="0">GLARF</definiendum>
			</definition>
			<definition id="6">
				<sentence>Slot filler detection ( SFD ) is the task of determining which named entities fill a slot in some event template .</sentence>
				<definiendum id="0">Slot filler detection</definiendum>
				<definiendum id="1">SFD</definiendum>
				<definiens id="0">the task of determining which named entities fill a slot in some event template</definiens>
			</definition>
			<definition id="7">
				<sentence>A matching function ) , ( 21 nnC is defined as ∑∑ == + &gt; &lt; &gt; &lt; 21 11 ) ) , ( ) , , , ( ( p j jijjii p i rrIararI .</sentence>
				<definiendum id="0">matching function</definiendum>
				<definiendum id="1">nnC</definiendum>
				<definiens id="0">∑∑ == + &gt; &lt; &gt; &lt; 21 11 ) ) , ( ) , , , ( ( p j jijjii p i rrIararI</definiens>
			</definition>
			<definition id="8">
				<sentence>EOD is to determine whether a sentence contains an event or not .</sentence>
				<definiendum id="0">EOD</definiendum>
				<definiens id="0">to determine whether a sentence contains an event or not</definiens>
			</definition>
</paper>

		<paper id="1029">
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>The semantic distance between words is defined as the distance from the leaf node to the most specific common abstraction ( MSCA ) in a thesaurus ( Ohno and Hamanishi , 1984 ) .</sentence>
				<definiendum id="0">semantic distance between words</definiendum>
			</definition>
</paper>

		<paper id="1102">
			<definition id="0">
				<sentence>Katakana is a syllabary which is used mostly to write Western loanwords , onomatopoeic words , names of plants and animals , non-Japanese personal and place names , for emphasis , and for slang , while hiragana is an ordinary syllabary .</sentence>
				<definiendum id="0">Katakana</definiendum>
				<definiendum id="1">hiragana</definiendum>
				<definiens id="0">a syllabary which is used mostly to write Western loanwords , onomatopoeic words , names of plants and animals , non-Japanese personal and place names</definiens>
			</definition>
			<definition id="1">
				<sentence>The similarity simed is de ned as follows : simed ( Str1 ; Str2 ) = 1 2ED ( Str1 ; Str2 ) jStr 1j+jStr2j ; ( 1 ) where ED ( Str1 ; Str2 ) denotes the ordinary edit distance .</sentence>
				<definiendum id="0">ED</definiendum>
				<definiens id="0">the ordinary edit distance</definiens>
			</definition>
			<definition id="2">
				<sentence>Table 1 : Decision list of deciding module katakana wordsAandB is de ned as Formula ( 2 ) , Sims ( A ; B ) = 1 2EDk ( rom ( A ) ; rom ( B ) ) jrom ( A ) j+jrom ( B ) j ; ( 2 ) whererom ( x ) denotes romanized strings ofx , and EDk ( x ; y ) denotes a weighted edit distance between x and y that is specialized for katakana .</sentence>
				<definiendum id="0">Decision list</definiendum>
				<definiendum id="1">EDk ( x ; y )</definiendum>
				<definiens id="0">a weighted edit distance between x and y that is specialized for katakana</definiens>
			</definition>
			<definition id="3">
				<sentence>EDk ( x ; y ) is a kind of weighted edit distance , and is marked by a distance function that determines the relaxed distance based on local strings .</sentence>
				<definiendum id="0">EDk ( x ; y )</definiendum>
				<definiens id="0">a kind of weighted edit distance , and is marked by a distance function that determines the relaxed distance based on local strings</definiens>
			</definition>
			<definition id="4">
				<sentence>W ( kwi ; ei ) = f ( kwi ; ei ) Nsf ( kw i ) : ( 5 ) Here , kwi is a katakana word , ei is an element of the vector corresponding to kwi , f ( kwi ; ei ) denotes the frequency of the element ei for kwi , sf ( kwi ) denotes the frequency of the sentence including kwi , and N denotes the number of katakana words in the corpus .</sentence>
				<definiendum id="0">kwi</definiendum>
				<definiendum id="1">ei</definiendum>
				<definiendum id="2">N</definiendum>
				<definiens id="0">a katakana word ,</definiens>
				<definiens id="1">an element of the vector corresponding to kwi , f ( kwi ; ei ) denotes the frequency of the element ei for kwi , sf</definiens>
				<definiens id="2">the frequency of the sentence including kwi</definiens>
			</definition>
			<definition id="5">
				<sentence>BTEC is a multilingual corpus and was mainly developed with English and Japanese .</sentence>
				<definiendum id="0">BTEC</definiendum>
				<definiens id="0">a multilingual corpus</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>For the French originals of all three sets of texts we computed resource-light parameters used in standard readability measures ( Flesch Reading Ease score or Flesch-Kincaid Grade Level score ) , i.e. average sentence length ( ASL – the number of words divided by the number of sentences ) and average number of syllables per word ( ASW – the number of syllables divided by the number of words ) .</sentence>
				<definiendum id="0">ASL</definiendum>
				<definiens id="0">the number of words divided by the number of sentences ) and average number of syllables per word ( ASW – the number of syllables divided by the number of words )</definiens>
			</definition>
			<definition id="1">
				<sentence>WNM is an extension of BLEU with weights of a term’s salience within a given text .</sentence>
				<definiendum id="0">WNM</definiendum>
			</definition>
			<definition id="2">
				<sentence>idf scores and are computed as follows : ( ) ) ( ) ( ) ( ) , ( / ) ( log ) , ( icorp iidoccorpjidoc P NdfNPPjiS −×−= − , where : – Pdoc ( i , j ) is the relative frequency of the word wi in the text j ; ( “Relative frequency” is the number of tokens of this word-type divided by the total number of tokens ) .</sentence>
				<definiendum id="0">“Relative frequency”</definiendum>
				<definiens id="0">the relative frequency of the word wi in the text j</definiens>
			</definition>
			<definition id="3">
				<sentence>– Pcorp-doc ( i ) is the relative frequency of the same word wi in the rest of the corpus , without this text ; – dfi is the number of documents in the corpus where the word wi occurs ; – N is the total number of documents in the corpus .</sentence>
				<definiendum id="0">– Pcorp-doc ( i )</definiendum>
				<definiendum id="1">dfi</definiendum>
				<definiendum id="2">– N</definiendum>
				<definiens id="0">the relative frequency of the same word wi in the rest of the corpus</definiens>
				<definiens id="1">the number of documents in the corpus where the word wi occurs ;</definiens>
				<definiens id="2">the total number of documents in the corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>In our experiment , we examined the following resource-light parameters for their correlation with both automated scores : – Flesch Reading Ease score , which rates text on a 100-point scale according to how easy it is to understand ; the score is computed as follows : FR = 206.835 – ( 1.015 * ASL ) – ( 84.6 * ASW ) , where : ASL is the average sentence length ( the number of words divided by the number of sentences ) ; ASW is the average number of syllables per word ( the number of syllables divided by the number of words ) – Flesch-Kincaid Grade Level score which rates texts on US grade-school level and is computed as : FKGL = ( 0.39 * ASL ) + ( 11.8 * ASW ) – 15.59 – each of the ASL and ASW parameters individually .</sentence>
				<definiendum id="0">ASL</definiendum>
				<definiendum id="1">ASW</definiendum>
				<definiens id="0">their correlation with both automated scores : – Flesch Reading Ease score , which rates text on a 100-point scale according to how easy it is to understand ; the score is computed as follows : FR = 206.835 – ( 1.015 * ASL ) – ( 84.6 * ASW</definiens>
				<definiens id="1">the average sentence length ( the number of words divided by the number of sentences</definiens>
				<definiens id="2">the average number of syllables per word ( the number of syllables divided by the number of words ) – Flesch-Kincaid Grade Level score which rates texts on US grade-school level and is computed as : FKGL = ( 0.39 * ASL ) + ( 11.8 * ASW ) – 15.59 – each of the ASL and ASW parameters individually</definiens>
			</definition>
			<definition id="5">
				<sentence>Weighted N-gram model for evaluating Machine Translation output .</sentence>
				<definiendum id="0">Weighted N-gram model</definiendum>
				<definiens id="0">for evaluating Machine Translation output</definiens>
			</definition>
</paper>

		<paper id="1204">
			<definition id="0">
				<sentence>Several parsers have been implemented in various grammar formalisms and empirical evaluation has been reported : LFG ( Riezler et al. , 2002 ; Cahill et al. , 2002 ; Burke et al. , 2004 ) , LTAG ( Chiang , 2000 ) , CCG ( Hockenmaier and Steedman , 2002b ; Clark et al. , 2002 ; Hockenmaier , 2003 ) , and HPSG ( Miyao et al. , 2003 ; Malouf and van Noord , 2004 ) .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiendum id="1">HPSG</definiendum>
				<definiens id="0">Miyao et al. , 2003</definiens>
			</definition>
			<definition id="1">
				<sentence>To date , accurate parsers have been developed for LTAG ( Chiang , 2000 ) , CCG ( Hockenmaier and Steedman , 2002b ; Clark et al. , 2002 ; Hockenmaier , 2003 ) , and LFG ( Cahill et al. , 2002 ; Burke et al. , 2004 ) .</sentence>
				<definiendum id="0">LTAG</definiendum>
				<definiendum id="1">CCG</definiendum>
				<definiendum id="2">LFG</definiendum>
			</definition>
			<definition id="2">
				<sentence>PropBank ( Kingsbury and Palmer , 2002 ) and FrameNet ( Baker et al. , 1998 ) are large English corpora annotated with the semantic relations of words in a sentence .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiendum id="1">FrameNet</definiendum>
				<definiens id="0">Baker et al. , 1998 ) are large English corpora annotated with the semantic relations of words in a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>The PropBank includes additional annotations representing a predicate and its semantic arguments in a syntactic tree .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">includes additional annotations representing a predicate and its semantic arguments in a syntactic tree</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , in Figure 1 , REL denotes a predicate , “choose” , and ARGa0 represents its semantic arguments : “they” for the 0th argument ( i.e. , subject ) and “this particular moment” for the 1st argument ( i.e. , object ) .</sentence>
				<definiendum id="0">REL</definiendum>
			</definition>
			<definition id="5">
				<sentence>We represent an HPSG sign as a tuple a1a3a2a5a4a7a6a9a8a7a10a11a8a13a12a15a14 , where a6 is a lexical sign of the head word , a10 is a part-of-speech , and a12 is a symbol representing the structure of the sign ( mostly corresponding to nonterminal symbols of the Penn Treebank ) .</sentence>
				<definiendum id="0">HPSG sign</definiendum>
				<definiendum id="1">a6</definiendum>
				<definiendum id="2">a10</definiendum>
				<definiendum id="3">a12</definiendum>
				<definiens id="0">a lexical sign of the head word ,</definiens>
				<definiens id="1">a part-of-speech , and</definiens>
				<definiens id="2">a symbol representing the structure of the sign ( mostly corresponding to nonterminal symbols of the Penn Treebank</definiens>
			</definition>
</paper>

		<paper id="1045">
			<definition id="0">
				<sentence>In the E-step the following types of counts are collected : † full form counts : C ( f ; e ) = X s X a p ( ajfs ; es ) ¢ ¢X i ; j - ( f ; fjs ) - ( e ; eis ) where f is the full form of the word , e.g. “gehe” ; † base form+tag counts : C ( fbt ; e ) = X s X a p ( ajfs ; es ) ¢ ¢X i ; j - ( fbt ; fbtjs ) - ( e ; eis ) where fbt represents the base form of the word f with sequence of corresponding tags , e.g. “gehen-V-IND-PRES” ; † base form counts : C ( fb ; e ) = X s X a p ( ajfs ; es ) ¢ ¢X i ; j - ( fb ; fbjs ) - ( e ; eis ) where fb is the base form of the word f , e.g. “gehen” .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">fbt</definiendum>
				<definiendum id="2">fb</definiendum>
				<definiens id="0">the full form of the word</definiens>
				<definiens id="1">the base form of the word f with sequence of corresponding tags</definiens>
				<definiens id="2">the base form of the word f</definiens>
			</definition>
			<definition id="1">
				<sentence>The Verbmobil task ( W. Wahlster , editor , 2000 ) is a speech translation task in the domain of appointment scheduling , travel planning and hotel reservation .</sentence>
				<definiendum id="0">W. Wahlster</definiendum>
				<definiens id="0">a speech translation task in the domain of appointment scheduling , travel planning and hotel reservation</definiens>
			</definition>
</paper>

		<paper id="1090">
			<definition id="0">
				<sentence>A transfer rule specifies how a path in the source language dependency tree is translated .</sentence>
				<definiendum id="0">transfer rule</definiendum>
			</definition>
			<definition id="1">
				<sentence>The translation probability P ( T i |S i ) can be computed as ( ) ( ) ( ) MSc STc STP i ii ii + = , | where c ( S i ) is the count of S i in the training corpus , c ( T i , S i ) is the number of times T i is the translation of S i , and M is a smoothing constant .</sentence>
				<definiendum id="0">translation probability P</definiendum>
				<definiendum id="1">c ( S i )</definiendum>
				<definiendum id="2">M</definiendum>
				<definiens id="0">a smoothing constant</definiens>
			</definition>
			<definition id="2">
				<sentence>4 ( e ) is a translation of Fig .</sentence>
				<definiendum id="0">e )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Given the dependency tree S of a source language sentence , the probability of the target dependency tree T , P ( T|S ) , is computed by decomposing it into a set of path translations : ( ) ( ) ∏ ∈ = CS ii i STPSTP |max| C where C is a set of paths covering S ; S i ’s are paths in C ; T i ’s are possible translations for the corresponding S i ’s and T is the merger of all T i ’s .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">dependency tree S of a source language sentence , the probability of the target dependency tree T</definiens>
			</definition>
			<definition id="4">
				<sentence>The training corpus consists of the English-French portion of the 1999 European Parliament Proceedings 1 ( Koehn 2002 ) .</sentence>
				<definiendum id="0">training corpus</definiendum>
			</definition>
			<definition id="5">
				<sentence>The Direct Correspondence Assumption ( DCA ) states that the dependency tree in source and target language have isomorphic structures ( Hwa et .</sentence>
				<definiendum id="0">Direct Correspondence Assumption ( DCA</definiendum>
				<definiens id="0">the dependency tree in source and target language have isomorphic structures ( Hwa et</definiens>
			</definition>
			<definition id="6">
				<sentence>Europarl : A Multilingual Corpus for Evaluation of Machine Translation .</sentence>
				<definiendum id="0">Europarl</definiendum>
			</definition>
			<definition id="7">
				<sentence>Learning Domain-Specific Transfer Rules : An Experiment with Korean to English Translation .</sentence>
				<definiendum id="0">Learning Domain-Specific Transfer Rules</definiendum>
			</definition>
</paper>

		<paper id="1188">
			<definition id="0">
				<sentence>The Table Lookup finds the entries whose relevant fields best match the keywords from the question .</sentence>
				<definiendum id="0">Table Lookup</definiendum>
				<definiens id="0">finds the entries whose relevant fields best match the keywords from the question</definiens>
			</definition>
			<definition id="1">
				<sentence>In these patterns , person is a phrase that is tagged as person by the Named Entity tagger , role is a word from a list of roles extracted from the WordNet ( all hyponyms of the word ‘person , ’ 15703 entries ) ,1 role-verb is from a manually constructed list of “important” verbs ( discovered , invented , etc. ; 48 entries ) , leader is a phrase identifying leadership from a manually created list of leaders ( president , minister , etc. ; 22 entries ) .</sentence>
				<definiendum id="0">person</definiendum>
				<definiendum id="1">leader</definiendum>
				<definiens id="0">a phrase that is tagged as person by the Named Entity tagger , role is a word from a list of roles extracted from the WordNet ( all hyponyms of the word ‘person</definiens>
				<definiens id="1">a phrase identifying leadership from a manually created list of leaders</definiens>
			</definition>
			<definition id="2">
				<sentence>in WordNet ) , role-verb is one of the “important verbs.”</sentence>
				<definiendum id="0">role-verb</definiendum>
			</definition>
			<definition id="3">
				<sentence>When an occurence of a pattern was found in a parsed sentence , the relation ( person ; infobit ) was extracted , where info-bit is a sequence of all words below role or role-verb in the dependency graph ( i.e. , all dependents along with their dependents etc. ) , excluding the person .</sentence>
				<definiendum id="0">info-bit</definiendum>
				<definiens id="0">a sequence of all words below role or role-verb in the dependency graph ( i.e. , all dependents along with their dependents etc. ) , excluding the person</definiens>
			</definition>
			<definition id="4">
				<sentence>CoNLL : Conference on Natural Language Learning .</sentence>
				<definiendum id="0">CoNLL</definiendum>
			</definition>
			<definition id="5">
				<sentence>Learning surface text patterns for a question answering system .</sentence>
				<definiendum id="0">Learning surface text</definiendum>
				<definiens id="0">patterns for a question answering system</definiens>
			</definition>
</paper>

		<paper id="1120">
</paper>

		<paper id="1058">
			<definition id="0">
				<sentence>The reconstituted training set is used by Error Corrector Learner , which learns a set of rules .</sentence>
				<definiendum id="0">Error Corrector Learner</definiendum>
				<definiens id="0">learns a set of rules</definiens>
			</definition>
			<definition id="1">
				<sentence>Rule hypotheses are generated according to the given set of allowable templates : R = { r|r∈H∧τ ( r ) &gt; τmin∧epsilon1 ( r ) = 0 } ( 1 ) τ ( r ) = summationdisplayX j=1 summationdisplay r ( xj , ˆyj ) negationslash=∅δ ( r ( xj , ˆyj ) , yj ) ( 2 ) epsilon1 ( r ) = summationdisplayX j=1 summationdisplay r ( xj , ˆyj ) negationslash=∅1−δ ( r ( xj , ˆyj ) , yj ) ( 3 ) where X is a sequence of X training examples xi , Y is a sequence of reference labels yi for each example respectively , ˆY is a sequence of labels ˆyi as predicted by the base model for each example respectively , H is the hypothesis space of valid rules implied by the templates , and τmin is a confidence threshold .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiendum id="2">ˆY</definiendum>
				<definiendum id="3">H</definiendum>
				<definiendum id="4">τmin</definiendum>
				<definiens id="0">the hypothesis space of valid rules implied by the templates</definiens>
			</definition>
			<definition id="2">
				<sentence>As a result , NTPC does bear a superficial resemblance to TBL , both of them being error-driven learning methods that seek to incrementally correct errors in a corpus by learning rules that are determined by a set of templates .</sentence>
				<definiendum id="0">NTPC</definiendum>
				<definiens id="0">a corpus by learning rules that are determined by a set of templates</definiens>
			</definition>
			<definition id="3">
				<sentence>MH ( Schapire and Singer , 2000 ) , the multi-class generalization of the original boosting algorithm , which implements boosting on top of decision stump classifiers ( decision trees of depth one ) .</sentence>
				<definiendum id="0">MH</definiendum>
				<definiens id="0">implements boosting on top of decision stump classifiers ( decision trees of depth one )</definiens>
			</definition>
			<definition id="4">
				<sentence>Another key difference between NTPC and TBL is the process of rule interaction .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">the process of rule interaction</definiens>
			</definition>
			<definition id="5">
				<sentence>Transformation-based learning ( Brill , 1995 ) , or TBL , is one of the most successful rule-based machine learning algorithms .</sentence>
				<definiendum id="0">Transformation-based learning</definiendum>
				<definiendum id="1">TBL</definiendum>
				<definiens id="0">one of the most successful rule-based machine learning algorithms</definiens>
			</definition>
			<definition id="6">
				<sentence>Boostexter : A boosting-based system for text categorization .</sentence>
				<definiendum id="0">Boostexter</definiendum>
				<definiens id="0">A boosting-based system for text categorization</definiens>
			</definition>
</paper>

		<paper id="1163">
</paper>

		<paper id="1156">
			<definition id="0">
				<sentence>Aligning a text and its translation ( also known as bitext ) at the word level is a basic Natural Language Processing task that has found various applications in recent years .</sentence>
				<definiendum id="0">level</definiendum>
				<definiens id="0">Aligning a text and its translation ( also known as bitext ) at the word</definiens>
				<definiens id="1">a basic Natural Language Processing task that has found various applications in recent years</definiens>
			</definition>
			<definition id="1">
				<sentence>KNOWA is an English/Italian word aligner , which relies mostly on information contained in the Collins bilingual dictionary , available in electronic format .</sentence>
				<definiendum id="0">KNOWA</definiendum>
				<definiens id="0">an English/Italian word aligner , which relies mostly on information contained in the Collins bilingual dictionary , available in electronic format</definiens>
			</definition>
			<definition id="2">
				<sentence>To work properly , KNOWA needs to identify them in the source and target sentences , and needs knowledge about their translation equivalents .</sentence>
				<definiendum id="0">KNOWA</definiendum>
				<definiens id="0">needs to identify them in the source and target sentences , and needs knowledge about their translation equivalents</definiens>
			</definition>
			<definition id="3">
				<sentence>Europarl : A Multilingual Corpus for Evaluation of Machine Translation , unpublised draft , available at http : //www.isi.edu/~koehn/publications/europarl.ps .</sentence>
				<definiendum id="0">Europarl</definiendum>
				<definiens id="0">A Multilingual Corpus for Evaluation of Machine Translation , unpublised draft</definiens>
			</definition>
</paper>

		<paper id="1154">
			<definition id="0">
				<sentence>Data-Oriented Translation ( DOT ) , based on DataOriented Parsing ( DOP ) , is a language-independent MT engine which exploits parsed , aligned bitexts to produce very high quality translations .</sentence>
				<definiendum id="0">Data-Oriented Translation</definiendum>
				<definiens id="0">a language-independent MT engine which exploits parsed , aligned bitexts to produce very high quality translations</definiens>
			</definition>
			<definition id="1">
				<sentence>DOT exploits bilingual treebanks comprising linguistic representations of previously seen translation pairs , as well as explicit links which map the translational equivalences present within these pairs at sub-sentential level – an example of such a linked translation pair can be seen in Figure 1 ( a ) .</sentence>
				<definiendum id="0">DOT</definiendum>
				<definiens id="0">exploits bilingual treebanks comprising linguistic representations of previously seen translation pairs</definiens>
			</definition>
			<definition id="2">
				<sentence>Fragments ( b ) and ( f ) were also derived by allowing the frontier operator to select the empty set ; the root operation selected node pairs &lt; A , N &gt; and &lt; NPadj , NPdet &gt; respectively .</sentence>
				<definiendum id="0">Fragments</definiendum>
				<definiens id="0">the frontier operator to select the empty set ; the root operation selected node pairs &lt; A</definiens>
			</definition>
			<definition id="3">
				<sentence>Fragments ( c ) , ( d ) and ( e ) were derived by selecting all further possible combinations of node pairs by root and frontier .</sentence>
				<definiendum id="0">Fragments</definiendum>
				<definiens id="0">selecting all further possible combinations of node pairs by root and frontier</definiens>
			</definition>
			<definition id="4">
				<sentence>( a ) ( b ) VPv V NPadj clearing A N paper jams NPpp N PP resolution P NPdet de D NPap les N N incidents papier A paper N papier ( c ) ( d ) VPv V NPadj clearing A N jams NPpp N PP resolution P NPdet de D NPap les N N incidents NPadj A N jams NPdet D NPap les N N incidents ( e ) ( f ) VPv V NPadj clearing NPpp N PP resolution P NPdet de NPadj A N paper jams NPdet D NPap les N N incidents papier Figure 1 : DOT fragments generated via root and frontier The DOT composition operator is defined as follows .</sentence>
				<definiendum id="0">N incidents NPadj A N jams NPdet D NPap</definiendum>
				<definiendum id="1">composition operator</definiendum>
				<definiens id="0">a ) ( b ) VPv V NPadj clearing A N paper jams NPpp N PP resolution P NPdet de D NPap les N N incidents papier A paper N papier ( c ) ( d ) VPv V NPadj clearing A N jams NPpp N PP resolution P NPdet de D NPap les N</definiens>
				<definiens id="1">les N N incidents ( e ) ( f ) VPv V NPadj clearing NPpp N PP resolution P NPdet de NPadj A N paper jams NPdet D NPap les N N incidents papier Figure 1 : DOT fragments generated via root and frontier The DOT</definiens>
			</definition>
			<definition id="5">
				<sentence>The DOT probability of a translation derivation is the joint probability of choosing each of the subtree pairs involved in that derivation .</sentence>
				<definiendum id="0">DOT probability of a translation derivation</definiendum>
				<definiens id="0">the joint probability of choosing each of the subtree pairs involved in that derivation</definiens>
			</definition>
			<definition id="6">
				<sentence>Parent Align ( Figure 4 ) : We have a current linked sourcetarget node pair 〈s , t〉 with unlinked parents pars and part respectively .</sentence>
				<definiendum id="0">Parent Align</definiendum>
				<definiens id="0">a current linked sourcetarget node pair 〈s , t〉 with unlinked parents pars and part respectively</definiens>
			</definition>
			<definition id="7">
				<sentence>Traverse up the source tree to find the topmost NP node nps dominating s and traverse up the target tree to find the topmost Nmod A NP color print head NPap NP N tˆete d’impression couleur Figure 4 : Parent Align : The dashed lines are the links made by Parent Align , when 〈color , couleur〉 is the current linked node pair .</sentence>
				<definiendum id="0">couleur〉</definiendum>
				<definiens id="0">the current linked node pair</definiens>
			</definition>
			<definition id="8">
				<sentence>K-vec : A New Approach for Aligning Parallel Texts .</sentence>
				<definiendum id="0">K-vec</definiendum>
			</definition>
			<definition id="9">
				<sentence>Recent Advances in Example-Based Machine Translation .</sentence>
				<definiendum id="0">Recent Advances</definiendum>
			</definition>
</paper>

		<paper id="1067">
			<definition id="0">
				<sentence>Unknown words are defined as words that do not exist in a system’s dictionary .</sentence>
				<definiendum id="0">Unknown words</definiendum>
			</definition>
			<definition id="1">
				<sentence>This method identifies POStags T = t1 ; : : : ; tn , given a sentence as a word sequence W = w1 ; : : : ; wn , where n is the number of words in the sentence .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of words in the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Given a sentence S , its most likely word sequence ˆW and POS sequence ˆT can be found as follows where W ranges over the possible segments of S ( w1¢¢¢wn = S ) : ( ˆW ; ˆT ) = argmax W ; T P ( W ; TjS ) ; = argmax W ; T P ( W ; T ; S ) P ( S ) ; = argmax W ; T P ( W ; T ; S ) ; = argmax W ; T P ( W ; T ) ; ’ argmax W ; T nY i=1 P ( wijti ) P ( tijti¡1 ) : ( 3 ) The equation above can be solved using the Viterbi algorithm as well .</sentence>
				<definiendum id="0">POS sequence ˆT</definiendum>
				<definiens id="0">follows where W ranges over the possible segments of S ( w1¢¢¢wn = S ) : ( ˆW ; ˆT ) = argmax W ; T P ( W ; TjS ) ; = argmax W ; T P ( W ; T ; S ) P ( S ) ; = argmax W ; T P ( W ; T ; S ) ; = argmax W ; T P ( W ; T ) ; ’ argmax W</definiens>
			</definition>
			<definition id="3">
				<sentence>Because the basic Markov models in Equation ( 1 ) are not expressive enough , we use the following equation instead to estimate probability of a path in a lattice more precisely : P ( W ; T ) = nY i=1 P ( witijw0t0 : : : wi¡1ti¡1 ) ; ’ nY i=1 f‚1P ( wijti ) P ( ti ) +‚2P ( wijti ) P ( tijti¡1 ) +‚3P ( wijti ) P ( tijti¡2ti¡1 ) +‚4P ( witijwi¡1ti¡1 ) g ; ( ‚1 +‚2 +‚3 +‚4 = 1 ) : ( 4 ) The probabilities in the equation above are estimated from a word segmented and POS-tagged corpus using the maximum-likelihood method , for example , P ( wijti ) = 8 &lt; : f ( wi ; ti ) P w f ( w ; ti ) ( f ( wi ; ti ) &gt; 0 ) , 0:5P w f ( w ; ti ) ( f ( wi ; ti ) = 0 ) , ( 5 ) where f ( w ; t ) is a frequency that the word w with the tag t occurred in training data .</sentence>
				<definiendum id="0">ti ) P w f</definiendum>
			</definition>
			<definition id="4">
				<sentence>In the above equation , P ( ti ) and P ( wi ; t ) are estimated by the maximum-likelihood method , and the probability of a POC tag ti , given a character wi ( P ( tijwi ; ti 2 TPOC ) ) is estimated using ME models ( Berger et al. , 1996 ) .</sentence>
				<definiendum id="0">P ( ti</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">( wi ; t ) are estimated by the maximum-likelihood method , and the probability of a POC tag ti , given a character wi</definiens>
			</definition>
			<definition id="5">
				<sentence>What our method is doing for unknown words can be interpreted as follows : The method examines all possible unknown words in a sentence , and probability for an unknown word of length k , wi = Character Type Description Alphabet Alphabets Numeral Arabic and Chinese numerals Symbol Symbols Kanji Chinese Characters Hiragana Hiragana ( Japanese scripts ) Katakana Katakana ( Japanese scripts ) Table 2 : Character Types cj ¢¢¢cj+k¡1 is calculated as : P ( witijh ) ( 7 ) = 8 &gt; &lt; &gt; : P ( cjSjh ) ( k = 1 ) ; P ( cjBjh ) Qj+k¡2l=j+1 P ( clIjh ) P ( cj+k¡1Ejh ) ( k &gt; 1 ) ; where h is a history of the sequence .</sentence>
				<definiendum id="0">h</definiendum>
				<definiens id="0">doing for unknown words can be interpreted as follows : The method examines all possible unknown words in a sentence , and probability for an unknown word of length k , wi = Character Type Description Alphabet Alphabets Numeral Arabic and Chinese numerals Symbol Symbols Kanji Chinese Characters Hiragana Hiragana ( Japanese scripts ) Katakana Katakana ( Japanese scripts ) Table 2 : Character Types cj ¢¢¢cj+k¡1 is calculated as : P ( witijh ) ( 7 ) = 8 &gt; &lt; &gt; : P ( cjSjh ) ( k = 1 ) ; P ( cjBjh ) Qj+k¡2l=j+1 P ( clIjh ) P ( cj+k¡1Ejh ) ( k &gt; 1</definiens>
			</definition>
			<definition id="6">
				<sentence>The following values are used to evaluate the performance of word segmentation : R : Recall ( The number of correctly segmented words in system’s output divided by the number of words in test data ) P : Precision ( The number of correctly segmented words in system’s output divided by the number of words in system’s output ) F : F-measure ( F = 2£R£P= ( R+P ) ) Rknown : Recall for known words Runknown : Recall for unknown words Corpus # of Training Words # of Testing Words # of Words Rate of ( known/unknown ) in Dictionary Unknown Words AS 5,806,611 11,985 ( 11,727/ 258 ) 146,212 0.0215 HK 239,852 34,955 ( 32,463/2,492 ) 23,747 0.0713 PK 1,121,017 17,194 ( 16,005/1,189 ) 55,226 0.0692 RWCP 840,879 93,155 ( 93,085/ 70 ) 315,602 0.0008 Table 3 : Statistical Information of Corpora Segmentation We use three Chinese word-segmented corpora , the Academia Sinica corpus ( AS ) , the Hong Kong City University corpus ( HK ) and the Beijing University corpus ( PK ) , all of which were used in the First International Chinese Word Segmentation Bakeoff ( Sproat and Emerson , 2003 ) at ACL-SIGHAN 2003 .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiendum id="1">Academia Sinica</definiendum>
				<definiens id="0">The number of correctly segmented words in system’s output divided by the number of words in test data</definiens>
				<definiens id="1">corpus ( AS ) , the Hong Kong City University corpus ( HK ) and the Beijing University corpus ( PK ) , all of which were used in the First International Chinese Word Segmentation Bakeoff ( Sproat and Emerson , 2003</definiens>
			</definition>
			<definition id="7">
				<sentence>Features described in Section 3.1 ( 1 ) – ( 4 ) and the following ( 5 ) are used to estimate a POC tag of a character ci0 , where tx is a POC-tag of the xth character in a sentence : ( 5 ) Unigram and bigram of previous POCtags ( ti0¡1 ; ti0¡2ti0¡1 ) All these systems including ours do not use any other knowledge or resources than the training data .</sentence>
				<definiendum id="0">tx</definiendum>
				<definiens id="0">used to estimate a POC tag of a character ci0</definiens>
				<definiens id="1">a POC-tag of the xth character in a sentence</definiens>
			</definition>
			<definition id="8">
				<sentence>Segmentation We use the RWCP corpus , which is a Japanese word-segmented and POS-tagged corpus .</sentence>
				<definiendum id="0">RWCP corpus</definiendum>
				<definiens id="0">a Japanese word-segmented and POS-tagged corpus</definiens>
			</definition>
			<definition id="9">
				<sentence>The Unknown Word Problem : a Morphological Analysis of Japanese Using Maximum Entropy Aided by a Dictionary .</sentence>
				<definiendum id="0">Unknown Word Problem</definiendum>
				<definiens id="0">a Morphological Analysis of Japanese Using Maximum Entropy Aided by a Dictionary</definiens>
			</definition>
</paper>

		<paper id="1148">
			<definition id="0">
				<sentence>The Papillon project is a collaborative project to establish a multilingual dictionary on the Web .</sentence>
				<definiendum id="0">Papillon project</definiendum>
			</definition>
			<definition id="1">
				<sentence>The lexical data is organized in 3 layers : • Limbo contains dictionaries in their original format and structure ; • Purgatory contains dictionaries in their original format but encoded in XML ; • Paradise contains the target dictionary , in our case Papillon dictionary .</sentence>
				<definiendum id="0">Paradise</definiendum>
				<definiens id="0">organized in 3 layers : • Limbo contains dictionaries in their original format and structure ; • Purgatory contains dictionaries in their original format but encoded in XML ; •</definiens>
			</definition>
			<definition id="2">
				<sentence>The tasks’ model is the set of all tasks that will be implemented independently of the type of user .</sentence>
				<definiendum id="0">tasks’ model</definiendum>
				<definiens id="0">the set of all tasks that will be implemented independently of the type of user</definiens>
			</definition>
			<definition id="3">
				<sentence>Each lexical function consists of a name and a list of valgroups ( group of values ) , and in turn , eachvalgroupconsists ofalistofvalues .</sentence>
				<definiendum id="0">lexical function</definiendum>
			</definition>
</paper>

		<paper id="1168">
			<definition id="0">
				<sentence>Based on Bayes’ rule , P ( JjX ) can be written as P ( JjX ) = Pam ( XjJ ) Plm ( J ) =P ( X ) where Pam ( XjJ ) is the acoustic model likelihood of the observations given the recognized sentence J ; Plm ( J ) , the source language model probability ; and P ( X ) , the probability of all acoustic observations .</sentence>
				<definiendum id="0">P ( JjX</definiendum>
				<definiendum id="1">Pam</definiendum>
				<definiens id="0">the acoustic model likelihood of the observations given the recognized sentence J</definiens>
				<definiens id="1">the probability of all acoustic observations</definiens>
			</definition>
			<definition id="1">
				<sentence>According to the statistical machine translation formalism ( Brown et al. , 1993 ) , the translation process is to search for the best sentence bE such that bE = arg max E P ( EjJ ) = arg maxE P ( JjE ) P ( E ) where P ( JjE ) is a translation model characterizing the correspondence between E and J ; P ( E ) , the English language model probability .</sentence>
				<definiendum id="0">translation process</definiendum>
				<definiens id="0">arg max E P ( EjJ ) = arg maxE P ( JjE ) P ( E ) where P ( JjE ) is a translation model characterizing the correspondence between E and J</definiens>
			</definition>
			<definition id="2">
				<sentence>1 , fi ( X ; E ) is the logarithm value of the i-th feature ; i is the weight of the ith feature .</sentence>
				<definiendum id="0">fi</definiendum>
				<definiens id="0">the logarithm value of the i-th feature</definiens>
			</definition>
			<definition id="3">
				<sentence>M1 = optimize D ( bE ; R ) ( 3 ) where bE = f bE1 ; ; bELg is a set of translations of all utterances .</sentence>
				<definiendum id="0">; bELg</definiendum>
				<definiens id="0">M1 = optimize D ( bE ; R ) ( 3 ) where bE = f bE1 ;</definiens>
				<definiens id="1">a set of translations of all utterances</definiens>
			</definition>
			<definition id="4">
				<sentence>NIST : An arithmetic mean of the n-gram matches between test and reference sentences multiplied by a length factor which again penalizes short translation sentences .</sentence>
				<definiendum id="0">NIST</definiendum>
				<definiens id="0">An arithmetic mean of the n-gram matches between test and reference sentences multiplied by a length factor which again penalizes short translation sentences</definiens>
			</definition>
			<definition id="5">
				<sentence>Optimized enhanced speech translation models ( oestm ) : Features from speech recognition , likelihood scores of acoustic and language models , were incorporated additionally into the model \oetm '' .</sentence>
				<definiendum id="0">Optimized enhanced speech translation models</definiendum>
				<definiens id="0">Features from speech recognition , likelihood scores of acoustic and language models</definiens>
			</definition>
			<definition id="6">
				<sentence>For each input speech utterance , N K candidate translations were generated , where N is the number of generated recognition hypotheses and K is the number of translation hypotheses .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">K</definiendum>
				<definiens id="0">the number of translation hypotheses</definiens>
			</definition>
</paper>

		<paper id="1187">
			<definition id="0">
				<sentence>We introduce our system , FADA , which relies on question parsing , web page classification/clustering , and content extraction to find reliable distinct answers with high recall .</sentence>
				<definiendum id="0">FADA</definiendum>
				<definiens id="0">relies on question parsing , web page classification/clustering , and content extraction to find reliable distinct answers with high recall</definiens>
			</definition>
			<definition id="1">
				<sentence>The well-known redundancy-based approach identifies the factoid answer as an N-gram appearing most frequently on the Web ( Brill et al. 2001 ) .</sentence>
				<definiendum id="0">factoid answer</definiendum>
			</definition>
			<definition id="2">
				<sentence>With the emphasis on answer completeness and uniqueness , FADA uses a large set of documents obtained from the Web to find answers .</sentence>
				<definiendum id="0">FADA</definiendum>
			</definition>
</paper>

		<paper id="1165">
			<definition id="0">
				<sentence>CSM ) and an alternative similarity measure based on coefficient overlap , to estimate hyperonym relations between words .</sentence>
				<definiendum id="0">CSM</definiendum>
				<definiens id="0">an alternative similarity measure based on coefficient overlap , to estimate hyperonym relations between words</definiens>
			</definition>
			<definition id="1">
				<sentence>To find an objective hierarchical word structure , we utilize the complementary similarity measure ( CSM ) , which estimates a one-to-many relation , such as superordinate–subordinate relations ( Hagita and Sawaki 1995 , Yamamoto and Umemura 2002 ) .</sentence>
				<definiendum id="0">CSM</definiendum>
				<definiens id="0">estimates a one-to-many relation , such as superordinate–subordinate relations</definiens>
			</definition>
			<definition id="2">
				<sentence>CSM ) and an alternative similarity measure based on coefficient overlap , to estimate hyperonym relations between words .</sentence>
				<definiendum id="0">CSM</definiendum>
				<definiens id="0">an alternative similarity measure based on coefficient overlap , to estimate hyperonym relations between words</definiens>
			</definition>
			<definition id="3">
				<sentence>According to Yamamoto and Umemura ( 2002 ) , who adopted CSM to classify words , CSM is calculated as follows. ) )</sentence>
				<definiendum id="0">CSM</definiendum>
				<definiens id="0">who adopted CSM to classify words</definiens>
			</definition>
			<definition id="4">
				<sentence>( ) ( ) ( ( ) 2/| ( | 2 dbcadcba nbcadn Yates ++++ −− = Here n is the sum of the number of cooccurring adjectives ; a indicates the number of times the two labels appear together ; b indicates the number of times “label 1” occurs but “label 2” does not ; c is the number of times “label 2” occurs but “label 1” does not ; and d is the number of times neither label occurs .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">the sum of the number of cooccurring adjectives</definiens>
			</definition>
			<definition id="5">
				<sentence>CSM is the deepest , and includes some hierarchies generated by CSM and the Overlap coefficient .</sentence>
				<definiendum id="0">CSM</definiendum>
				<definiens id="0">the deepest , and includes some hierarchies generated by CSM and the Overlap coefficient</definiens>
			</definition>
</paper>

		<paper id="1157">
			<definition id="0">
				<sentence>Ellipsis is a linguistic phenomenon that has received considerable attention , mostly focusing on its interpretation .</sentence>
				<definiendum id="0">Ellipsis</definiendum>
				<definiens id="0">a linguistic phenomenon that has received considerable attention , mostly focusing on its interpretation</definiens>
			</definition>
			<definition id="1">
				<sentence>Decision trees , on the other hand , Precision = No ( correct ellipses found ) No ( all ellipses found ) ( 2 ) F1 = 2£Precision£RecallPrecision+Recall ( 3 ) 2Downloadable from https : //sourceforge.net/projects/maxent/ 3Downloadable from http : //www.nlplab.cn/zhangle/maxent toolkit .</sentence>
				<definiendum id="0">Decision trees</definiendum>
				<definiens id="0">//sourceforge.net/projects/maxent/ 3Downloadable from http : //www.nlplab.cn/zhangle/maxent toolkit</definiens>
			</definition>
			<definition id="2">
				<sentence>* ) ( NP ( -NONE*-1 ) ) ) ) ) ) ) ) ) ) Figure 3 : Missed VPE parse VP which consists only of an empty element .</sentence>
				<definiendum id="0">VPE parse VP</definiendum>
				<definiens id="0">consists only of an empty element</definiens>
			</definition>
			<definition id="3">
				<sentence>The difierences between the two corpora MBL GIS-MaxEnt L-BFGS-MaxEnt Rec Prec F1 Rec Prec F1 Rec Prec F1 Charniak Words + POS 54.00 62.30 57.85 38.66 79.45 52.01 56.66 71.42 63.19 + features 62.66 71.21 66.66 48.00 70.58 57.14 64.66 72.93 68.55 RASP Words + POS 55.92 66.92 60.93 43.42 56.89 49.25 51.63 79.00 62.45 + features 57.23 71.31 63.50 61.84 72.30 66.66 62.74 73.84 67.84 Table 10 : Results on re-parsed data from the Treebank Charniak RASP Algorithm Recall Precision F1 Recall Precision F1 MBL 58.76 63.35 60.97 61.97 71.50 66.39 GIS-MaxEnt 46.22 71.66 56.19 56.58 72.27 63.47 L-BFGS-MaxEnt 63.14 71.82 67.20 64.52 69.85 67.08 Table 12 : Cross-validation on re-parsed Treebank MBL GIS-MaxEnt L-BFGS-MaxEnt Rec Prec F1 Rec Prec F1 Rec Prec F1 Charniak Words + POS 66.50 63.63 65.03 55.00 75.86 63.76 71.00 70.64 70.82 + features 69.00 65.40 67.15 64.00 72.72 68.08 74.00 68.83 71.32 RASP Words + POS 61.92 63.21 62.56 64.46 54.04 58.79 65.34 70.96 68.04 + features 71.06 73.29 72.16 73.09 61.01 66.51 70.29 67.29 68.76 Table 13 : Results on parsed data from the BNC Charniak RASP Algorithm Recall Precision F1 Recall Precision F1 MBL 68.46 66.94 67.69 69.26 73.06 71.11 GIS-MaxEnt 61.75 72.63 66.75 67.49 72.37 69.84 L-BFGS-MaxEnt 71.10 71.96 71.53 70.68 72.22 71.44 Table 15 : Cross-validation on parsed BNC MBL GIS-MaxEnt L-BFGS-MaxEnt Rec Prec F1 Rec Prec F1 Rec Prec F1 Charniak Words + POS 62.28 69.20 65.56 54.28 77.86 63.97 65.14 69.30 67.15 + features 65.71 71.87 68.65 63.71 72.40 67.78 70.85 69.85 70.35 RASP Words + POS 63.61 67.47 65.48 59.31 55.94 57.37 57.46 71.83 63.84 + features 68.48 69.88 69.17 67.61 71.47 69.48 70.14 72.17 71.14 Table 16 : Results on parsed data using the combined dataset Charniak RASP Algorithm Recall Precision F1 Recall Precision F1 MBL 66.37 68.57 67.45 68.21 73.62 70.81 GIS-MaxEnt 61.43 74.53 67.35 66.22 72.46 69.20 L-BFGS-MaxEnt 69.78 71.65 70.70 71.00 73.22 72.09 Table 17 : Cross-validation on combined dataset may also limit the relevance of examples from one to the other .</sentence>
				<definiendum id="0">Treebank Charniak RASP Algorithm Recall Precision F1 Recall Precision</definiendum>
				<definiens id="0">Results on parsed data from the BNC Charniak RASP Algorithm Recall Precision F1 Recall Precision F1</definiens>
			</definition>
</paper>

		<paper id="1138">
			<definition id="0">
				<sentence>The news corpus consists of a daily average of 3350 English news items , 2100 German , 870 Italian , 800 French and 530 Spanish articles , coming from over three hundred different internet sources .</sentence>
				<definiendum id="0">news corpus</definiendum>
			</definition>
			<definition id="1">
				<sentence>Eurovoc is a widecoverage classification scheme with approximately 6000 hierarchically organised classes .</sentence>
				<definiendum id="0">Eurovoc</definiendum>
				<definiens id="0">a widecoverage classification scheme with approximately 6000 hierarchically organised classes</definiens>
			</definition>
</paper>

		<paper id="1106">
</paper>

		<paper id="1195">
			<definition id="0">
				<sentence>WordNet is a lexical ontology , and ultimately , ontologies derive a large part of their functionality from their structure .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a lexical ontology , and ultimately , ontologies derive a large part of their functionality from their structure</definiens>
			</definition>
			<definition id="1">
				<sentence>Systematicity is a related issue that arises when a group of existing compounds suggests that another should also exist for the ontology to be consistent .</sentence>
				<definiendum id="0">Systematicity</definiendum>
				<definiens id="0">a related issue that arises when a group of existing compounds suggests that another should also exist for the ontology to be consistent</definiens>
			</definition>
			<definition id="2">
				<sentence>Novelty can be measured along either a psychological or a historical dimension , while utility is a reflection of the uses to which a compound can be put .</sentence>
				<definiendum id="0">Novelty</definiendum>
			</definition>
			<definition id="3">
				<sentence>WordNet is a rich source of explicit antonymous oppositions , but contextual oppositions must be inferred from the structure of the ontology itself and from existing compounds .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a rich source of explicit antonymous oppositions , but contextual oppositions must be inferred from the structure of the ontology itself and from existing compounds</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , while Greek-alphabet is a LMH ( it literally is a kind of alphabet , and it is literally Greek ) , neither monkey-bread ( which is not literally a kind of bread ) nor Dutch-courage ( which is not literally Dutch ) is a LMH concept .</sentence>
				<definiendum id="0">Greek-alphabet</definiendum>
				<definiens id="0">a kind of alphabet</definiens>
			</definition>
			<definition id="5">
				<sentence>We thus define the relative affinity between two modifier terms c 1 and c 2 as follows : A rel ( c 1 , c 2 ) = | { x  D : c 1  x  c 2  x } | ( 2 ) / | { x  D : c 1  x  c 2  x } | A relative affinity of 1.0 means that both terms differentiate exactly the same concepts in WordNet .</sentence>
				<definiendum id="0">rel</definiendum>
				<definiens id="0">c 1  x  c 2  x } | A relative affinity of 1.0 means that both terms differentiate exactly the same concepts in WordNet</definiens>
			</definition>
</paper>

		<paper id="1191">
			<definition id="0">
				<sentence>This is followed by a comparison to related work in Section In development since 1984 , the Cyc knowledge base ( Lenat , 1995 ) is the world’s largest formalized representation of commonsense knowledge , containing over 120,000 concepts and more than a million axioms .</sentence>
				<definiendum id="0">Cyc knowledge base</definiendum>
				<definiens id="0">the world’s largest formalized representation of commonsense knowledge , containing over 120,000 concepts and more than a million axioms</definiens>
			</definition>
			<definition id="1">
				<sentence>Brill uses an error-driven transformationbased learning approach that learns lists for transforming the initial tags assigned to the sentence .</sentence>
				<definiendum id="0">Brill</definiendum>
				<definiens id="0">uses an error-driven transformationbased learning approach that learns lists for transforming the initial tags assigned to the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Cyc : A large-scale investment in knowledge infrastructure .</sentence>
				<definiendum id="0">Cyc</definiendum>
				<definiens id="0">A large-scale investment in knowledge infrastructure</definiens>
			</definition>
</paper>

		<paper id="1169">
</paper>

		<paper id="1151">
			<definition id="0">
				<sentence>A parallel corpus is a sentence-aligned corpus containing bilingual translations of the same document .</sentence>
				<definiendum id="0">parallel corpus</definiendum>
				<definiens id="0">a sentence-aligned corpus containing bilingual translations of the same document</definiens>
			</definition>
			<definition id="1">
				<sentence>The Hong Kong Laws Corpus is a parallel corpus with sentence level alignment ; and is used as a parallel sentence resource for statistical machine translation systems .</sentence>
				<definiendum id="0">Hong Kong Laws Corpus</definiendum>
				<definiens id="0">a parallel corpus with sentence level alignment</definiens>
			</definition>
			<definition id="2">
				<sentence>On the other hand , a quasi-comparable corpus is one that contains non-aligned , and non-translated bilingual documents that could either be on the same topic ( in-topic ) or not ( off-topic ) .</sentence>
				<definiendum id="0">topic</definiendum>
				<definiens id="0">one that contains non-aligned , and non-translated bilingual documents that could either be on the same</definiens>
			</definition>
			<definition id="3">
				<sentence>TDT3 Corpus is a good source of truly non-parallel and quasi-comparable corpus .</sentence>
				<definiendum id="0">TDT3 Corpus</definiendum>
				<definiens id="0">a good source of truly non-parallel and quasi-comparable corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>Lexical alignment score is then defined as the sum of the mutual information score of all word pairs that appear in the corpus : ∑ = = ) , ( ) , ( ) ( ) ( ) , ( ) , ( ec WWall ec ec ec ec WWSS WfWf WWf WWS where f ( W c , W e ) is the co-occurrence frequency of bilexicon pair ( W c , W e ) in the aligned sentence pairs .</sentence>
				<definiendum id="0">Lexical alignment score</definiendum>
				<definiendum id="1">f ( W c , W e )</definiendum>
				<definiens id="0">the sum of the mutual information score of all word pairs that appear in the corpus : ∑ = = ) , ( ) , ( ) ( ) ( ) , ( )</definiens>
			</definition>
			<definition id="5">
				<sentence>We evaluated different combinations of term weighting of each word in the corpus : term freuency ( tf ) , inverse document frequency ( idf ) , tf .</sentence>
				<definiendum id="0">term freuency</definiendum>
				<definiendum id="1">inverse document frequency</definiendum>
				<definiens id="0">term weighting of each word in the corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>Augusto Pinochet ( transliteration ) 奋进号 Space Shuttle Endeavor ( translation ) 奥委会 Olympic Committee ( translation ) 内塔尼亚Benjamin Netanyahu ( transliteration ) This step replaces the original corpus by the set of documents that are found to contain at least one pair of parallel sentences .</sentence>
				<definiendum id="0">transliteration</definiendum>
				<definiens id="0">the original corpus by the set of documents that are found to contain at least one pair of parallel sentences</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>“No parse” denotes pse’s in sentences where the parse failed , and so the part of speech could not be determined .</sentence>
				<definiendum id="0">“No parse”</definiendum>
			</definition>
			<definition id="1">
				<sentence>They define an opinion as “a sentence , or part of a sentence that would answer the question ‘How does X feel about Y ? ’ ”</sentence>
				<definiendum id="0">question ‘How</definiendum>
				<definiens id="0">an opinion as “a sentence , or part of a sentence that would answer the</definiens>
			</definition>
			<definition id="2">
				<sentence>“Lin” is Lin’s dependency score , “perf” is the fraction of sentences whose structure was identified perfectly , and “bin” is the performance of the binary classifier ( broken down for positive and negative instances ) .</sentence>
				<definiendum id="0">“bin”</definiendum>
				<definiens id="0">Lin’s dependency score</definiens>
			</definition>
			<definition id="3">
				<sentence>“Size” is the number of sentences or pse pairs .</sentence>
				<definiendum id="0">“Size”</definiendum>
			</definition>
			<definition id="4">
				<sentence># pse’s # sents heurOne heurTwo decTree 3 1810 70.88 % 75.41 % 81.82 % 4 778 59.17 % 67.82 % 74.38 % 5 239 53.87 % 61.92 % 68.93 % &gt; 5 113 49.31 % 58.03 % 68.68 % Table 4 : Performance by number of pse’s per sentence method evaluated on the entire corpus ( “Lin” ) issummationtext s∈S | { pse|pse∈Non writer pseprimes ( s ) ∧parent ( pse ) =autopar ( pse ) ) } | |Non writer pseprimes ( s ) | |S| , where S is the set of all sentences in the corpus , Non writer pseprimes ( s ) is the set of non-writer pse’s in sentence s , parent ( pse ) is the correct parent of pse , and autopar ( pse ) is the automatically identified parent of pse .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">s )</definiendum>
				<definiendum id="2">parent ( pse )</definiendum>
				<definiendum id="3">autopar</definiendum>
				<definiens id="0">Performance by number of pse’s per sentence method evaluated on the entire corpus ( “Lin” ) issummationtext s∈S | { pse|pse∈Non writer pseprimes ( s ) ∧parent ( pse ) =autopar ( pse ) ) } | |Non writer pseprimes ( s ) | |S| , where</definiens>
				<definiens id="1">the set of all sentences in the corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>The “perf” metric measures the fraction of sentences whose structure is determined entirely correctly ( i.e. “perf”ectly ) .</sentence>
				<definiendum id="0">“perf” metric</definiendum>
				<definiens id="0">measures the fraction of sentences whose structure is determined entirely correctly</definiens>
			</definition>
			<definition id="6">
				<sentence>“Bin” is the accuracy of the binary classifier ( with a 0.5 threshold ) on the instances created from the test corpus .</sentence>
				<definiendum id="0">“Bin”</definiendum>
				<definiens id="0">the accuracy of the binary classifier ( with a 0.5 threshold ) on the instances created from the test corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>We compare the learning-based approach ( decTree ) to the heuristic-based approaches introduced in Section 3 — heurOne assumes that all pse’s are attached to the writer’s implicit pse ; heurTwo is the parse-based heuristic that relies solely on the dominance relation13 .</sentence>
				<definiendum id="0">heurTwo</definiendum>
				<definiens id="0">the learning-based approach ( decTree ) to the heuristic-based approaches introduced in Section 3 — heurOne assumes that all pse’s are attached to the writer’s implicit pse ;</definiens>
				<definiens id="1">the parse-based heuristic that relies solely on the dominance relation13</definiens>
			</definition>
</paper>

		<paper id="1152">
			<definition id="0">
				<sentence>The minimum description length principle ( Barron et al. , 1998 ) is an information-theoretic criterion to prefer that model for observed data which gives a minimal length coding of the observed data set ( given the model ) together with the model itself .</sentence>
				<definiendum id="0">minimum description length principle</definiendum>
				<definiens id="0">an information-theoretic criterion to prefer that model for observed data which gives a minimal length coding of the observed data set ( given the model ) together with the model itself</definiens>
			</definition>
			<definition id="1">
				<sentence>This gives the local heuristic formula : ∆CODE1ap ( M ) = 1 + |Sp −M| −α|Sp ∩M| where α is a tunable parameter determining the relative weights of the two factors .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">a tunable parameter determining the relative weights of the two factors</definiens>
			</definition>
			<definition id="2">
				<sentence>where b is the number of bits needed to represent a character and len ( m ) is the length of m in characters .</sentence>
				<definiendum id="0">b</definiendum>
				<definiens id="0">the number of bits needed to represent a character and len</definiens>
				<definiens id="1">the length of m in characters</definiens>
			</definition>
			<definition id="3">
				<sentence>The coding cost CODE ( Data|M ) of the corpus given the dictionary is simply the total number of bits to encode the data using M’s code : CODE2 ( Data|M ) = CODE ( M ( Data ) = M1 ... N ) = −summationtextNi=1 logP ( mi ) = −summationtext|M|j=1C ( mj ) logP ( mj ) = −summationtext|M|j=1C ( mj ) ( logC ( mj ) − logN ) where M ( Data ) is the corpus segmented according to M , N is the number of morph tokens in the segmented corpus , mi is the ith morph token in that segmentation , P ( m ) is the probability of morph m in the corpus estimated as P ( m ) = C ( m ) /N , C ( m ) is the number of times morph m appears in the corpus , |M| is the total number of morph types in M , and mj is the jth morph type in the M. Now suppose we wish to add a new morph to M by resegmenting on a prefix p from all morphs sharing that prefix , as above .</sentence>
				<definiendum id="0">coding cost CODE</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">|M|</definiendum>
				<definiendum id="3">mj</definiendum>
				<definiens id="0">Data|M ) of the corpus given the dictionary is simply the total number of bits to encode the data using M’s code : CODE2 ( Data|M ) = CODE ( M ( Data ) = M1 ... N ) = −summationtextNi=1 logP ( mi ) = −summationtext|M|j=1C ( mj ) logP ( mj ) = −summationtext|M|j=1C ( mj ) ( logC ( mj ) − logN ) where M ( Data ) is the corpus segmented according to M</definiens>
				<definiens id="1">the number of morph tokens in the segmented corpus , mi is the ith morph token in that segmentation</definiens>
				<definiens id="2">the probability of morph m in the corpus estimated as P ( m ) = C ( m ) /N</definiens>
				<definiens id="3">the number of times morph m appears in the corpus</definiens>
				<definiens id="4">the total number of morph types in M</definiens>
			</definition>
			<definition id="4">
				<sentence>Next , add a code for each occurrence of the new morph created by the prefix : −C ( vk ) log ˆP ( p ) , where ˆP ( p ) = B ( p ) / ( N + B ( p ) ) is the probability of morph p in the resegmented corpus .</sentence>
				<definiendum id="0">ˆP</definiendum>
				<definiendum id="1">ˆP</definiendum>
				<definiens id="0">the probability of morph p in the resegmented corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>Finally , code the continuations sk : −C ( vk ) log ˆP ( sk ) ( where ˆP ( sk ) = ˆC ( sk ) ˆN = C ( vk ) +C ( sk ) ˆN is the probability of the ‘new’ morph sk ) .</sentence>
				<definiendum id="0">log ˆP</definiendum>
				<definiendum id="1">ˆP</definiendum>
				<definiens id="0">the probability of the ‘new’ morph sk )</definiens>
			</definition>
			<definition id="6">
				<sentence>The first , which we term the main suffix trie ( MST ) , is a suffix trie ( Gusfield , 1997 ) for all the words in the corpus .</sentence>
				<definiendum id="0">MST</definiendum>
				<definiens id="0">a suffix trie ( Gusfield , 1997 ) for all the words in the corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>Each node in the MST represents either the prefix of a current morph ( initially , a word in the corpus ) , or the prefix of a potential morph ( in case its preceding prefix gets segmented ) .</sentence>
				<definiendum id="0">MST</definiendum>
				<definiens id="0">either the prefix of a current morph ( initially , a word in the corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>The second trie , the reversed prefix trie ( RPT ) , contains all the words in the corpus in reverse .</sentence>
				<definiendum id="0">RPT</definiendum>
				<definiens id="0">contains all the words in the corpus in reverse</definiens>
			</definition>
			<definition id="9">
				<sentence>The complexity for resegmenting on p is O ( len ( p ) + summationdisplay sk∈Sp len ( sk ) + NSUF ( Sp ) log ( |M| ) ) where NSUF ( Sp ) is the number of different morphs in the previous dictionary that have a suffix in Sp ( which need to be updated in the heap ) .</sentence>
				<definiendum id="0">NSUF</definiendum>
				<definiens id="0">the number of different morphs in the previous dictionary that have a suffix in Sp ( which need to be updated in the heap )</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>For example , the input sentence , ”This is a medium size jacket I think it’s a good size for you try it on please” 1 can be split into three portions , ”This is a medium size jacket” , ”I think it’s a good size for you” and ”try it on please” .</sentence>
				<definiendum id="0">”This</definiendum>
				<definiendum id="1">”This</definiendum>
				<definiens id="0">a medium size jacket”</definiens>
			</definition>
			<definition id="1">
				<sentence>The probability of a sentence-splitting , Prob , is defined as the product of the probabilities of the sub-sentences in equation ( 1 ) , where P is the probability of a sentence based on an NLM , S is a sentence-splitting , that is , a list of sub-sentences that are portions of a sentence , and P is applied to the sub-sentences .</sentence>
				<definiendum id="0">probability of a sentence-splitting , Prob ,</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">P</definiendum>
				<definiens id="0">the product of the probabilities of the sub-sentences in equation ( 1 ) , where P is the probability of a sentence based on an NLM ,</definiens>
				<definiens id="1">a sentence-splitting , that is , a list of sub-sentences that are portions of a sentence , and</definiens>
			</definition>
			<definition id="2">
				<sentence>In this equation , L is the word count of the corresponding sentence .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">the word count of the corresponding sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Sem is the division of K ( the level of the least common abstraction in the thesaurus of two words ) by N ( the height of the thesaurus ) according to equation ( 3 ) ( Sumita and Iida , 1991 ) .</sentence>
				<definiendum id="0">Sem</definiendum>
			</definition>
			<definition id="4">
				<sentence>Sim 0 ( s 1 , s 2 ) =1− I + D +2 summationtext Sem L s 1 + L s 2 ( 2 ) Sem = K N ( 3 ) Using Sim 0 , the similarity of a sentencesplitting to a corpus is defined as Sim in equation ( 4 ) .</sentence>
				<definiendum id="0">Sim 0</definiendum>
			</definition>
			<definition id="5">
				<sentence>In this equation , S is a sentence-splitting and C is a given corpus that is a set of sentences .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">a sentence-splitting and</definiens>
				<definiens id="1">a given corpus that is a set of sentences</definiens>
			</definition>
			<definition id="6">
				<sentence>Sim is a mean similarity of sub-sentences against the corpus weighted with the length of each subsentence .</sentence>
				<definiendum id="0">Sim</definiendum>
				<definiens id="0">a mean similarity of sub-sentences against the corpus weighted with the length of each subsentence</definiens>
			</definition>
			<definition id="7">
				<sentence>Sim ( S ) = summationtext s∈S L s · max { Sim 0 ( s , c ) |c ∈ C } summationtext s∈S L s ( 4 ) Candidates To calculate Sim is similar to retrieving the most similar sentence from a corpus .</sentence>
				<definiendum id="0">Sim</definiendum>
				<definiens id="0">similar to retrieving the most similar sentence from a corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>HPAT translates an input sentence by combining phrases .</sentence>
				<definiendum id="0">HPAT</definiendum>
			</definition>
			<definition id="9">
				<sentence>We used Japanese-and-English parallel corpora , i.e. , a Basic Travel Expression Corpus ( BTEC ) and a bilingual travel conversation corpus of Spoken Language ( SLDB ) for training , and English sentences in Machine-Translation-Aided bilingual Dialogues ( MAD ) for a test set ( Takezawa and Kikui , 2003 ) .</sentence>
				<definiendum id="0">MAD</definiendum>
				<definiens id="0">a Basic Travel Expression Corpus ( BTEC ) and a bilingual travel conversation corpus of Spoken Language ( SLDB ) for training , and English sentences in Machine-Translation-Aided bilingual Dialogues</definiens>
			</definition>
			<definition id="10">
				<sentence>BTEC is a collection of Japanese sentences and their English translations usually found in phrase-books for foreign tourists .</sentence>
				<definiendum id="0">BTEC</definiendum>
				<definiens id="0">a collection of Japanese sentences and their English translations usually found in phrase-books for foreign tourists</definiens>
			</definition>
			<definition id="11">
				<sentence>The average length of the 237 sentences was 12.79 words original P 1 S 0 P 1/2 S 1/2 P 1/3 S 2/3 P 1/4 S 3/4 P 0 S 1 # of split sentences 0 237 236 236 235 233 BLEU 0.2979 0.3179 0.3201 0.3192 0.3193 0.3172 NIST 7.1030 7.2616 7.2618 7.2709 7.2748 7.2736 mWER 0.5828 0.5683 0.5665 0.5666 0.5658 0.5703 HPAT SM +6.9 % +8.7 % +10.1 % +10.1 % +9.5 % # of wins 89 95 99 99 104 # of defeats 54 51 48 48 56 # of draws 94 90 89 88 73 BLEU 0.2992 0.3702 0.3704 0.3685 0.3695 0.3705 NIST 2.1302 5.7809 5.8524 5.9115 5.9786 6.2545 mWER 0.5844 0.5432 0.5433 0.5434 0.5424 0.5440 D 3 SM +20.6 % +21.8 % +21.8 % +22.4 % +23.0 % # of wins 141 145 145 146 151 # of defeats 37 35 35 33 35 # of draws 59 56 56 56 47 Table 2 : MT Quality : Using splitting vs. not using splitting , on the test set of 505 sentences ( P indicates Proband S indicates Sim ) per sentence .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">indicates Proband S indicates Sim ) per sentence</definiens>
			</definition>
			<definition id="12">
				<sentence>The NIST score uses information weights when comparing the result of an MT system and reference translations .</sentence>
				<definiendum id="0">NIST score</definiendum>
				<definiens id="0">uses information weights when comparing the result of an MT system and reference translations</definiens>
			</definition>
</paper>

		<paper id="1186">
			<definition id="0">
				<sentence>2 Dependency Bank ( DepBank ) In this section , we describe the corpus that we automatically created using the syntactic annotations of the Penn TreeBank with the semantic annotations of the PropBank .</sentence>
				<definiendum id="0">Dependency Bank ( DepBank</definiendum>
				<definiens id="0">annotations of the Penn TreeBank with the semantic annotations of the PropBank</definiens>
			</definition>
</paper>

		<paper id="1132">
			<definition id="0">
				<sentence>Word sense disambiguation ( WSD ) is the process of selecting the appropriate meaning or sense for a given word in a document .</sentence>
				<definiendum id="0">Word sense disambiguation ( WSD</definiendum>
				<definiens id="0">the process of selecting the appropriate meaning or sense for a given word in a document</definiens>
			</definition>
			<definition id="1">
				<sentence>Obviously , WSD is one of the fundamental and important processes needed for many natural language processing ( NLP ) applications .</sentence>
				<definiendum id="0">WSD</definiendum>
			</definition>
			<definition id="2">
				<sentence>• ( B case ; B noun ) A pair of the base forms of a case marker ( B case ) and a case filler noun ( B noun ) when the target word is a verb .</sentence>
				<definiendum id="0">B noun</definiendum>
				<definiens id="0">a verb</definiens>
			</definition>
			<definition id="3">
				<sentence>• ( B case ; C noun ) A pair of the base form of a case marker ( B case ) and the semantic class of a case filler noun ( C noun ) when the target word is a verb .</sentence>
				<definiendum id="0">C noun</definiendum>
				<definiens id="0">a verb</definiens>
			</definition>
			<definition id="4">
				<sentence>3 ChaSen is the Japanese morphological analyzer .</sentence>
				<definiendum id="0">ChaSen</definiendum>
			</definition>
			<definition id="5">
				<sentence>As all we want to do is to choose an s prime which maximizes ( 4 ) , P ( F ) can be eliminated : s prime =argmax s P ( s ) P ( F|c ) P ( F ) ( 5 ) =argmax s P ( s ) P ( F|c ) ( 6 ) Finally , by the Naive Bayes assumption , that is all features in F are conditionally independent , Equation ( 6 ) can be approximated as follows : s prime =argmax s P ( s ) productdisplay f i ∈F P ( f i |c ) ( 7 ) In ( 7 ) , P ( s ) is the prior probability of a sense s which reflects statistics of the appearance of senses , while P ( f i |c ) is the posterior probability which reflects collocation statistics between an individual feature f i and a hypernym c.The parameters of these probabilistic models can be estimated from the word sense-tagged corpus .</sentence>
				<definiendum id="0">P ( f</definiendum>
				<definiens id="0">s prime =argmax s P ( s ) P ( F|c ) P ( F ) ( 5 ) =argmax s P ( s ) P ( F|c ) ( 6 ) Finally , by the Naive Bayes assumption , that is all features in F are conditionally independent , Equation ( 6 ) can be approximated as follows : s prime =argmax s P ( s ) productdisplay</definiens>
				<definiens id="1">the prior probability of a sense s which reflects statistics of the appearance of senses</definiens>
				<definiens id="2">reflects collocation statistics between an individual feature f i and a hypernym c.The parameters of these probabilistic models can be estimated from the word sense-tagged corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>In order to apply our model for multiple hypernyms , we must consider the probabilistic model P ( s , C|F ) instead of Equation ( 1 ) , where C is a set of hypernyms .</sentence>
				<definiendum id="0">C</definiendum>
			</definition>
</paper>

		<paper id="1068">
			<definition id="0">
				<sentence>The posting frequency of a word is the number of postings where the word is used .</sentence>
				<definiendum id="0">posting frequency of a word</definiendum>
				<definiens id="0">the number of postings where the word is used</definiens>
			</definition>
			<definition id="1">
				<sentence>In our experiments it is calculated as TFa1a3a2a5a4a7a6a9a8a11a10a13a12a15a14a17a16a18a1a3a2a20a19a22a21a24a23 and IDFa1a25a4a26a6a9a8a11a10a27a12a11a14a29a28a31a30a33a32a34a1a35a23 , where a16 a1a3a2 is the frequency of word a36 in document a37 , a32 a1 is the number of documents where word a36 appears , and a28 is the total number of documents in the dataset .</sentence>
				<definiendum id="0">a16 a1a3a2</definiendum>
				<definiendum id="1">a28</definiendum>
				<definiens id="0">the frequency of word a36 in document a37 , a32 a1 is the number of documents where word a36 appears , and</definiens>
				<definiens id="1">the total number of documents in the dataset</definiens>
			</definition>
			<definition id="2">
				<sentence>The clustering procedure is evaluated using two main measures : ( 1 ) the number of newsgroups that were matched by the generated clusters ( between 1 and a38 ) , and ( 2 ) the F-score of the pooled clusters .</sentence>
				<definiendum id="0">clustering procedure</definiendum>
				<definiens id="0">the number of newsgroups that were matched by the generated clusters</definiens>
			</definition>
			<definition id="3">
				<sentence>hp ( 2 clusters , 1162 documents , P=0.97 , R=0.93 , F=0.95 ) lprng , connected , linuxprinting.org , kernel , red , psc , hat , configure , unable , configuration , configured , parallel , ljet , printtool , series , database , jobs , gimp-print , debian , entry , suse , cupsomatic , officejet , cat , perfectly , jetdirect , duplex , devices , kde , happens tex ( 1 cluster , 1040 documents , P=0.98 , R=0.91 , F=0.95 ) arseneau , ctan , fairbairns , style , miktex , pdflatex , faq , chapter , apr , symbols , dvips , figures , title , include , math , bibtex , kastrup , university , examples , english , dvi , peter , plain , documents , contents , written , e.g , macro , robin , donald photoshop ( 2 clusters , 1287 documents , P=0.88 , R=0.98 , F=0.93 ) tacit , james , gifford , folder , rgb , pictures , created , colors , tutorials , illustrator , window , tom , mask , money , whatever , newsgroup , drive , brush , plugin , professional , stafford , view , menu , palette , channel , graphic , pixel , ram , tutorial , paint Table 3 : Top 30 centroid words found by the clustering procedure with filtering .</sentence>
				<definiendum id="0">psc</definiendum>
				<definiendum id="1">officejet</definiendum>
				<definiens id="0">fairbairns , style , miktex , pdflatex , faq , chapter , apr , symbols , dvips , figures , title , include , math , bibtex , kastrup , university , examples , english , dvi , peter , plain , documents , contents , written</definiens>
				<definiens id="1">james , gifford , folder , rgb , pictures , created , colors , tutorials , illustrator , window , tom , mask , money , whatever , newsgroup , drive , brush , plugin , professional , stafford , view , menu , palette , channel , graphic , pixel , ram , tutorial , paint Table 3 : Top 30 centroid words found by the clustering procedure with filtering</definiens>
			</definition>
			<definition id="4">
				<sentence>The retrieval performance of the matching cluster filter hp tex photoshop Query 1 : letter backend ( total 25 ) off 0.87 ( 0.32 ) 0.07 ( 0.23 ) 0.06 ( 0.22 ) on 0.93 ( 0.10 ) 0.05 ( 0.10 ) 0.02 ( 0.03 ) Query 2 : compile miktex ( total 21 ) off 0.20 ( 0.32 ) 0.67 ( 0.36 ) 0.13 ( 0.27 ) on 0.00 ( 0.01 ) 0.99 ( 0.06 ) 0.01 ( 0.06 ) Query 3 : rgb colour ( total 22 ) off 0.20 ( 0.21 ) 0.11 ( 0.24 ) 0.69 ( 0.30 ) on 0.15 ( 0.14 ) 0.02 ( 0.12 ) 0.83 ( 0.19 ) Table 4 : Queries used to evaluate the retrieval task .</sentence>
				<definiendum id="0">letter backend</definiendum>
				<definiens id="0">Queries used to evaluate the retrieval task</definiens>
			</definition>
			<definition id="5">
				<sentence>Web document clustering : A feasibility demonstration .</sentence>
				<definiendum id="0">Web document clustering</definiendum>
				<definiens id="0">A feasibility demonstration</definiens>
			</definition>
</paper>

		<paper id="1113">
			<definition id="0">
				<sentence>Nevertheless , the UML has been a perfect starting point for the endeavour of developing an adequate modeling language for verbal semantics , because on a coarse level of granularity the UML itself supports cognitive modeling in the sense that it allows to model software requirements , without going too deep into implementational issues in the beginning .</sentence>
				<definiendum id="0">UML</definiendum>
				<definiens id="0">granularity the UML itself supports cognitive modeling in the sense that it allows to model software requirements</definiens>
			</definition>
			<definition id="1">
				<sentence>In addition to de ning new modeling elements for the UER ( and adapting UML ones ) , the UML’s division into different modeling views resulting in separate diagrams ( such as class , statechart , activity , or collaboration diagrams , cf. Object Management Group 2003 : I 2 ) 3 is given up in the UER .</sentence>
				<definiendum id="0">UER</definiendum>
				<definiens id="0">such as class , statechart , activity , or collaboration diagrams</definiens>
			</definition>
			<definition id="2">
				<sentence>Instigator is an abstract role description , meaning that it can not be directly instantiated but only by its children ( we employ the object-orientational concept of inheritance at this point ) , namely Agent ( volitional instigator ) or Effector ( involitional instigator ) .</sentence>
				<definiendum id="0">Instigator</definiendum>
				<definiendum id="1">Effector</definiendum>
				<definiens id="0">an abstract role description , meaning that it can not be directly instantiated but only by its children</definiens>
			</definition>
			<definition id="3">
				<sentence>( 1 ) CAUSE ( x , BECOME ( AWAKE ( y ) ) ) ( s ) sides , whereas passive states are shown as rectangles with rounded corners .</sentence>
				<definiendum id="0">CAUSE</definiendum>
				<definiens id="0">AWAKE ( y ) ) ) ( s ) sides , whereas passive states</definiens>
			</definition>
			<definition id="4">
				<sentence>The UER is the rst linguistic representational framework that explicitly accounts for metaconcepts , rendering them graphically and thus fundamentally different from their contents , and displaying different structural concepts with visually different modeling elements .</sentence>
				<definiendum id="0">UER</definiendum>
				<definiens id="0">the rst linguistic representational framework that explicitly accounts for metaconcepts , rendering them graphically and thus fundamentally different from their contents , and displaying different structural concepts with visually different modeling elements</definiens>
			</definition>
			<definition id="5">
				<sentence>Hence , in xing the meta-concepts but not their contents , the UER is a modeling language that can readily accommodate different linguistic facts and allows for adequate recording of language specicity due to its exibility concerning the ‘ lling’ of the meta-concept .</sentence>
				<definiendum id="0">UER</definiendum>
				<definiens id="0">a modeling language that can readily accommodate different linguistic facts and allows for adequate recording of language specicity due to its exibility concerning the ‘ lling’ of the meta-concept</definiens>
			</definition>
			<definition id="6">
				<sentence>It is our hope that the UER is a modeling language that can be universally applied to model verbal semantics because of its general exibility , no matter what natural language’s verbal system is described and what granularity is needed for the semantic descriptions .</sentence>
				<definiendum id="0">UER</definiendum>
				<definiens id="0">a modeling language that can be universally applied to model verbal semantics because of its general exibility , no matter what natural language’s verbal system is described and what granularity is needed for the semantic descriptions</definiens>
			</definition>
			<definition id="7">
				<sentence>In other words , the UER is a practical tool for the study of semantic relationships .</sentence>
				<definiendum id="0">UER</definiendum>
				<definiens id="0">a practical tool for the study of semantic relationships</definiens>
			</definition>
			<definition id="8">
				<sentence>The UER is a rigorous , but cognitively oriented , non-iconic , but intuitive decompositional modeling language both suitable for human and computational usage .</sentence>
				<definiendum id="0">UER</definiendum>
				<definiens id="0">a rigorous , but cognitively oriented , non-iconic , but intuitive decompositional modeling language both suitable for human and computational usage</definiens>
			</definition>
</paper>

		<paper id="1103">
			<definition id="0">
				<sentence>Transliteration model is a knowledge base to support the execution of transliteration strategy .</sentence>
				<definiendum id="0">Transliteration model</definiendum>
				<definiens id="0">a knowledge base to support the execution of transliteration strategy</definiens>
			</definition>
			<definition id="1">
				<sentence>For instance , noisy-channel model ( NCM ) ( Virga et al. , 2003 ; Lee et al. , 2003 ) , HMM ( Sung et al. , 2000 ) , decision tree ( Kang et al. , 2000 ) , transformation-based learning ( Meng et al. , 2001 ) , statistical machine transliteration model ( Lee et al. , 2003 ) , finite state transducers ( Knight et al. , 1998 ) and rule-based approach ( Wan et al. , 1998 ; Oh et al. , 2002 ) .</sentence>
				<definiendum id="0">NCM )</definiendum>
				<definiendum id="1">HMM</definiendum>
			</definition>
			<definition id="2">
				<sentence>Given α and β , the joint probability of ) , , ( γβαP is the probability of alignment γ , which can be formulated as follows : ∏ = − &gt; &lt; &gt; &lt; = = K k k k ceceP PPP 1 1 1 ) , | , ( ) ( * ) | , ( ) , , ( γγβαγβα ( 3 ) In eqn .</sentence>
				<definiendum id="0">γβαP</definiendum>
				<definiens id="0">the probability of alignment γ , which can be formulated as follows : ∏ = − &gt; &lt; &gt; &lt; = = K k k k ceceP PPP 1 1 1 ) , | , ( ) ( * ) |</definiens>
			</definition>
			<definition id="3">
				<sentence>Indeed , NCM consists of two models ; one is the channel model or transliteration model , ∏ = K k kk ceP 1 ) | ( , which tries to estimate the mapping probability between the two units ; DOM Framework Name in Language A Bi-directional Decoder Name in Language B n-gram TM another is the source model or language model , ∏ = − K k kk ccP 1 1 ) | ( , which tries to estimate the generative probability of the Chinese name , given the sequence of Chinese transliteration units .</sentence>
				<definiendum id="0">NCM</definiendum>
				<definiens id="0">consists of two models ; one is the channel model or transliteration model , ∏ = K k kk ceP 1 ) | ( , which tries to estimate the mapping probability between the two units ; DOM Framework Name in Language A Bi-directional Decoder Name in Language B n-gram TM another is the source model or language model , ∏ = − K k kk ccP 1 1 ) | ( , which tries to estimate the generative</definiens>
			</definition>
			<definition id="4">
				<sentence>The character error rate is the sum of deletion , insertion and substitution errors .</sentence>
				<definiendum id="0">character error rate</definiendum>
				<definiens id="0">the sum of deletion , insertion and substitution errors</definiens>
			</definition>
			<definition id="5">
				<sentence>A LM unit is a word itself .</sentence>
				<definiendum id="0">LM unit</definiendum>
				<definiens id="0">a word itself</definiens>
			</definition>
			<definition id="6">
				<sentence>Assuming sufficient training corpus , the modeling approach applies to different language pairs ; 3 ) DOM presents a paradigm shift for machine transliteration , that provides a platform for implementation of many other transliteration models ; The n-gram TM is a successful implementation of DOM framework due to the following aspects : 1 ) N-gram TM captures contextual information in both source and target languages jointly ; unlike the phoneme-based approach , the modeling of transformation rules and target language is tightly coupled in n-gram TM model .</sentence>
				<definiendum id="0">n-gram TM</definiendum>
				<definiens id="0">a successful implementation of DOM framework due to the following aspects : 1 ) N-gram TM captures contextual information in both source and target languages jointly</definiens>
			</definition>
			<definition id="7">
				<sentence>The N-best algorithm : An efficient and Exact procedure for finding the N most likely sentence hypothesis , Proceedings of ICASSP 1990 , Albuquerque , pp .</sentence>
				<definiendum id="0">N-best algorithm</definiendum>
				<definiens id="0">An efficient and Exact procedure for finding the N most likely sentence hypothesis</definiens>
			</definition>
</paper>

		<paper id="1202">
			<definition id="0">
				<sentence>In our current system , every sentence s is represented by five normalized features : • Location of the Paragraph ( P ) : MYP /= ( 1 ) where M is the total number of paragraphs in a document ; Y is the index of the paragraph s belongs to .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">the total number of paragraphs in a document ;</definiens>
			</definition>
			<definition id="1">
				<sentence>• Location of the Sentence ( S ) : NXS /= ( 2 ) where N is the total number of sentences in the paragraph ; X is the index of sentence s. • Length of the Sentence ( L ) : The length of the sentence is the number of words it contained , i.e. , l ( s ) , normalized by Sigmoid function : ) ) ( ( ) ) ( ( ) ( , 1 1 slstd slsl e e L µ α α α − = + − = − − ( 3 ) Where u ( l ( s ) ) is the average length of sentences , and std ( l ( s ) ) is the standard deviation of the sentence lengths .</sentence>
				<definiendum id="0">Sentence ( S )</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">X</definiendum>
				<definiendum id="3">u ( l ( s ) )</definiendum>
				<definiens id="0">the total number of sentences in the paragraph ;</definiens>
				<definiens id="1">the index of sentence s. • Length of the Sentence ( L ) : The length of the sentence is the number of words it contained</definiens>
				<definiens id="2">the average length of sentences</definiens>
				<definiens id="3">the standard deviation of the sentence lengths</definiens>
			</definition>
			<definition id="2">
				<sentence>, ( log [ ) ( ( 5 ) where Freq ( w i ) is the frequency of w i in that document ; µ ( CW ( S ) ) is the mean of all the sentence scores , and std ( CW ( s ) ) is the standard deviation .</sentence>
				<definiendum id="0">µ ( CW</definiendum>
				<definiendum id="1">std ( CW</definiendum>
				<definiens id="0">the mean of all the sentence scores</definiens>
			</definition>
			<definition id="3">
				<sentence>Gene Expression Programming : A New Adaptive Algorithm for solving problems .</sentence>
				<definiendum id="0">Gene Expression Programming</definiendum>
				<definiens id="0">A New Adaptive Algorithm for solving problems</definiens>
			</definition>
			<definition id="4">
				<sentence>Gene Expression Programming : Mathematical Modeling by an Artificial Intelligence .</sentence>
				<definiendum id="0">Gene Expression Programming</definiendum>
				<definiens id="0">Mathematical Modeling by an Artificial Intelligence</definiens>
			</definition>
			<definition id="5">
				<sentence>Columbia Multi-Document Summarization : Approach and Evaluation , in Proceedings of the Document Understanding Conference ( DUC01 ) .</sentence>
				<definiendum id="0">Columbia Multi-Document Summarization</definiendum>
			</definition>
</paper>

		<paper id="1095">
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>Among all possible target language sentences , we will choose the sentence with the highest probability : ˆeI1 = argmax eI1 'Pr ( eI 1jf J 1 ) “ = argmax eI1 'Pr ( eI 1 ) ¢Pr ( f J 1 je I 1 ) “ This decomposition into two knowledge sources allows for an independent modeling of target language model Pr ( eI1 ) and translation model Pr ( fJ1 jeI1 ) .</sentence>
				<definiendum id="0">¢Pr</definiendum>
			</definition>
			<definition id="1">
				<sentence>For its lexicon parameters , the marginal probability of a target word ei to occur at the target sentence position i as the translation of the source word fj at the source sentence position j is estimated with the following sum : pj ( i ; fJ1 jeI1 ) = X aJ1 : aj=i Pr ( fJ1 ; aJ1jeI1 ) This value represents the likelihood of aligning fj to ei via every possible alignment A = aJ1 that includes the alignment connection aj = i. By normalizing over the target sentence positions , we arrive at the state occupation probability : pj ( ijfJ1 ; eI1 ) = pj ( i ; f J1 jeI1 ) IP i0=1 pj ( i0 ; fJ1 jeI1 ) In the M-step of the EM training , the state occupation probabilities are aggregated for all words in the source and target vocabularies by taking the sum over all training sentence pairs .</sentence>
				<definiendum id="0">aJ1jeI1</definiendum>
				<definiendum id="1">f J1 jeI1 ) IP i0=1 pj</definiendum>
			</definition>
			<definition id="2">
				<sentence>For a given alignment A I £ J , we define the costs of this alignment c ( A ) as the sum of the local costs of all aligned word pairs : c ( A ) = X ( i ; j ) 2A cij ( 2 ) Now , our task is to find the alignment with the minimum costs .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">to find the alignment with the minimum costs</definiens>
			</definition>
			<definition id="3">
				<sentence>The French–English Canadian Hansards task consists of the debates in the Canadian Parliament .</sentence>
				<definiendum id="0">French–English Canadian Hansards task</definiendum>
			</definition>
			<definition id="4">
				<sentence>Experimentally , the best generalization heuristic for the Canadian Hansards task is the intersection of the sourceto-target and the target-to-source alignments .</sentence>
				<definiendum id="0">best generalization heuristic</definiendum>
				<definiens id="0">the intersection of the sourceto-target and the target-to-source alignments</definiens>
			</definition>
			<definition id="5">
				<sentence>Table 5 : AER [ % ] for different alignment symmetrization methods and for various alignment models on the Canadian Hansards and the Verbmobil tasks ( MWEC : minimum weight edge cover , EW : empty word ) .</sentence>
				<definiendum id="0">EW</definiendum>
				<definiens id="0">minimum weight edge cover ,</definiens>
				<definiens id="1">empty word )</definiens>
			</definition>
</paper>

		<paper id="1100">
</paper>

		<paper id="1175">
			<definition id="0">
				<sentence>Word segmentation is an important part of many applications , including information retrieval , information filtering , document analysis , and text summarization .</sentence>
				<definiendum id="0">Word segmentation</definiendum>
				<definiens id="0">an important part of many applications , including information retrieval , information filtering , document analysis , and text summarization</definiens>
			</definition>
			<definition id="1">
				<sentence>PPM maintains predictions , computed from the training data , for the largest context ( k ) as well as all shorter contexts in tables , as shown in Table 2 .</sentence>
				<definiendum id="0">PPM</definiendum>
				<definiens id="0">maintains predictions , computed from the training data , for the largest context ( k ) as well as all shorter contexts in tables</definiens>
			</definition>
			<definition id="2">
				<sentence>Thai language consists of 66 distinct characters .</sentence>
				<definiendum id="0">Thai language</definiendum>
				<definiens id="0">consists of 66 distinct characters</definiens>
			</definition>
			<definition id="3">
				<sentence>To handle zero frequency , we use method D ( PPMD ) ( Witten and Bell , 1991 ) where the escape character gets a probability of ( d/2n ) , and the symbol gets a probability of ( 2c-1 ) /2n where n is the total number of symbols seen previously , d is the total number of distinct contexts , and c is the total number of contexts that appear in the string .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">the total number of symbols seen previously</definiens>
				<definiens id="1">the total number of distinct contexts</definiens>
				<definiens id="2">the total number of contexts that appear in the string</definiens>
			</definition>
			<definition id="4">
				<sentence>The final set consists of 35 variables , as shown in Table 5 .</sentence>
				<definiendum id="0">final set</definiendum>
			</definition>
			<definition id="5">
				<sentence>The value of each variable is either 1 or -1 which means either the syllable contains or does not contain that particular character , respectively .</sentence>
				<definiendum id="0">variable</definiendum>
				<definiens id="0">means either the syllable contains or does not contain that particular character , respectively</definiens>
			</definition>
			<definition id="6">
				<sentence>The ZeroFrequency Problem : Estimating the Probabilities of Novel Events in Adaptive Text Compression .</sentence>
				<definiendum id="0">ZeroFrequency Problem</definiendum>
				<definiens id="0">Estimating the Probabilities of Novel Events in Adaptive Text Compression</definiens>
			</definition>
</paper>

		<paper id="1046">
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>durrelTF : relative duration , w.r.t temporal focus ( `` since '' ) .</sentence>
				<definiendum id="0">durrelTF</definiendum>
				<definiens id="0">relative duration , w.r.t temporal focus ( `` since '' )</definiens>
			</definition>
			<definition id="1">
				<sentence>In order to measure these , we propose two elementary comparison functions between two sets of relations S and H , where S is the annotation proposed by the system and H is the annotation inferred from what was proposed by the human .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">H</definiendum>
				<definiens id="0">the annotation proposed by the system</definiens>
				<definiens id="1">the annotation inferred from what was proposed by the human</definiens>
			</definition>
</paper>

		<paper id="1093">
			<definition id="0">
				<sentence>The World Wide Web ( the Web ) , which contains an enormous volume of up-to-date information , is a promising source to obtain new term descriptions .</sentence>
				<definiendum id="0">World Wide Web</definiendum>
				<definiendum id="1">Web )</definiendum>
				<definiens id="0">contains an enormous volume of up-to-date information , is a promising source to obtain new term descriptions</definiens>
			</definition>
			<definition id="1">
				<sentence>Our viewpoint-based summarization ( VBS ) method consists of the following four steps : unit associated with a viewpoint , associated with the same viewpoint into a single group , sentative units for each group , specific format .</sentence>
				<definiendum id="0">viewpoint-based summarization</definiendum>
				<definiendum id="1">VBS ) method</definiendum>
				<definiens id="0">consists of the following four steps : unit associated with a viewpoint , associated with the same viewpoint into a single group , sentative units for each group , specific format</definiens>
			</definition>
			<definition id="2">
				<sentence>XML is an abbreviation for eXtensible Markup Language , and is a markup language .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">an abbreviation for eXtensible Markup Language , and is a markup language</definiens>
			</definition>
			<definition id="3">
				<sentence>• XML is an abbreviation for eXtensible Markup Language .</sentence>
				<definiendum id="0">XML</definiendum>
			</definition>
			<definition id="4">
				<sentence>• ( XML ) is a markup language .</sentence>
				<definiendum id="0">XML )</definiendum>
				<definiens id="0">a markup language</definiens>
			</definition>
			<definition id="5">
				<sentence>( a ) XML is an extensible markup language .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">an extensible markup language</definiens>
			</definition>
			<definition id="6">
				<sentence>→ definition ( b ) an abbreviation for eXtensible Markup Language → abbreviation ( c ) was advised as a standard by W3C in 1998 → history ( d ) XML is an abbreviation for Extensible Markup Language → abbreviation ( e ) the standard of XML was advised by W3C → ? ? ?</sentence>
				<definiendum id="0">abbreviation for eXtensible Markup Language → abbreviation</definiendum>
				<definiendum id="1">XML</definiendum>
				<definiens id="0">an abbreviation for Extensible Markup Language → abbreviation ( e ) the standard of XML was advised</definiens>
			</definition>
			<definition id="7">
				<sentence>• the rank in Cyclone ( R ) As depicted in Figure 2 , Cyclone sorts the retrieved paragraphs according to the plausibility as the description .</sentence>
				<definiendum id="0">Cyclone</definiendum>
				<definiens id="0">sorts the retrieved paragraphs according to the plausibility as the description</definiens>
			</definition>
			<definition id="8">
				<sentence>• definition : XML is an extensible markup language ( eXtensible Markup Language ) .</sentence>
				<definiendum id="0">XML</definiendum>
			</definition>
			<definition id="9">
				<sentence>• advantage : XML is advantageous to developers of the file maker Pro , which needs to receive data from the client .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">advantageous to developers of the file maker Pro , which needs to receive data from the client</definiens>
			</definition>
			<definition id="10">
				<sentence>Utilizing the World Wide Web as an encyclopedia : Extracting term descriptions from semi-structured texts .</sentence>
				<definiendum id="0">Utilizing the World Wide Web</definiendum>
				<definiens id="0">an encyclopedia : Extracting term descriptions from semi-structured texts</definiens>
			</definition>
</paper>

		<paper id="1069">
			<definition id="0">
				<sentence>Information retrieval ( IR ) is used to retrieve relevant documents from a large document set for a given query where the query is a simple description by natural language .</sentence>
				<definiendum id="0">Information retrieval</definiendum>
				<definiendum id="1">IR</definiendum>
				<definiens id="0">a simple description by natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>Traditionally , IR system uses a one-stage or a two-stage mechanism to retrieve relevant documents from document set .</sentence>
				<definiendum id="0">IR system</definiendum>
			</definition>
			<definition id="2">
				<sentence>Suppose r is the reference document set ( reference document set including document set and other statistical large document collection ) , d is a document ( or a document set ) , w is an individual Chinese Character in d , let Pr ( w ) and Pd ( w ) be the probability of w occurring in r and d respectively , we adopt 1 ) , relative probability or salience of w in d with respect to r ( Schutze .</sentence>
				<definiendum id="0">w</definiendum>
				<definiendum id="1">Pd ( w</definiendum>
				<definiens id="0">a document ( or a document set ) ,</definiens>
			</definition>
			<definition id="3">
				<sentence>3 describes the procedure to extract Key Terms from a document ( or document cluster ) d. let Fd ( t ) represents the frequency of t in d ; let N is a given threshold ( N &gt; 1 ) ; K = { } ; collect Seeds in d into S ; for all c∈S { let Q = { t : t contains c and Fd ( t ) ≥N } ; while Q ≠ NIL { max-t ← the longest string in Q ; K ← K + { max-t } ; Remove max-t from Q ; for all other t in Q { if t is a substring of max-t { Fd ( t ) ← Fd ( t ) Fd ( max-t ) ; if Fd ( t ) &lt; N removing t from Q ; } } } } return K as Key Terms in document d ; Fig. 3 Key Term Extraction from document d To acquire Global Key Terms , we first roughly cluster the whole document set r into K ( K &lt; 2000 ) document clusters , then we regard each document cluster as a large document and apply our proposed Key Term Extraction algorithm ( see Fig. 3 ) on each document cluster and respectively get Key Terms in each document cluster. All these Key Terms from document clusters form Global Key Terms. There are many document clustering approaches to cluster document set. K-Means and hierarchical clustering are the two usually used approaches. In our algorithm , we don’t need to use complicated clustering approaches because we only need to roughly cluster document set r into K document clusters. Here we use a simple K-Means approach to cluster document set. Firstly , we pick up randomly 10*K documents from document set r ; secondly , we use K-Means approach to cluster these 10*K documents into K document clusters ; finally , we insert every other document into one of the K document clusters. Fig. 4 describes the general process to cluster document set r into K document clusters. let K is the number of documnet clusters to get ; T←10*K documents randomly pickuped from r ; cluster T into K clusters { Kj } by using K-Means ; for any document d in { r-T } { Ki← document cluster which has the maximal similarity with d ; insert d to document cluster Ki ; } return K document clusters { Kj|1 &lt; =j &lt; =K } ; Fig. 4 Cluster document set r into K clusters Fig. 5 describes the procedure to acquire Global Key Terms from document set r. roughly cluster document set r to K document clusters { Kj|1 &lt; =j &lt; =K } ( See Fig. 4 ) ; G = { } ; for each Kj { extract Key Terms g from Kj ; ( See Fig. 3 ) G ← G + g ; } return G as Global Key Terms in document set r ; Fig. 5 Global Key Terms Acquisition In the processing of Global Key Terms acquisition , the frequency of each Global Key Term is also recorded for further use in identifying Local Key Terms terms in a single document or query. Unlike Global Key Terms , Local Key Terms are not extracted by using Key Term extraction algorithm from single document or query , they are identified based on Global Key Terms and their frequencies. Fig.6 describes the procedure of Local Key Terms acquisition from a single document or query d. Given threshold M ( M &gt; 10 ) , N ( N &gt; 100 ) and document d ; L = { } ; collect Global Key Terms occurred in d and their frequency in document set r into S = &lt; c , tf &gt; ; for all &lt; c , tf &gt; ∈S { if tf &lt; M remove &lt; c , tf &gt; from S ; } ; for all &lt; c , tf &gt; ∈S { if c = c1c2 and &lt; c1 , tf1 &gt; ∈S and &lt; c2 , tf2 &gt; ∈S if ( tf1 &gt; tf *N and tf2 &gt; &gt; tf*N ) remove &lt; c , tf &gt; from S ; } ; while S ≠ NIL { let Q = { &lt; t , tf &gt; : t is the longest string is S } ; find &lt; max-c , max-tf &gt; in Q where max-tf has the maximum value ; remove &lt; max-t , max-tf &gt; from S ; if max-t occurs in d { L ← L + max-t ; remove all occurrance of max_t in d ; for all &lt; b , tf-b &gt; ∈S where b is a substring of max-t ; if tf-b &lt; max-tf remove &lt; b , tf-b &gt; from S ; } } ; return L as Local Key Terms in document d ; Fig .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">K</definiendum>
				<definiendum id="2">max-tf</definiendum>
				<definiendum id="3">b</definiendum>
				<definiens id="0">describes the procedure to extract Key Terms from a document ( or document cluster ) d. let Fd ( t ) represents the frequency of t in d</definiens>
				<definiens id="1">a given threshold ( N &gt; 1 ) ; K = { } ; collect Seeds in d into S ; for all c∈S { let Q = { t : t contains c and Fd ( t ) ≥N } ; while Q ≠ NIL { max-t ← the longest string in Q ; K ← K + { max-t } ; Remove max-t from Q</definiens>
				<definiens id="2">a substring of max-t { Fd ( t ) ← Fd ( t ) Fd ( max-t ) ; if Fd ( t ) &lt; N removing t from Q ; } } } } return K as Key Terms in document d ; Fig. 3 Key Term Extraction from document d To acquire Global Key Terms</definiens>
				<definiens id="3">a large document and apply our proposed Key Term Extraction algorithm ( see Fig. 3 ) on each document cluster and respectively get Key Terms in each document cluster. All these Key Terms from document clusters form Global Key Terms. There are many document clustering approaches to cluster document set. K-Means and hierarchical clustering</definiens>
				<definiens id="4">the general process to cluster document set r into K document clusters. let</definiens>
				<definiens id="5">describes the procedure to acquire Global Key Terms from document set r. roughly cluster document set r to K document clusters { Kj|1 &lt; =j &lt; =K } ( See Fig. 4 ) ; G = { } ; for each Kj { extract Key Terms g from Kj ; ( See Fig. 3 ) G ← G + g ; } return G as Global Key Terms in document set r</definiens>
				<definiens id="6">identified based on Global Key Terms and their frequencies. Fig.6 describes the procedure of Local Key Terms acquisition from a single document or query d. Given threshold M ( M &gt; 10 ) , N ( N &gt; 100 ) and document d ; L = { } ; collect Global Key Terms occurred in d and their frequency in document set r into S = &lt; c</definiens>
			</definition>
			<definition id="4">
				<sentence>Example : Query : a0a1a2a3a4a5a6a7a8a9a10a11a12a13a14a15a5a16a17 a18a19a20a21 ( Find information of the exhibition `` Art and Culture of the Han Dynasty '' in the National Palace Museum ) Global Key Terms occurred in Query and their frequencies in document set : a0a1 ( Cha2 Xun2 ) – 4948 a2a3 ( Gu4 Gong1 ) – 3456 a2a3a4a5a6 ( Gu4 Gong1 Bo2 Wu4 Yuan4 ) – 727 a4a5a6 ( Bo2 Wu4 Yuan4 ) – 772 a6a7 ( Yuan4 Suo3 ) – 2991 a8a9 ( Zhu3 Ban4 ) – 38698 a11a12 ( Qian1 Xi3 ) – 11510 a13a14 ( Han4 Dai4 ) – 411 a13a14a15a5 ( Han4 Dai4 Wen3 Wu4 ) 173 a13a14a15a5a16a17 ( Han4 Dai4 Wen3 Wu4 Da4 Zhan3 ) – 133 a15a5 ( Wen3 Wu4 ) – 7088 a15a5a16a17 ( Wen3 Wu4 Da4 Zhan3 ) – 158 a16a17 ( Da4 Zhan3 ) – 2270 a18a19 ( Xiang3 Guan3 ) – 67990 a18a19a20a21 ( Xiang3 Guan3 Nei3 Rong2 ) – 148 a20a21 ( Nei3 Rong2 ) – 31165 Local Key Terms in Query : a13a14a15a5a16a17 ( Han4 Dai4 Wen3 Wu4 Da4 Zhan3 ) a13a14a15a5 ( Han4 Dai4 Wen3 Wu4 ) a15a5 ( Wen3 Wu4 ) a16a17 ( Da4 Zhan3 ) a2a3a4a5a6 ( Gu4 Gong1 Bo2 Wu4 Yuan4 ) a4a5a6 ( Bo2 Wu4 Yuan4 ) a2a3 ( Gu4 Gong1 ) a18a19 ( Xiang3 Guan3 ) a20a21 ( Nei3 Rong2 ) a8a9 ( Zhu3 Ban4 ) a11a12 ( Qian1 Xi3 ) a0a1 ( Cha2 Xun2 ) From the example , we can see the difference between Global Key Terms and Local Key Terms .</sentence>
				<definiendum id="0">Han4 Dai4 Wen3 Wu4 Da4 Zhan3</definiendum>
				<definiens id="0">Find information of the exhibition `` Art and Culture of the Han Dynasty '' in the National Palace Museum ) Global Key Terms occurred in Query and their frequencies in document set : a0a1 ( Cha2 Xun2</definiens>
			</definition>
			<definition id="5">
				<sentence>PreAt10 is the average precision of 42 queries in precision of top 10 ranking documents , while PreAt100 is the average precision of 42 queries in precision of top 100 ranking documents .</sentence>
				<definiendum id="0">PreAt10</definiendum>
				<definiendum id="1">PreAt100</definiendum>
				<definiens id="0">the average precision of 42 queries in precision of top 100 ranking documents</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>Yaari uses a cosine measure to define segment similarity ( cf. Salton and Buckley , ( 1994 ) ) : a0a2a1a4a3a5a1a7a6a9a8a11a10a12a1a4a13a15a14a17a16a4a18a20a19a22a21a23a18a25a24a27a26a29a28 a30a32a31a34a33 a31a9a35a36a27a37 a33 a31a9a35a36a23a38 a39 a30a40a31 a33a42a41a31a9a35a36a27a37a33a43a41a31a9a35a36a44a38 ( 1 ) Herea13 ranges over the set of terms in the text .</sentence>
				<definiendum id="0">Yaari</definiendum>
				<definiens id="0">uses a cosine measure to define segment similarity ( cf. Salton and Buckley , ( 1994 ) ) : a0a2a1a4a3a5a1a7a6a9a8a11a10a12a1a4a13a15a14a17a16a4a18a20a19a22a21a23a18a25a24a27a26a29a28 a30a32a31a34a33 a31a9a35a36a27a37 a33 a31a9a35a36a23a38 a39 a30a40a31 a33a42a41a31a9a35a36a27a37a33a43a41a31a9a35a36a44a38 ( 1 ) Herea13 ranges over the set of terms in the text</definiens>
			</definition>
			<definition id="1">
				<sentence>Each term is weighted , where a33 a31a9a35a36a27a37 is the weight assigned to term a13 in segment a18a45a19 , defined as the product of three factors : the frequency of the term in the segment , the relative frequency of the term in the text , and the general significance of the term in a corpus ( a46 a0a2a1a48a47 a31 ) : a33 a31a9a35a36a2a37 a28a50a49 a31a9a35a36a2a37a29a51 a49 a31 a49a53a52a55a54a57a56 a51 a46 a0a58a1a48a47 a31 ( 2 ) a46 a0a58a1a48a47 a31 a28a59a6a9a60a27a47a42a61 a61 a31 ( 3 ) In the definition ofa46 a0a58a1a48a47 a31 , a61 is the number of files in the corpus ( Yaari uses the British National Corpus1 ) and a61 a31 is the number of files containing the terma13 .</sentence>
				<definiendum id="0">a33 a31a9a35a36a27a37</definiendum>
				<definiendum id="1">a61</definiendum>
				<definiens id="0">the weight assigned to term a13 in segment a18a45a19 , defined as the product of three factors : the frequency of the term in the segment , the relative frequency of the term in the text , and the general significance of the term in a corpus ( a46 a0a2a1a48a47 a31 ) : a33 a31a9a35a36a2a37 a28a50a49 a31a9a35a36a2a37a29a51 a49 a31 a49a53a52a55a54a57a56 a51 a46 a0a58a1a48a47 a31 ( 2 ) a46 a0a58a1a48a47 a31 a28a59a6a9a60a27a47a42a61 a61 a31</definiens>
				<definiens id="1">the number of files in the corpus ( Yaari uses the British National Corpus1 ) and a61 a31 is the number of files containing the terma13</definiens>
			</definition>
			<definition id="2">
				<sentence>We used a maximum entropy learner ( Ratnaparkhi , 1998 ) to train our model , but any machine learnt classifier that returns a probability distribution over possible outcome ( e.g. merge , don’t merge ) or at least ranks them would be suitable .</sentence>
				<definiendum id="0">maximum entropy learner</definiendum>
				<definiens id="0">but any machine learnt classifier that returns a probability distribution over possible outcome ( e.g. merge , don’t merge</definiens>
			</definition>
			<definition id="3">
				<sentence>A lexical chain is a sequence of semantically related words and can indicate the presence and extent of subtopics in a text .</sentence>
				<definiendum id="0">lexical chain</definiendum>
				<definiens id="0">a sequence of semantically related words and can indicate the presence and extent of subtopics in a text</definiens>
			</definition>
			<definition id="4">
				<sentence>For both types the features encode whether and how many chains : a0 span the two segments a0 exclusively span the two segment ( i.e. start in the left segment and end in the right ) a0 start or end in the left ( right ) segment a0 skip both of the segments a0 exclusively skip the two segments ( i.e. skip both segments but none of the neighbouring segments ) a0 skip one of the two segments a0 exclusively skip the left ( right ) segment To combine all features , we trained a maximum entropy model ( see e.g. Ratnaparkhi ( 1998 ) ) on the training set .</sentence>
				<definiendum id="0">many chains</definiendum>
				<definiens id="0">a0 span the two segments a0 exclusively span the two segment ( i.e. start in the left segment and end in the right ) a0 start or end in the left ( right ) segment a0 skip both of the segments a0 exclusively skip the two segments ( i.e. skip both segments but none of the neighbouring segments ) a0 skip one of the two segments a0 exclusively skip the left</definiens>
			</definition>
			<definition id="5">
				<sentence>Precision ( P ) and recall ( R ) were defined in accordance with the PARSEVAL measures ( Black et al. , 1991 ) , i.e. precision is random RB TO LB ME MEa0 LC MEa0 TO MEa0 LCTO human* P 44.37 % 36.76 % 49.98 % 53.52 % 58.06 % 55.86 % 57.12 % 55.26 % 64.37 % R 46.71 % 40.35 % 52.42 % 56.23 % 60.78 % 58.29 % 59.70 % 57.69 % 64.60 % F 45.05 % 37.58 % 50.79 % 54.27 % 59.00 % 56.66 % 58.00 % 56.07 % 64.34 % Table 1 : Results on RST-DT test set ( * on doubly annotated set ) defined as the number of correct nodes ( i.e. matching brackets ) divided by the number of nodes in the automatically built tree and recall as the number of correct nodes divided by the number of nodes in the manually built tree .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiendum id="2">MEa0 LC MEa0 TO MEa0 LCTO</definiendum>
				<definiens id="0">defined in accordance with the PARSEVAL measures ( Black et al. , 1991 ) , i.e. precision is random RB TO LB ME</definiens>
				<definiens id="1">Results on RST-DT test set ( * on doubly annotated set ) defined as the number of correct nodes ( i.e. matching brackets ) divided by the number of nodes in the automatically built tree and recall as the number of correct nodes divided by the number of nodes in the manually built tree</definiens>
			</definition>
			<definition id="6">
				<sentence>Introduction to WordNet : An on-line lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="1142">
</paper>

		<paper id="1121">
			<definition id="0">
				<sentence>Sentiment classification is a special case of text categorization , where the criterion of classification is the attitude expressed in the text , rather than the “content” or topic .</sentence>
				<definiendum id="0">Sentiment classification</definiendum>
				<definiens id="0">a special case of text categorization</definiens>
				<definiens id="1">the attitude expressed in the text</definiens>
			</definition>
			<definition id="1">
				<sentence>Feature reduction is an important part of optimizing the performance of a ( linear ) classifier by reducing the feature vector to a size that does not exceed the number of training cases as a starting point .</sentence>
				<definiendum id="0">Feature reduction</definiendum>
				<definiens id="0">an important part of optimizing the performance of a ( linear ) classifier by reducing the feature vector to a size that does not exceed the number of training cases as a starting point</definiens>
			</definition>
</paper>

		<paper id="1172">
			<definition id="0">
				<sentence>Emdros is a text database engine for linguistic analysis or annotation of text .</sentence>
				<definiendum id="0">Emdros</definiendum>
				<definiens id="0">a text database engine for linguistic analysis or annotation of text</definiens>
			</definition>
			<definition id="1">
				<sentence>Emdros is a text database engine which attempts to remedy this situation in some measure .</sentence>
				<definiendum id="0">Emdros</definiendum>
				<definiens id="0">a text database engine which attempts to remedy this situation in some measure</definiens>
			</definition>
			<definition id="2">
				<sentence>Emdros is a general-purpose engine , not a speci c application .</sentence>
				<definiendum id="0">Emdros</definiendum>
				<definiens id="0">a general-purpose engine , not a speci c application</definiens>
			</definition>
			<definition id="3">
				<sentence>The EMdF ( Extended MdF ) model is based on four concepts : Monad , object , object type , and feature .</sentence>
				<definiendum id="0">EMdF</definiendum>
				<definiens id="0">based on four concepts : Monad , object , object type , and feature</definiens>
			</definition>
			<definition id="4">
				<sentence>The WI database is a large text database comprising a syntactic analysis of the Hebrew Bible ( also called the Old Testament in Hebrew and Aramaic ) .</sentence>
				<definiendum id="0">WI database</definiendum>
			</definition>
			<definition id="5">
				<sentence>Thus Emdros provides a solid platform on which to build applications in corpus linguistics , capable of answering linguistic questions of a complexity higher than what most systems can offer today .</sentence>
				<definiendum id="0">Emdros</definiendum>
				<definiens id="0">provides a solid platform on which to build applications in corpus linguistics</definiens>
			</definition>
</paper>

		<paper id="1036">
			<definition id="0">
				<sentence>A feature is defined as a pair &lt; term , syntacCountryState Ranks CountryEconomy Ranks Broadcast Goods Civil_servant Bloc Nonaligned Neighboring Statistic Border Northwest 24 140 64 30 55 15 165 10 41 50 16 54 77 60 165 43 247 174 Devastate Developed Dependent Industrialized Shattered Club Black Million Electricity 81 36 101 49 16 155 122 31 130 8 78 26 85 141 38 109 245 154 Table 3 : The top-10 common features for the word pairs country-state and country-economy , along with their corresponding ranks in the sorted feature lists of the two words. Feature Weight Commercial-bank , gena0 Destination , pcompa1 Airspace , pcomp a0 Landlocked , mod a1 Trade_balance , gen a0 Sovereignty , pcompa0 Ambition , nn a0 Bourse , gen a0 Politician , gen a0 Border , pcomp a0 Table 2 : The top-10 ranking features for country. tic_relation &gt; .</sentence>
				<definiendum id="0">syntacCountryState Ranks CountryEconomy Ranks Broadcast Goods Civil_servant Bloc Nonaligned Neighboring Statistic</definiendum>
				<definiens id="0">a pair &lt; term ,</definiens>
				<definiens id="1">The top-10 common features for the word pairs country-state and country-economy , along with their corresponding ranks in the sorted feature lists of the two words. Feature Weight Commercial-bank</definiens>
			</definition>
			<definition id="1">
				<sentence>More formally , given a pair of similar words ( judged as substitutable ) w and v we define the top joint feature rank criterion for evaluating feature vector quality : ] , ) , ( ) , ( [ 211 ) , , ( ) ) ( ) ( ( ∑ + =− ∩−∈ fvrankfwrankn nvwranktop vFwFntopf where rank ( w , f ) is the feature’s position in the sorted vector of the word w , and n is the number of top joint features to consider ( top-n ) , when sorted by the sum of their weights in the two word vectors .</sentence>
				<definiendum id="0">rank</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the feature’s position in the sorted vector of the word w</definiens>
				<definiens id="1">the number of top joint features to consider ( top-n ) , when sorted by the sum of their weights in the two word vectors</definiens>
			</definition>
			<definition id="2">
				<sentence>That is , we identify all words v that are in the semantic neighborhood of w and are also characterized by f and sum their similarities to w. Notice that RFF is a sum of word similarity values rather than being a direct function of wordfeature association values ( which is the more common approach ) .</sentence>
				<definiendum id="0">RFF</definiendum>
				<definiens id="0">a sum of word similarity</definiens>
			</definition>
			<definition id="3">
				<sentence>Probabilistic Textual Entailment : Generic Applied Modeling of Language Variability .</sentence>
				<definiendum id="0">Probabilistic Textual Entailment</definiendum>
			</definition>
</paper>

		<paper id="1143">
			<definition id="0">
				<sentence>Email is one of the most ubiquitous applications used on a daily basis by millions of people world-wide , traditionally accessed over a fixed terminal or laptop computer .</sentence>
				<definiendum id="0">Email</definiendum>
				<definiens id="0">one of the most ubiquitous applications used on a daily basis by millions of people world-wide , traditionally accessed over a fixed terminal or laptop computer</definiens>
			</definition>
			<definition id="1">
				<sentence>Email is a form of short , largely informal , written communication that excludes methods that need large amounts of words and phrases to work well .</sentence>
				<definiendum id="0">Email</definiendum>
				<definiens id="0">a form of short , largely informal , written communication that excludes methods that need large amounts of words and phrases to work well</definiens>
			</definition>
			<definition id="2">
				<sentence>The FASiL summariser uses named entities as an indication of the importance of every sentence , and performs anaphora resolution automatically .</sentence>
				<definiendum id="0">FASiL summariser</definiendum>
				<definiens id="0">uses named entities as an indication of the importance of every sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>One of the most important components in the FASiL Summariser is the Named Entity Recogniser ( NER ) system .</sentence>
				<definiendum id="0">FASiL Summariser</definiendum>
			</definition>
			<definition id="4">
				<sentence>Named entities are automatically classified according to the following list of 11 classes : • Male proper names ( M ) • Female proper names ( F ) • Places ( towns , cities , etc. ) ( P ) • Locations ( upstairs , boardroom , etc. ) ( L ) • Male titles ( Mr. , Esq. , etc. ) ( Mt ) • Female titles ( Ms. , Mrs. , etc. ) ( Ft ) • Generic titles ( t ) • Date and time references ( TIME ) • Male anaphors ( Ma ) • Female anaphors ( Fa ) • Indeterminate anaphors ( a ) The gazetteer list for Locations , Titles , and Anaphors were compiled manually .</sentence>
				<definiendum id="0">Female proper names</definiendum>
				<definiens id="0">gazetteer list for Locations , Titles , and Anaphors were compiled manually</definiens>
			</definition>
			<definition id="5">
				<sentence>Anaphora resolution is an effective way of reducing the incoherence in resulting summaries by replacing anaphors with references to the appropriate named entities ( Mitkov , 2002 ) .</sentence>
				<definiendum id="0">Anaphora resolution</definiendum>
				<definiens id="0">an effective way of reducing the</definiens>
			</definition>
			<definition id="6">
				<sentence>The following ranking function rank ( j ) , where j is the sentence number , is used to rank and select excerpts : ( ) ( ) ( ) ( ) ( ) ( ) ++−= ∑ = τ ωτβα 0 ,1 i c iijjrank ( )  ( )         −− +         + ρ ρρ βα jlength j j 1 max where α and β are empirically determined constants , ρ is the preferred summary length , and j max is the number of sentences in the email .</sentence>
				<definiendum id="0">j</definiendum>
				<definiens id="0">empirically determined constants</definiens>
				<definiens id="1">the preferred summary length , and j max is the number of sentences in the email</definiens>
			</definition>
			<definition id="7">
				<sentence>The FASiL Email Summarisation system represents a compact summarisation system optimised for email summarisation in a voice-based system context .</sentence>
				<definiendum id="0">FASiL Email Summarisation system</definiendum>
				<definiens id="0">a compact summarisation system optimised for email summarisation in a voice-based system context</definiens>
			</definition>
			<definition id="8">
				<sentence>‘OCELOT : A system for summarizing web pages’ .</sentence>
				<definiendum id="0">‘OCELOT</definiendum>
				<definiens id="0">A system for summarizing web pages’</definiens>
			</definition>
			<definition id="9">
				<sentence>‘Ultra Summarization : A Statistical Approach to Generating Non-Extractive Summaries.’</sentence>
				<definiendum id="0">‘Ultra Summarization</definiendum>
			</definition>
</paper>

		<paper id="1064">
			<definition id="0">
				<sentence>For instance , summary sentence ( A ) consists of a part of source sentence ( A ) .</sentence>
				<definiendum id="0">summary sentence</definiendum>
				<definiens id="0">a part of source sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Summary sentence ( B ) consists of parts of source sentences ( A ) , ( B ) , and ( C ) .</sentence>
				<definiendum id="0">Summary sentence ( B )</definiendum>
				<definiens id="0">consists of parts of source sentences ( A ) , ( B ) , and ( C )</definiens>
			</definition>
			<definition id="2">
				<sentence>First , we introduce the “dependency tree path” ( DTP ) for Source ( A ) : a2a4a3a6a5a8a7a10a9a12a11a12a13a15a14a17a16a19a18a21a20a21a22a15a23a25a24a12a26a10a27a19a28a30a29a15a31a33a32 a34a33a35a4a36 a2a25a37a6a38a15a39a12a40a19a20a42a41a19a43a45a44 a46 a47 a48 a49 a50 a51 a52 a53 a48 a54 a55 a56 a57 a58 a59 a60 a61 a62a63 a64 a65 a66 a67 a68 a69 a70 a71 a72 a73 a74 a75 a76 a77 a78 a79 a80 a81 a76 a48 a49 a50 a51 a82 a83 a84 a85 a86 a87 a88 a89 a90 a91a93a92a6a5a95a94a95a96a98a97 a99 a100 a101 a102 a84 a103 a104a25a105a15a106a8a107a17a108a110a109a112a111a33a113a114a109a116a115a118a117a21a119a42a11a12a120a12a121a12a122a98a20 a123a8a124a8a125a45a126a128a127a12a129a95a130a21a131a133a132 a20a42a134 a135 a87 a88 a136 a137 a138 a57 a78a140a139 a43a10a141a143a142 First , we stop the new investment of 64-Mega bit memory from competitive companies , such as in Korea or Taiwan , and we begin the investment for development of valuable system-on-chip or 256-Mega bit DRAM from now on .</sentence>
				<definiendum id="0">DTP</definiendum>
				<definiens id="0">A ) : a2a4a3a6a5a8a7a10a9a12a11a12a13a15a14a17a16a19a18a21a20a21a22a15a23a25a24a12a26a10a27a19a28a30a29a15a31a33a32 a34a33a35a4a36 a2a25a37a6a38a15a39a12a40a19a20a42a41a19a43a45a44 a46 a47 a48 a49 a50 a51 a52 a53 a48 a54 a55 a56 a57 a58 a59 a60 a61 a62a63 a64 a65 a66 a67 a68 a69 a70 a71 a72 a73 a74 a75 a76 a77 a78 a79 a80 a81 a76 a48 a49 a50 a51 a82 a83 a84 a85 a86 a87 a88 a89 a90</definiens>
			</definition>
			<definition id="3">
				<sentence>Source ( C ) : a94a4a96a42a5a177a176a21a178a95a16 a58 a59 a60 a61 a149 a179 a180 a48 a51 a181 a51 a182 a183 a184 a185 a186 a187 a171a4a173a175a174a45a142 From now on , we will be supplied with DRAM from Taiwan .</sentence>
				<definiendum id="0">Source ( C )</definiendum>
				<definiens id="0">a94a4a96a42a5a177a176a21a178a95a16 a58 a59 a60 a61 a149 a179 a180 a48 a51 a181 a51 a182 a183 a184 a185 a186 a187 a171a4a173a175a174a45a142 From now on</definiens>
			</definition>
			<definition id="4">
				<sentence>Barzilay ( Barzilay and Elhadad , 2003 ) combines edit distance and context information around sentences .</sentence>
				<definiendum id="0">Barzilay</definiendum>
				<definiens id="0">combines edit distance and context information around sentences</definiens>
			</definition>
			<definition id="5">
				<sentence>The algorithm consists of the following steps : Step 0 Transform all source sentences into DTPs .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiens id="0">consists of the following steps : Step 0 Transform all source sentences into DTPs</definiens>
			</definition>
			<definition id="6">
				<sentence>a50a52a51a53a56a58a57a59a54 denotes the DTP set of thea60-th source sentences .</sentence>
				<definiendum id="0">a50a52a51a53a56a58a57a59a54</definiendum>
			</definition>
			<definition id="7">
				<sentence>a61a63a62a65a64a58a66a63a67 φ λ0 λ0 λ0 λ0 λ0 λ0 a68a70a69a72a71 λ0 λ1 λ0 λ1 λ1 λ1 λ1 λ0 λ0 λ0 λ1 a68a72a69a74a73 λ0 λ0 λ0 λ0 λ0 λ0 a68a70a69a72a75 a61a76a62a65a64a58a66a59a77 a61a63a62a65a64a78a66a65a79 Term a80 a66a65a81a55a82a83a61a63a84a86a85a88a87 a87a89a82a83a84a86a66a65a90a53a62a59a91a89a92a94a93a96a95 a97 a95 a97a86a98 a97a86a99 a93 a99 a93a96a100 0 DTP t1 t2 t3 m1 m2 m3 t1 t2 t1 * t3 t2 t3 m1 * m3 m1 * m4 t1 * m3 t1 * m4 t2 m3 t2 m4 m1 t2 m1 * t3 t1 t2 t3 t1 t2 m3 t1 t2 m4 m1 t2 t3 m1 t2 m3 m1 t2 m4 Component ( =Subsequence ) Value Component ( =Subsequence ) Value Component ( =Subsequence ) Value Figure 4 : ESK with node sequence .</sentence>
				<definiendum id="0">t2 m4 Component ( =Subsequence ) Value Component ( =Subsequence ) Value Component ( =Subsequence</definiendum>
				<definiens id="0">a93 a99 a93a96a100 0 DTP t1 t2 t3 m1 m2 m3 t1 t2 t1 * t3 t2 t3 m1 * m3 m1 * m4 t1 * m3 t1 * m4 t2 m3 t2 m4 m1 t2 m1 * t3 t1 t2 t3 t1 t2 m3 t1 t2 m4 m1 t2 t3 m1 t2 m3 m1</definiens>
			</definition>
			<definition id="8">
				<sentence>String Subsequence Kernel ( SSK ) ( Lodhi et al. , 2002 ) and Word Sequence Kernel ( WSK ) ( Cancedda et al. , 2003 ) are extensions of ngram-based measures used for text categorization .</sentence>
				<definiendum id="0">String Subsequence Kernel ( SSK )</definiendum>
				<definiendum id="1">Word Sequence Kernel</definiendum>
				<definiens id="0">Cancedda et al. , 2003 ) are extensions of ngram-based measures used for text categorization</definiens>
			</definition>
			<definition id="9">
				<sentence>Here , a153 is a decay parameter for the number of skipped words .</sentence>
				<definiendum id="0">a153</definiendum>
				<definiens id="0">a decay parameter for the number of skipped words</definiens>
			</definition>
			<definition id="10">
				<sentence>ESK allows us to add word senses to each word .</sentence>
				<definiendum id="0">ESK</definiendum>
				<definiens id="0">allows us to add word senses to each word</definiens>
			</definition>
			<definition id="11">
				<sentence>BOW BOW is defined by equation ( 1 ) .</sentence>
				<definiendum id="0">BOW BOW</definiendum>
			</definition>
			<definition id="12">
				<sentence>TREE The Tree Kernel ( Collins and Duffy , 2001 ) is a similarity measure based on the number of common subtrees .</sentence>
				<definiendum id="0">Tree Kernel</definiendum>
				<definiens id="0">a similarity measure based on the number of common subtrees</definiens>
			</definition>
			<definition id="13">
				<sentence>F-measure a199 a222a32a23a78a77 a79 a193 a204 Precision a23a80a77 a79 a204 Recalla198 ( 8 ) Here , Precision a58a82a81a84a83 a244 and Recall a58a82a81a85a83a73a86 , where a244 is the number of source sentences aligned by a system for the summary sentence .</sentence>
				<definiendum id="0">a244</definiendum>
				<definiens id="0">the number of source sentences aligned by a system for the summary sentence</definiens>
			</definition>
			<definition id="14">
				<sentence>a81 is the number of correct source sentences in the output .</sentence>
				<definiendum id="0">a81</definiendum>
				<definiens id="0">the number of correct source sentences in the output</definiens>
			</definition>
			<definition id="15">
				<sentence>a86 is the number of source sentences aligned by the human expert .</sentence>
				<definiendum id="0">a86</definiendum>
				<definiens id="0">the number of source sentences aligned by the human expert</definiens>
			</definition>
			<definition id="16">
				<sentence>Experiments on the TSC ( Text Summarization Challenge ) corpus , which has complex correspondence , showed that the introduction of DTP consistently improves alignment accuracy and that ESK gave the best results .</sentence>
				<definiendum id="0">TSC ( Text Summarization Challenge ) corpus</definiendum>
			</definition>
			<definition id="17">
				<sentence>SimFinder : A Flexible Clustering Tool for Summarization .</sentence>
				<definiendum id="0">SimFinder</definiendum>
			</definition>
			<definition id="18">
				<sentence>Bleu : a Method for Automatic Evaluation of Machine Translation .</sentence>
				<definiendum id="0">Bleu</definiendum>
			</definition>
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>Discourse segments can be defined as nonoverlapping spans of prosodic units ( Hirschberg &amp; Nakatani , 1996 ) , intentional units ( Grosz &amp; Sidner , 1986 ) , phrasal units ( Lascarides &amp; Asher , 1993 ) , or sentences ( Hobbs , 1985 ) .</sentence>
				<definiendum id="0">Discourse segments</definiendum>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>TCCG combines the fully lexical nature of CCG with the type-inheritance hierarchies and complex feature structures of Headdriven Phrase Structure Grammars ( HPSG ) .</sentence>
				<definiendum id="0">TCCG</definiendum>
			</definition>
			<definition id="1">
				<sentence>Type-inheritance Combinatory Categorial Grammar ( TCCG ) is a type-inheritance , unification-based CCG of the English fragment in Sag and Wasow ( 1999 ) , implemented in the LKB ( Copestake , 2002 ) , a grammar development platform for producing efficient grammars for deep parsing .</sentence>
				<definiendum id="0">Type-inheritance Combinatory Categorial Grammar ( TCCG )</definiendum>
				<definiens id="0">a type-inheritance , unification-based CCG of the English fragment in Sag</definiens>
			</definition>
			<definition id="2">
				<sentence>Turning to encoding , I assume a sign-based packaging of syntactic and semantic information:2 ( 2 ) ( a ) a6a7 a7 a7 a7 a7 a7 a7 a7 a7 a7 a7 a7 a7 a7a8 sign ORTH *diff-list-of-strings* NF nf SS a6a7 a7 a7 a7 a7 a7a8 synsem ROOT a6 a8 root-struct RCAT basic-category FEATS features a9a10 CAT category SEM sem-struct a9a12a11 a11 a11 a11 a11 a11 a10 DTRS list-of-signs a9a12a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a10 ( b ) Feature Description ORTH Orthography NF Normal form feature SS Syntactic/Semantic info ROOT Root category info RCAT Simple root category FEATS Morphosyntactic features CAT Category information SEM Semantic information DTRS Phrasal daughters Following Baldridge ( 2002 ) , the root category is the final result of a category after all applications ( e.g. S for a transitive verb ( Sa1 NP ) a2 NP ) and defines the morphosyntactic features of a category .</sentence>
				<definiendum id="0">root category</definiendum>
				<definiens id="0">a ) a6a7 a7 a7 a7 a7 a7 a7 a7 a7 a7 a7 a7 a7 a7a8 sign ORTH *diff-list-of-strings* NF nf SS a6a7 a7 a7 a7 a7 a7a8 synsem ROOT a6 a8 root-struct RCAT basic-category FEATS features a9a10 CAT category SEM sem-struct a9a12a11 a11 a11 a11 a11 a11 a10 DTRS list-of-signs a9a12a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a11 a10 ( b</definiens>
				<definiens id="1">features CAT Category information SEM Semantic information DTRS Phrasal daughters Following Baldridge</definiens>
				<definiens id="2">the final result of a category after all applications ( e.g. S for a transitive verb ( Sa1 NP ) a2 NP ) and defines the morphosyntactic features of a category</definiens>
			</definition>
			<definition id="3">
				<sentence>Traditionally , CCG offers no grammatical tools to statically relate categories .</sentence>
				<definiendum id="0">CCG</definiendum>
			</definition>
			<definition id="4">
				<sentence>HPSG has from its inception employed multiple inheritance type hierarchies ( e.g. as in ( 4 ) ) , where some of the grammatical information for a particular sign is inherited from its immediate supertype , which itself inherits grammatical information from which its supertype , and all types share inherited information with their sisters .</sentence>
				<definiendum id="0">HPSG</definiendum>
				<definiens id="0">itself inherits grammatical information from which its supertype , and all types share inherited information with their sisters</definiens>
			</definition>
			<definition id="5">
				<sentence>Using as my case study the hierarchy of verbal signs , in CCG the following categories are assigned to various verb types ( note that in TCCG CPs are categorially finite NPs ) : ( 6 ) ( a ) Intransitive ( sleep ) : Sa1 NP ( b ) Intransitive PP complement ( speak ( to ) ) : ( Sa1 NP ) a2 PP ( c ) Intransitive CP complement ( think ) : ( Sa1 NP ) a2 NPa36a1a0a3a2 ( d ) Intransitive PP-CP complement ( say ( to ) ) : ( ( Sa1 NP ) a2 NPa36a1a0a3a2 ) a2 PP ( e ) Intransitive CP-subject ( suck ) : Sa1 NPa36a4a0a5a2 ( f ) Transitive verbs ( see ) : ( Sa1 NP ) a2 NP ( g ) Transitive PP complement ( donate ) : ( ( Sa1 NP ) a2 PP ) a2 NP ( h ) Transitive CP complement ( tell ) : ( ( Sa1 NP ) a2 NPa36a1a0a3a2 ) a2 NP ( i ) Ditransitive ( give ) : ( ( Sa1 NP ) a2 NP ) a2 NP ( j ) Subject control ( want/appear ) : ( Sa1 NP ) a2 ( Sa1 NP ) ( k ) Object control ( persuade/ask ) : ( ( Sa1 NP ) a2 ( Sa1 NP ) ) a2 NP ( l ) Auxiliary ( will ) : ( Sa1 NP ) a2 ( Sa1 NP ) Villavicencio’s implementation , which has generalized weak permutation and product categories but no type-raising .</sentence>
				<definiendum id="0">Intransitive CP complement</definiendum>
				<definiendum id="1">Transitive PP complement</definiendum>
				<definiens id="0">k ) Object control ( persuade/ask ) : ( ( Sa1 NP ) a2 ( Sa1 NP</definiens>
			</definition>
			<definition id="6">
				<sentence>More generally , TCCG implements CCG analyses of non-constituent coordination ( e.g. right node raising and argument cluster coordination ) , largely unanalyzed in HPSG ( although see Yatabe 2002 , Chrysmann 2003 , Beavers and Sag to appear ) .</sentence>
				<definiendum id="0">TCCG</definiendum>
				<definiens id="0">implements CCG analyses of non-constituent coordination ( e.g. right node raising and argument cluster coordination )</definiens>
			</definition>
			<definition id="7">
				<sentence>TCCG is an implemented CCG in an HPSG framework that combines the advantages of both theories : well-organized , minimally redundant lexical and grammatical information mixed with the theoretical elegance of CCG grammars .</sentence>
				<definiendum id="0">TCCG</definiendum>
			</definition>
			<definition id="8">
				<sentence>The grammar matrix : An open-source starterkit for the rapid development of cross-linguistically consistent broad-coverage precisions grammars .</sentence>
				<definiendum id="0">grammar matrix</definiendum>
			</definition>
			<definition id="9">
				<sentence>Minimal recursion semantics : An introduction .</sentence>
				<definiendum id="0">Minimal recursion semantics</definiendum>
				<definiens id="0">An introduction</definiens>
			</definition>
			<definition id="10">
				<sentence>A Categorial-Modal Architecture of Informativity : Dependency Grammar Logic and Information Structure .</sentence>
				<definiendum id="0">Categorial-Modal Architecture of Informativity</definiendum>
				<definiens id="0">Dependency Grammar Logic and Information Structure</definiens>
			</definition>
</paper>

		<paper id="1114">
			<definition id="0">
				<sentence>The UMLS Metathesaurus provides a common structure for approximately 100 source biomedical vocabularies .</sentence>
				<definiendum id="0">UMLS Metathesaurus</definiendum>
				<definiens id="0">provides a common structure for approximately 100 source biomedical vocabularies</definiens>
			</definition>
			<definition id="1">
				<sentence>The UMLS Semantic Network categorizes the concepts of the UMLS Metathesaurus through semantic types and relationships .</sentence>
				<definiendum id="0">UMLS Semantic Network</definiendum>
				<definiens id="0">categorizes the concepts of the UMLS Metathesaurus through semantic types and relationships</definiens>
			</definition>
			<definition id="2">
				<sentence>The Baseline system , which we used to test different approaches to improve the translation performance , is a statistical machine translation system .</sentence>
				<definiendum id="0">Baseline system</definiendum>
				<definiens id="0">a statistical machine translation system</definiens>
			</definition>
			<definition id="3">
				<sentence>BLEU : a Method for Automatic Evaluation of Machine Translation , Proceedings of the ACL 2002 , Philadelphia , USA .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">a Method for Automatic Evaluation of Machine Translation , Proceedings of the ACL 2002 , Philadelphia , USA</definiens>
			</definition>
</paper>

		<paper id="1153">
			<definition id="0">
				<sentence>The part-of-speech ( pos ) , the grammatical case , and the verb voice are key morphological features for complement detection .</sentence>
				<definiendum id="0">part-of-speech ( pos</definiendum>
				<definiens id="0">the grammatical case , and the verb voice are key morphological features for complement detection</definiens>
			</definition>
			<definition id="1">
				<sentence>Concerning sentence structure , MG is a ‘semifree’ word-order language .</sentence>
				<definiendum id="0">MG</definiendum>
				<definiens id="0">a ‘semifree’ word-order language</definiens>
			</definition>
			<definition id="2">
				<sentence>Mode is the property that determines the semantic relation between the verb and its subject ( whether the latter affects or is affected by the verb action .</sentence>
				<definiendum id="0">Mode</definiendum>
				<definiens id="0">the property that determines the semantic relation between the verb and its subject ( whether the latter affects or is affected by the verb action</definiens>
			</definition>
			<definition id="3">
				<sentence>( Labros is a good boy and believes in God . )</sentence>
				<definiendum id="0">Labros</definiendum>
				<definiens id="0">a good boy and believes in God</definiens>
			</definition>
			<definition id="4">
				<sentence>The value difference metric ( VDM ) is more appropriate for this type of attributes , as it considers two nominal values to be closer if they have more similar classifications , i.e. more similar correlations with the output class .</sentence>
				<definiendum id="0">value difference metric ( VDM</definiendum>
				<definiens id="0">it considers two nominal values to be closer if they have more similar classifications , i.e. more similar correlations with the output class</definiens>
			</definition>
			<definition id="5">
				<sentence>The VDM of two values a x and a y of a nominal attribute A in two vectors x and y is estimated as : , , , , , , ( , ) y x xy A ac Aa c Axy cC Aa Aa N N vdm a a NN ∈ =− ∑ , A a N is the number of times value a of attribute A was found in the training set , , ,A a c N is the number of times value a co-occurred with output class c and C is the set of class labels .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">a y of a nominal attribute A in two vectors x and y is estimated as : , , , , , , ( , ) y x xy A ac Aa c Axy</definiens>
				<definiens id="1">the number of times value a of attribute A was found in the training set , , ,A a c</definiens>
				<definiens id="2">the number of times value a co-occurred with output class c</definiens>
			</definition>
			<definition id="6">
				<sentence>Metacost : A general method for making classifiers cost-sensitive .</sentence>
				<definiendum id="0">Metacost</definiendum>
				<definiens id="0">A general method for making classifiers cost-sensitive</definiens>
			</definition>
			<definition id="7">
				<sentence>DELOS : An automatically tagged economic corpus for Modern Greek .</sentence>
				<definiendum id="0">DELOS</definiendum>
			</definition>
</paper>

		<paper id="1037">
			<definition id="0">
				<sentence>Ambiguity occurs between word classes , between variously inflected wordforms , and above all , between various meanings of a word .</sentence>
				<definiendum id="0">Ambiguity</definiendum>
				<definiens id="0">occurs between word classes</definiens>
			</definition>
			<definition id="1">
				<sentence>WordNet : An electronic lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An electronic lexical database</definiens>
			</definition>
			<definition id="2">
				<sentence>, WordNet : An electronic lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An electronic lexical database</definiens>
			</definition>
			<definition id="3">
				<sentence>Two-level morphology : A general computational model for word-form recognition and production .</sentence>
				<definiendum id="0">Two-level morphology</definiendum>
				<definiens id="0">A general computational model for word-form recognition and production</definiens>
			</definition>
			<definition id="4">
				<sentence>Wordnet : An On-line Lexical Database .</sentence>
				<definiendum id="0">Wordnet</definiendum>
			</definition>
			<definition id="5">
				<sentence>, WordNet : An electronic lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An electronic lexical database</definiens>
			</definition>
</paper>

		<paper id="1105">
			<definition id="0">
				<sentence>A context vector consists of associated words weighted with mutual information .</sentence>
				<definiendum id="0">context vector</definiendum>
				<definiens id="0">consists of associated words weighted with mutual information</definiens>
			</definition>
			<definition id="1">
				<sentence>That is , Y ( x , x� ( j ) ) = { ( y , y� ) | ( y , y� ) ∈R 2 , ( x , y ) ∈D , ( x� ( j ) , y� ) ∈D } , where R 2 is the collection of word associations extracted from a corpus of the second language , and D is a bilingual dictionary to be adapted .</sentence>
				<definiendum id="0">R 2</definiendum>
				<definiendum id="1">D</definiendum>
				<definiens id="0">a bilingual dictionary to be adapted</definiens>
			</definition>
			<definition id="2">
				<sentence>The correlation between the i-th translation equivalent of target word x , denoted as y ( i ) , and the j-th associated word x� ( j ) is defined as ( ) ( ) ( ) ( ) , jx ' , kyPLmax jx ' , iyPL jx ' , xMIjx ' , iyC k ) ( ) ( ) ( ) ( ) ( ) ( ) ( ⋅= where MI ( x , x� ( j ) ) is the mutual information between x and x� ( j ) , and PL ( y ( i ) , x� ( j ) ) is the plausibility factor for y ( i ) given by x� ( j ) .</sentence>
				<definiendum id="0">MI</definiendum>
				<definiendum id="1">PL ( y</definiendum>
				<definiens id="0">the mutual information between x and x� ( j ) , and</definiens>
				<definiens id="1">the plausibility factor for y ( i ) given by x� ( j )</definiens>
			</definition>
			<definition id="3">
				<sentence>The plausibility factor is defined as the weighted sum of two component plausibility factors .</sentence>
				<definiendum id="0">plausibility factor</definiendum>
			</definition>
			<definition id="4">
				<sentence>The first component plausibility factor , PL 1 , is defined as the sum of correlations between the translation equivalent and the accompanying associated words .</sentence>
				<definiendum id="0">PL 1</definiendum>
				<definiens id="0">the sum of correlations between the translation equivalent and the accompanying associated words</definiens>
			</definition>
			<definition id="5">
				<sentence>x '' , iyCjx ' , iyPL jx ' , xx '' ∑ ∈ = ) ) ( Z ( 1 ) ( ) ( ) ( This is based on the assumption that an associated Target word Extract word associations 1st-language corpus Original bilingual dictionary 2nd-language corpus Extract word associations 2nd-language word associations 1st-language word associations Calculate correlation between translation equivalents and associated words Assign each associated word to the translation equivalent having the highest correlation with it Binary matrix of translation equivalents vs. associated words Representative associated words Aligned word associations Correlation matrix of translation equivalents vs. associated words Align word associations Candidate translation equivalents Adapted bilingual dictionary Select representative associated words Select translation equivalents to which more than a certain percentage of associated words are assigned Figure 2 : Bilingual-dictionary adaptation using the ratio of associated words word usually correlates closely with the translation equivalent that correlates closely with a majority of its accompanying associated words .</sentence>
				<definiendum id="0">) ( )</definiendum>
				<definiens id="0">equivalents vs. associated words Representative associated words Aligned word associations Correlation matrix of translation equivalents vs. associated words Align word associations Candidate translation equivalents Adapted bilingual</definiens>
			</definition>
			<definition id="6">
				<sentence>ing recall and precision measures defined as , T TS ecisionPrand S TS callRe ∩ = ∩ = where S is a set consisting of pairs of translation equivalents contained in the test comparable corpora , and T is a set consisting of pairs of translation equivalents selected by the method .</sentence>
				<definiendum id="0">T TS ecisionPrand S TS</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">T</definiendum>
				<definiens id="0">a set consisting of pairs of translation equivalents contained in the test comparable corpora , and</definiens>
				<definiens id="1">a set consisting of pairs of translation equivalents selected by the method</definiens>
			</definition>
			<definition id="7">
				<sentence>That is , , 'T 'T 'S ecisionPrand 'S 'T 'S callRe ∩ = ∩ = where S� is a set consisting of pseudo senses corresponding to the first two constituent words , and T� is a set consisting of pseudo senses relevant to translation equivalents selected by the method .</sentence>
				<definiendum id="0">S�</definiendum>
				<definiendum id="1">T�</definiendum>
				<definiens id="0">a set consisting of pseudo senses corresponding to the first two constituent words</definiens>
				<definiens id="1">a set consisting of pseudo senses relevant to translation equivalents selected by the method</definiens>
			</definition>
</paper>

		<paper id="1133">
			<definition id="0">
				<sentence>FrameNet ( freely available online in a beautifully designed data base at http : //www.icsi.berkeley.edu/~framenet/ ) , is an attempt to implement Fillmore’s 1975 proposal that , instead of seeking to satisfy a set of necessary and su cient conditions , the meanings of words in text should be analyzed by calculating resemblance to a prototype ( Fillmore , 1975 ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">freely available online in a beautifully designed data base at http : //www.icsi.berkeley.edu/~framenet/ )</definiens>
			</definition>
			<definition id="1">
				<sentence>Word senses for verbs are distinguished through corpus-derived syntagmatic patterns mapped to Generative Lexicon Theory ( Pustejovsky ( 1995 ) ) as a linguistic model of interpretation , which guides and constrains the induction of senses from word distributional information .</sentence>
				<definiendum id="0">interpretation</definiendum>
				<definiens id="0">guides and constrains the induction of senses from word distributional information</definiens>
			</definition>
			<definition id="2">
				<sentence>The procedure consists of three subtasks : ( 1 ) the manual discovery of selection context patterns for speci c verbs ; ( 2 ) the automatic recognition of instances of the identi ed patterns ; and ( 3 ) automatic acquisition of patterns for unanalyzed cases .</sentence>
				<definiendum id="0">procedure</definiendum>
			</definition>
			<definition id="3">
				<sentence>The model bias provided by GL acts to guide the interpretation of purely statistically based measures ( cf. Pustejovsky ( 2000 ) ) .</sentence>
				<definiendum id="0">model bias</definiendum>
				<definiens id="0">provided by GL acts to guide the interpretation of purely statistically based measures</definiens>
			</definition>
			<definition id="4">
				<sentence>For each parse , RASP produces a set of grammatical relations , specifying the relation type , the headword , and the dependent element .</sentence>
				<definiendum id="0">RASP</definiendum>
				<definiens id="0">produces a set of grammatical relations , specifying the relation type</definiens>
			</definition>
			<definition id="5">
				<sentence>Lexicographic relevance : Selecting information from corpus evidence .</sentence>
				<definiendum id="0">Lexicographic relevance</definiendum>
				<definiens id="0">Selecting information from corpus evidence</definiens>
			</definition>
			<definition id="6">
				<sentence>Selectional constraints : An informationtheoretic model and its computational realization .</sentence>
				<definiendum id="0">Selectional constraints</definiendum>
				<definiens id="0">An informationtheoretic model and its computational realization</definiens>
			</definition>
</paper>

		<paper id="1128">
			<definition id="0">
				<sentence>Email is a written medium of asynchronous multi-party communication .</sentence>
				<definiendum id="0">Email</definiendum>
				<definiens id="0">a written medium of asynchronous multi-party communication</definiens>
			</definition>
			<definition id="1">
				<sentence>5 cosine sim ( x ; y ) = PN i=1 ( cxi cyi ) qP N j=1 c 2 xj PN j=1 c 2 xj where cxi is the count of word i in segment x , and cyi is the count of word i in segment y. 6 euclidean dis ( x ; y ) = vu ut NX i=1 ( c2xi c2yi ) where cxi is the count of word i in segment x , and cyi is the count of word i in segment y. lier than mq and all the messages in t , and similarly for ma ; ( e ) whether a is the rst segment in the list of candidate answer segments of q ( this is true if a segment is the rst segment in the rst message sent in reply to mq ) ; answer segments of q ( f ) number of candidate answer segments of q and the number of candidate answer segments of q after a ( a segment x is considered to be after another segment y if x is from a message sent later than that of y , or if x appears after y in the same message ) ; ( g ) the ratio of the number of candidate answer segments before a and the number of all candidate answer segments ( a segment x is considered to be before another segment y if x is from a message sent earlier than that of y , or if x appears before y in the same message ) ; and ( h ) whether q is the most similar segment of a among all segments from ancestor messages of ma based on cosine similarity ( the list of ancestor messages of a message is computed by recursively following the In-Reply-To header information that points to the parent message of a message ) .</sentence>
				<definiendum id="0">cxi</definiendum>
				<definiendum id="1">cyi</definiendum>
				<definiendum id="2">cxi</definiendum>
				<definiendum id="3">cyi</definiendum>
				<definiens id="0">the count of word i in segment x</definiens>
				<definiens id="1">the count of word i in segment y. lier than mq and all the messages in t</definiens>
				<definiens id="2">the rst segment in the list of candidate answer segments of q</definiens>
				<definiens id="3">the rst segment in the rst message sent in reply to mq ) ; answer segments of q ( f ) number of candidate answer segments of q and the number of candidate answer segments of q after a ( a segment x is considered to be after another segment y if x is from a message sent later than that of y , or if x appears after y in the same message ) ; ( g ) the ratio of the number of candidate answer segments before a and the number of all candidate answer segments ( a segment x is considered to be before another segment y if x is from a message sent earlier than that of y , or if x appears before y in the same message</definiens>
				<definiens id="4">the most similar segment of a among all segments from ancestor messages of ma based on cosine similarity ( the list of ancestor messages of a message is computed by recursively following the In-Reply-To header information that points to the parent message of a message )</definiens>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>This paper introduces the Generalized ID/LP ( GIDLP ) grammar format , which supports a direct encoding of such theories , and discusses key aspects of a parser that makes use of the dominance , precedence , and linearization domain information explicitly encoded in this grammar format .</sentence>
				<definiendum id="0">Generalized ID/LP ( GIDLP ) grammar format</definiendum>
				<definiens id="0">supports a direct encoding of such theories , and discusses key aspects of a parser that makes use of the dominance , precedence , and linearization domain information explicitly encoded in this grammar format</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , a theory in the HPSG architecture consists of a set of constraints on the data structures introduced in the signature ; thus , word order domains and the constraints thereon can be straightforwardly expressed .</sentence>
				<definiendum id="0">HPSG architecture</definiendum>
				<definiens id="0">consists of a set of constraints on the data structures introduced in the signature ; thus , word order domains and the constraints thereon can be straightforwardly expressed</definiens>
			</definition>
			<definition id="2">
				<sentence>The LSL grammar format as defined by Suhre ( 1999 ) ( based on G¨otz and Penn , 1997 ) allows elements to be ordered in domains that are larger than a local tree ; as a result , categories are not required to cover contiguous strings .</sentence>
				<definiendum id="0">LSL grammar format</definiendum>
				<definiens id="0">based on G¨otz and Penn , 1997 ) allows elements to be ordered in domains that are larger than a local tree ; as a result , categories are not required to cover contiguous strings</definiens>
			</definition>
			<definition id="3">
				<sentence>A Generalized ID/LP ( GIDLP ) grammar consists of four parts : a root declaration , a set of lexical entries , a set of grammar rules , and a set of global order constraints .</sentence>
				<definiendum id="0">Generalized ID/LP</definiendum>
				<definiendum id="1">GIDLP ) grammar</definiendum>
				<definiens id="0">consists of four parts : a root declaration , a set of lexical entries , a set of grammar rules</definiens>
			</definition>
			<definition id="4">
				<sentence>All precedence constraints enforce the following property : given any appropriate pair of elements in the same domain , one must completely precede the other for the resulting parse to be valid .</sentence>
				<definiendum id="0">precedence constraints</definiendum>
				<definiens id="0">given any appropriate pair of elements in the same domain</definiens>
			</definition>
			<definition id="5">
				<sentence>( 2 ) A→NP 1 , V 2 , NP 3 ; 3 &lt; V This constraint specifies that the token 3 in the rule’s RHS ( the second NP ) must precede any constituents described as V occurring in the same domain ( this includes , but is not limited to , the V introduced by the rule ) .</sentence>
				<definiendum id="0">RHS</definiendum>
				<definiens id="0">V occurring in the same domain ( this includes , but is not limited to , the V introduced by the rule )</definiens>
			</definition>
			<definition id="6">
				<sentence>A rule-level compaction statement has the form 〈α , A , L〉 , where α is a list of tokens , A is the category representing the compacted domain , and L is a list of domain-level precedence constraints .</sentence>
				<definiendum id="0">rule-level compaction statement</definiendum>
				<definiendum id="1">α</definiendum>
				<definiendum id="2">L</definiendum>
				<definiens id="0">a list of tokens</definiens>
				<definiens id="1">a list of domain-level precedence constraints</definiens>
			</definition>
			<definition id="7">
				<sentence>A global compaction statement has the form 〈A , L〉 , where A is a description specifying a category that always forms a compacted domain , and L is a list of domain-level precedence constraints applying to the compacted domain .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">a description specifying a category that always forms a compacted domain , and</definiens>
			</definition>
			<definition id="8">
				<sentence>A Formal Theory of Word Order : A Case Study in West Germanic .</sentence>
				<definiendum id="0">Formal Theory of Word Order</definiendum>
				<definiens id="0">A Case Study in West Germanic</definiens>
			</definition>
</paper>

		<paper id="1003">
</paper>

		<paper id="1173">
			<definition id="0">
				<sentence>To compare the human annotation to the automated one , we have applied the following measures , where ( h1 ; h2 ; ; : : : ) is the human tag , and ( s1 ; s2 ; : : ) is the top-ranked system output for a context i defined as the entry and the target word to disambiguate : graph score is 1 if h1 = s1 , 0 otherwise ; h2 = s2 , 0 otherwise ; hi = si Thus , the coarse polysemy score computes how many times the algorithm gives a sub-sense that has the same `` main '' sense as the human tag ( the main-sense corresponds to the first level in the hierarchy of senses as defined above ) .</sentence>
				<definiendum id="0">coarse polysemy score</definiendum>
				<definiendum id="1">tag</definiendum>
				<definiens id="0">the human tag</definiens>
				<definiens id="1">computes how many times the algorithm gives a sub-sense that has the same</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>A bunsetsu consists of one or more content words followed by zero or more function words .</sentence>
				<definiendum id="0">bunsetsu</definiendum>
			</definition>
			<definition id="1">
				<sentence>‘Bun’ means a sentence and ’setsu’ means a segment .</sentence>
				<definiendum id="0">‘Bun’</definiendum>
				<definiendum id="1">’setsu’</definiendum>
				<definiens id="0">means a sentence and</definiens>
			</definition>
			<definition id="2">
				<sentence>The parsing algorithms in their papers require C7B4D2 BF B5 time where D2 is the number of words .</sentence>
				<definiendum id="0">D2</definiendum>
				<definiens id="0">the number of words</definiens>
			</definition>
			<definition id="3">
				<sentence>Both Haruno et al. , and Fujio and Matsumoto used the CYK algorithm , which requires C7B4D2 BF B5 time , where D2 is a sentence length , i.e. , the number of bunsetsus .</sentence>
				<definiendum id="0">CYK algorithm</definiendum>
				<definiens id="0">requires C7B4D2 BF B5 time , where D2 is a sentence length</definiens>
			</definition>
			<definition id="4">
				<sentence>Context , Rich , and Conj mean the features in Sec .</sentence>
				<definiendum id="0">Conj mean</definiendum>
				<definiens id="0">the features in Sec</definiens>
			</definition>
			<definition id="5">
				<sentence>The dependency accuracy is the percentage of correct dependencies and the sentence accuracy is the percentage of sentences , all the dependencies in which are correctly analyzed .</sentence>
				<definiendum id="0">dependency accuracy</definiendum>
				<definiendum id="1">sentence accuracy</definiendum>
			</definition>
			<definition id="6">
				<sentence>Grammatical trigrams : A probabilistic model of link grammar .</sentence>
				<definiendum id="0">Grammatical trigrams</definiendum>
				<definiens id="0">A probabilistic model of link grammar</definiens>
			</definition>
</paper>

		<paper id="1071">
			<definition id="0">
				<sentence>Sentiment analysis ( SA ) ( Nasukawa and Yi , 2003 ; Yi et al. , 2003 ) is a task to obtain writers’ feelings as expressed in positive or negative comments , questions , and requests , by analyzing large numbers of documents .</sentence>
				<definiendum id="0">SA )</definiendum>
				<definiens id="0">a task to obtain writers’ feelings as expressed in positive or negative comments , questions , and requests</definiens>
			</definition>
			<definition id="1">
				<sentence>A sentiment unit consists of a sentiment , a predicate , its one or more arguments , and a surface form .</sentence>
				<definiendum id="0">sentiment unit</definiendum>
				<definiens id="0">consists of a sentiment , a predicate , its one or more arguments , and a surface form</definiens>
			</definition>
			<definition id="2">
				<sentence>A predicate is a word , typically a verb or an adjective , which conveys the main notion of the sentiment unit .</sentence>
				<definiendum id="0">predicate</definiendum>
				<definiens id="0">a word</definiens>
				<definiens id="1">conveys the main notion of the sentiment unit</definiens>
			</definition>
			<definition id="3">
				<sentence>A translation pattern consists of a tree of the source language , a tree of the target language , and the word correspondences between both languages .</sentence>
				<definiendum id="0">translation pattern</definiendum>
			</definition>
			<definition id="4">
				<sentence>We prepared the following resources for sentiment analysis : Principal patterns : The verbal and adjectival patterns for machine translation were converted to principal patterns for sentiment analysis .</sentence>
				<definiendum id="0">Principal patterns</definiendum>
				<definiens id="0">The verbal and adjectival patterns for machine translation were converted to principal patterns for sentiment analysis</definiens>
			</definition>
			<definition id="5">
				<sentence>Auxiliary/Nominal patterns : A total of 95 auxiliary patterns and 36 nominal patterns were created manually .</sentence>
				<definiendum id="0">Auxiliary/Nominal patterns</definiendum>
				<definiens id="0">A total of 95 auxiliary patterns and 36 nominal patterns were created manually</definiens>
			</definition>
			<definition id="6">
				<sentence>Polarity lexicon : Some nouns were assigned sentiment polarity , e.g. [ unf ] for ‘noise’ .</sentence>
				<definiendum id="0">Polarity lexicon</definiendum>
				<definiens id="0">Some nouns were assigned sentiment polarity</definiens>
			</definition>
			<definition id="7">
				<sentence>Recall : The detection rate of sentiment units within the manual output .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">The detection rate of sentiment units within the manual output</definiens>
			</definition>
			<definition id="8">
				<sentence>These metrics are measured by using two methods : ( A ) our proposed method based on the machine translation engine , and ( B ) the lexicon-only method , which emulates the shallow parsing approach .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">emulates the shallow parsing approach</definiens>
			</definition>
</paper>

		<paper id="1054">
			<definition id="0">
				<sentence>A consumer health information system must be able to comprehend both expert and nonexpert medical vocabulary and to map between the two .</sentence>
				<definiendum id="0">consumer health information system</definiendum>
				<definiens id="0">both expert and nonexpert medical vocabulary and to map between the two</definiens>
			</definition>
			<definition id="1">
				<sentence>We describe an ongoing project to create a new lexical database called Medical WordNet ( MWN ) , consisting of medically relevant terms used by and intelligible to non-expert subjects and supplemented by a corpus of natural-language sentences that is designed to provide medically validated contexts for MWN terms .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="2">
				<sentence>WordNet is the principal lexical database used in natural language processing ( NLP ) research and applications .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">the principal lexical database used in natural language processing ( NLP ) research and applications</definiens>
			</definition>
			<definition id="3">
				<sentence>Our response is to create Medical WordNet ( MWN ) , a free-standing lexical database designed specifically for the needs of natural-language processing in the medical domain , with the goal of removing the ‘noise’ which is associated with the application of WordNet and similar resources to this specialized domain .</sentence>
				<definiendum id="0">MWN</definiendum>
				<definiens id="0">a free-standing lexical database designed specifically for the needs of natural-language processing in the medical domain , with the goal of removing the ‘noise’ which is associated with the application of WordNet and similar resources to this specialized domain</definiens>
			</definition>
			<definition id="4">
				<sentence>MFN consists of those sentences in the corpus which receive high marks for correctness on being assessed by medical experts .</sentence>
				<definiendum id="0">MFN</definiendum>
				<definiens id="0">consists of those sentences in the corpus which receive high marks for correctness on being assessed by medical experts</definiens>
			</definition>
			<definition id="5">
				<sentence>MBN consists of those sentences in the corpus which receive high marks for assent .</sentence>
				<definiendum id="0">MBN</definiendum>
				<definiens id="0">consists of those sentences in the corpus which receive high marks for assent</definiens>
			</definition>
			<definition id="6">
				<sentence>WordNet 2.0 is a large electronic lexical database of English that has found wide acceptance in areas as diverse as artificial intelligence , natural language processing , and psychology .</sentence>
				<definiendum id="0">WordNet 2.0</definiendum>
				<definiens id="0">a large electronic lexical database of English that has found wide acceptance in areas as diverse as artificial intelligence , natural language processing , and psychology</definiens>
			</definition>
			<definition id="7">
				<sentence>palpate , feel – ( examine ( a body part ) by palpation : The nurse palpated the patient’s stomach ; The runner felt her pulse ) For the adjective dead , WordNet 2.0 distinguishes 21 meanings , with only two approximating to meanings of this term as used in medical contexts : to have or expecting to have life : The nerve is dead ; A dead pallor ) numb : his gums were dead from the Novocain ) Not only does WordNet fail to distinguish those medically relevant meaning distinctions illustrated by phrases such as dead tissue , dead organ , dead matter , dead cell , dead body , etc. , but its definition of the primary medically relevant sense of dead ( as : ‘no longer having or seeming to have or expecting to have life’ ) runs together three separate notions which it is medically important to keep separate .</sentence>
				<definiendum id="0">dead</definiendum>
				<definiens id="0">a body part</definiens>
			</definition>
			<definition id="8">
				<sentence>( Medin and Atran , 1999 ) , ( Berlin and Kay , 1969 ) For example , tomato is often cited as an example of a basic level word , whereas vegetable is a superordinate , and cherry tomato is a subordinate .</sentence>
				<definiendum id="0">vegetable</definiendum>
				<definiendum id="1">cherry tomato</definiendum>
				<definiens id="0">a superordinate , and</definiens>
			</definition>
			<definition id="9">
				<sentence>Basic level words have many striking properties : they are universally lexicalized , characterized by high frequency of occurrence , and they are learned first by children .</sentence>
				<definiendum id="0">Basic level</definiendum>
				<definiens id="0">many striking properties : they are universally lexicalized , characterized by high frequency of occurrence , and they are learned first by children</definiens>
			</definition>
			<definition id="10">
				<sentence>, WordNet : An Electronic Lexical Database , MIT Press , Cambridge , Maryland , May 1998 .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An Electronic Lexical Database</definiens>
			</definition>
			<definition id="11">
				<sentence>Berwick , R. , Fellbaum , C. , Gross , D. , Miller , G. WordNet : A lexical database organized on psycholinguistic principles .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="12">
				<sentence>, WordNet : An Electronic Lexical Database , MIT Press , Cambridge , Maryland , May 1998 .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An Electronic Lexical Database</definiens>
			</definition>
			<definition id="13">
				<sentence>WordNet : an electronic lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">an electronic lexical database</definiens>
			</definition>
</paper>

		<paper id="1099">
			<definition id="0">
				<sentence>We tune the categorization system on a small set of OHSUMED abstracts : 1200 randomly selected abstracts were used to select the weighting parameters of the vector space classifler , and the best combination of these parameters with the regular expression-based classifler .</sentence>
				<definiendum id="0">OHSUMED</definiendum>
				<definiens id="0">abstracts : 1200 randomly selected abstracts were used to select the weighting parameters of the vector space classifler</definiens>
			</definition>
			<definition id="1">
				<sentence>Indeed , the MeSH provides a large set of related terms , which are mapped to a unique MeSH representative in the canonic collection .</sentence>
				<definiendum id="0">MeSH</definiendum>
				<definiens id="0">provides a large set of related terms , which are mapped to a unique MeSH representative in the canonic collection</definiens>
			</definition>
			<definition id="2">
				<sentence>Therefore the combination does not use the RegEx’s edit distance , and instead it uses the list returned by the vector space module as a reference list ( RL ) , while the list returned by the regular expression module is used as boosting list ( BL ) , which serves to improve the ranking of terms listed in RL .</sentence>
				<definiendum id="0">RL</definiendum>
				<definiendum id="1">BL</definiendum>
				<definiens id="0">serves to improve the ranking of terms listed in RL</definiens>
			</definition>
			<definition id="3">
				<sentence>BoosTexter : A boosting-based system for text categorization .</sentence>
				<definiendum id="0">BoosTexter</definiendum>
				<definiens id="0">A boosting-based system for text categorization</definiens>
			</definition>
</paper>

		<paper id="1182">
			<definition id="0">
				<sentence>The Colorado Literacy Tutor ( CLT ) is a technology-based literacy program , designed on the basis of cognitive theory and scientifically motivated reading research , which aims to improve literacy and student achievement in public schools .</sentence>
				<definiendum id="0">Colorado Literacy Tutor ( CLT )</definiendum>
				<definiens id="0">a technology-based literacy program , designed on the basis of cognitive theory and scientifically motivated reading research</definiens>
				<definiens id="1">aims to improve literacy and student achievement in public schools</definiens>
			</definition>
			<definition id="1">
				<sentence>One of the critical components of the CLT is a speech recognition system which is used to track the child’s progress during oral reading and to provide sufficient information to detect reading miscues .</sentence>
				<definiendum id="0">CLT</definiendum>
				<definiens id="0">a speech recognition system which is used to track the child’s progress during oral reading and to provide sufficient information to detect reading miscues</definiens>
			</definition>
			<definition id="2">
				<sentence>A key component of this program is the Interactive Book , which combines real-time multilingual speech recognition , facial animation , and natural language understanding capabilities to teach children to read and comprehend text .</sentence>
				<definiendum id="0">Interactive Book</definiendum>
				<definiens id="0">combines real-time multilingual speech recognition</definiens>
			</definition>
			<definition id="3">
				<sentence>The Colorado Literacy Tutor ( CLT ) 2 is a technology-based literacy program , designed on the basis of cognitive theory and scientifically motivated reading research , which aims to improve literacy and student achievement in public schools .</sentence>
				<definiendum id="0">Colorado Literacy Tutor</definiendum>
				<definiens id="0">a technology-based literacy program , designed on the basis of cognitive theory and scientifically motivated reading research</definiens>
				<definiens id="1">aims to improve literacy and student achievement in public schools</definiens>
			</definition>
			<definition id="4">
				<sentence>The CLT project consists of four tightly integrated components : Managed Learning Environment , Foundational Reading Skills Tutors , Interactive Books , and Latent-Semantic Analysis ( LSA ) -based comprehension training ( Steinhart 2001 ; Deerwester et al. , 1990 ; Landauer and Dumais , 1997 ) .</sentence>
				<definiendum id="0">CLT project</definiendum>
			</definition>
			<definition id="5">
				<sentence>Interactive Books incorporate speech recognition , spoken dialogue , natural language processing , and computer animation technologies to enable natural face-to-face conversational 2 http : //www.colit.org interaction with users .</sentence>
				<definiendum id="0">Interactive Books</definiendum>
				<definiens id="0">incorporate speech recognition , spoken dialogue , natural language processing , and computer animation technologies to enable natural face-to-face conversational 2 http : //www.colit.org interaction with users</definiens>
			</definition>
			<definition id="6">
				<sentence>The current 16 kHz sampled corpus consists of 10 different stories .</sentence>
				<definiendum id="0">kHz sampled corpus</definiendum>
				<definiens id="0">consists of 10 different stories</definiens>
			</definition>
			<definition id="7">
				<sentence>The reading tracking module determines the current reading location by aligning each partial hypothesis with the story text using a Dynamic Programming search .</sentence>
				<definiendum id="0">reading tracking module</definiendum>
				<definiens id="0">determines the current reading location by aligning each partial hypothesis with the story text using a Dynamic Programming search</definiens>
			</definition>
			<definition id="8">
				<sentence>Repetitions ( REP ) occur when the child realizes he/she has made a mistake and self corrects him/herself usually by repeating the misread word or by beginning the sentence over again .</sentence>
				<definiendum id="0">Repetitions</definiendum>
				<definiendum id="1">REP</definiendum>
				<definiens id="0">) occur when the child realizes he/she has made a mistake and self corrects him/herself usually by repeating the misread word or by beginning the sentence over again</definiens>
			</definition>
			<definition id="9">
				<sentence>We define a reading miscue event as any instance in which the child inserts , deletes or substitutes a word during oral reading .</sentence>
				<definiendum id="0">reading miscue event</definiendum>
				<definiens id="0">any instance in which the child inserts , deletes or substitutes a word during oral reading</definiens>
			</definition>
			<definition id="10">
				<sentence>The detection rate is defined as the number of times the hypothesis-target and transcription-target alignments show miscues at the same position divided by the number of transcription-target miscues .</sentence>
				<definiendum id="0">detection rate</definiendum>
				<definiens id="0">the number of times the hypothesis-target and transcription-target alignments show miscues at the same position divided by the number of transcription-target miscues</definiens>
			</definition>
			<definition id="11">
				<sentence>SONIC : The University of Colorado Continuous Speech Recognizer .</sentence>
				<definiendum id="0">SONIC</definiendum>
			</definition>
			<definition id="12">
				<sentence>Multilingual Human-Computer Interactions : From Information Access to Language Learning .</sentence>
				<definiendum id="0">Multilingual Human-Computer Interactions</definiendum>
			</definition>
</paper>

		<paper id="1126">
			<definition id="0">
				<sentence>The test corpus consists of 100 Wall Street Journal documents from the period January 1993 to June 1994 , 54 of which contained management succession events ( Sundheim , 1995 ) .</sentence>
				<definiendum id="0">test corpus</definiendum>
			</definition>
			<definition id="1">
				<sentence>type ( person in ) person ( ‘R. Wayne Diesel’j‘Diesel’ ) org ( ‘Mechanical Technology Inc.’| ‘Mechanical Technology’ ) post ( ‘chief executive officer’ ) type ( person in ) person ( ‘R. Wayne Diesel’ ) org ( ‘Mechanical Technology’ ) post ( ‘chief executive officer’ ) PartialApartialmatchoccurswhenoneevent contains a proper subset of the flelds of another event .</sentence>
				<definiendum id="0">‘R. Wayne Diesel’j‘Diesel’ ) org</definiendum>
				<definiendum id="1">‘R. Wayne Diesel’ ) org</definiendum>
				<definiens id="0">‘chief executive officer’ ) PartialApartialmatchoccurswhenoneevent contains a proper subset of the flelds of another event</definiens>
			</definition>
</paper>

		<paper id="1130">
</paper>

		<paper id="1061">
			<definition id="0">
				<sentence>The DTD introduces XML tags for each of the connectives ( &lt; connective &gt; ) , their possible modi ers ( &lt; modifier &gt; ) and respective discourse units ( &lt; unit &gt; , where the type can be lled by int or ext ) , as well as the entire text ( &lt; discourse &gt; ) .</sentence>
				<definiendum id="0">DTD</definiendum>
				<definiens id="0">introduces XML tags for each of the connectives ( &lt; connective &gt; ) , their possible modi ers ( &lt; modifier &gt; ) and respective discourse units ( &lt; unit &gt;</definiens>
			</definition>
			<definition id="1">
				<sentence>&lt; ? xml version=’1.0’ encoding=’UTF-8’ ? &gt; &lt; ! ELEMENT modifier ( # PCDATA ) &gt; &lt; ! ELEMENT connective ( # PCDATA|modifier ) &gt; &lt; ! ATTLIST connective id CDATA # IMPLIED rel CDATA # IMPLIED &gt; &lt; ! ELEMENT unit ( # PCDATA|connective|unit ) * &gt; &lt; ! ATTLIST unit id CDATA # IMPLIED type CDATA # IMPLIED &gt; &lt; ! ELEMENT discourse ( # PCDATA|unit ) * &gt; Figure 1 : The DTD for texts-with-connectives &lt; ? xml version= '' 1.0 '' ? &gt; &lt; ! DOCTYPE discourse SYSTEM `` discourse.dtd '' &gt; &lt; discourse &gt; &lt; unit type= '' ext '' id= '' 4 '' &gt; Auch Berlin koennte , &lt; connective id= '' 4 '' relation= '' condition '' &gt; &lt; modifier &gt; jedenfalls &lt; /modifier &gt; dann &lt; /connective &gt; , &lt; /unit &gt; &lt; unit type= '' int '' id= '' 4 '' &gt; &lt; connective id= '' 4 '' relation= '' condition '' &gt; wenn &lt; /connective &gt; der Bund sich erkenntlich zeigt , um die Notlage seiner Hauptstadt zu lindern , &lt; /unit &gt; &lt; unit type= '' ext '' id= '' 4 '' &gt; davon profitieren .</sentence>
				<definiendum id="0">DOCTYPE discourse SYSTEM</definiendum>
			</definition>
			<definition id="2">
				<sentence>&lt; /example &gt; &lt; /entry &gt; &lt; /dictionary &gt; Figure 5 : DiMLex extract this purpose , we present an annotation environment , including our ConAno tool , which helps human annotators to mark discourse connectives and their argument units by nding possible connectives and making suggestions on their estimated argument structure .</sentence>
				<definiendum id="0">ConAno tool</definiendum>
				<definiens id="0">helps human annotators to mark discourse connectives and their argument units by nding possible connectives and making suggestions on their estimated argument structure</definiens>
			</definition>
			<definition id="3">
				<sentence>RST-Tool : An RST Analysis Tool .</sentence>
				<definiendum id="0">RST-Tool</definiendum>
				<definiens id="0">An RST Analysis Tool</definiens>
			</definition>
</paper>

		<paper id="1108">
			<definition id="0">
				<sentence>Lapata ( Lapata , 2003 ) proposes another approach to information ordering based on a probabilistic model that assumes the probability of any given sentence is determined by its adjacent sentence and learns constraints on sentence order from a corpus of domain specific texts .</sentence>
				<definiendum id="0">Lapata</definiendum>
				<definiens id="0">information ordering based on a probabilistic model that assumes the probability of any given sentence is determined by its adjacent sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Lapata estimates transitional probability between sentences by some attributes such as verbs ( precedence relationships of verbs in the corpus ) , nouns ( entity-based coherence by keeping track of the nouns ) and dependencies ( structure of sentences ) .</sentence>
				<definiendum id="0">Lapata</definiendum>
			</definition>
			<definition id="2">
				<sentence>Hence , publication date ( time ) of each article turns out to be a good estimator of resemblance relation ( i.e. , we observe a trend or series of relevant events in a time period ) , contiguity in time , and cause-effect relation ( i.e. , an event occurs as a result of previous events ) .</sentence>
				<definiendum id="0">cause-effect relation</definiendum>
				<definiens id="0">a trend or series of relevant events in a time period ) , contiguity in time</definiens>
			</definition>
			<definition id="3">
				<sentence>Let { s1 , ... , sn } be a set of summary sentences identified with index numbers from 1 to n. We define a permutation pi ∈ Sn to denote an ordering of sentences where pi ( i ) represents an order of sentence si .</sentence>
				<definiendum id="0">{ s1 , ... , sn</definiendum>
				<definiens id="0">a permutation pi ∈ Sn to denote an ordering of sentences where pi ( i ) represents an order of sentence si</definiens>
			</definition>
			<definition id="4">
				<sentence>( 3 ) Spearman’s rank correlation τs ( pi , σ ) and Kendall’s rank correlation τk ( pi , σ ) are known as famous rank correlation metrics .</sentence>
				<definiendum id="0">3 ) Spearman’s rank correlation τs</definiendum>
			</definition>
			<definition id="5">
				<sentence>Chronological ordering ( CO ) did not yield satisfactory result losing a thread of 63 % summaries although CO performed much better than RO .</sentence>
				<definiendum id="0">Chronological ordering</definiendum>
				<definiens id="0">a thread of 63 % summaries although CO performed much better than RO</definiens>
			</definition>
			<definition id="6">
				<sentence>It appears that average figures shows similar tendency to the rating task with three measures : HO is the best ; PO is better than CO ; and RO is definitely the worst .</sentence>
				<definiendum id="0">HO</definiendum>
				<definiens id="0">the best ; PO is better than CO</definiens>
			</definition>
			<definition id="7">
				<sentence>Only sentence continuity τc proved PO is better than CO ; and HO is better than CO ( α = 0.05 ) .</sentence>
				<definiendum id="0">HO</definiendum>
				<definiens id="0">better than CO</definiens>
			</definition>
			<definition id="8">
				<sentence>TISS : An integrated summarization system for TSC-3 .</sentence>
				<definiendum id="0">TISS</definiendum>
				<definiens id="0">An integrated summarization system for TSC-3</definiens>
			</definition>
</paper>

		<paper id="1123">
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>To address this quandary , this paper reports on the PRECISE NLI , which uses a statistical parser as a “plug in” .</sentence>
				<definiendum id="0">PRECISE NLI</definiendum>
				<definiens id="0">uses a statistical parser as a “plug in”</definiens>
			</definition>
			<definition id="1">
				<sentence>We define a lexicon as a tuple ( T ; E ; M ) , where T is a set of strings , called tokens ( intuitively , tokens are strings of one or more words , like “New York” ) ; E is a set of database elements , wh-values , and join paths ; 2 and M is a subset of T E — a binary relation between tokens and database elements .</sentence>
				<definiendum id="0">T</definiendum>
				<definiendum id="1">; E</definiendum>
				<definiendum id="2">M</definiendum>
				<definiens id="0">a set of strings , called tokens ( intuitively , tokens are strings of one or more words , like “New York” )</definiens>
				<definiens id="1">a set of database elements</definiens>
				<definiens id="2">a subset of T E — a binary relation between tokens and database elements</definiens>
			</definition>
			<definition id="2">
				<sentence>The query generator takes each semantic logical form and uses the join path information available in the restrictions to form the final SQL queries corresponding to each semantic interpretation .</sentence>
				<definiendum id="0">query generator</definiendum>
				<definiens id="0">takes each semantic logical form and uses the join path information available in the restrictions to form the final SQL queries corresponding to each semantic interpretation</definiens>
			</definition>
			<definition id="3">
				<sentence>A tokenization of a question ( with respect to a lexicon ) is an ordered set of strings such that each element of the tokenization is an element of the lexicon’s token set , and the concatenation of the elements of the tokenization , in order , is equal to the original question .</sentence>
				<definiendum id="0">tokenization of a question</definiendum>
				<definiens id="0">an element of the lexicon’s token set</definiens>
			</definition>
			<definition id="4">
				<sentence>Then we require that f ( f 1 ( g 1 ( a ) ) ; f 1 ( a ) ) j a 2 A0g respects FL ; q. ) We say that an NLI is sound for a class of questions Q using lexicon L and attachment function FL if for every input q 2 Q , every output of the NLI is a valid interpretation .</sentence>
				<definiendum id="0">f 1</definiendum>
				<definiendum id="1">NLI</definiendum>
				<definiens id="0">a valid interpretation</definiens>
			</definition>
			<definition id="5">
				<sentence>PRECISE , which embodies the model of semantic tractability , achieves very high accuracy because in practice it either has correct and complete lexical and syntactic information or it has enough semantic information to compensate for its imperfect inputs .</sentence>
				<definiendum id="0">PRECISE</definiendum>
				<definiens id="0">embodies the model of semantic tractability , achieves very high accuracy because in practice it either has correct and complete lexical and syntactic information</definiens>
			</definition>
			<definition id="6">
				<sentence>However , we have been able to formulate PRECISE’s constraint satisfaction problem as a graph matching problem that is solved in polynomial time by the MaxFlow algorithm : Theorem 2 For lexicon L , PRECISE finds one valid interpretation for a tokenization T of a semantically tractable question in time O ( Mn2 ) , where n is the number of tokens in T and M is the maximum number of interpretations that a token can have in L. Semantic Tractability ( ST ) theory and PRECISE’s architecture raise a four empirical questions that we now address via experiments on the ATIS data set ( Price , 1990 ) : how prevalent are ST questions ?</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of tokens in T and M is the maximum number of interpretations that a token can have in L. Semantic Tractability ( ST ) theory</definiens>
			</definition>
			<definition id="7">
				<sentence>ParserORIG is the original version of the parser , ParserTRAINED is the version re-trained for the ATIS domain , and ParserCORRECT is the version whose output is corrected manually .</sentence>
				<definiendum id="0">ParserORIG</definiendum>
				<definiendum id="1">ParserTRAINED</definiendum>
				<definiendum id="2">ParserCORRECT</definiendum>
				<definiens id="0">the original version of the parser</definiens>
				<definiens id="1">the version whose output is corrected manually</definiens>
			</definition>
			<definition id="8">
				<sentence>Most recently , ( He and Young , 2003 ) introduced the HEY system , which learns a semantic parser without requiring fully-annotated corpora .</sentence>
				<definiendum id="0">HEY system</definiendum>
				<definiens id="0">learns a semantic parser without requiring fully-annotated corpora</definiens>
			</definition>
			<definition id="9">
				<sentence>TEAM : An Experiment in the Design of Transportable Natural Language Interfaces .</sentence>
				<definiendum id="0">TEAM</definiendum>
			</definition>
</paper>

		<paper id="1043">
			<definition id="0">
				<sentence>In this paper we present Uni cational Combinatory Categorial Grammar ( UCCG ) , which integrates aspects of Combinatory Categorial Grammar ( Steedman , 2000 ) , Uni cation Categorial Grammar ( Zeevat , 1988 ; Calder et al. , 1988 ) , and Discourse Representation Theory ( Kamp and Reyle , 1993 ) .</sentence>
				<definiendum id="0">Discourse Representation Theory</definiendum>
				<definiens id="0">cational Combinatory Categorial Grammar ( UCCG ) , which integrates aspects of Combinatory Categorial Grammar ( Steedman , 2000 ) , Uni cation Categorial Grammar ( Zeevat , 1988 ; Calder et al. , 1988 ) , and</definiens>
			</definition>
			<definition id="1">
				<sentence>While the pure CG only involved functional application rules for combining categories , CCG introduces several additional combinatory rules for both syntactic and semantic composition | forward and backward composition , and crossed composition , as well as substitution rules .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiens id="0">introduces several additional combinatory rules for both syntactic and semantic composition | forward and backward composition , and crossed composition</definiens>
			</definition>
			<definition id="2">
				<sentence>For building semantic representation CCG uses the lambda calculus , although unication has been proposed as well ( Steedman , 1990 ) .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiens id="0">uses the lambda calculus</definiens>
			</definition>
			<definition id="3">
				<sentence>UCCG employs DRT ( Kamp and Reyle , 1993 ) with neo-davidsonian style event semantics as semantic formalism , but extends the basic DRS language to allow integration of prosodic information in syntactic and semantic analysis .</sentence>
				<definiendum id="0">DRT</definiendum>
				<definiens id="0">semantic formalism , but extends the basic DRS language to allow integration of prosodic information in syntactic and semantic analysis</definiens>
			</definition>
			<definition id="4">
				<sentence>A basic sign is a list of attributes or features describing the syntactic and semantic characteristics of a lexical expression , in the spirit of UCG .</sentence>
				<definiendum id="0">basic sign</definiendum>
				<definiens id="0">a list of attributes or features describing the syntactic and semantic characteristics of a lexical expression , in the spirit of UCG</definiens>
			</definition>
			<definition id="5">
				<sentence>Y is the argument of a sign X/Y or XnY .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">the argument of a sign X/Y or XnY</definiens>
			</definition>
			<definition id="6">
				<sentence>where word is a lexical item , and W1 and W2 are variables that get values through uni cation in the categorial combination process .</sentence>
				<definiendum id="0">word</definiendum>
				<definiens id="0">a lexical item , and W1 and W2 are variables that get values through uni cation in the categorial combination process</definiens>
			</definition>
			<definition id="7">
				<sentence>2 66 66 66 66 66 66 64 pho : married+Manny cat : vp var : Z sit : E inf : drs : X E manny ( X ) : + marry ( E ) : agent ( E , Z ) patient ( E , X ) 3 77 77 77 77 77 77 75 2 66 66 64 pho : W cat : C var : X sit : E inf : drs : D 3 77 77 75 $ n 2 66 66 64 pho : W cat : C var : X sit : E inf : drs : D 3 77 77 75 $ |||||||||||||||||||| { &lt; 2 66 66 66 66 66 66 64 pho : married+Manny cat : vp var : Z sit : E inf : drs : X E manny ( X ) : + marry ( E ) : agent ( E , Z ) patient ( E , X ) 3 77 77 77 77 77 77 75 Figure 2 : Derivation of married Manny H* LL % using Backward Application Finally , Figures 1 to 3 show a complete parse of the prosodically marked sentence ’Anna L+H* LH % married Manny H* LL % ’ .</sentence>
				<definiendum id="0">E inf</definiendum>
				<definiens id="0">married+Manny cat : vp var : Z sit : E inf : drs : X E manny ( X ) : + marry ( E ) : agent ( E</definiens>
				<definiens id="1">married+Manny cat : vp var : Z sit : E inf : drs : X E manny ( X ) : + marry ( E ) : agent ( E , Z ) patient ( E , X</definiens>
			</definition>
			<definition id="8">
				<sentence>Due to variable uni cation in the features var and sit , while performing the syntactic combination of the lexical signs , we simultaneously construct the semantic representation in the DRS. 2 66 66 4 pho : Anna+W cat : s inf : drs : Y anna ( Y ) : + ; D 3 77 77 5 / 2 66 66 66 4 pho : W cat : vp var : Y sit : E inf : drs : D 3 77 77 77 5 2 66 66 66 66 66 66 64 pho : married+Manny cat : vp var : Z sit : E inf : drs : X E manny ( X ) : + marry ( E ) : agent ( E , Z ) patient ( E , X ) 3 77 77 77 77 77 77 75 ||||||||||||||||||| { &gt; 2 66 66 66 66 66 64 pho : Anna+married+Manny cat : s inf : drs : Y X E anna ( Y ) : + manny ( X ) : + marry ( E ) : agent ( E , Y ) patient ( E , X ) 3 77 77 77 77 77 75 Figure 3 : Derivation for ’Anna L+H* LH % married Manny H* LL % ’ , using Forward Application and Merge-Reduction The present paper described the Uni cational Combinatory Categorial Grammar ( UCCG ) formalism , which was developed bearing in mind its future application in parsing and generating prosodically annotated text .</sentence>
				<definiendum id="0">Z ) patient</definiendum>
				<definiens id="0">Z sit : E inf : drs : X E manny ( X ) : + marry ( E ) : agent ( E ,</definiens>
				<definiens id="1">Anna+married+Manny cat : s inf : drs : Y X E anna ( Y ) : + manny ( X ) : + marry ( E ) : agent ( E , Y ) patient ( E , X ) 3 77 77 77 77 77 75 Figure 3 : Derivation for ’Anna L+H* LH % married Manny H* LL % ’ , using Forward Application and Merge-Reduction The present paper described the Uni cational Combinatory Categorial Grammar</definiens>
			</definition>
</paper>

		<paper id="1144">
</paper>

		<paper id="1034">
			<definition id="0">
				<sentence>dar follows the es00 and phora strategy of discriminating between IPAsandAPAs by rules looking at the semantic constraints on the predication contexts in which the anaphors occur .</sentence>
				<definiendum id="0">dar</definiendum>
				<definiens id="0">follows the es00 and phora strategy of discriminating between IPAsandAPAs by rules looking at the semantic constraints on the predication contexts in which the anaphors occur</definiens>
			</definition>
			<definition id="1">
				<sentence>dar consists of two diﬀerent functions ResolveDet and ResolveIpa .</sentence>
				<definiendum id="0">dar</definiendum>
				<definiens id="0">consists of two diﬀerent functions ResolveDet and ResolveIpa</definiens>
			</definition>
			<definition id="2">
				<sentence>ResolveIpa resolves the occurrence of the pronoun hun ( she ) in U 3 to the most salient candidate NP in the Ilist , vores nabo .</sentence>
				<definiendum id="0">ResolveIpa</definiendum>
				<definiens id="0">resolves the occurrence of the pronoun hun ( she ) in U 3 to the most salient candidate NP in the Ilist , vores nabo</definiens>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>FLMs are a generalization of standard language models in that they allow a larger set of conditioning variables for predicting the current word .</sentence>
				<definiendum id="0">FLMs</definiendum>
				<definiens id="0">a larger set of conditioning variables for predicting the current word</definiens>
			</definition>
			<definition id="1">
				<sentence>Backo is a common smoothing technique in language modeling .</sentence>
				<definiendum id="0">Backo</definiendum>
			</definition>
			<definition id="2">
				<sentence>Ngrams whose counts are above the threshold retain their maximum-likelihood estimates , discounted by a factor that re-distributes probability mass to the lower-order distribution : pBO ( wtjwt 1 ; wt 2 ) ( 3 ) = d cpML ( wtjwt 1 ; wt 2 ) if c &gt; 3 ( wt 1 ; wt 2 ) pBO ( wtjwt 1 ) otherwise where c is the count of ( wt ; wt 1 ; wt 2 ) , pML denotes the maximum-likelihood estimate and dc is a discounting factor that is applied to the higher-order distribution .</sentence>
				<definiendum id="0">c</definiendum>
				<definiendum id="1">pML</definiendum>
				<definiendum id="2">dc</definiendum>
				<definiens id="0">Ngrams whose counts are above the threshold retain their maximum-likelihood estimates , discounted by a factor that re-distributes probability mass to the lower-order distribution : pBO ( wtjwt 1</definiens>
				<definiens id="1">the maximum-likelihood estimate and</definiens>
				<definiens id="2">a discounting factor that is applied to the higher-order distribution</definiens>
			</definition>
			<definition id="3">
				<sentence>The morphological tags consist of the initial root , followed by a sequence of in ectional groups delimited by derivation boundaries ( ^DB ) .</sentence>
				<definiendum id="0">morphological tags</definiendum>
			</definition>
			<definition id="4">
				<sentence>A sample annotation ( for the word yararlanmak , consisting of the root yarar plus three in ectional groups ) is shown below : yararmanlak : yarar+Noun+A3sg+Pnon+Nom ^DB+Verb+Acquire+Pos ^DB+Noun+Inf+A3sg+Pnon+Nom We removed segmentation marks ( for titles and paragraph boundaries ) from the corpus but included punctuation .</sentence>
				<definiendum id="0">sample annotation</definiendum>
				<definiens id="0">the word yararlanmak , consisting of the root yarar plus three in ectional groups</definiens>
			</definition>
			<definition id="5">
				<sentence>The Arabic models made use of all conditioning variables ( Word , Stem , Root , Pattern , and Morph ) whereas the Turkish models used only the W , P , C , and R variables ( see above Section 4 ) .</sentence>
				<definiendum id="0">Morph )</definiendum>
				<definiendum id="1">R variables</definiendum>
				<definiens id="0">whereas the Turkish models used only the W , P , C , and</definiens>
			</definition>
			<definition id="6">
				<sentence>Hierarchical class n-gram language models : towards better estimation of unseen events in speech recognition .</sentence>
				<definiendum id="0">Hierarchical class n-gram language models</definiendum>
				<definiens id="0">towards better estimation of unseen events in speech recognition</definiens>
			</definition>
</paper>

		<paper id="1201">
			<definition id="0">
				<sentence>Moreover , current evaluation environments of QA systems , such as TREC QA track ( Voorhees , 2001 ) and CLEF ( Peters et al. , 2003 ) , restrict the size of the answers to a maximum of 50 bytes .</sentence>
				<definiendum id="0">CLEF</definiendum>
				<definiens id="0">Peters et al. , 2003 ) , restrict the size of the answers to a maximum of 50 bytes</definiens>
			</definition>
			<definition id="1">
				<sentence>These queries take the following form : • “President is a person” • “President is a place” • “President is a date” • “President is a measure” • “President is an organization” We count the number of results returned by Google for each query and normalize them by their sum .</sentence>
				<definiendum id="0">“President</definiendum>
				<definiendum id="1">“President</definiendum>
				<definiendum id="2">“President</definiendum>
				<definiens id="0">an organization” We count the number of results returned by Google for each query and normalize them by their sum</definiens>
			</definition>
			<definition id="2">
				<sentence>The query is now like this : “President French is a si” and given that again we have no results returned we finally formulate the last possible query : “President is a si” which returns results for all the semantic classes except for Date .</sentence>
				<definiendum id="0">“President</definiendum>
				<definiens id="0">a si” which returns results for all the semantic classes except for Date</definiens>
			</definition>
			<definition id="3">
				<sentence>Creating the DISEQuA corpus : a test set for multilingual question answering .</sentence>
				<definiendum id="0">Creating the DISEQuA corpus</definiendum>
			</definition>
</paper>

		<paper id="1200">
			<definition id="0">
				<sentence>Then the sentence sentiment classifier calculates the polarity of all sentiment-bearing words individually .</sentence>
				<definiendum id="0">sentence sentiment classifier</definiendum>
				<definiens id="0">calculates the polarity of all sentiment-bearing words individually</definiens>
			</definition>
			<definition id="1">
				<sentence>That is , we compute ( 1 ) ) ... .. , | ( maxarg ) | ( maxarg 21 n c c synsynsyncP wcP ≅ where c is a sentiment category ( positive or negative ) , w is the unseen word , and syn n are the WordNet synonyms of w. To compute Equation ( 1 ) , we tried two different models : ( 2 ) ) | ( ) ( maxarg ) | ( ) ( maxarg ) | ( ) ( maxarg ) | ( maxarg 1 ) ) ( , ( ... 3 2 1 ∏ = = = = m k wsynsetfcount k c n c cc k cfPcP csynsynsynsynPcP cwPcPwcP where f k is the k th feature ( list word ) of sentiment class c which is also a member of the synonym set of w , and count ( f k , synset ( w ) ) is the total number of occurrences of f k in the synonym set of w. P ( c ) is the number of words in class c divided by the total number of words considered .</sentence>
				<definiendum id="0">c</definiendum>
				<definiendum id="1">w</definiendum>
				<definiendum id="2">syn n</definiendum>
				<definiendum id="3">)</definiendum>
				<definiens id="0">( 2 ) ) | ( ) ( maxarg ) | ( ) ( maxarg ) | ( ) ( maxarg ) | ( maxarg 1 ) ) ( , ( ... 3 2 1 ∏ = = = = m k wsynsetfcount k c n c cc k cfPcP csynsynsynsynPcP cwPcPwcP where f k is the k th feature ( list word ) of sentiment class c which is also a member of the synonym set of w , and count ( f k , synset ( w )</definiens>
				<definiens id="1">the total number of occurrences of f k in the synonym set of w. P ( c ) is the number of words in class c divided by the total number of words considered</definiens>
			</definition>
			<definition id="2">
				<sentence>Adjective ( test : 231 adjectives ) Verb ( test : 251 verbs ) Lenient agreement Lenient agreement H1 : M H2 : M recall H1 : M H3 : M recall Random selection ( average of 10 iterations ) 59.35 % 57.81 % 100 % 59.02 % 56.59 % 100 % Basic method 68.37 % 68.60 % 93.07 % 75.84 % 72.72 % 83.27 % p1/p2 and p3/p4 represent the word classifier models in Equation ( 2 ) and Equation ( 3 ) with normalization and without normalization respectively .</sentence>
				<definiendum id="0">Adjective ( test</definiendum>
				<definiens id="0">231 adjectives ) Verb ( test : 251 verbs ) Lenient agreement Lenient agreement H1</definiens>
			</definition>
			<definition id="3">
				<sentence>Introduction to WordNet : An On-Line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="4">
				<sentence>The New Rhetoric : A Theory of Practical Reasoning .</sentence>
				<definiendum id="0">New Rhetoric</definiendum>
			</definition>
</paper>

		<paper id="1084">
			<definition id="0">
				<sentence>Object Object C−relation C−relation C−relation C−relation after a truck crammed with explosives plowed into a203a16a217a227a242 a236 a228a135a213a90a19 a159 a0a8a221a45a220a87a226a158a216a45a222a227a213a159a215a87a219a16a214a156a215a69a216a45a217a227a218a33a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a34a232 a25 a52a120a71a61a64a66a80a28a80a28a54a2a71a139a186a100a70a28a71a61a88a63a82a14a69a9a70a28a71a14a62a63a70a28a72a84a64a66a62a78a77a79a74a66a64a83a82a60a77a85a56a58a64a66a70a28a62a57a56a44a58a18a70a79a69a117a103a98a54a2a71a58a101a60a59 a77a79a71a61a54a73a70a28a101a55a75 a56a61a77a79a64a66a62a63a54a2a88a21a101a47a188a90a67a63a82a61a64a66a62a63a80a102a56a61a53a63a54a73a72a84a70a28a71a61a76a63a53a63a70a28a74a66a70a28a80a28a64a66a59a60a77a79a74a57a88a63a54a2a71a61a64a103a28a77a85a56a58a64a66a70a28a62a63a82a86a70a79a69a100a56a58a53a63a54a173a56a61a71a58a64a66a80a28a80a28a54a2a71 a186a100a70a28a71a58a88a63a82a100a69a137a70a28a71a61a59a173a104 a155a157a156a155 a159a63a62a37a163a64a32 a166 a168a120a163a55a48a43a166a66a65a4a67a152a161a142a169a69a68a109a166a11a35a12a163a164a160a33a161a23a39a37a162a39a159a187a166a66a47a120a161a23a68 a70 a163a11a48a40a37a38a33a34a161a142a166a71a39a37a169 a72 a236 a228a70a226a14a215a110a237a110a213a127a222a10a215a146a219a145a237a45a217a227a224a135a218a26a215a80a235a69a213a34a228a135a217a199a225a45a242a172a213a34a221a129a214a135a228a135a220a69a218a152a214a135a217a199a215a69a225a20a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a151a213a127a226a35a243 a216a45a222a227a215a80a223a110a224a25a220a170a235a69a213a34a228a135a223a185a222a227a220a146a228a156a242a69a213a244a218a34a215a146a228a135a216 a236 a224a94a215a87a219a14a214a156a213a34a221a164a214a135a224a127a232 a240a244a213 a236 a224a156a213a127a237a43a214a156a212a72a213 a36a6a73a61a28a32a36a10a254a138a229a10a211 a218a34a215a146a228a135a216 a236 a224a76a248a78a230a43a4a27a19a31a19a38a220a80a214a125a220a87a222a227a215a146a242a64a74a35a230a43a4a27a19a84a251a87a252a69a252a69a251a146a211a84a15a33a44a71a253a26a238 a239a6a212a45a217a148a218a125a212a29a218a26a215a146a225a129a214a125a220a87a217a227a225a72a224 a15a22a49a48a19 a226a14a217a227a222a227a222a199a217a227a215a146a225a29a239a38a215a146a228a125a237a45a224a185a218a26a215a69a228a156a228a135a213a34a222a148a220a80a214a135a217a199a225a72a242a179a214a135a215 a220a87a233a55a215 a236 a214a102a15a76a75a12a145a184a215a87a219a8a237a45a220a80a214a125a220a45a232a163a211a84a212a72a213a18a217a227a237a45a213a127a220a2a77a18a217a227a224a84a214a135a212a72a220a80a214a33a224a138a214a125a220a87a228a156a214a156a217a227a225a45a242a151a239a6a217a133a214a135a212 a220a76a224a156a213a34a213a71a237a62a224a156a213a26a214a159a215a87a219a208a213a34a221a129a214a135a228a135a220a69a218a152a214a135a217a199a215a69a225a182a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a12a239a38a213a35a218a26a215 a236 a222a148a237a62a224a156a213a34a216a72a220a146a228a135a220a87a214a156a213 a214a156a212a72a213a31a218a26a215a146a228a135a216 a236 a224a32a217a227a225a129a214a156a215 a159 a248a2a44a67a253a32a220a159a224a51a213a34a214a208a215a87a219a58a228a156a213a127a222a199a213a127a235a67a220a146a225a129a214a8a237a45a215a164a218 a236 a226a158a213a34a225a129a214a135a224a49a218a26a215a146a225a45a243 a214a135a220a146a217a199a225a72a217a199a225a45a242a35a214a156a212a72a213a159a224a156a213a34a213a71a237a154a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a34a238a110a220a146a225a72a237a62a248a74a251a146a253a163a220a35a218a34a215a146a226a158a216a45a222a227a213a34a226a158a213a34a225a129a214a135a220a146a228a156a223 a224a156a213a26a214a12a215a146a219a8a225a45a215a146a225a110a243a181a228a135a213a34a222a227a213a34a235a80a220a87a225a129a214a12a237a110a215a110a218 a236 a226a158a213a34a225a129a214a135a224a127a232a6a254a131a225a72a224a51a214a156a213a127a220a69a237a25a215a87a219a208a218a34a215a146a225a72a224a156a217a227a237a45a213a34a228a156a243 a217a227a225a45a242a154a214a135a212a45a213a161a213a127a225a69a214a135a217a199a228a135a213a63a36a6a73a61a28a14a36a31a254a138a229a12a211a241a218a26a215a146a228a135a216 a236 a224a10a239a163a213 a236 a224a156a213a127a237a25a215a69a225a45a222a199a223a4a237a110a215a110a218a152a243 a236 a226a158a213a34a225a129a214a125a224a35a228a135a213a26a214a135a228a156a217a227a213a34a235a69a213a127a237a172a239a6a212a45a213a127a225a192a219a169a215a69a228a156a226 a236 a222a227a220a87a214a156a217a227a225a45a242a62a220a153a245 a236 a213a34a228a135a223a79a78a25a214a156a212a72a220a87a214 a218a125a212a72a220a146a228a135a220a69a218a152a214a156a213a127a228a156a217a137a8a34a213a71a224a8a214a135a212a45a213a33a224a135a218a26a213a127a225a72a220a87a228a135a217a227a215a35a237a110a215a69a226a158a220a146a217a199a225a112a232a32a211a84a212a72a213a12a254a131a225a110a219a169a215a69a228a156a226a151a220a87a214a156a217a227a215a146a225 a54a6a213a34a214a156a228a135a217a199a213a127a235a67a220a146a222a208a248a169a254a134a54a10a253a31a224a51a223a110a224a51a214a156a213a34a226 a239a163a213a145a213a127a226a14a216a72a222a199a215a80a223a154a217a148a224a186a6a120a3a18a36a14a54a32a211a42a248a58a145 a236 a218a79a144a129a243 a222a227a213a34a223a159a213a26a214a8a220a87a222a74a232a199a238a120a44a55a46a48a46a26a25a69a253a152a232a45a203a45a215a146a228a96a213a26a221a45a220a87a226a158a216a45a222a227a213a146a238a67a219a169a215a69a228a112a214a135a212a45a213a80a50a51a233a55a215a146a226a161a233a72a217a199a225a45a242a55a52a31a237a110a215a146a243 a226a151a220a87a217a227a225a2a238a58a239a163a213 a236 a224a156a213a127a237a182a220a70a224a51a217a227a225a45a242a146a222a227a213a26a243a81a144a146a213a127a223a164a239a163a215a69a228a135a237a94a245 a236 a213a34a228a135a223 a159 a126a187a38a81a121a6a5a98a108a37a164a9a107a34a40a48a121a42a41a79a140a82a81 a220a87a225a59a237a76a228a135a213a26a214a135a228a156a217a227a213a34a235a69a213a127a237a4a251a87a252a146a252a69a252a35a237a45a215a164a218 a236 a226a158a213a34a225a129a214a135a224a127a232 a211a84a212a45a213a151a214a156a228a135a217a227a242a146a242a146a213a127a228a145a239a163a215a69a228a135a237a72a224a159a219a169a215a146a228a161a214a156a212a45a213a154a225a72a213a34a239a42a214a156a215a69a216a45a217a227a218a154a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a165a220a87a228a135a213 a220a87a222a148a224a156a215a70a237a110a213a127a228a156a217a227a235a146a213a71a237a102a232a30a203a72a215a146a228a33a213a26a221a45a220a87a226a158a216a45a222a227a213a146a238a58a217a227a225a182a214a135a212a45a213a14a218a127a220a146a224a156a213a161a215a146a219a8a214a156a212a45a213a158a211a112a215a69a216a45a217a148a218 a178a14a183 a214a156a212a45a213a94a237a110a213a34a228a135a217a199a235a69a213a127a237a153a214a156a228a135a217a227a242a146a242a146a213a127a228a18a239a38a215a146a228a125a237a45a224a159a219a169a215a146a228a161a214a156a212a45a213a70a224a51a213a127a213a127a237a172a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a59a224 a220a87a228a135a213 a38a81a121a6a5a98a108a37a164a9a107a34a40a48a121a42a41a151a220a146a225a72a237a35a38a121a40a48a121a68a105a81a107a87a115a37a116a78a105a5a121a42a41a152a232a206a211a84a212a45a213a182a218a26a215a69a228a156a228a135a213a127a224a156a216a59a215a69a225a72a237a110a217a227a225a45a242 a228a135a213a34a222a227a213a34a235a80a220a87a225a129a214a154a213a34a225a129a214a135a217a133a214a135a217a199a213a71a224a151a219a169a215a146a228a154a214a156a212a45a213a64a83a85a84a61a86a6a87 a88a155a107a87a119a79a40a25a218a34a215a146a225a72a224a156a217a227a224a51a214a135a224a154a215a87a219a1a15 a239a38a215a146a228a125a237a45a224 a159 a50a51a233a55a215a146a226a35a233a34a52a45a238a57a50a51a242a69a228a156a213a127a225a72a220a146a237a45a213a89a52a146a220a146a225a72a237a90a50a51a226a158a217a199a225a72a213a89a52a45a232a241a211a84a212a45a213a182a214a156a228a135a217a199a242a146a243 a242a146a213a127a228a12a239a38a215a146a228a125a237a45a224a127a238a55a214a156a212a45a213a151a218a26a215a69a228a156a216 a236 a224a20a91a57a92a161a220a87a225a72a237a62a214a156a212a72a213a14a224a156a213a34a213a71a237a62a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a62a220a87a228a135a213 a214a156a212a72a213a6a215a146a225a45a222a227a223a161a217a227a225a45a216 a236 a214a125a224a8a214a135a215a33a215 a236 a228a208a216a45a228a135a215a110a218a26a213a71a237 a236 a228a135a213a163a214a135a212a72a220a80a214a49a237a45a217a227a224a135a218a26a215a80a235a69a213a34a228a125a224a96a233a55a215a87a214a135a212 a224a156a223a129a225a129a214a125a220a80a221a164a243a74a233a59a220a146a224a156a213a127a237a165a220a87a225a59a237a55a19a49a243a181a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a18a219a169a228a156a215a69a226a28a214a156a212a45a213a4a237a110a215a110a218 a236 a226a158a213a127a225a69a214a125a224a34a232 a211a84a212a45a213a18a237a110a217a148a224a135a218a26a215a80a235a146a213a127a228a156a223a158a216a45a228a135a215a110a218a26a213a71a237 a236 a228a135a213a33a212a59a220a146a224a38a214a156a212a72a213a159a219a169a215a146a222a227a222a199a215a80a239a6a217a227a225a45a242a158a224a138a214a135a213a34a216a72a224 a159 a93 a33a92a163a55a47 a158 a159a20a94a96a95 a48 a95a98a97 a177a100a99 a95 a180 a177a57a48a44a101a44a102a103a101a32a177a100a99 a95a104a97a6a95a98a105 a177a100a99a71a102a73a174a22a48 a160 a232 a106 a6a164a223a164a225a129a214a135a220a87a221a129a243a181a233a72a220a69a224a51a213a71a237a154a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a59a224 a159 a220a45a232a14a203a72a228a156a215a69a226 a213a127a220a146a218a125a212a94a237a110a215a110a218 a236 a226a158a213a127a225a69a214a84a219a169a228a135a215a146a226a107a91 a92 a239a163a213a33a213a26a221a164a214a156a228a125a220a146a218a26a214a84a220a146a222a199a222 a170a8a213a34a228a135a233a110a243a2a6 a236 a233a120a147a138a213a71a218a152a214a71a238a22a170a8a213a34a228a135a233a110a243 a72 a233a120a147a138a213a127a218a26a214a127a238a22a170a8a213a127a228a156a233a110a243a131a231a208a228a135a213a34a216a55a215a69a224a156a217a199a214a156a217a227a215a146a225a72a220a146a222a43a36a38a214a51a243 a214a135a220a69a218a125a212a45a226a158a213a34a225a129a214a112a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a34a232a35a203a72a215a146a228a112a214a156a212a45a217a148a224a2a216 a236 a228a156a216a55a215a69a224a156a213a8a239a163a213 a236 a224a51a213a71a237a145a220a6a237a110a215a110a218 a236 a243 a226a158a213a34a225a129a214a32a216a72a220a87a228a125a224a51a213a127a228a2a214a135a212a72a220a80a214a32a217a227a224a16a233a72a220a69a224a51a213a71a237a145a226a151a220a87a217a227a225a45a222a227a223a33a215a69a225a90a125a72a225a72a217a133a214a135a213a38a224a51a214a135a220a87a214a156a213a208a214a135a213a127a218a125a212a110a243 a225a45a215a69a222a199a215a69a242a146a223a146a232 a4a12a215a110a218 a236 a226a158a213a34a225a129a214a18a216a45a228a135a215a110a218a26a213a71a224a156a224a156a217a199a225a72a242a94a224a51a214a135a220a146a228a51a214a125a224a159a239a6a217a133a214a135a212a153a214a135a212a45a213a151a217a148a237a110a213a34a225a110a243 a214a156a217a9a125a59a218a127a220a80a214a156a217a227a215a146a225a20a215a87a219a12a225a72a220a87a226a158a213a127a237a170a213a34a225a129a214a135a217a133a214a135a217a199a213a71a224a34a232a20a231a8a220a87a228a156a214a51a243a181a215a87a219a243a131a224a51a216a55a213a34a213a71a218a125a212a247a248a249a231 a72 a6a72a253 a214a135a220a146a242a69a224a241a220a146a225a72a237 a225a45a215a146a225a110a243a181a228a135a213a127a218 a236 a228a135a224a156a217a199a235a69a213a146a238a192a215a69a228a241a233a72a220a146a224a156a217a148a218a87a238a20a225a45a215 a236 a225a28a216a45a212a72a228a135a220a69a224a51a213a71a224 a248a249a229a12a231a26a145a6a253a102a220a146a228a156a213a32a217a148a237a110a213a34a225a129a214a156a217a9a125a72a213a71a237 a236 a224a51a217a227a225a45a242a6a214a135a212a45a213a208a211a84a145a84a230a151a226a158a213a26a214a135a212a45a215a110a237a159a228a156a213a127a216a59a215a69a228a51a214a135a213a127a237 a217a227a225a188a248a78a229a31a242a129a220a87a217a31a220a87a225a59a237a158a203a16a222a227a215a146a228a135a217a227a220a146a225a2a238a84a251a146a252a146a252a181a44a71a253a152a232 a6a164a217a227a226a158a216a45a222a199a213a25a235a69a213a34a228a135a233a22a216a45a212a72a228a135a220a69a224a51a213a71a224 a248a148a170a33a231a163a253a159a220a146a225a72a237a244a216a45a228a156a213a127a216a59a215a129a224a51a217a199a214a156a217a227a215a146a225a59a220a87a222a8a216a45a212a45a228a125a220a146a224a156a213a127a224a158a248a78a231a49a231a163a253a159a220a146a228a156a213a158a217a148a237a110a213a34a225a129a214a135a217a114a125a72a213a71a237 a239a6a217a199a214a156a212a18a125a59a225a45a217a133a214a135a213a26a243a131a224a138a214a125a220a80a214a135a213a94a220 a236 a214a156a215a69a226a158a220a87a214a135a220a170a248a10a203a14a6a107a36a12a253a35a242a69a228a135a220a146a226a14a226a151a220a146a228a135a224a127a232 a6a164a223a164a225a110a243 a214a135a220a69a218a152a214a135a217a227a218a158a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a159a224 a236 a218a125a212a172a220a146a224a150a170a8a213a127a228a156a233a45a243a5a6 a236 a233a120a147a138a213a127a218a26a214a127a238a157a170a8a213a127a228a156a233a45a243 a72 a233a120a147a138a213a71a218a152a214a71a238 a220a87a225a59a237a149a170a8a213a34a228a135a233a110a243a131a231a208a228a135a213a34a216a55a215a69a224a156a217a133a214a135a217a199a215a69a225a72a220a87a222a187a36a38a214a51a214a125a220a146a218a125a212a45a226a158a213a34a225a129a214a151a220a87a228a135a213a70a228a135a213a127a218a34a215a146a242a69a225a45a217a9a8a127a213a127a237 a233a164a223a76a220a87a225a72a215a87a214a156a212a72a213a34a228a186a203a14a6a107a36a18a232 a233a2a232a7a0a49a220a146a218a125a212a172a224a156a223a129a225a129a214a125a220a80a221a164a243a74a233a59a220a146a224a156a213a127a237a182a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a153a217a148a224a145a213a34a221a164a216a59a220a87a225a72a237a110a213a71a237a62a233a164a223 a218a26a215a69a225a72a224a156a217a227a237a110a213a127a228a156a217a227a225a45a242a35a214a156a212a45a228a135a213a34a213a145a216a55a215a69a224a135a224a156a217a199a233a45a217a227a222a227a217a133a214a135a217a199a213a71a224 a159 a248a169a217a253a32a54a31a213a34a216a45a222a148a220a146a218a34a213a35a213a71a220a146a218a125a212a182a239a38a215a146a228a125a237a25a239a6a217a199a214a156a212a62a217a199a214a135a224a33a228a135a215a164a215a87a214a10a219a169a215a69a228a156a226a4a238a58a213a146a232a242a72a232 a214a156a212a72a213a153a235a69a213a34a228a135a233a108a50a51a239a38a215 a236 a225a72a237a110a213a127a237a34a52a165a239a6a217a133a214a135a212a109a50a156a239a163a215 a236 a225a72a237a17a52a170a220a87a225a72a237a247a214a156a212a45a213a244a225a45a215 a236 a225 a50a138a214a135a228 a236 a218a79a144a164a224a54a52a35a239a6a217a133a214a135a212a110a50a51a214a156a228 a236 a218a79a144a38a52a45a232 a248a169a217a227a217a148a253a187a54a6a213a127a216a45a222a148a220a146a218a26a213a10a214a156a212a45a213a33a239a38a215a146a228a125a237a151a239a6a217a133a214a135a212a70a220a146a225a129a223a158a215a146a219a2a214a156a212a45a213a145a218a34a215a146a225a72a218a34a213a34a216a110a214a125a224 a214a156a212a59a220a80a214a6a224 a236 a233a59a224 a236 a226a158a213a33a217a133a214a84a217a227a225a70a220a18a212a59a220a87a225a72a237a164a243a131a218a26a228a125a220a80a219a214a135a213a127a237a102a238a164a242a69a213a34a225a45a213a127a228a135a220a146a222a72a215a146a225a129a214a135a215a146a222a227a215a146a242a146a223a69a238 a213a146a232a242a72a232a111a50a138a214a156a228 a236 a218a79a144a38a52a182a226a151a220a67a223a172a233a55a213a94a228a135a213a34a216a72a222a227a220a69a218a26a213a127a237a22a233a164a223a22a112a21a31a17a113a43a38a36a114a57a39a22a31a58a238a116a115a80a117a22a34a100a38a137a36 a118a24a119 a114a57a34a16a238a45a215a146a228a20a120a121a87a71a122a28a31a34a114a57a34a16a232 a248a169a217a227a217a199a217a253a24a54a31a213a34a216a45a222a148a220a146a218a34a213a10a213a127a220a69a218a125a212a154a225a72a220a146a226a14a213a12a239a6a217a133a214a135a212a76a217a199a214a135a224a38a218a26a215a69a228a156a228a135a213a127a224a156a216a59a215a69a225a72a237a110a217a227a225a45a242 a225a72a220a146a226a14a213a71a237a247a213a127a225a69a214a135a217a133a214a138a223a247a218a34a222a227a220a69a224a156a224a127a238a31a213a69a232a242a59a232a123a50a156a230a2a215a129a224a70a36a10a225a45a242a146a213a127a222a199a213a71a224a103a52a22a239a6a217a133a214a135a212 a168a58a198a163a160 a124 a52a43a53a55a64a66a82a43a64a66a88a55a54a93a77a24a186a35a77a79a82a126a125a63a71a61a82a58a56a35a71a58a54a2a76a48a70a28a71a10a56a61a54a2a88a12a64a66a62a90a89a128a127a117a77a79a62a63a80a98a77a79a71a58a101a87a54a60a71a45a54a5a56a83a77a79a74a92a104a66a94a69a129a14a130a14a130a14a130a98a99a81a104 a131a79a52a43a53a55a54a45a65a68a67a63a54a2a71a182a188a133a132a83a64a66a82a37a80a28a54a2a62a63a54a2a71a81a77a85a56a58a54a2a88a186a101a104a188a73a59a60a70a28a62a55a82a61a64a66a88a63a54a2a71a61a64a66a62a55a80a86a56a58a53a63a54a35a103a98a54a2a71a61a101a84a70a28a71a37a62a55a70a28a72a173a75 a64a66a62a78a77a79a74a66a64a83a82a60a77a85a56a58a64a66a70a28a62a102a69a9a71a61a70a28a72a18a56a61a53a63a54a14a72a84a70a28a82a10a56a58a75a92a71a61a54a2a59a2a54a60a62a98a56a45a77a79a88a63a88a63a54a2a88a30a56a58a70a28a76a63a64a66a59a14a71a61a54a2a74a165a77a85a56a58a64a66a70a28a62a22a104 a0a2a1 a178a32a190a131a198a38a186 a220a87a225a72a237 a50a85a145a84a220a87a225a33a144a94a215a87a219a24a36a10a226a14a213a127a228a156a217a148a218a34a220a76a52a154a239a6a217a199a214a156a212 a198a4a3a6a5 a1 a186a38a190a8a7 a1 a160 a178a32a190a131a198a38a186 a232a63a203a16a217a199a242 a236 a228a156a213a173a23a31a217a227a222a227a222 a236 a224a51a214a156a228a125a220a80a214a135a213a127a224a112a214a156a212a45a213a84a213a34a221a164a216a59a220a87a225a72a224a156a217a199a215a69a225a145a215a87a219a72a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a127a232 EXPANSIONS EXPANSIONS exploded − truck exploded − Colombo ORIGINAL RELATION ORIGINAL RELATION a203a16a217a199a242 a236 a228a135a213a12a23 a159 a0a8a221a110a216a72a220a87a225a59a224a51a217a227a215a146a225a72a224a38a215a146a219a96a214a138a239a38a215a35a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a127a232 a106 a6a110a220a146a222a199a217a227a213a34a225a72a218a34a213a26a243a181a233a72a220a146a224a156a213a127a237a132a19a49a243a74a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224 a159 a220a45a232a95a36a10a237a45a237a110a217a199a214a156a217a227a215a146a225a59a220a87a222a59a214a156a215a146a216a72a217a227a218a6a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a8a226a151a220a67a223a14a233a59a213a33a237a110a217a227a224a135a218a26a215a80a235a69a213a34a228a135a213a127a237 a239a6a217a199a214a156a212a45a217a227a225a151a220a145a224a156a220a146a222a199a217a227a213a34a225a72a218a34a213a84a239a6a217a199a225a72a237a45a215a80a239a192a219a169a215a146a228a8a213a71a220a146a218a125a212a14a235a146a213a127a228a156a233a2a232a32a211a84a212a45a213a6a239a6a217a227a225a72a237a110a215a80a239 a217a148a224a49a218a26a228a135a213a127a220a87a214a156a213a71a237a158a233a129a223a158a218a26a215a69a225a72a224a156a217a227a237a110a213a127a228a156a217a227a225a45a242a10a9a234a224a156a213a34a225a129a214a156a213a127a225a72a218a26a213a71a224a208a216a45a228a135a213a127a218a34a213a127a237a110a217a227a225a45a242a18a220a146a225a72a237 a224 a236 a218a34a218a34a213a34a213a127a237a45a217a199a225a45a242a14a214a135a212a45a213a161a224a156a213a34a225a129a214a156a213a127a225a72a218a26a213a145a218a26a215a69a225a129a214a135a220a87a217a227a225a45a217a227a225a45a242a14a214a156a212a45a213a161a235a146a213a34a228a135a233a2a232a8a254a131a225a4a215 a236 a228 a213a26a221a110a216a55a213a34a228a135a217a199a226a158a213a127a225a69a214a125a224a84a239a163a213a145a224a156a213a26a214a11a9 a143 a251a110a232 a233a2a232a43a211a84a212a45a213a182a229a10a231a163a224a158a215a87a219a159a213a127a220a146a218a125a212a117a224a135a220a87a222a227a217a199a213a127a225a72a218a26a213a4a239a6a217a227a225a72a237a110a215a80a239 a220a87a228a135a213a94a213a34a221a164a243 a214a156a228a125a220a146a218a26a214a156a213a71a237a151a220a87a225a72a237a158a215a69a228a135a237a110a213a127a228a156a213a71a237a102a232a32a211a84a212a45a213a31a233a72a220a69a224a51a217a148a218 a236 a225a72a237a45a213a34a228a135a222a199a223a164a217a227a225a45a242a145a212a164a223a129a216a55a215a87a214a135a212a45a213a26a243 a224a156a217a227a224a6a217a148a224a6a214a135a212a72a220a80a214a27a19a49a243a74a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a84a233a59a213a34a214a138a239a163a213a127a213a34a225a25a220a151a235a69a213a34a228a135a233a94a220a146a225a72a237a25a220a87a225a4a213a34a225a129a214a135a217a133a214a138a223 a219a169a228a135a215a146a226 a217a199a214a135a224a158a237a110a215a146a226a151a220a146a217a199a225a22a220a146a228a156a213a94a224a51a217a227a226a158a217a199a222a148a220a87a228a14a214a135a215a62a214a135a212a45a213a94a220a146a225a72a220a87a216a72a212a45a215a146a228a135a217a227a218a154a228a156a213a127a222a227a220a87a243 a214a156a217a227a215a146a225a59a224a145a233a59a213a34a214a138a239a163a213a127a213a34a225a172a213a34a225a129a214a135a217a133a214a135a217a199a213a71a224a145a217a199a225a244a214a135a213a26a221a164a214a135a224a127a232a70a211a84a212a45a213a127a228a156a213a34a219a169a215a146a228a135a213a146a238a112a220a69a224a159a217a199a222a227a222 a236 a224a138a243 a214a156a228a125a220a80a214a135a213a127a237a22a217a199a225a20a203a96a217a227a242 a236 a228a156a213a11a49a164a238a49a224a156a217a199a221a172a216a55a215a69a224a135a224a156a217a199a233a45a222a227a213a70a214a156a213a26a221a164a214a154a224a156a216a72a220a87a225a72a224a127a238a208a211a186a6a117a44a34a243a81a23a72a238 a218a34a220a146a225a153a233a55a213a154a237a110a213a68a125a72a225a45a213a127a237a2a232a76a211a84a212a45a213a158a216a45a228a135a215a146a226a158a217a199a225a72a213a34a225a72a218a34a213a14a215a146a219a38a213a127a225a129a214a156a217a199a214a156a217a227a213a127a224a145a228a135a213a34a222a148a220a80a214a135a213a127a237 a214a156a215a159a214a135a212a45a213a10a220a146a225a72a218a125a212a45a215a146a228a8a218a127a220a87a225a158a233a59a213a12a220a87a216a45a216a45a228a135a215a67a221a110a217a199a226a151a220a87a214a156a213a127a237a161a233a164a223a35a220a159a222a227a213a26a219a214a51a243a74a214a156a215a146a243a74a228a135a217a227a242a146a212a129a214 a215a146a228a125a237a110a213a127a228a156a217a227a225a45a242a72a232a173a0a208a225a129a214a135a217a133a214a135a217a199a213a71a224a10a220a87a228a135a213a12a125a72a228a125a224a138a214a12a228a156a213a34a214a156a228a135a217a199a213a127a235a146a213a127a237a70a219a169a228a135a215a146a226 a214a156a213a34a221a129a214a33a224a51a216a72a220a146a225 a122a100a142a38a233a59a213a34a219a169a215a146a228a135a213a35a233a55a213a34a217a227a225a45a242a4a228a156a213a34a214a156a228a135a217a199a213a127a235a146a213a71a237a25a219a169a228a135a215a146a226 a122a100a142a13a12 a27 a232a158a211a84a212a45a213a151a224a156a220a146a226a14a213a158a220a87a216a45a243 a216a45a228a135a215a67a221a110a217a199a226a151a220a80a214a135a217a199a215a69a225a153a239a84a220a146a224a18a217a199a225a129a214a156a228a135a215a110a237 a236 a218a34a213a127a237a244a233a164a223a170a248a142a181a145a220a146a226a158a213a34a223a69a220a146a226a151a220a45a238a26a44a55a46a48a46a50a49a87a253 a219a169a215a146a228a6a228a135a213a127a224a156a215a146a222a227a235a164a217a199a225a72a242a14a218a34a215a146a228a135a213a26a219a169a213a34a228a135a213a34a225a59a218a26a213a33a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a127a232 TS5Sentence ( i−2 ) Sentence ( i ) Trigger−Word Sentence ( i−1 ) TS3 TS1 TS2 Sentence ( i+1 ) TS4 Sentence ( i+2 ) TS6 a203a96a217a227a242 a236 a228a156a213 a49 a159 a72 a228a125a237a110a213a34a228a135a217a227a225a45a242a14a224a135a220a87a222a227a217a227a213a34a225a129a214a6a213a34a225a129a214a156a217a199a214a156a217a227a213a127a224a127a232 a218a87a232a14a19a38a220a87a225a59a237a110a217a227a237a72a220a80a214a156a213a161a213a26a221a164a214a156a228a125a220a146a218a26a214a156a217a227a215a146a225a25a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a59a224a31a220a87a228a135a213a145a242a146a213a127a225a45a213a34a228a125a220a80a214a135a213a127a237 a217a227a225a241a213a127a220a146a218a125a212a241a224a135a220a87a222a227a217a199a213a127a225a72a218a26a213a165a239a6a217a227a225a72a237a110a215a80a239a145a232 a203a16a217a199a228a125a224a51a214a127a238 a144 a99a120a119a28a109a114a113a55a113a22a121a98a119a50a172 a0a57a121a68a119a104a171a15a14 a7a17a16a83a142a145 a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a76a220a87a228a135a213a62a218a26a228a135a213a127a220a87a214a156a213a127a237a117a220a146a225a72a237a117a213a26a221a110a216a72a220a146a225a72a237a110a213a127a237a20a219a169a215a69a228a76a213a71a220a146a218a125a212 a218a34a220a146a225a72a237a110a217a148a237a45a220a80a214a135a213a12a213a127a225a129a214a156a217a199a214a138a223a146a232a208a211a84a212a45a213a159a213a26a221a110a216a72a220a146a225a72a224a156a217a199a215a69a225a72a224a84a220a87a228a135a213a12a237a110a215a69a225a45a213a145a224a51a217a227a226a158a217a199a222a148a220a87a228a135a222a199a223 a220a146a224a145a219a169a215a146a228a35a224a156a223a164a225a129a214a135a220a80a221a164a243a181a233a72a220a146a224a156a213a127a237a153a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a59a224a34a232a4a250a31a215a80a239a38a213a34a235a69a213a34a228a71a238a112a239a6a212a45a213a127a225a192a218a26a215a146a225a45a243 a224a156a217a227a237a110a213a127a228a156a217a227a225a45a242a31a215a69a225a45a213a49a213a34a221a110a216a72a220a87a225a72a224a156a217a227a215a146a225a145a219a169a215a69a228 a144 a99a120a119a28a109a114a113a55a113a22a121a98a119a50a172 a0a57a121a68a119a104a171a18a14a20a7a19a16 a138a47a145 a214a156a212a72a213 a213a26a221a110a216a72a220a146a225a72a224a156a217a199a215a69a225a192a217a227a224a14a220a87a222a227a222a227a215a80a239a163a213a71a237a172a215a146a225a45a222a227a223a165a217a133a219a12a217a133a214a158a239a38a220a69a224a18a225a45a215a146a214a158a220a146a222a199a228a135a213a127a220a69a237a110a223a244a217a199a225a110a243 a214a156a228a135a215a110a237 a236 a218a34a213a127a237a154a233a164a223a154a220a146a225a129a223a151a213a34a221a110a216a72a220a87a225a72a224a156a217a227a215a146a225a151a219a169a215a69a228a84a220a146a225a164a223 a144 a99a33a119a28a109a114a113a47a113a22a121a68a119a50a172 a0a57a121a98a119a104a171a20a14 a7a17a16 a146 a145 a238a80a239a6a217a133a214a135a212a22a21a7a130a24a23a59a232a83a203a45a215a146a228a8a224a156a223a164a225a69a214a125a220a80a221a164a243a181a233a72a220a146a224a156a213a127a237a33a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a59a224a34a238a67a228a135a213a34a216a55a213a26a214a51a243 a217a199a214a156a217a227a235a146a213a158a213a26a221a110a216a72a220a146a225a72a224a51a217a227a215a146a225a59a224a33a237a45a215a94a225a72a215a87a214a145a213a26a221a110a217a148a224a138a214a71a232a158a211a84a212a72a217a227a224a159a217a148a224a33a214a156a212a45a213a151a228a125a220a80a214a135a217a199a215a69a225a72a220a87a222a227a213 a219a169a215a146a228a31a237a45a217a227a224a135a220a87a233a45a222a227a217a227a225a45a242a158a228a156a213a127a216a59a213a34a214a156a217a199a214a156a217a227a215a146a225a72a224a6a215a146a219a139a19a49a243a181a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a70a213a26a221a110a216a72a220a87a225a59a224a51a217a227a215a146a225a72a224a127a232 a93 a33a92a163a55a47 a30 a159a27a97 a177a57a48a26a25 a180 a177a32a48a6a101 a102a19a101a32a177a100a99 a95a104a97a6a95a96a105 a177a100a99a71a102a73a174a22a48 a160 a232a17a203a45a215a69a222a133a243 a222a227a215a80a239a6a217a199a225a45a242a161a214a156a212a45a213a159a226a158a213a26a214a135a212a45a215a110a237a76a217a227a225a129a214a156a228a135a215a110a237 a236 a218a26a213a71a237a154a217a227a225a244a248a182a54a6a217a227a222a199a215a48a167a16a238a100a44a55a46a48a46a48a23a129a253a8a213a71a220a146a218a125a212 a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a172a217a148a224a18a228a125a220a87a225a33a144a69a213a127a237a153a233a72a220a146a224a156a213a127a237a244a215a69a225a165a217a133a214a125a224 a97 a121a68a164a9a121a28a27a63a116a87a115a37a110a79a121a104a172 a97 a116a78a105a5a121a145a220a146a225a72a237 a217a199a214a135a224a151a163a100a119a93a121a30a29a68a118a181a121a98a115a117a110a32a31a80a232 a211a84a212a45a213a157a163a35a119a93a121a30a29a98a118a181a121a68a115a37a110a28a31a25a215a87a219a18a220a146a225a247a213a26a221a164a214a156a228a125a220a146a218a26a214a156a213a71a237a117a228a156a213a34a243 a222a148a220a80a214a156a217a227a215a146a225a206a218a26a215 a236 a225a129a214a135a224a94a214a156a212a72a213a244a225 a236 a226a35a233a59a213a127a228a4a215a87a219a161a214a135a217a199a226a158a213a71a224a94a214a156a212a45a213a172a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a43a217a227a224 a217a148a237a110a213a34a225a129a214a156a217a9a125a72a213a71a237a43a217a227a225a206a214a156a212a45a213a165a228a135a213a34a222a227a213a34a235a80a220a146a225a69a214a182a237a110a215a110a218 a236 a226a158a213a34a225a129a214a135a224a127a232a29a254a131a225a206a220a185a224a156a217a227a225a45a242a146a222a227a213 a237a110a215a110a218 a236 a226a14a213a127a225a129a214a127a238a102a215a146a225a72a213a161a213a26a221a164a214a135a228a135a220a69a218a152a214a156a213a71a237a4a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a182a226a151a220a67a223a4a233a55a213a35a217a148a237a110a213a34a225a129a214a135a217a114a125a72a213a71a237 a226 a236 a222a133a214a135a217a199a216a45a222a227a213a14a214a156a217a227a226a158a213a127a224a127a232a161a211a84a212a45a213 a97 a121a68a164a9a121a28a27a63a116a87a115a37a110a79a121a47a172 a97 a116a78a105a5a121 a143 a163a100a119a93a121a30a29a68a118a181a121a98a115a117a110a32a31a152a148 a180 a107a78a118a120a115a57a105a78a238a102a239a6a212a45a213a127a228a156a213 a180 a107a78a118a120a115a181a105a32a226a158a213a127a220a69a224 a236 a228a156a213a71a224a31a214a135a212a45a213a35a225 a236 a226a35a233a59a213a127a228a159a215a87a219a208a214a135a217a199a226a158a213a127a224 a220a87a225a70a213a26a221a164a214a156a228a125a220a146a218a26a214a156a213a71a237a151a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a154a217a148a224a38a228a156a213a71a218a26a215a69a242a146a225a45a217a137a8a34a213a71a237a151a217a199a225a4a220a87a225a164a223a151a237a110a215a110a218 a236 a226a14a213a127a225a129a214 a218a26a215a69a225a72a224a156a217a227a237a110a213a127a228a156a213a71a237a102a232a150a54a6a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a10a239a6a217a199a214a156a212 a97 a121a68a164a9a121a28a27a63a116a87a115a37a110a79a121a47a172 a97 a116a78a105a5a121a90a130a34a33a117a220a87a228a135a213 a237a110a217a148a224a156a218a127a220a87a228a125a237a110a213a127a237a170a220a146a224a158a225a45a215a69a225a110a243a181a228a156a213a127a222a199a213a127a235a67a220a146a225a129a214a127a232 a36a10a237a45a237a110a217a199a214a156a217a227a215a146a225a59a220a87a222a227a222a199a223a69a238a163a239a38a213a70a226a151a220a146a217a199a225a110a243 a214a135a220a146a217a199a225a244a215a146a225a72a222a199a223a182a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a33a239a6a217a133a214a135a212a19a35a39a75a37a36a4a38a28a39a41a40a43a42a45a44a30a46a48a47a50a49a51a36a4a38a52a39a53a40a51a42a32a75a55a54a58a238 a239a6a212a45a213a127a228a156a213a56a46a57a47a50a49a51a36a4a38a28a39a41a40a43a42a12a217a227a225a72a237a110a217a148a218a34a220a87a214a156a213a71a224a145a214a156a212a72a213a151a214a156a215a146a214a135a220a87a222a163a225 a236 a226a161a233a55a213a34a228a18a215a146a219a6a217a199a225a110a243 a224a51a214a135a220a87a225a59a218a26a213a127a224a96a219a169a215a69a228a96a214a135a212a45a213a84a226a158a215a69a224a51a214a8a218a34a215a146a226a158a226a158a215a146a225a35a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a2a238a67a214a135a215a33a220a67a235a69a215a146a217a148a237a18a225a45a215a69a217a227a224a156a213 a215a146a228 a236 a225a45a217a199a225a45a219a169a215a146a228a135a226a158a220a87a214a156a217a227a235a146a213a159a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a59a224a34a232a58 a93 a33a92a163a55a47 a155 a159 a160 a95a98a105a61a95 a180 a99a39a177 a48 a95 a88 a99a24a174a24a175 a102 a180 a97a6a95a96a105 a177a100a99a71a102a73a174a22a48 a232 a211a84a212a45a213a25a228a125a220a87a225a33a144a164a217a227a225a45a242a153a219a169a228a156a215a69a226 a6a129a214a135a213a34a216a247a251a244a237a110a213a26a214a135a213a34a228a135a226a14a217a227a225a45a213a71a224a154a220a87a225a117a215a146a228a125a237a110a213a127a228a14a233a55a213a26a243 a214a138a239a38a213a34a213a34a225a170a220a87a222a227a222a38a218a127a220a87a225a72a237a110a217a148a237a45a220a87a214a156a213a76a213a34a221a164a214a156a228a125a220a146a218a152a214a135a217a199a215a69a225a165a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a127a232 a72 a225a72a222a199a223a244a214a156a212a72a213 a125a72a228a125a224a138a214a31a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a76a217a148a224a31a224a156a213a34a222a227a213a127a218a152a214a135a213a127a237a4a220a87a225a59a237a70a220a69a237a45a237a110a213a127a237a70a214a135a215a158a214a156a212a45a213a18a224a156a213a26a214a31a215a146a219a16a237a110a217a148a224a138a243 a218a26a215a80a235a69a213a34a228a135a213a127a237a62a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a127a232a151a211a84a212a45a213a158a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a145a220a146a225a72a237a62a217a199a214a135a224a18a228a135a220a146a225a33a144a110a224a145a218a26a215a146a225a45a243 a224a51a214a156a217a199a214 a236 a214a135a213a158a214a156a212a45a213a151a225a45a213a127a239 a214a135a215a146a216a45a217a148a218a151a224a51a217a227a242a146a225a59a220a80a214 a236 a228a156a213a21a122a102a124 a150 a232a158a254a131a225a45a217a199a214a156a217a148a220a87a222a227a222a227a223a146a238a43a122a30a124 a150 a214a156a212a72a213a18a224a51a213a127a213a127a237a70a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a2a232 a93 a33a92a163a55a47a60a59 a159a60a97a6a95 a160 a99a164a177 a97 a99 a99a62a61 a95 a101 a102 a160a120a180 a174a63a0 a95a98a97a22a63 a232a62a211a84a212a45a213a76a225a72a213a34a239 a224a156a213a26a214a18a215a87a219a84a237a110a217a148a224a156a218a34a215a80a235a146a213a34a228a135a213a127a237a62a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a33a217a148a224 a236 a224a156a213a127a237a62a214a156a215a25a228a135a213a26a243a131a218a26a222a148a220a146a224a135a224a51a217a199a219a169a223a4a214a156a212a72a213 a237a110a215a110a218 a236 a226a14a213a127a225a129a214a135a224a10a219a169a228a156a215a69a226 a91 a92 a217a199a225a129a214a156a215a70a228a156a213a127a222a199a213a127a235a80a220a87a225a129a214a12a220a87a225a59a237a25a225a45a215a146a225a45a243a74a228a135a213a34a222a227a213a34a235a80a220a87a225a129a214a71a232 a36a192a225a72a213a34a239a172a217a133a214a135a213a34a228a125a220a80a214a135a217a199a215a69a225a145a228a156a213a71a224 a236 a226a158a213a71a224a102a233a164a223a26a147 a236 a226a158a216a45a217a227a225a45a242a10a214a156a215a102a6a129a214a135a213a34a216a35a251a45a238a67a239a6a212a45a213a34a228a135a213 a214a156a212a72a213a153a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a76a220a146a228a156a213a153a228a135a220a146a225a33a144a146a213a71a237a185a220a87a242a69a220a146a217a199a225a112a238a31a233a72a220a146a224a156a213a127a237a247a215a146a225a185a214a135a212a45a213a153a225a72a213a34a239 a224a156a213a26a214a159a215a87a219a163a228a135a213a34a222a227a213a34a235a80a220a146a225a69a214a159a237a110a215a110a218 a236 a226a158a213a127a225a69a214a125a224a145a237a110a213a26a214a135a213a34a228a135a226a158a217a199a225a45a213a71a237a182a233a164a223a4a214a156a212a72a213a158a245 a236 a213a127a228a156a223 a237a110a213a127a228a156a217a227a235a146a213a71a237a20a219a169a228a156a215a69a226 a214a135a212a45a213a182a235a146a213a127a228a156a233a117a148a67a225a45a215a69a226a14a217a227a225a72a220a146a222a199a217a137a8a127a220a87a214a156a217a227a215a146a225a20a215a87a219a145a214a156a212a72a213a182a226a158a215a69a224a51a214 a228a135a213a127a218a26a213a127a225a129a214a156a222a227a223a117a220a69a237a45a237a110a213a71a237a185a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a2a232a246a211a84a212a45a213a172a237a110a217a148a224a156a218a34a215a80a235a146a213a34a228a135a223a22a216a72a228a156a215a110a218a26a213a71a237 a236 a228a135a213 a224a51a214a156a215a146a216a59a224a33a220a87a219a214a156a213a127a228a159a229 a143 a44a71a252a146a252a154a217a199a214a156a213a127a228a135a220a87a214a156a217a227a215a146a225a72a224a127a238a58a215a146a228a33a239a6a212a45a213a34a225a244a225a45a215a94a225a45a213a34a239a179a228a156a213a34a243 a222a148a220a80a214a156a217a227a215a146a225a59a224a6a220a87a228a135a213a159a237a45a217a227a224a135a218a26a215a80a235a69a213a34a228a135a213a127a237a102a232 ( a ) 10 .</sentence>
				<definiendum id="0">Object Object C−relation C−relation C−relation C−relation</definiendum>
				<definiens id="0">a236 a214a102a15a76a75a12a145a184a215a87a219a8a237a45a220a80a214a125a220a45a232a163a211a84a212a72a213a18a217a227a237a45a213a127a220a2a77a18a217a227a224a84a214a135a212a72a220a80a214a33a224a138a214a125a220a87a228a156a214a156a217a227a225a45a242a151a239a6a217a133a214a135a212 a220a76a224a156a213a34a213a71a237a62a224a156a213a26a214a159a215a87a219a208a213a34a221a129a214a135a228a135a220a69a218a152a214a135a217a199a215a69a225a182a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a12a239a38a213a35a218a26a215 a236 a222a148a237a62a224a156a213a34a216a72a220a146a228a135a220a87a214a156a213 a214a156a212a72a213a31a218a26a215a146a228a135a216 a236 a224a32a217a227a225a129a214a156a215 a159 a248a2a44a67a253a32a220a159a224a51a213a34a214a208a215a87a219a58a228a156a213a127a222a199a213a127a235a67a220a146a225a129a214a8a237a45a215a164a218 a236 a226a158a213a34a225a129a214a135a224a49a218a26a215a146a225a45a243 a214a135a220a146a217a199a225a72a217a199a225a45a242a35a214a156a212a72a213a159a224a156a213a34a213a71a237a154a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a34a238a110a220a146a225a72a237a62a248a74a251a146a253a163a220a35a218a34a215a146a226a158a216a45a222a227a213a34a226a158a213a34a225a129a214a135a220a146a228a156a223 a224a156a213a26a214a12a215a146a219a8a225a45a215a146a225a110a243a181a228a135a213a34a222a227a213a34a235a80a220a87a225a129a214a12a237a110a215a110a218 a236 a226a158a213a34a225a129a214a135a224a127a232a6a254a131a225a72a224a51a214a156a213a127a220a69a237a25a215a87a219a208a218a34a215a146a225a72a224a156a217a227a237a45a213a34a228a156a243 a217a227a225a45a242a154a214a135a212a45a213a161a213a127a225a69a214a135a217a199a228a135a213a63a36a6a73a61a28a14a36a31a254a138a229a12a211a241a218a26a215a146a228a135a216 a236 a224a10a239a163a213 a236 a224a156a213a127a237a25a215a69a225a45a222a199a223a4a237a110a215a110a218a152a243 a236 a226a158a213a34a225a129a214a125a224a35a228a135a213a26a214a135a228a156a217a227a213a34a235a69a213a127a237a172a239a6a212a45a213a127a225a192a219a169a215a69a228a156a226 a236 a222a227a220a87a214a156a217a227a225a45a242a62a220a153a245 a236 a213a34a228a135a223a79a78a25a214a156a212a72a220a87a214 a218a125a212a72a220a146a228a135a220a69a218a152a214a156a213a127a228a156a217a137a8a34a213a71a224a8a214a135a212a45a213a33a224a135a218a26a213a127a225a72a220a87a228a135a217a227a215a35a237a110a215a69a226a158a220a146a217a199a225a112a232a32a211a84a212a72a213a12a254a131a225a110a219a169a215a69a228a156a226a151a220a87a214a156a217a227a215a146a225 a54a6a213a34a214a156a228a135a217a199a213a127a235a67a220a146a222a208a248a169a254a134a54a10a253a31a224a51a223a110a224a51a214a156a213a34a226 a239a163a213a145a213a127a226a14a216a72a222a199a215a80a223a154a217a148a224a186a6a120a3a18a36a14a54a32a211a42a248a58a145 a236 a218a79a144a129a243 a222a227a213a34a223a159a213a26a214a8a220a87a222a74a232a199a238a120a44a55a46a48a46a26a25a69a253a152a232a45a203a45a215a146a228a96a213a26a221a45a220a87a226a158a216a45a222a227a213a146a238a67a219a169a215a69a228a112a214a135a212a45a213a80a50a51a233a55a215a146a226a161a233a72a217a199a225a45a242a55a52a31a237a110a215a146a243 a226a151a220a87a217a227a225a2a238a58a239a163a213 a236 a224a156a213a127a237a182a220a70a224a51a217a227a225a45a242a146a222a227a213a26a243a81a144a146a213a127a223a164a239a163a215a69a228a135a237a94a245 a236 a213a34a228a135a223 a159 a126a187a38a81a121a6a5a98a108a37a164a9a107a34a40a48a121a42a41a79a140a82a81 a220a87a225a59a237a76a228a135a213a26a214a135a228a156a217a227a213a34a235a69a213a127a237a4a251a87a252a146a252a69a252a35a237a45a215a164a218 a236 a226a158a213a34a225a129a214a135a224a127a232 a211a84a212a45a213a151a214a156a228a135a217a227a242a146a242a146a213a127a228a145a239a163a215a69a228a135a237a72a224a159a219a169a215a146a228a161a214a156a212a45a213a154a225a72a213a34a239a42a214a156a215a69a216a45a217a227a218a154a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a165a220a87a228a135a213 a220a87a222a148a224a156a215a70a237a110a213a127a228a156a217a227a235a146a213a71a237a102a232a30a203a72a215a146a228a33a213a26a221a45a220a87a226a158a216a45a222a227a213a146a238a58a217a227a225a182a214a135a212a45a213a14a218a127a220a146a224a156a213a161a215a146a219a8a214a156a212a45a213a158a211a112a215a69a216a45a217a148a218 a178a14a183 a214a156a212a45a213a94a237a110a213a34a228a135a217a199a235a69a213a127a237a153a214a156a228a135a217a227a242a146a242a146a213a127a228a18a239a38a215a146a228a125a237a45a224a159a219a169a215a146a228a161a214a156a212a45a213a70a224a51a213a127a213a127a237a172a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a59a224 a220a87a228a135a213 a38a81a121a6a5a98a108a37a164a9a107a34a40a48a121a42a41a151a220a146a225a72a237a35a38a121a40a48a121a68a105a81a107a87a115a37a116a78a105a5a121a42a41a152a232a206a211a84a212a45a213a182a218a26a215a69a228a156a228a135a213a127a224a156a216a59a215a69a225a72a237a110a217a227a225a45a242 a228a135a213a34a222a227a213a34a235a80a220a87a225a129a214a154a213a34a225a129a214a135a217a133a214a135a217a199a213a71a224a151a219a169a215a146a228a154a214a156a212a45a213a64a83a85a84a61a86a6a87 a88a155a107a87a119a79a40a25a218a34a215a146a225a72a224a156a217a227a224a51a214a135a224a154a215a87a219a1a15 a239a38a215a146a228a125a237a45a224 a159 a50a51a233a55a215a146a226a35a233a34a52a45a238a57a50a51a242a69a228a156a213a127a225a72a220a146a237a45a213a89a52a146a220a146a225a72a237a90a50a51a226a158a217a199a225a72a213a89a52a45a232a241a211a84a212a45a213a182a214a156a228a135a217a199a242a146a243 a242a146a213a127a228a12a239a38a215a146a228a125a237a45a224a127a238a55a214a156a212a45a213a151a218a26a215a69a228a156a216 a236 a224a20a91a57a92a161a220a87a225a72a237a62a214a156a212a72a213a14a224a156a213a34a213a71a237a62a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a62a220a87a228a135a213 a214a156a212a72a213a6a215a146a225a45a222a227a223a161a217a227a225a45a216 a236 a214a125a224a8a214a135a215a33a215 a236 a228a208a216a45a228a135a215a110a218a26a213a71a237 a236 a228a135a213a163a214a135a212a72a220a80a214a49a237a45a217a227a224a135a218a26a215a80a235a69a213a34a228a125a224a96a233a55a215a87a214a135a212 a224a156a223a129a225a129a214a125a220a80a221a164a243a74a233a59a220a146a224a156a213a127a237a165a220a87a225a59a237a55a19a49a243a181a228a156a213a127a222a227a220a87a214a156a217a227a215a146a225a72a224a18a219a169a228a156a215a69a226a28a214a156a212a45a213a4a237a110a215a110a218 a236 a226a158a213a127a225a69a214a125a224a34a232 a211a84a212a45a213a18a237a110a217a148a224a135a218a26a215a80a235a146a213a127a228a156a223a158a216a45a228a135a215a110a218a26a213a71a237 a236 a228a135a213a33a212a59a220a146a224a38a214a156a212a72a213a159a219a169a215a146a222a227a222a199a215a80a239a6a217a227a225a45a242a158a224a138a214a135a213a34a216a72a224 a159 a93 a33a92a163a55a47 a158 a159a20a94a96a95 a48 a95a98a97 a177a100a99 a95 a180 a177a57a48a44a101a44a102a103a101a32a177a100a99 a95a104a97a6a95a98a105 a177a100a99a71a102a73a174a22a48 a160 a232 a106 a6a164a223a164a225a129a214a135a220a87a221a129a243a181a233a72a220a69a224a51a213a71a237a154a228a135a213a34a222a148a220a80a214a156a217a227a215a146a225a59a224 a159 a220a45a232a14a203a72a228a156a215a69a226 a213a127a220a146a218a125a212a94a237a110a215a110a218 a236 a226a158a213a127a225a69a214a84a219a169a228a135a215a146a226a107a91 a92 a239a163a213a33a213a26a221a164a214a156a228a125a220a146a218a26a214a84a220a146a222a199a222 a170a8a213a34a228a135a233a110a243a2a6 a236 a233a120a147a138a213a71a218a152a214a71a238a22a170a8a213a34a228a135a233a110a243 a72 a233a120a147a138a213a127a218a26a214a127a238a22a170a8a213a127a228a156a233a110a243a131a231a208a228a135a213a34a216a55a215a69a224a156a217a199a214a156a217a227a215a146a225a72a220a146a222a43a36a38a214a51a243 a214a135a220a69a218a125a212a45a226a158a213a34a225a129a214a112a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a34a232a35a203a72a215a146a228a112a214a156a212a45a217a148a224a2a216 a236 a228a156a216a55a215a69a224a156a213a8a239a163a213 a236 a224a51a213a71a237a145a220a6a237a110a215a110a218 a236 a243 a226a158a213a34a225a129a214a32a216a72a220a87a228a125a224a51a213a127a228a2a214a135a212a72a220a80a214a32a217a227a224a16a233a72a220a69a224a51a213a71a237a145a226a151a220a87a217a227a225a45a222a227a223a33a215a69a225a90a125a72a225a72a217a133a214a135a213a38a224a51a214a135a220a87a214a156a213a208a214a135a213a127a218a125a212a110a243 a225a45a215a69a222a199a215a69a242a146a223a146a232 a4a12a215a110a218 a236 a226a158a213a34a225a129a214a18a216a45a228a135a215a110a218a26a213a71a224a156a224a156a217a199a225a72a242a94a224a51a214a135a220a146a228a51a214a125a224a159a239a6a217a133a214a135a212a153a214a135a212a45a213a151a217a148a237a110a213a34a225a110a243 a214a156a217a9a125a59a218a127a220a80a214a156a217a227a215a146a225a20a215a87a219a12a225a72a220a87a226a158a213a127a237a170a213a34a225a129a214a135a217a133a214a135a217a199a213a71a224a34a232a20a231a8a220a87a228a156a214a51a243a181a215a87a219a243a131a224a51a216a55a213a34a213a71a218a125a212a247a248a249a231 a72 a6a72a253 a214a135a220a146a242a69a224a241a220a146a225a72a237 a225a45a215a146a225a110a243a181a228a135a213a127a218 a236 a228a135a224a156a217a199a235a69a213a146a238a192a215a69a228a241a233a72a220a146a224a156a217a148a218a87a238a20a225a45a215 a236 a225a28a216a45a212a72a228a135a220a69a224a51a213a71a224 a248a249a229a12a231a26a145a6a253a102a220a146a228a156a213a32a217a148a237a110a213a34a225a129a214a156a217a9a125a72a213a71a237 a236 a224a51a217a227a225a45a242a6a214a135a212a45a213a208a211a84a145a84a230a151a226a158a213a26a214a135a212a45a215a110a237a159a228a156a213a127a216a59a215a69a228a51a214a135a213a127a237 a217a227a225a188a248a78a229a31a242a129a220a87a217a31a220a87a225a59a237a158a203a16a222a227a215a146a228a135a217a227a220a146a225a2a238a84a251a146a252a146a252a181a44a71a253a152a232 a6a164a217a227a226a158a216a45a222a199a213a25a235a69a213a34a228a135a233a22a216a45a212a72a228a135a220a69a224a51a213a71a224 a248a148a170a33a231a163a253a159a220a146a225a72a237a244a216a45a228a156a213a127a216a59a215a129a224a51a217a199a214a156a217a227a215a146a225a59a220a87a222a8a216a45a212a45a228a125a220a146a224a156a213a127a224a158a248a78a231a49a231a163a253a159a220a146a228a156a213a158a217a148a237a110a213a34a225a129a214a135a217a114a125a72a213a71a237 a239a6a217a199a214a156a212a18a125a59a225a45a217a133a214a135a213a26a243a131a224a138a214a125a220a80a214a135a213a94a220 a236 a214a156a215a69a226a158a220a87a214a135a220a170a248a10a203a14a6a107a36a12a253a35a242a69a228a135a220a146a226a14a226a151a220a146a228a135a224a127a232 a6a164a223a164a225a110a243 a214a135a220a69a218a152a214a135a217a227a218a158a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a159a224 a236 a218a125a212a172a220a146a224a150a170a8a213a127a228a156a233a45a243a5a6 a236 a233a120a147a138a213a127a218a26a214a127a238a157a170a8a213a127a228a156a233a45a243 a72 a233a120a147a138a213a71a218a152a214a71a238 a220a87a225a59a237a149a170a8a213a34a228a135a233a110a243a131a231a208a228a135a213a34a216a55a215a69a224a156a217a133a214a135a217a199a215a69a225a72a220a87a222a187a36a38a214a51a214a125a220a146a218a125a212a45a226a158a213a34a225a129a214a151a220a87a228a135a213a70a228a135a213a127a218a34a215a146a242a69a225a45a217a9a8a127a213a127a237 a233a164a223a76a220a87a225a72a215a87a214a156a212a72a213a34a228a186a203a14a6a107a36a18a232 a233a2a232a7a0a49a220a146a218a125a212a172a224a156a223a129a225a129a214a125a220a80a221a164a243a74a233a59a220a146a224a156a213a127a237a182a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a153a217a148a224a145a213a34a221a164a216a59a220a87a225a72a237a110a213a71a237a62a233a164a223 a218a26a215a69a225a72a224a156a217a227a237a110a213a127a228a156a217a227a225a45a242a35a214a156a212a45a228a135a213a34a213a145a216a55a215a69a224a135a224a156a217a199a233a45a217a227a222a227a217a133a214a135a217a199a213a71a224 a159 a248a169a217a253a32a54a31a213a34a216a45a222a148a220a146a218a34a213a35a213a71a220a146a218a125a212a182a239a38a215a146a228a125a237a25a239a6a217a199a214a156a212a62a217a199a214a135a224a33a228a135a215a164a215a87a214a10a219a169a215a69a228a156a226a4a238a58a213a146a232a242a72a232 a214a156a212a72a213a153a235a69a213a34a228a135a233a108a50a51a239a38a215 a236 a225a72a237a110a213a127a237a34a52a165a239a6a217a133a214a135a212a109a50a156a239a163a215 a236 a225a72a237a17a52a170a220a87a225a72a237a247a214a156a212a45a213a244a225a45a215 a236 a225 a50a138a214a135a228 a236 a218a79a144a164a224a54a52a35a239a6a217a133a214a135a212a110a50a51a214a156a228 a236 a218a79a144a38a52a45a232 a248a169a217a227a217a148a253a187a54a6a213a127a216a45a222a148a220a146a218a26a213a10a214a156a212a45a213a33a239a38a215a146a228a125a237a151a239a6a217a133a214a135a212a70a220a146a225a129a223a158a215a146a219a2a214a156a212a45a213a145a218a34a215a146a225a72a218a34a213a34a216a110a214a125a224 a214a156a212a59a220a80a214a6a224 a236 a233a59a224 a236 a226a158a213a33a217a133a214a84a217a227a225a70a220a18a212a59a220a87a225a72a237a164a243a131a218a26a228a125a220a80a219a214a135a213a127a237a102a238a164a242a69a213a34a225a45a213a127a228a135a220a146a222a72a215a146a225a129a214a135a215a146a222a227a215a146a242a146a223a69a238 a213a146a232a242a72a232a111a50a138a214a156a228 a236 a218a79a144a38a52a182a226a151a220a67a223a172a233a55a213a94a228a135a213a34a216a72a222a227a220a69a218a26a213a127a237a22a233a164a223a22a112a21a31a17a113a43a38a36a114a57a39a22a31a58a238a116a115a80a117a22a34a100a38a137a36 a118a24a119 a114a57a34a16a238a45a215a146a228a20a120a121a87a71a122a28a31a34a114a57a34a16a232 a248a169a217a227a217a199a217a253a24a54a31a213a34a216a45a222a148a220a146a218a34a213a10a213a127a220a69a218a125a212a154a225a72a220a146a226a14a213a12a239a6a217a133a214a135a212a76a217a199a214a135a224a38a218a26a215a69a228a156a228a135a213a127a224a156a216a59a215a69a225a72a237a110a217a227a225a45a242 a225a72a220a146a226a14a213a71a237a247a213a127a225a69a214a135a217a133a214a138a223a247a218a34a222a227a220a69a224a156a224a127a238a31a213a69a232a242a59a232a123a50a156a230a2a215a129a224a70a36a10a225a45a242a146a213a127a222a199a213a71a224a103a52a22a239a6a217a133a214a135a212 a168a58a198a163a160 a124 a52a43a53a55a64a66a82a43a64a66a88a55a54a93a77a24a186a35a77a79a82a126a125a63a71a61a82a58a56a35a71a58a54a2a76a48a70a28a71a10a56a61a54a2a88a12a64a66a62a90a89a128a127a117a77a79a62a63a80a98a77a79a71a58a101a87a54a60a71a45a54a5a56a83a77a79a74a92a104a66a94a69a129a14a130a14a130a14a130a98a99a81a104 a131a79a52a43a53a55a54a45a65a68a67a63a54a2a71a182a188a133a132a83a64a66a82a37a80a28a54a2a62a63a54a2a71a81a77a85a56a58a54a2a88a186a101a104a188a73a59a60a70a28a62a55a82a61a64a66a88a63a54a2a71a61a64a66a62a55a80a86a56a58a53a63a54a35a103a98a54a2a71a61a101a84a70a28a71a37a62a55a70a28a72a173a75 a64a66a62a78a77a79a74a66a64a83a82a60a77a85a56a58a64a66a70a28a62a102a69a9a71a61a70a28a72a18a56a61a53a63a54a14a72a84a70a28a82a10a56a58a75a92a71a61a54a2a59a2a54a60a62a98a56a45a77a79a88a63a88a63a54a2a88a30a56a58a70a28a76a63a64a66a59a14a71a61a54a2a74a165a77a85a56a58a64a66a70a28a62a22a104 a0a2a1 a178a32a190a131a198a38a186 a220a87a225a72a237 a50a85a145a84a220a87a225a33a144a94a215a87a219a24a36a10a226a14a213a127a228a156a217a148a218a34a220a76a52a154a239a6a217a199a214a156a212 a198a4a3a6a5 a1 a186a38a190a8a7 a1 a160 a178a32a190a131a198a38a186 a232a63a203a16a217a199a242 a236 a228a156a213a173a23a31a217a227a222a227a222 a236 a224a51a214a156a228a125a220a80a214a135a213a127a224a112a214a156a212a45a213a84a213a34a221a164a216a59a220a87a225a72a224a156a217a199a215a69a225a145a215a87a219a72a228a135a213a34a222a148a220a80a214a135a217a199a215a69a225a72a224a127a232 EXPANSIONS EXPANSIONS exploded − truck exploded</definiens>
			</definition>
</paper>

		<paper id="1161">
			<definition id="0">
				<sentence>Adjectives are predicates , equivalent to verbs when appearing in predicative environments .</sentence>
				<definiendum id="0">Adjectives</definiendum>
				<definiens id="0">predicates , equivalent to verbs when appearing in predicative environments</definiens>
			</definition>
			<definition id="1">
				<sentence>The arity is a basic parameter for the semantic characterisation of any predicate .</sentence>
				<definiendum id="0">arity</definiendum>
				<definiens id="0">a basic parameter for the semantic characterisation of any predicate</definiens>
			</definition>
			<definition id="2">
				<sentence>Lexical semantics of adjectives : A microtheory of adjectival meaning .</sentence>
				<definiendum id="0">Lexical semantics of adjectives</definiendum>
				<definiens id="0">A microtheory of adjectival meaning</definiens>
			</definition>
</paper>

		<paper id="1082">
			<definition id="0">
				<sentence>Syntactic probabilities model the probability of the occurrence of tag ti given a history which is the knowledge of the h preceding tags ( ti¡1 ... ti¡h ) .</sentence>
				<definiendum id="0">Syntactic probabilities</definiendum>
				<definiens id="0">model the probability of the occurrence of tag ti given a history which is the knowledge of the h preceding tags</definiens>
			</definition>
			<definition id="1">
				<sentence>Increasing the length of the history increases the predictive power of the tagger but also the number of parameters to estimate and therefore the amount of training data needed .</sentence>
				<definiendum id="0">Increasing the length of the history</definiendum>
				<definiens id="0">increases the predictive power of the tagger but also the number of parameters to estimate and therefore the amount of training data needed</definiens>
			</definition>
			<definition id="2">
				<sentence>† ' reaches its maximum at the point ( 1N ; : : : ; 1N ) † ' achieves its minimum at the points ( 1 ; 0 ; : : : ; 0 ) ; ( 0 ; 1 ; : : : ; 0 ) ; : : : ( 0 ; 0 ; : : : ; 1 ) Given an impurity function ' , we deflne the impurity measure of a N-tuple of counts C = ( c1 ; : : : ; cN ) as follows : I ( c1 ; : : : ; cN ) = ' ( f1 ; : : : ; fN ) ( 1 ) where fi is the relative frequency of ci in C : fi = ciPN k=1 ck The impurity function we have used is the Gini impurity criteria : ' ( f1 ; : : : ; fN ) = X i6=j fifj whose maximal value is equal to N¡1N .</sentence>
				<definiendum id="0">fN</definiendum>
				<definiendum id="1">fi</definiendum>
				<definiens id="0">the impurity measure of a N-tuple of counts C = ( c1 ; : : : ; cN ) as follows : I ( c1 ; : : : ; cN ) = ' ( f1 ; : : : ;</definiens>
			</definition>
			<definition id="3">
				<sentence>The result of the tagging process consists in a sequence of ambiguous and non ambiguous tags .</sentence>
				<definiendum id="0">tagging process</definiendum>
			</definition>
			<definition id="4">
				<sentence>Given an output of the tagger T = t1 : : : tn , where ti is the tag associated to word i by the tagger , and a gold reference R = r1 : : : rn where r1 is the correct tag for word wi , the recall of T is computed as follows : REC ( T ) = Pn i=1 – ( ri 2 ti ) n where – ( p ) equals to 1 if predicate p is true and 0 otherwise .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiens id="0">the tag associated to word i by the tagger , and a gold reference R = r1 : : : rn where r1 is the correct tag for word wi , the recall of T is computed as follows : REC ( T ) = Pn i=1 – ( ri 2 ti ) n where – ( p ) equals to 1 if predicate p is true and 0 otherwise</definiens>
			</definition>
			<definition id="5">
				<sentence>If there is an ambiguous tag T in Ti such that all its elements are possible tags of wj then , couple ( wj ; Tj ) is replaced with ( wj ; T ) in the corpus .</sentence>
				<definiendum id="0">Tj</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">an ambiguous tag T in Ti such that all its elements are possible tags of wj then , couple ( wj ;</definiens>
			</definition>
			<definition id="6">
				<sentence>1 0 5 10 15 20 25 30 35 40 45 50 1 recall ambiguity iterations recallambiguity recall ( baseline ) ambiguity ( baseline ) Figure 1 : Recall and ambiguity rate of the successive models on development corpus 1 ambiguity recall Model MiBaseline Figure 2 : Comparing ambiguity rates for a flxed value of recall 10 DT_RB 20 JJ_NN_NNP_NNS Model DEV TEST REC AMB REC AMB M0 = B0 0:955 1 0:955 1 B40 0:978 1:414 0:979 1:418 M40 0:980 1:232 0:982 1:232 Table 1 : Results on development and test corpus The original idea of our method consists in correcting errors that were made by M0 , through the introduction of ambiguous tags .</sentence>
				<definiendum id="0">recall ambiguity iterations recallambiguity recall</definiendum>
				<definiens id="0">Recall and ambiguity rate of the successive models on development corpus 1 ambiguity recall Model MiBaseline Figure 2</definiens>
				<definiens id="1">Results on development and test corpus The original idea of our method consists in correcting errors that were made by M0 , through the introduction of ambiguous tags</definiens>
			</definition>
</paper>

		<paper id="1055">
			<definition id="0">
				<sentence>SA_TELL LF : :FILL-CONTAINER : content A ( SET-OF LF : :FRUIT ) : theme : goal THE ( SET-OF LF : :FRUIT ) : subset : of THE LF : :LAND-VEHICLE LF : :WEIGHT-UNIT POUND : QUANTITY LF : :QMODIFIER MIN : quan 300 : is LF : :NUMBER : mods ( SPEECHACT V38109 SA_TELL : CONTENT V37618 ) ( F V37618 ( LF : :FILL-CONTAINER LOAD ) : GOAL V37800 : THEME V38041 : TMA ( ( TENSE PAST ) ( PASSIVE + ) ) ) ( THE V37800 ( LF : :LAND-VEHICLE TRUCK ) ) ( A V38041 ( SET-OF ( LF : :FRUIT ORANGE ) ) : QUANTITY V37526 : SUBSET V37539 ) ( QUANTITY-TERM V37526 ( LF : :WEIGHT-UNIT POUND ) : QUAN V37479 ) ( QUANTITY-TERM V37479 LF : :NUMBER : MODS ( V38268 ) ) ( F V38268 ( LF : :QMODIFIER MIN ) : OF V37479 : IS V37523 ) ( QUANTITY-TERM V37523 LF : :NUMBER : VALUE 300 ) ( THE V37539 ( SET-OF ( LF : :FRUIT ORANGE ) ) ) Figure 2 : Parser logical form ( together with a graphical approximation of the semantic content ) for At least three hundred pounds of the oranges were put in the truck .</sentence>
				<definiendum id="0">SA_TELL LF</definiendum>
				<definiendum id="1">SET-OF LF</definiendum>
				<definiendum id="2">:FRUIT )</definiendum>
				<definiendum id="3">SET-OF LF</definiendum>
				<definiendum id="4">:FRUIT )</definiendum>
				<definiendum id="5">:LAND-VEHICLE LF</definiendum>
				<definiendum id="6">QUANTITY LF</definiendum>
				<definiendum id="7">LF</definiendum>
				<definiendum id="8">) ) ( A V38041 ( SET-OF</definiendum>
				<definiens id="0">:FILL-CONTAINER LOAD ) : GOAL V37800 : THEME V38041 : TMA ( ( TENSE PAST ) ( PASSIVE + ) ) ) ( THE V37800 ( LF : :LAND-VEHICLE TRUCK</definiens>
				<definiens id="1">:FRUIT ORANGE ) ) : QUANTITY V37526 : SUBSET V37539 ) ( QUANTITY-TERM V37526 ( LF : :WEIGHT-UNIT POUND ) : QUAN V37479 ) ( QUANTITY-TERM V37479 LF : :NUMBER : MODS ( V38268 ) ) ( F V38268 ( LF : :QMODIFIER MIN ) : OF V37479 : IS V37523 ) ( QUANTITY-TERM V37523 LF : :NUMBER : VALUE 300 ) ( THE V37539 ( SET-OF ( LF : :FRUIT ORANGE ) ) ) Figure 2 : Parser logical form ( together with a graphical approximation of the semantic content ) for At least three hundred pounds of the oranges were put in the truck</definiens>
			</definition>
			<definition id="1">
				<sentence>4 4 Term constructors appearing at the leftmost edge of terms in the parser output are F ( relation ) , A ( indefinite entity ) , THE ( definite entity ) and QUANTITY-TERM ( numeric expressions ) .</sentence>
				<definiendum id="0">QUANTITY-TERM</definiendum>
				<definiens id="0">constructors appearing at the leftmost edge of terms in the parser output are F ( relation ) , A ( indefinite entity ) , THE ( definite entity</definiens>
			</definition>
			<definition id="2">
				<sentence>Recall refers to how many of the gold-standard TRIPS constituents were produced by Collins , precision to how many of the produced constituents matched TRIPS , and crossing brackets to the percentage of TRIPS constituents that were violated by any bracketing produced by Collins .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the percentage of TRIPS constituents that were violated by any bracketing produced by Collins</definiens>
			</definition>
</paper>

		<paper id="1047">
			<definition id="0">
				<sentence>The proposed RSCM is an extension of the existing RSCM outlined in Section 2 .</sentence>
				<definiendum id="0">RSCM</definiendum>
			</definition>
			<definition id="1">
				<sentence>Correct acceptance rate ( CAR ) is defined as the number of satisfactory outputs that have been accepted , divided by the total number of satisfactory outputs , that is , Vs ; a=Vs ( Table 1 ) .</sentence>
				<definiendum id="0">Correct acceptance rate</definiendum>
				<definiendum id="1">CAR</definiendum>
			</definition>
			<definition id="2">
				<sentence>Correct rejection rate ( CRR ) is defined as the number of unsatisfactory outputs that have been rejected , divided by the total number of unsatisfactory outputs , that is , Vu ; r=Vu ( Table 1 ) .</sentence>
				<definiendum id="0">Correct rejection rate ( CRR</definiendum>
				<definiens id="0">the number of unsatisfactory outputs that have been rejected , divided by the total number of unsatisfactory outputs , that is , Vu</definiens>
			</definition>
			<definition id="3">
				<sentence>H-mean is defined as a harmonic mean5 of the CAR and the CRR ( Table 1 ) , 2 CAR CRR= ( CAR + CRR ) .</sentence>
				<definiendum id="0">H-mean</definiendum>
				<definiendum id="1">CRR</definiendum>
				<definiens id="0">a harmonic mean5 of the CAR and the</definiens>
			</definition>
			<definition id="4">
				<sentence>Accuracy is defined as a weighted mean6 of the CAR and the CRR ( Table 1 ) , ( Vs CAR + Vu CRR ) = ( Vs + Vu ) = ( Vs ; a + Vu ; r ) = ( Vs + Vu ) .</sentence>
				<definiendum id="0">Accuracy</definiendum>
				<definiens id="0">a weighted mean6 of the CAR and the CRR ( Table 1 ) , ( Vs CAR + Vu CRR ) = ( Vs + Vu ) = ( Vs ; a + Vu</definiens>
			</definition>
			<definition id="5">
				<sentence>0 1 0 0.2 0.4 0.6 0.8 1 Correct rejection rate : y Correct acceptance rate : x J2E-D3 ( A|BCD ) y=x Existing method Proposed method ( D3+HPAT+SAT ) Proposed method ( D3+HPAT ) Existing method + reordering Contours by H-mean Figure 5 : ROC Curves of both RSCMs for J2E-D3 0 1 0 0.2 0.4 0.6 0.8 1 Correct rejection rate : y Correct acceptance rate : x J2E-HPAT ( A|BCD ) y=x Existing method Proposed method ( D3+HPAT+SAT ) Proposed method ( D3+HPAT ) Existing method + reordering Contours by H-mean Figure 6 : ROC Curves of both RSCMs for J2E-HPAT 0 1 0 0.2 0.4 0.6 0.8 1 Correct rejection rate : y Correct acceptance rate : x J2E-SAT ( A|BCD ) y=x Existing method Proposed method ( D3+HPAT+SAT ) Contours by H-mean Figure 7 : ROC Curves of both RSCMs for J2E-SAT Table 2 : Performance of MT systems : Each number in the AB row indicates the ratio of A-or-B-graded translation by each MT system .</sentence>
				<definiendum id="0">J2E-HPAT ( A|BCD</definiendum>
				<definiendum id="1">J2E-SAT</definiendum>
			</definition>
			<definition id="6">
				<sentence>jppro pextj &gt; t ( ; 10 1 ) S=p10 ; where ppro and pext , respectively , denote the average performance of the proposed RSCM and the existing RSCM , t ( ; 10 1 ) denotes the upper point of the Student’s t-distribution with ( 10 1 ) degrees of freedom , and S denotes the estimated standard deviation of the average difference in performance .</sentence>
				<definiendum id="0">ppro</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">the upper point of the Student’s t-distribution with ( 10 1 ) degrees of freedom , and</definiens>
				<definiens id="1">the estimated standard deviation of the average difference in performance</definiens>
			</definition>
			<definition id="7">
				<sentence>D3 ( DP-match Driven transDucer ) is an example-based MT system using onlinegenerated translation patterns ( Doi and Sumita , 2003 ) .</sentence>
				<definiendum id="0">D3</definiendum>
				<definiens id="0">an example-based MT system using onlinegenerated translation patterns</definiens>
			</definition>
			<definition id="8">
				<sentence>HPAT ( Hierarchical Phrase Alignment based Translation ) is a pattern-based system using automatically generated syntactic transfer ( Imamura et al. , 2003 ) .</sentence>
				<definiendum id="0">HPAT</definiendum>
			</definition>
			<definition id="9">
				<sentence>BTEC contains a variety of expressions used in a number of situations related to overseas travel .</sentence>
				<definiendum id="0">BTEC</definiendum>
				<definiens id="0">contains a variety of expressions used in a number of situations related to overseas travel</definiens>
			</definition>
			<definition id="10">
				<sentence>In Figure 7 , the curve of the proposed RSCM is a little closer when CRR is larger than CAR ; and the curve of the existing RSCM is a little closer when CAR is larger than CRR .</sentence>
				<definiendum id="0">RSCM</definiendum>
				<definiens id="0">a little closer when CRR is larger than CAR</definiens>
				<definiens id="1">a little closer when CAR is larger than CRR</definiens>
			</definition>
</paper>

		<paper id="1062">
			<definition id="0">
				<sentence>The CIA is a modular and highly configurable multiapplication system : a separation is made between generic dialogue processes and those specific to a particular domain .</sentence>
				<definiendum id="0">CIA</definiendum>
				<definiens id="0">a modular and highly configurable multiapplication system : a separation is made between generic dialogue processes and those specific to a particular domain</definiens>
			</definition>
			<definition id="1">
				<sentence>The recognition engine uses a trigram LM trained on the complete set of possible utterances expected given a small handcrafted scenario like that in the example dialogue .</sentence>
				<definiendum id="0">recognition engine</definiendum>
				<definiendum id="1">scenario</definiendum>
				<definiens id="0">uses a trigram LM trained on the complete set of possible utterances expected given a small handcrafted</definiens>
			</definition>
			<definition id="2">
				<sentence>To begin , each dialogue-move hypothesis consists of the following elements : ( 1 ) the DMT node associated with this hypothesis , ( 2 ) the parse that gave rise to the hypothesis , ( 3 ) the probability of the hypothesis , ( 4 ) an isUnimodal flag indicating whether or not the dialogue move requires confirmation from other modalities , ( 5 ) a list of artifact-change events to be made to the KB , and ( 6 ) the information state update function to be invoked if this hypothesis is confirmed by the multimodal integrator .</sentence>
				<definiendum id="0">dialogue-move hypothesis</definiendum>
				<definiendum id="1">artifact-change events</definiendum>
				<definiens id="0">consists of the following elements : ( 1 ) the DMT node associated with this hypothesis</definiens>
			</definition>
			<definition id="3">
				<sentence>Gemini : a natural language system for spoken-language understanding .</sentence>
				<definiendum id="0">Gemini</definiendum>
			</definition>
</paper>

		<paper id="1051">
			<definition id="0">
				<sentence>A simple edit distance metric ( Levenshtein 1966 ) was used to identify pairs of sentences within a cluster that are similar at the string level .</sentence>
				<definiendum id="0">simple edit distance metric</definiendum>
				<definiens id="0">used to identify pairs of sentences within a cluster that are similar at the string level</definiens>
			</definition>
			<definition id="1">
				<sentence>Nevertheless , even after filtering in these ways , a significant amount of unfiltered noise remains in the F2 corpus , which consisted of 214K sentence pairs .</sentence>
				<definiendum id="0">F2 corpus</definiendum>
			</definition>
			<definition id="2">
				<sentence>• Phrasal : An entire group of words in one sentence alternates with one word or a phrase in the other .</sentence>
				<definiendum id="0">Phrasal</definiendum>
			</definition>
			<definition id="3">
				<sentence>• Anaphora : A full NP in one sentence corresponds to an anaphor in the other ( Prime Minister Blair / He ) .</sentence>
				<definiendum id="0">Anaphora</definiendum>
				<definiendum id="1">NP</definiendum>
				<definiens id="0">A full</definiens>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>The LSD-DHMM overcomes the strong context independent assumption in traditional generative HMMs ( GHMMs ) and models the sequential data in a discriminative way , by assuming a novel mutual information independence .</sentence>
				<definiendum id="0">LSD-DHMM</definiendum>
				<definiens id="0">overcomes the strong context independent assumption in traditional generative HMMs ( GHMMs ) and models the sequential data in a discriminative way , by assuming a novel mutual information independence</definiens>
			</definition>
			<definition id="1">
				<sentence>, ... ,2,1| { KkE k i = arytryDiction Form Form Given a pattern entry E and a dictionary of frequently occurring pattern entries , a simple algorithm is applied to find the K nearest neighbors of the pattern entry from the dictionary as follows : i arytryDiction i E • compare with each entry in the dictionary and find all the compatible entries i E • compute the cosine similarity between E and each of the compatible entries i • sort out the K nearest neighbors according to their cosine similarities Finally , the conditional state probability distribution of the pattern entry is aggregated over those of its K nearest neighbors weighted by their frequencies and cosine similarities : ) ( k i Ef ) ∑ ∑ = = ⋅ •⋅⋅ K k k i k i K k k i k i k i EfkNNEp EPEfkNNEp 1 1 ) ( ) | ( ˆ ) | ( ) ( ) | ( ˆ ( 5 ) p In the literature , an ensemble has been widely used in the classification problem to combine several classifiers ( Breiman 1996 ; Hamamoto 1997 ; Dietterich 1998 ; Zhou Z.H. et al 2002 ; Kim et al 2003 ) .</sentence>
				<definiendum id="0">ensemble</definiendum>
				<definiens id="0">aggregated over those of its K nearest neighbors weighted by their frequencies and cosine similarities : ) ( k i Ef</definiens>
			</definition>
			<definition id="2">
				<sentence>Here , a structural tag consists of three parts : ii wp= 1 n n wwww L 211 = n n ppp L 211 = • Boundary Category ( BOUNDARY ) : it is a set of four values : “O”/“B”/“M”/“E” , where “O” means that current word is a whOle phrase and “B”/“M”/“E” means that current word is at the Beginning/in the Middle/at the End of a phrase .</sentence>
				<definiendum id="0">structural tag</definiendum>
			</definition>
			<definition id="3">
				<sentence>• Part-of-Speech ( POS ) : Because of the limited number of boundary and phrase categories , the POS is added into the structural tag to represent more accurate state transition and output models .</sentence>
				<definiendum id="0">Part-of-Speech</definiendum>
				<definiens id="0">Because of the limited number of boundary and phrase categories</definiens>
			</definition>
			<definition id="4">
				<sentence>Here , the Fmeasure is the weighted harmonic mean of the precision ( P ) and the recall ( R ) : PR RP + + = 2 2 ) 1 ( β β F with =1 ( Rijsbergen 1979 ) , where the precision ( P ) is the percentage of predicted phrase chunks that are actually correct and the recall ( R ) is the percentage of correct phrase chunks that are actually found .</sentence>
				<definiendum id="0">Fmeasure</definiendum>
				<definiens id="0">the weighted harmonic mean of the precision ( P ) and the recall ( R ) : PR RP + + = 2 2</definiens>
				<definiens id="1">the percentage of predicted phrase chunks that are actually correct and the recall ( R ) is the percentage of correct phrase chunks that are actually found</definiens>
			</definition>
</paper>

		<paper id="1135">
			<definition id="0">
				<sentence>Given a set of hypernyms , for which we’d like to acquire their hyponyms , HEAIH finds the headings ( or , more precisely , candidates of headings ) that include the given hypernyms , and extracts the itemizations which are located near the headings .</sentence>
				<definiendum id="0">HEAIH</definiendum>
				<definiens id="0">finds the headings</definiens>
			</definition>
			<definition id="1">
				<sentence>It will then obtain that “Toyota” is a hyponym of “car company” from document ( A ) in the figure , while it finds that “Toyota” is a hyponym of “car” from ( B ) .</sentence>
				<definiendum id="0">“Toyota”</definiendum>
				<definiendum id="1">“Toyota”</definiendum>
				<definiens id="0">a hyponym of “car company” from document ( A ) in the figure</definiens>
			</definition>
			<definition id="2">
				<sentence>h ( C ) = argmaxn2NfhS ( n ; C ) g hS ( n ; C ) = df ( n ; LD ( C ) ) ¢ idf ( n ; G ) df ( n ; D ) is a document frequency , which is actually the number of documents including a noun n in a document set D. idf ( n ; G ) is an inverse document frequency , which is defined as log ( jGj=df ( n ; G ) ) .</sentence>
				<definiendum id="0">h ( C ) = argmaxn2NfhS</definiendum>
				<definiendum id="1">G ) df</definiendum>
				<definiendum id="2">D )</definiendum>
				<definiendum id="3">G )</definiendum>
				<definiendum id="4">log ( jGj=df</definiendum>
				<definiendum id="5">G</definiendum>
				<definiens id="0">( n ; C ) g hS ( n ; C ) = df ( n ; LD ( C ) ) ¢ idf ( n ;</definiens>
				<definiens id="1">a document frequency , which is actually the number of documents including a noun n in a document set D. idf ( n ;</definiens>
				<definiens id="2">an inverse document frequency</definiens>
			</definition>
			<definition id="3">
				<sentence>Here , Ci is an HCS , and h ( Ci ) is a common hypernym candidate for hyponym candidates in an HCS Ci .</sentence>
				<definiendum id="0">Ci</definiendum>
				<definiens id="0">a common hypernym candidate for hyponym candidates in an HCS Ci</definiens>
			</definition>
			<definition id="4">
				<sentence>The semantic similarities between hyponym candidates in an HCS C and a hypernym candidate n are computed using a cosine measure between cooccurrence vectors : sim ( n ; C ) = ( ho ( C ) ¢ hy ( n ) ) = ( jho ( C ) jjhy ( n ) j ) : Here , ho ( C ) denotes a co-occurrence vector of hyponym candidates , while hy ( n ) is the co-occurrence vector of a hypernym candidate n. Assume that all possible argument positions are denoted as fp1 ; ¢¢¢ ; plg and fv1 ; ¢¢¢ ; vog denotes a set of verbs .</sentence>
				<definiendum id="0">vog</definiendum>
				<definiens id="0">The semantic similarities between hyponym candidates in an HCS C and a hypernym candidate n are computed using a cosine measure between cooccurrence vectors : sim ( n ; C ) = ( ho ( C ) ¢ hy ( n ) ) = ( jho ( C ) jjhy ( n ) j ) : Here , ho ( C ) denotes a co-occurrence vector of hyponym candidates</definiens>
				<definiens id="1">the co-occurrence vector of a hypernym candidate n. Assume that all possible argument positions are denoted as fp1 ; ¢¢¢ ; plg and fv1 ; ¢¢¢ ;</definiens>
			</definition>
			<definition id="5">
				<sentence>ho ( C ) = hfh ( C ; p1 ; v1 ) ; ¢¢¢ ; fh ( C ; pl ; vo ) i hy ( n ) = hf ( n ; p1 ; v1 ) ; ¢¢¢ ; f ( n ; pl ; vo ) i Here , fh ( C ; p ; v ) denotes the frequency of the hyponym candidates in an HCS C occupying an argument position p of a verb v in a local document set and f ( n ; p ; v ) is the frequency of a noun n occupying an argument position p of a verb v in a large document set .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">the frequency of the hyponym candidates in an HCS C occupying an argument position p of a verb v in a local document set and</definiens>
			</definition>
			<definition id="6">
				<sentence>The results obtained in this step are denoted by B ( X ) = fhx0h ; Chigmh=1 , where x0h is one of the given hypernyms and Ch is an HCS extracted from a document downloaded for x0h .</sentence>
				<definiendum id="0">B ( X</definiendum>
				<definiendum id="1">x0h</definiendum>
				<definiendum id="2">Ch</definiendum>
				<definiens id="0">one of the given hypernyms and</definiens>
				<definiens id="1">an HCS extracted from a document downloaded for x0h</definiens>
			</definition>
</paper>

		<paper id="1127">
			<definition id="0">
				<sentence>The test set consists of 100 Yomiuri Newspaper articles from 1999 , out of which only 61 articles contain at least one management succession event .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of 100 Yomiuri Newspaper articles from 1999 , out of which only 61 articles contain at least one management succession event</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>Among others generalisations like the following were obtained ( all variables are implicitly universally quantified ) : fare ( A ) ∧airline ( B ) → on ( A , B ) meal ( A ) ∧flight ( B ) → on ( A , B ) flight ( A ) ∧day ( B ) → on ( A , B ) flight ( A ) ∧airline ( B ) → on ( A , B ) This domain theory was then used successfully in disambiguating a small held-out section of the corpus , by checking for consistency between logical forms and domain theories .</sentence>
				<definiendum id="0">B ) meal</definiendum>
				<definiendum id="1">B</definiendum>
				<definiens id="0">all variables are implicitly universally quantified ) : fare ( A ) ∧airline ( B ) → on ( A ,</definiens>
			</definition>
			<definition id="1">
				<sentence>There is an event e5 of succeeding , and x1 is the subject of that event .</sentence>
				<definiendum id="0">x1</definiendum>
				<definiens id="0">the subject of that event</definiens>
			</definition>
			<definition id="2">
				<sentence>Such filters consist of constraints ruling out patterns that are definitely not useful , for example patterns containing a verb but no arguments or attributes .</sentence>
				<definiendum id="0">Such filters</definiendum>
			</definition>
			<definition id="3">
				<sentence>The only statistics we have correspond to the frequency of each entire pattern , which is defined as : Freq = number of times the pattern matched the training datanumber of examples in the training set We took this frequency measure as the probability of patterns consisting of single predicates ( e.g. ’elect ( A , B , C ) ’ , which is equivalent to ’B elects C’ ) whereas the probabilities of all other pattern constituents have to be conditioned on the probabilities of terms preceding them .</sentence>
				<definiendum id="0">C ) ’</definiendum>
				<definiens id="0">the probability of patterns consisting of single predicates ( e.g. ’elect ( A , B ,</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , the probability of ’cperson ( C ) ’ , given ’elect ( A , B , C ) ’ is defined by the following : P ( ′cperson ( C ) ′|′elect ( A , B , C ) ′ ) = P ( ′elect ( A , B , C ) ′ , ′cperson ( C ) ′ ) P ( ′elect ( A , B , C′ ) where P ( ′elect ( A , B , C ) ′ , ′ cperson ( C ) ) ′ is the frequency of the pattern [ ′elect ( A , B , C ) ′ , ′ cperson ( C ) ′ ] and P ( ′elect ( A , B , C ) ′ ) is defined as : P ( ′elect ( A , B , C ) ′ ) =summationtextX P ( ′elect ( A , B , C ) ′ , X ) That is , the probability of P ( ′elect ( A , B , C ) ′ ) is the sum of all the probabilities of the patterns that contain ’elect ( A , B , C ) ’ followed by another predicate .</sentence>
				<definiendum id="0">′</definiendum>
				<definiendum id="1">P ( ′elect ( A , B , C ) ′ )</definiendum>
				<definiens id="0">the probability of ’cperson ( C ) ’ , given ’elect ( A , B , C ) ’ is defined by the following : P ( ′cperson ( C ) ′|′elect ( A , B , C ) ′ ) = P ( ′elect ( A , B , C ) ′ , ′cperson ( C ) ′ ) P ( ′elect ( A , B , C′ ) where P ( ′elect ( A , B , C ) ′ , ′ cperson ( C ) )</definiens>
				<definiens id="1">the frequency of the pattern [ ′elect ( A , B , C ) ′ , ′ cperson ( C ) ′ ] and</definiens>
			</definition>
</paper>

		<paper id="1060">
			<definition id="0">
				<sentence>The Inversion Transduction Grammar of Wu ( 1997 ) can be thought as a a generative process which simultaneously produces strings in both languages through a series of synchronous context-free grammar productions .</sentence>
				<definiendum id="0">Inversion Transduction Grammar</definiendum>
				<definiens id="0">a a generative process which simultaneously produces strings in both languages through a series of synchronous context-free grammar productions</definiens>
			</definition>
			<definition id="1">
				<sentence>The probability of adding a clone of original node `` i as a child of node `` j is calculated in two steps : first , the choice of whether to insert a clone under `` j , with probability Pins ( clonej '' j ) , and the choice of which original node to copy , with probability Pclone ( `` ijclone = 1 ) = Pmakeclone ( `` i ) P k Pmakeclone ( `` k ) where Pmakeclone is the probability of an original node producing a copy .</sentence>
				<definiendum id="0">Pmakeclone</definiendum>
				<definiens id="0">The probability of adding a clone of original node `` i as a child of node `` j is calculated in two steps : first , the choice of whether to insert a clone under `` j , with probability Pins ( clonej '' j ) , and the choice of which original node to copy , with probability Pclone ( `` ijclone = 1 ) = Pmakeclone ( `` i ) P k Pmakeclone ( `` k ) where</definiens>
				<definiens id="1">the probability of an original node producing a copy</definiens>
			</definition>
			<definition id="2">
				<sentence>In our implementation , Pins ( clone ) is estimated by the Expectation Maximization algorithm conditioned on the label of the parent node `` j , and Pmakeclone is a constant , meaning that the node to be copied is chosen from all the nodes in the original tree with uniform probability .</sentence>
				<definiendum id="0">Pmakeclone</definiendum>
			</definition>
			<definition id="3">
				<sentence>For scoring the viterbi alignments of each system against goldstandard annotated alignments , we use the alignment error rate ( AER ) of Och and Ney ( 2000 ) , which measures agreement at the level of pairs of words : AER = 1 jA \ GPj + jA \ GSjjAj + jG Sj where A is the set of word pairs aligned by the automatic system , GS is the set marked in the gold standard as “sure” , and GP is the set marked as “possible” ( including the “sure” pairs ) .</sentence>
				<definiendum id="0">AER</definiendum>
				<definiendum id="1">GS</definiendum>
				<definiendum id="2">GP</definiendum>
				<definiens id="0">the set of word pairs aligned by the automatic system ,</definiens>
				<definiens id="1">the set marked as “possible” ( including the “sure” pairs )</definiens>
			</definition>
			<definition id="4">
				<sentence>“Inversion Transduction Grammar” ( ITG ) is the model of Wu ( 1997 ) , “Tree-to-String” is the model of Yamada and Knight ( 2001 ) , and “Tree-to-String , Clone” allows the node cloning operation described above .</sentence>
				<definiendum id="0">“Inversion Transduction Grammar”</definiendum>
				<definiendum id="1">ITG</definiendum>
				<definiendum id="2">“Tree-to-String”</definiendum>
				<definiens id="0">the model of Yamada and Knight ( 2001 ) , and “Tree-to-String , Clone” allows the node cloning operation described above</definiens>
			</definition>
			<definition id="5">
				<sentence>The Inversion Transduction Grammar significantly outperforms the syntactically supervised tree-tostring model of Yamada and Knight ( 2001 ) .</sentence>
				<definiendum id="0">Inversion Transduction Grammar</definiendum>
			</definition>
			<definition id="6">
				<sentence>Alignment Precision Recall Error Rate Inversion Transduction Grammar .68 .52 .40 Tree-to-String , automatic parses .61 .48 .46 Tree-to-String , gold parses .61 .52 .44 Table 3 : Chinese Tree to English String ( 1997 ) as well as Brown et al. ( 1993 ) .</sentence>
				<definiendum id="0">Alignment Precision Recall Error Rate Inversion Transduction</definiendum>
			</definition>
			<definition id="7">
				<sentence>Computational complexity is an issue for the treebased models presented here .</sentence>
				<definiendum id="0">Computational complexity</definiendum>
				<definiens id="0">an issue for the treebased models presented here</definiens>
			</definition>
			<definition id="8">
				<sentence>Machine translation divergences : A formal description and proposed solution .</sentence>
				<definiendum id="0">Machine translation divergences</definiendum>
				<definiens id="0">A formal description</definiens>
			</definition>
</paper>

		<paper id="1185">
			<definition id="0">
				<sentence>Representation Copestake ( 2003 ) presents a formalism for partial semantic representation that is derived from MRS semantics ( Copestake et al. , 2003 ) .</sentence>
				<definiendum id="0">Representation Copestake</definiendum>
			</definition>
			<definition id="1">
				<sentence>A ‘Parsons style‘ notation accommodates for partiality of shallow systems wrt .</sentence>
				<definiendum id="0">‘Parsons style‘ notation</definiendum>
			</definition>
			<definition id="2">
				<sentence>It allows the definition of finite state transduction rules that apply to ( sequences of ) typed feature structures ( TFS ) , as opposed to atomic symbols .</sentence>
				<definiendum id="0">TFS</definiendum>
				<definiens id="0">apply to ( sequences of ) typed feature structures</definiens>
			</definition>
			<definition id="3">
				<sentence>A general reparsing rule ( cf. Figure 3 ) is applied to an input sequence of TFS for lexical or phrasal nodes and produces as output a TFS for the implicitly defined mother node .</sentence>
				<definiendum id="0">general reparsing rule</definiendum>
				<definiens id="0">lexical or phrasal nodes and produces as output a TFS for the implicitly defined mother node</definiens>
			</definition>
			<definition id="4">
				<sentence>MRS in the LinGO Grammar Matrix : A Practical User’s Guide .</sentence>
				<definiendum id="0">LinGO Grammar Matrix</definiendum>
			</definition>
</paper>

		<paper id="1104">
</paper>

		<paper id="1146">
			<definition id="0">
				<sentence>Previous work on this problem ( Caraballo , 1999 ; Lin et al. , 2003 ) involves identifying speci c phrasal patterns within text e.g. , \Xs and other Ys '' is used as evidence that X is a hyponym of Y. Our work explores the connection between relative frequency , distributional generality and semantic generality with promising results .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a hyponym of Y. Our work explores the connection between relative frequency , distributional generality and semantic generality with promising results</definiens>
			</definition>
			<definition id="1">
				<sentence>The confusion probability ( Sugawara et al. , 1985 ) is an estimate of the probability that one word can be substituted for another .</sentence>
				<definiendum id="0">confusion probability</definiendum>
				<definiens id="0">an estimate of the probability that one word</definiens>
			</definition>
			<definition id="2">
				<sentence>simja+mi is a variant ( Lin , 1998 ) in which the features of a word are those contexts for which the pointwise mutual information ( MI ) between the word and the context is positive , where MI can be calculated using I ( c ; w ) = log P ( cjw ) P ( c ) .</sentence>
				<definiendum id="0">simja+mi</definiendum>
				<definiens id="0">a variant ( Lin , 1998 ) in which the features of a word are those contexts for which the pointwise mutual information</definiens>
			</definition>
			<definition id="3">
				<sentence>Lin’s Measure ( Lin , 1998 ) is based on his information-theoretic similarity theorem , which states , \the similarity between A and B is measured by the ratio between the amount of information needed to state the commonality of A and B and the information needed to fully describe what A and B are . ''</sentence>
				<definiendum id="0">Lin’s Measure</definiendum>
			</definition>
			<definition id="4">
				<sentence>+MI simja+mi ( w2 ; W1 ) = jF ( w1 ) \F ( w2 ) jjF ( w1 ) [ F ( w2 ) j where F ( w ) =fc : I ( c ; w ) &gt; 0g Lin’s simlin ( w2 ; w1 ) = P F ( w1 ) \F ( w2 ) ( I ( c ; w1 ) +I ( c ; w2 ) ) P F ( w1 ) I ( c ; w1 ) + P F ( w2 ) I ( c ; w2 ) where F ( w ) =fc : I ( c ; w ) &gt; 0g precision simP ( w2 ; w1 ) = P F ( w1 ) \F ( w2 ) I ( c ; w2 ) P F ( w2 ) I ( c ; w2 ) where F ( w ) =fc : I ( c ; w ) &gt; 0g recall simR ( w2 ; w1 ) = P F ( w1 ) \F ( w2 ) I ( c ; w1 ) P F ( w1 ) I ( c ; w1 ) where F ( w ) =fc : I ( c ; w ) &gt; 0g harm .</sentence>
				<definiendum id="0">+MI simja+mi</definiendum>
			</definition>
			<definition id="5">
				<sentence>mean simhm ( w2 ; w1 ) = 2 : simP ( w2 ; w1 ) : simR ( w2 ; w1 ) simP ( w2 ; w1 ) +simR ( w2 ; w1 ) where F ( w ) =fc : I ( c ; w ) &gt; 0g Table 1 : Ten distributional similarity measures their harmonic mean ( or F-score ) .</sentence>
				<definiendum id="0">mean simhm</definiendum>
				<definiendum id="1">F ( w</definiendum>
				<definiens id="0">Ten distributional similarity measures their harmonic mean ( or F-score )</definiens>
			</definition>
			<definition id="6">
				<sentence>The complete set of 2000 nouns ( WScomp ) is the union of two sets WShigh and WSlow for which nouns were selected on the basis of frequency : WShigh contains the 1000 most frequently occurring nouns ( frequency &gt; 500 ) , and WSlow contains the nouns ranked 3001-4000 ( frequency 100 ) .</sentence>
				<definiendum id="0">WScomp )</definiendum>
				<definiendum id="1">WSlow</definiendum>
				<definiens id="0">the union of two sets WShigh and WSlow for which nouns were selected on the basis of frequency : WShigh contains the 1000 most frequently occurring nouns ( frequency &gt; 500 )</definiens>
			</definition>
			<definition id="7">
				<sentence>The complete data-set consists of 1,596,798 cooccurrence tokens distributed over 331,079 cooccurrence types .</sentence>
				<definiendum id="0">complete data-set</definiendum>
				<definiens id="0">consists of 1,596,798 cooccurrence tokens distributed over 331,079 cooccurrence types</definiens>
			</definition>
			<definition id="8">
				<sentence>The concept of distributional generality introduced in the previous section has parallels with the linguistic relation of hyponymy , where a hypernym is a semantically more general term and a hyponym is a semantically more speci c term .</sentence>
				<definiendum id="0">hyponym</definiendum>
				<definiens id="0">a semantically more general term and a</definiens>
				<definiens id="1">a semantically more speci c term</definiens>
			</definition>
			<definition id="9">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="10">
				<sentence>Diversity : Its measurement , decomposition , apportionment and analysis .</sentence>
				<definiendum id="0">Diversity</definiendum>
				<definiens id="0">Its measurement , decomposition , apportionment and analysis</definiens>
			</definition>
</paper>

		<paper id="1178">
</paper>

		<paper id="1193">
			<definition id="0">
				<sentence>Lexeed consists of all open class words with a familiarity greater than or equal to ve .</sentence>
				<definiendum id="0">Lexeed</definiendum>
				<definiens id="0">consists of all open class words with a familiarity greater than or equal to ve</definiens>
			</definition>
			<definition id="1">
				<sentence>Previous work has successfully used regular expressions , both for 2 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 4 Headword a0a2a1a4a3a6a5a8a7 doraibaPOS noun Lexical-type noun-lex Familiarity 6.5 [ 1 { 7 ] Sense 1 2 66 66 66 66 4 Definition 2 66 64 S1 a9a11a10 /a12a6a13a15a14 /a16 screw turn ( screwdriver ) S10 a9a11a10 /a17 /a18a19a14a21a20a23a22 /a24a26a25 / a27 /a28a30a29a32a31a30a33 /a24 /a34a30a35 /a36a23a37 /a16 A tool for inserting and removing screws .</sentence>
				<definiendum id="0">regular expressions</definiendum>
				<definiens id="0">S1 a9a11a10 /a12a6a13a15a14 /a16 screw turn ( screwdriver ) S10 a9a11a10 /a17 /a18a19a14a21a20a23a22 /a24a26a25 / a27 /a28a30a29a32a31a30a33 /a24 /a34a30a35 /a36a23a37 /a16 A tool for inserting and removing screws</definiens>
			</definition>
			<definition id="2">
				<sentence>The parser uses the stochastic parse ranking model learned from the Hinoki treebank , and returns the MRS of the rst ranked parse .</sentence>
				<definiendum id="0">MRS of</definiendum>
			</definition>
			<definition id="3">
				<sentence>An MRS consists of a bag of labeled elementary predicates and their arguments , a list of scoping constraints , and a pair of relations that provide a hook into the representation | a label , which must outscope all the handles , and an index ( Copestake et al. , 2001 ) .</sentence>
				<definiendum id="0">MRS</definiendum>
			</definition>
			<definition id="4">
				<sentence>hh0 ; x1fh0 : prpstn rel ( h1 ) h1 : hito ( x1 ) h2 : udef ( x1 ; h1 ; h6 ) h3 : jidosha ( x2 ) h4 : udef ( x2 ; h3 ; h7 ) h5 : unten ( u1 ; x1 ; x2 ) gi hh1 ; x1fh : prpstn rel ( h0 ) h1 : person ( x1 ) h2 : some ( x1 ; h1 ; h6 ) h3 : car ( x2 ) h4 : indef ( x1 ; h3 ; h7 ) h5 : drive ( u1 ; x1 ; x2 ) gi a0a2a1a4a3a6a5a8a7a10a9a12a11a14a13a16a15a18a17 a19 somebody who drives a car Figure 2 : Simpli ed MRS represntations for doraib a2 In most cases , the rst sentence of a dictionary de nition consists of a fragment headed by the same part of speech as the headword .</sentence>
				<definiendum id="0">prpstn rel</definiendum>
				<definiendum id="1">prpstn rel</definiendum>
			</definition>
</paper>

		<paper id="1089">
			<definition id="0">
				<sentence>The document with the highest ) | ( DQP is the one that best matches the query .</sentence>
				<definiendum id="0">DQP</definiendum>
				<definiens id="0">the one that best matches the query</definiens>
			</definition>
			<definition id="1">
				<sentence>( c tq is the number of occurrences of c t in ) ( cC . ) )</sentence>
				<definiendum id="0">c tq</definiendum>
				<definiens id="0">the number of occurrences of c t in</definiens>
			</definition>
			<definition id="2">
				<sentence>We use backoff and linear interpolation for probability estimation : ) ( ) 1 ( ) ) ) ( ( | ( ) ) ) ( ( | ( cml ccmlcc tP eCTtPeCTtP ⋅−+ ⋅= α α ∑ ∈ = ) ) ( ( ) ) ( ( ) ) ( ( ) ( ) ( ) ) ) ( ( | ( eCTt eCT ceCT ccml c c c td td eCTtP where ) ( • ml P are the maximum likelihood estimates , ) ( ) ) ( ( ceCT td c is the number of occurrences of the term c t in ) ) ( ( eCT c , and ) ( cml tP is estimated similarly by counting the occurrences of c t in the Chinese translation of the whole English corpus .</sentence>
				<definiendum id="0">ceCT td c</definiendum>
				<definiens id="0">| ( ) ) ) ( ( | ( cml ccmlcc tP eCTtPeCTtP ⋅−+ ⋅= α α ∑ ∈ = ) ) ( ( ) ) ( ( ) ) ( ( ) ( ) ( ) ) ) ( ( | ( eCTt eCT ceCT ccml c c c td td eCTtP</definiens>
				<definiens id="1">the number of occurrences of the term c</definiens>
			</definition>
			<definition id="3">
				<sentence>Chinese Gigaword corpus consists of news from two agencies : Xinhua News Agency and Central News Agency .</sentence>
				<definiendum id="0">Chinese Gigaword corpus</definiendum>
				<definiens id="0">consists of news from two agencies : Xinhua News Agency and Central News Agency</definiens>
			</definition>
			<definition id="4">
				<sentence>The English Gigaword corpus consists of news from four newswire services : Agence France Press English Service , Associated Press Worldstream English Service , New York Times Newswire Service , and Xinhua News Agency English Service .</sentence>
				<definiendum id="0">Gigaword corpus</definiendum>
			</definition>
			<definition id="5">
				<sentence># Cor is the number of correct English translations output .</sentence>
				<definiendum id="0">Cor</definiendum>
				<definiens id="0">the number of correct English translations output</definiens>
			</definition>
</paper>

		<paper id="1199">
			<definition id="0">
				<sentence>1 Here , qn is the term to define , and dp is a phrase that contains a definition of qn ; dp no longer necessarily contains a hypernym of qn .</sentence>
				<definiendum id="0">dp</definiendum>
				<definiens id="0">a phrase that contains a definition of qn</definiens>
			</definition>
			<definition id="1">
				<sentence>( 5 ) qn “ ( ” dp “ ) ” | “ ( ” dp “ ) ” qn e.g. , “MP ( Member of Parliament ) ” ( 6 ) qn ( is | was | are | were ) ( a | an | the ) dp e.g. , “Tony Blair is a politician” ( 7 ) qn , ( a | an | the ) dp e.g. , “Tony Blair , the politician” ( 8 ) qn , which ( is | was | are | were ) dp e.g. , “bronchitis , which is a disease of…” ( 9 ) qn , dp , ( is | was | are | were ) e.g. , “Blair , Prime Minister of Britain , is…” Joho and Sanderson first locate all the sentences of the document collection that contain the term to define , and then rank them using three attributes .</sentence>
				<definiendum id="0">, “Tony Blair</definiendum>
				<definiendum id="1">“Tony Blair</definiendum>
				<definiens id="0">a | an | the ) dp e.g.</definiens>
				<definiens id="1">a politician” ( 7 ) qn , ( a | an | the ) dp e.g. ,</definiens>
			</definition>
			<definition id="2">
				<sentence>The second attribute ( SN ) is the ordinal number of the sentence in its document , ignoring sentences that do not contain the term ; sentences that mention first the term in a document are more likely to define it .</sentence>
				<definiendum id="0">SN )</definiendum>
				<definiens id="0">the ordinal number of the sentence in its document , ignoring sentences that do not contain the term ; sentences that mention</definiens>
			</definition>
			<definition id="3">
				<sentence>WC is the percentage of these words that are present in the sentence being ranked .</sentence>
				<definiendum id="0">WC</definiendum>
			</definition>
			<definition id="4">
				<sentence>Given a training set of terms to be defined and the corresponding documents that the IR engine returned , we collect from the documents all the 250-character snippets 3 Following Prager et al. ( 2002 ) , we consider synonyms of the input term as level-0 hypernyms , and include them in the search for best hypernyms ; their LAC is the number of times they co-occur with the input term .</sentence>
				<definiendum id="0">LAC</definiendum>
				<definiens id="0">the number of times they co-occur with the input term</definiens>
			</definition>
			<definition id="5">
				<sentence>( 10 ) dp like qn e.g. , “antibiotics like amoxicillin” ( 11 ) qn or dp e.g. , “autism or some other type of disorder” ( 12 ) qn ( can | refer | have ) dp e.g. , “amphibians can live on land and…” ( 13 ) dp ( called | known as | defined ) qn e.g. , “the giant wave known as tsunami” This configuration can be seen as an approximation of Joho et al.’s method , although it is actually an improvement , because of the extra attributes and the fact that it uses an SVM learner 4 We used Weka’s SVM implementation .</sentence>
				<definiendum id="0">qn</definiendum>
				<definiens id="0">| refer | have ) dp e.g. , “amphibians can live on land and…” ( 13 ) dp ( called | known as | defined ) qn e.g.</definiens>
			</definition>
			<definition id="6">
				<sentence>In our experiments , this pattern acquisition process re-discovered several of the patterns ( 1 ) – ( 13 ) or sub-expressions of them , namely [ dp such as qn ] , [ qn and other dp ] , [ qn “ ( “ dp ] , [ dp “ ) ” qn ] , [ qn is ( a | an | the ) dp ] , [ qn ( are | were ) dp ] , [ qn , ( a | an | the ) dp ) , [ qn , which is dp ] , [ qn , dp ] , [ qn or dp ] , [ qn can dp ] , [ dp called qn ] , [ dp known as qn ] .</sentence>
				<definiendum id="0">dp known</definiendum>
				<definiens id="0">qn ] , [ qn and other dp ] , [ qn “ ( “ dp ] , [ dp “ ) ” qn ] , [ qn is ( a | an | the ) dp ] , [ qn ( are | were ) dp ] , [ qn , ( a | an | the ) dp )</definiens>
				<definiens id="1">dp ] , [ qn , dp ] , [ qn or dp ] , [ qn can dp ] , [ dp called qn ] , [</definiens>
			</definition>
			<definition id="7">
				<sentence>It also discovered some reasonable variations of patterns ( 1 ) – ( 13 ) ; e.g , [ qn is one dp ] , [ dp , ( a | an ) qn ] ( as in “A sudden health problem , a heart attack or …” ) , [ dp , qn ] , [ qn , or dp ] .</sentence>
				<definiendum id="0">qn</definiendum>
				<definiens id="0">one dp ] , [ dp , ( a | an ) qn ]</definiens>
			</definition>
			<definition id="8">
				<sentence>In that case , one selects the n-grams with the m highest IG ( C , X ) scores , defined below , where C and X are random variables denoting the category of a snippet and the value of the n-gram’s binary attribute , respectively , and H ( C ) and H ( C|X ) are the entropy and conditional entropy of C. By selecting the attributes with the highest information gain scores , one selects the attributes that carry most information about the value of C. ) | ( ) ( ) ( ) , ( } 1,0 { xXCHxXPCHXCIG x =⋅=−= ∑ ∈ Although information gain is one of the best attribute selection measures in text categorization ( Yang and Pedersen , 1997 ) , in our case it led to very few attributes with non-zero IG ( C , X ) scores ( around 90 attributes from the entire dataset of section 4 ) .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">the entropy and conditional entropy of C. By selecting the attributes with the highest information gain scores</definiens>
			</definition>
			<definition id="9">
				<sentence>, WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="10">
				<sentence>Automatic Derivation of Surface Text Patterns for a Maximum Entropy Based Question Answering System .</sentence>
				<definiendum id="0">Automatic Derivation of Surface Text Patterns for</definiendum>
				<definiens id="0">a Maximum Entropy Based Question Answering System</definiens>
			</definition>
</paper>

		<paper id="1134">
			<definition id="0">
				<sentence>BiFrameNet is a frame semantic representation , and contains semantic structure transfers between English and Chinese .</sentence>
				<definiendum id="0">BiFrameNet</definiendum>
				<definiens id="0">a frame semantic representation , and contains semantic structure transfers between English and Chinese</definiens>
			</definition>
			<definition id="1">
				<sentence>The Berkeley FrameNet database consists of frame-semantic descriptions of more than 7000 English lexical items , together with example sentences annotated with semantic roles ( Baker et al. , 1998 ) .</sentence>
				<definiendum id="0">Berkeley FrameNet database</definiendum>
			</definition>
			<definition id="2">
				<sentence>FrameNet is a collection of lexical entries grouped by frame semantics .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">a collection of lexical entries grouped by frame semantics</definiens>
			</definition>
			<definition id="3">
				<sentence>Each lexical entry represents an individual word sense , and is associated with semantic roles and some annotated sentences .</sentence>
				<definiendum id="0">lexical entry</definiendum>
				<definiens id="0">represents an individual word sense , and is associated with semantic roles and some annotated sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>α is an adjusting parameter , which controls the curvature of the similarity score .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">controls the curvature of the similarity score</definiens>
			</definition>
			<definition id="5">
				<sentence>Example Chinese annotated sentences Initialization [ 0,0 ] 0 ; [ 0 , -1 ] ( , ) ; [ -1,0 ] ( , ) ji SSj cSi eσ εσ=+ +ε Recursion [ -1 , ] ( , ) [ , ] [ 1 , 1 ] ( , ) [ , 1 ] ( , ) [ -1 , ] ( , ) [ , ] arg [ 1 , 1 ] ( , ) [ , 1 ] ( , ) i ij j i ij j Si j e Si j max Si j e c Si j c Si j e Ti j max Si j e c Si j c σε σ σε σε σ σε  +  =−−+   −+   +  =−−   −+  where ( , ) ij ecσ is the transfer cost of an English POS tag from a Chinese POS tag ; ε is an empty word .</sentence>
				<definiendum id="0">ε</definiendum>
				<definiens id="0">Si j max Si j e c Si j c Si j e Ti j max Si j e c Si j c σε σ σε σε σ σε  +  =−−+   −+   +  =−−   −+  where ( , ) ij ecσ is the transfer cost of an English POS tag from a Chinese POS tag ;</definiens>
				<definiens id="1">an empty word</definiens>
			</definition>
			<definition id="6">
				<sentence>A V x W POS tag “confusion matrix” is generated , where V is the vocabulary of the Chinese POS tags , and W is the vocabulary of the English POS tags .</sentence>
				<definiendum id="0">V x W POS tag “confusion matrix”</definiendum>
				<definiendum id="1">V</definiendum>
				<definiendum id="2">W</definiendum>
				<definiens id="0">the vocabulary of the Chinese POS tags , and</definiens>
			</definition>
			<definition id="7">
				<sentence>BiFrameNet consists of mappings between FrameNet semantic frames and HowNet concepts , as well as English and Chinese example sentences for a particular frame , with annotated semantic roles in the English FrameNet labels .</sentence>
				<definiendum id="0">BiFrameNet</definiendum>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>A probabilistic deterministic nite state automaton is a mathematical object that stochastically generates strings of symbols .</sentence>
				<definiendum id="0">probabilistic deterministic nite state automaton</definiendum>
				<definiens id="0">a mathematical object that stochastically generates strings of symbols</definiens>
			</definition>
			<definition id="1">
				<sentence>A PDFA A is a tuple ( Q ; ; q0 ; qf ; ; ; ) , where Q is a nite set of states , is the alphabet , a nite set of symbols , q0 2 Q is the single initial state , qf 62 Q is the nal state , 62 is the nal symbol , : Q [ f g !</sentence>
				<definiendum id="0">PDFA A</definiendum>
				<definiendum id="1">Q</definiendum>
				<definiens id="0">a tuple ( Q ; ; q0</definiens>
				<definiens id="1">a nite set of states , is the alphabet , a nite set of symbols</definiens>
				<definiens id="2">the nal state , 62 is the nal symbol</definiens>
			</definition>
			<definition id="2">
				<sentence>The Cherno bound says that for any &gt; 0 , for the sum of n bernouilli variables with prob p and Pr ( X &gt; ( 1 + ) np ) &lt; e ( 1 + ) ( 1+ ) np ( 7 ) Now we bound each group separately , using the binomial Cherno bound where n = m 0 &gt; mp ( which is true since p &lt; 0 ) Pr ^p ( s ) 0 mp n n en mp ( 8 ) This bound decreases with p , so we can replace this for all strings in Sk with the upper bound for the probability , and we can replace m with m0 .</sentence>
				<definiendum id="0">8</definiendum>
				<definiens id="0">true since p &lt; 0 ) Pr ^p ( s ) 0 mp n n en mp (</definiens>
			</definition>
</paper>

		<paper id="1080">
			<definition id="0">
				<sentence>Derived from his supervised transformation-based tagger ( Brill , 1992 ) , UTBL uses information from the distribution of unambiguously tagged data to make informed labeling decisions in ambiguous contexts .</sentence>
				<definiendum id="0">transformation-based tagger</definiendum>
				<definiendum id="1">UTBL</definiendum>
				<definiens id="0">uses information from the distribution of unambiguously tagged data to make informed labeling decisions in ambiguous contexts</definiens>
			</definition>
			<definition id="1">
				<sentence>In order to build both left and right-context into an HMM part-of-speech tagger , we reformulate the Figure 1 : Graphical Structure of Traditional HMM Tagger ( top ) and Contextualized HMM Tagger ( bottom ) trigram HMM model traditionally described as ∏ = −−−− ×= n i iiiiiiiii twtwtpttwtwwpTWp 1 111111 ) .</sentence>
				<definiendum id="0">Contextualized HMM Tagger</definiendum>
				<definiens id="0">Graphical Structure of Traditional HMM Tagger ( top )</definiens>
			</definition>
</paper>

		<paper id="1131">
			<definition id="0">
				<sentence>WSD is usually performed by matching information from the context in which the word occurs with disambiguation knowledge source .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">matching information from the context in which the word occurs with disambiguation knowledge source</definiens>
			</definition>
			<definition id="1">
				<sentence>Véronis J. ( 2001 ) , Sense Tagging : Does It Make Sense ?</sentence>
				<definiendum id="0">Sense Tagging</definiendum>
			</definition>
</paper>

		<paper id="1073">
</paper>

		<paper id="1162">
			<definition id="0">
				<sentence>1We use the term knowledge-based to denote methods that involve logical inferences and derivation of global properties that extend the data in a dictionary and/or a corpus with new knowledge .</sentence>
				<definiendum id="0">1We</definiendum>
				<definiens id="0">use the term knowledge-based to denote methods that involve logical inferences and derivation of global properties that extend the data in a dictionary and/or a corpus with new knowledge</definiens>
			</definition>
			<definition id="1">
				<sentence>The PageRank score of vertex Vi is defined as follows : S ( Vi ) = ( 1 d ) + d P j2In ( Vi ) S ( Vj ) jOut ( Vj ) j where d is a damping factor that can be set between 0 and 1 2 .</sentence>
				<definiendum id="0">PageRank score of vertex Vi</definiendum>
				<definiendum id="1">Vi ) S ( Vj ) jOut</definiendum>
				<definiendum id="2">d</definiendum>
				<definiens id="0">follows : S ( Vi ) = ( 1 d ) + d P j2In (</definiens>
				<definiens id="1">a damping factor that can be set between 0 and 1 2</definiens>
			</definition>
			<definition id="2">
				<sentence>WordNet is a lexical knowledge base for English that defines words , meanings , and relations between them .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a lexical knowledge base for English that defines words , meanings , and relations between them</definiens>
			</definition>
			<definition id="3">
				<sentence>Given a subset of the WordNet synsets , as identified in a given text or by other selectional criteria , and given a semantic relation , a graph is constructed by identifying all the synsets ( vertices ) in the given subset that can be linked by the given relation ( edges ) .</sentence>
				<definiendum id="0">WordNet synsets</definiendum>
				<definiens id="0">identified in a given text or by other selectional criteria , and given a semantic relation , a graph is constructed by identifying all the synsets ( vertices ) in the given subset that can be linked by the given relation ( edges )</definiens>
			</definition>
			<definition id="4">
				<sentence>The Lesk algorithm ( Lesk , 1986 ) is one of the first algorithms used for the semantic disambiguation of all words in open text .</sentence>
				<definiendum id="0">Lesk algorithm</definiendum>
				<definiens id="0">one of the first algorithms used for the semantic disambiguation of all words in open text</definiens>
			</definition>
			<definition id="5">
				<sentence>WordNet keeps track of the frequency of each word meaning within a sense-annotated corpus .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">keeps track of the frequency of each word meaning within a sense-annotated corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>The PageRank+Lesk algorithm consists in providing a default ordering by Lesk ( possibly after shuffling WordNet senses to remove the sense frequency bias ) , and then applying PageRank , which 4Consider for instance the text “I saw a man who is 108 years old and can still walk and tell jokes” , with nine open class words , each with several possible senses : see ( 26 ) , man ( 11 ) , year ( 4 ) , old ( 8 ) , can ( 5 ) , still ( 4 ) , walk ( 10 ) , tell ( 8 ) , joke ( 3 ) .</sentence>
				<definiendum id="0">PageRank+Lesk algorithm</definiendum>
				<definiens id="0">instance the text “I saw a man who is 108 years old and can still walk and tell jokes” , with nine open class words</definiens>
			</definition>
			<definition id="7">
				<sentence>As PageRank overrides Lesk one can notice that in this case we prioritize PageRank , which tends to outperform Lesk .</sentence>
				<definiendum id="0">PageRank</definiendum>
				<definiens id="0">tends to outperform Lesk</definiens>
			</definition>
			<definition id="8">
				<sentence>Frequency The combination of PageRank with the WordNet sense frequency information is done in two steps : introduce the WordNet frequency ordering by removing the random permutation of senses use a formula which combines PageRank and actual WordNet sense frequency information While a simple product of the two ranks already provides an improvement over both algorithms the following formula which prioritizes the first sense provides the best results : Rank = FR PR if N &gt; 1 where FR represents the WordNet sense frequency , PR represents the rank computed by PageRank , N is the position in the frequency ordered synset list , and Rank represents the combined rank .</sentence>
				<definiendum id="0">FR</definiendum>
				<definiendum id="1">PR</definiendum>
				<definiendum id="2">N</definiendum>
				<definiendum id="3">Rank</definiendum>
				<definiens id="0">the rank computed by PageRank</definiens>
			</definition>
			<definition id="9">
				<sentence>The Lesk algorithm described in section 5.1 , applied on an ordered set of senses .</sentence>
				<definiendum id="0">Lesk algorithm</definiendum>
				<definiens id="0">described in section 5.1 , applied on an ordered set of senses</definiens>
			</definition>
			<definition id="10">
				<sentence>In the context of text meaning , PageRank implements the concept of text cohesion ( Halliday and Hasan , 1976 ) , where from a certain concept C in a text , we are likely to “follow” links to related concepts – that is , concepts that have a semantic relation with the current concept C. Intuitively , PageRank-style algorithms work well for finding the meaning of all words in open text because they combine together information drawn from the entire text ( graph ) , and try to identify those synsets ( vertices ) that are of highest importance for the text unity and understanding .</sentence>
				<definiendum id="0">PageRank</definiendum>
				<definiens id="0">implements the concept of text cohesion</definiens>
				<definiens id="1">likely to “follow” links to related concepts – that is , concepts that have a semantic relation with the current concept C. Intuitively , PageRank-style algorithms work well for finding the meaning of all words in open text because they combine together information drawn from the entire text ( graph ) , and try to identify those synsets ( vertices ) that are of highest importance for the text unity and understanding</definiens>
			</definition>
			<definition id="11">
				<sentence>Wordnet : A lexical database .</sentence>
				<definiendum id="0">Wordnet</definiendum>
				<definiens id="0">A lexical database</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>We consider the problem of computing the Kullback-Leibler distance , also called the relative entropy , between a probabilistic context-free grammar and a probabilistic nite automaton .</sentence>
				<definiendum id="0">relative entropy</definiendum>
				<definiens id="0">a probabilistic context-free grammar and a probabilistic nite automaton</definiens>
			</definition>
			<definition id="1">
				<sentence>The di erence between the cross-entropy and the KL distance is the entropy of the PCFG , which does not rely on the PFA .</sentence>
				<definiendum id="0">KL distance</definiendum>
				<definiens id="0">the entropy of the PCFG , which does not rely on the PFA</definiens>
			</definition>
			<definition id="2">
				<sentence>A context-free grammar ( CFG ) is a 4-tuple G = ( ; N ; S ; R ) where and N are nite disjoint sets of terminals and nonterminals , respectively , S2N is the start symbol and R is a nite set of rules .</sentence>
				<definiendum id="0">context-free grammar ( CFG )</definiendum>
				<definiendum id="1">S2N</definiendum>
				<definiendum id="2">R</definiendum>
				<definiens id="0">a 4-tuple G = ( ; N ; S ; R ) where and N are nite disjoint sets of terminals and nonterminals , respectively</definiens>
				<definiens id="1">the start symbol</definiens>
				<definiens id="2">a nite set of rules</definiens>
			</definition>
			<definition id="3">
				<sentence>A left-most derivation ( for G ) is a string d = 1 m , m 0 , such that 0 1 ) 1 2 ) m ) m , for some 0 ; : : : ; m 2 ( [ N ) ; d = ( where denotes the empty string ) is also a left-most derivation .</sentence>
				<definiendum id="0">left-most derivation</definiendum>
				<definiens id="0">the empty string ) is also a left-most derivation</definiens>
			</definition>
			<definition id="4">
				<sentence>A probabilistic CFG ( PCFG ) is a pair Gp = ( G ; pG ) , where G is a CFG and pG is a function from R to real numbers in the interval [ 0 ; 1 ] .</sentence>
				<definiendum id="0">probabilistic CFG ( PCFG )</definiendum>
				<definiendum id="1">pG</definiendum>
				<definiendum id="2">G</definiendum>
				<definiens id="0">a pair Gp = ( G ;</definiens>
				<definiens id="1">a CFG and pG is a function from R to real numbers in the</definiens>
			</definition>
			<definition id="5">
				<sentence>A nite automaton ( FA ) is a 5-tuple M = ( ; Q ; q0 ; Qf ; T ) , where and Q are two nite sets of terminals and states , respectively , q0 is the initial state , Qf Q is the set of nal states , and T is a nite set of transitions , each of the form s a7 !</sentence>
				<definiendum id="0">nite automaton ( FA )</definiendum>
				<definiendum id="1">q0</definiendum>
				<definiendum id="2">Qf Q</definiendum>
				<definiendum id="3">T</definiendum>
				<definiens id="0">a 5-tuple M = ( ; Q ; q0 ; Qf ; T ) , where and Q are two nite sets of terminals and states , respectively</definiens>
				<definiens id="1">the initial state</definiens>
				<definiens id="2">the set of nal states , and</definiens>
				<definiens id="3">a nite set of transitions</definiens>
			</definition>
			<definition id="6">
				<sentence>A probabilistic nite automaton ( PFA ) is a pair Mp = ( M ; pM ) , where M is an FA and pM is a function from T to real numbers in the interval [ 0 ; 1 ] .1 For a xed ( P ) FA M , we de ne a con guration to be an element of Q , and we de ne the relation ‘ on triples consisting of two con gurations and a transition 2 T by : ( s ; w ) ‘ ( t ; w0 ) if and only if w is of the form aw0 , for some a2 , and = ( s a7 !</sentence>
				<definiendum id="0">probabilistic nite automaton</definiendum>
				<definiendum id="1">PFA</definiendum>
				<definiendum id="2">M</definiendum>
				<definiendum id="3">pM</definiendum>
				<definiendum id="4">w0</definiendum>
				<definiens id="0">a function from T to real numbers in the</definiens>
				<definiens id="1">an element of Q , and we de ne the relation ‘ on triples consisting of two con gurations and a transition 2 T by : ( s ; w ) ‘ ( t ;</definiens>
			</definition>
			<definition id="7">
				<sentence>: The derivational entropy of Gp is de ned as the expectation of the information of the complete derivations generated by Gp , i.e. , Hd ( Gp ) = EpG log 1p G ( d ) = X d pG ( d ) log 1p G ( d ) : ( 1 ) We now characterize derivational entropy using expected rule frequencies as Hd ( Gp ) = X d pG ( d ) log 1p G ( d ) = X d pG ( d ) log Y A !</sentence>
				<definiendum id="0">pG</definiendum>
				<definiens id="0">the expectation of the information of the complete derivations generated by Gp , i.e. , Hd ( Gp ) = EpG log 1p G ( d ) = X d pG ( d ) log 1p G ( d ) : ( 1 ) We now characterize derivational entropy using expected rule frequencies as Hd ( Gp ) = X d pG ( d ) log 1p G ( d ) = X d</definiens>
			</definition>
</paper>

		<paper id="1197">
			<definition id="0">
				<sentence>SRL is a difficult task , and one can not expect high levels of performance from either purely manual classifiers or purely learned classifiers .</sentence>
				<definiendum id="0">SRL</definiendum>
				<definiens id="0">a difficult task</definiens>
			</definition>
			<definition id="1">
				<sentence>We encode the constraints as linear inequalities , and use integer linear programming ( ILP ) as an inference procedure to make a final decision that is both consistent with the constraints and most likely according to the learning system .</sentence>
				<definiendum id="0">ILP</definiendum>
				<definiens id="0">an inference procedure to make a final decision that is both consistent with the constraints and most likely according to the learning system</definiens>
			</definition>
			<definition id="2">
				<sentence>Here A0 represents the leaver , A1 represents the thing left , A2 represents the benefactor , AM-LOC is an adjunct indicating the location of the action , and V determines the verb .</sentence>
				<definiendum id="0">A1</definiendum>
				<definiendum id="1">A2</definiendum>
				<definiendum id="2">AM-LOC</definiendum>
				<definiendum id="3">V</definiendum>
				<definiens id="0">an adjunct indicating the location of the action</definiens>
				<definiens id="1">determines the verb</definiens>
			</definition>
			<definition id="3">
				<sentence>SNoW learns a sparse network of linear functions , in which the targets ( argument border predictions or argument type predictions , in this case ) are represented as linear functions over a common feature space .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiens id="0">learns a sparse network of linear functions , in which the targets</definiens>
			</definition>
			<definition id="4">
				<sentence>† Part-of-speech tag ( POS ) feature includes the POS tags of all words in a window of size two .</sentence>
				<definiendum id="0">† Part-of-speech tag</definiendum>
				<definiendum id="1">feature</definiendum>
				<definiens id="0">includes the POS tags of all words in a window of size two</definiens>
			</definition>
			<definition id="5">
				<sentence>† Predicate lemma &amp; POS tag show the lemma form and POS tag of the active predicate .</sentence>
				<definiendum id="0">POS tag</definiendum>
				<definiens id="0">show the lemma form and POS tag of the active predicate</definiens>
			</definition>
</paper>

		<paper id="1124">
			<definition id="0">
				<sentence>2The GENIA Corpus V3.0p consists of 2000 POS-tagged MEDLINE abstracts , V3.01 consists of the same 2000 abstracts annotated semantically with the GENIA ontology , available at http : //www-tsujii.is.s.u-tokyo.ac.jp/GENIA/ .</sentence>
				<definiendum id="0">GENIA Corpus V3.0p</definiendum>
			</definition>
			<definition id="1">
				<sentence>Definition Γ = { S , I , O , F , G , START } , where : • S is the set of automaton states , S = { nextOut , stop , nextIn , head , halt } ; • I is the input set , namely the chunks in both POS tag sequence and lexical sequence ; • O is the output set , namely the MWV candidates , O = { oi|oi is a successful MWV candidate . }</sentence>
				<definiendum id="0">O</definiendum>
				<definiens id="0">the set of automaton states</definiens>
				<definiens id="1">a successful MWV candidate</definiens>
			</definition>
			<definition id="2">
				<sentence>; • F is the set of output controlling functions ; • G is the set of automaton state transition functions ; • START is the initial state of the automaton , START = head .</sentence>
				<definiendum id="0">START</definiendum>
				<definiens id="0">the set of output controlling functions ; • G is the set of automaton state transition functions ; •</definiens>
				<definiens id="1">the initial state of the automaton</definiens>
			</definition>
			<definition id="3">
				<sentence>SEPR where ADJP is an adjective phrase ; ENP is a singular English noun phrase ; ENPS is a plural English noun phrase ; EVP is a singular English verb phrase ; IN is a preposition ; IVP is an infinitive verb phrase ; and , SEPR is a sentence seperator .</sentence>
				<definiendum id="0">ADJP</definiendum>
				<definiendum id="1">ENP</definiendum>
				<definiendum id="2">ENPS</definiendum>
				<definiendum id="3">EVP</definiendum>
				<definiendum id="4">IN</definiendum>
				<definiendum id="5">IVP</definiendum>
				<definiendum id="6">, SEPR</definiendum>
				<definiens id="0">an adjective phrase ;</definiens>
				<definiens id="1">a singular English noun phrase</definiens>
				<definiens id="2">a plural English noun phrase</definiens>
				<definiens id="3">a singular English verb phrase</definiens>
				<definiens id="4">a preposition ;</definiens>
				<definiens id="5">an infinitive verb phrase ; and</definiens>
				<definiens id="6">a sentence seperator</definiens>
			</definition>
			<definition id="4">
				<sentence>In the following equations , X denotes the set of candidates in CP , whose scores of reliability evaluation are greater than t , i.e. , X = { c|c ∈ CP and E ( c ) ≥ t } ; Y denotes the set of candidates in CM , whose scores of reliability evaluation are greater than t , i.e. , Y = { c|c ∈ CM and E ( c ) ≥ t } .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">; Y</definiendum>
				<definiens id="0">the set of candidates in CP , whose scores of reliability evaluation are greater than t , i.e. , X = { c|c ∈ CP and E ( c ) ≥ t }</definiens>
				<definiens id="1">the set of candidates in CM , whose scores of reliability evaluation are greater than t</definiens>
			</definition>
			<definition id="5">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="1057">
			<definition id="0">
				<sentence>One such way is to assume minimum overlap ( the most conservative assumption ) and define the total information in the summary as I ( S ) = X i=1 ; : : : ; m wi ¢maxj f ( tj ; ci ) ( 2 ) An alternative is to consider that f ( tj ; ci ) represents the extent of the [ 0 ; 1 ] interval corresponding to concept ci that tj covers , and assume that the coverage is spread over that interval uniformly and independently across textual units .</sentence>
				<definiendum id="0">m wi ¢maxj f</definiendum>
				<definiendum id="1">ci )</definiendum>
				<definiens id="0">represents the extent of the [ 0 ; 1 ] interval corresponding to concept ci that tj covers , and assume that the coverage is spread over that interval uniformly and independently across textual units</definiens>
			</definition>
			<definition id="1">
				<sentence>However , this can only sensibly happen when additional constraints on the number or length of the selected textual units are introduced ; otherwise , the full set of available textual units would be a solution that proffers a maximal value for equations ( 1 ) – ( 3 ) , i.e. , 8S ‰ T ; I ( S ) • I ( T ) .</sentence>
				<definiendum id="0">I</definiendum>
				<definiens id="0">the number or length of the selected textual units are introduced</definiens>
			</definition>
			<definition id="2">
				<sentence>This collection contains 30 test document sets , each containing approximately 10 news stories on different events ; document sets vary significantly in their internal cohereness .</sentence>
				<definiendum id="0">document</definiendum>
				<definiens id="0">sets vary significantly in their internal cohereness</definiens>
			</definition>
			<definition id="3">
				<sentence>Defscriber : A hybrid system for definitional qa .</sentence>
				<definiendum id="0">Defscriber</definiendum>
				<definiens id="0">A hybrid system for definitional qa</definiens>
			</definition>
			<definition id="4">
				<sentence>Simfinder : A flexible clustering tool for summarization .</sentence>
				<definiendum id="0">Simfinder</definiendum>
				<definiens id="0">A flexible clustering tool for summarization</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>Overall agreement was improved in all classes , except for 2K = P ( A ) P ( E ) =1 P ( E ) , where P ( A ) is the proportion of actual agreements and P ( E ) is the proportion of expected agreement by chance , which depends on the number of relative frequencies of the categories under test .</sentence>
				<definiendum id="0">P ( A )</definiendum>
				<definiens id="0">the proportion of actual agreements and P ( E ) is the proportion of expected agreement by chance , which depends on the number of relative frequencies of the categories under test</definiens>
			</definition>
			<definition id="1">
				<sentence>The denominator is the total proportion less the proportion of chance expectation .</sentence>
				<definiendum id="0">denominator</definiendum>
				<definiens id="0">the total proportion less the proportion of chance expectation</definiens>
			</definition>
			<definition id="2">
				<sentence>reprise ( x ) [ .78 ] This rule states that if x is a sluice construction with lexical head where , and its antecedent utterance ( identi ed with the latest move in the dialogue ) contains the word ‘there’ , then x is a reprise sluice .</sentence>
				<definiendum id="0">reprise ( x</definiendum>
				<definiens id="0">a sluice construction with lexical head where , and its antecedent utterance ( identi ed with the latest move in the dialogue ) contains the word ‘there’</definiens>
			</definition>
			<definition id="3">
				<sentence>We have then used the predicates of these clauses as features to annotate an input dataset , and ran two different machine learning algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based learning system .</sentence>
				<definiendum id="0">TiMBL</definiendum>
				<definiens id="0">a memory-based learning system</definiens>
			</definition>
			<definition id="4">
				<sentence>SCoRE : A tool for searching the BNC .</sentence>
				<definiendum id="0">SCoRE</definiendum>
				<definiens id="0">A tool for searching the BNC</definiens>
			</definition>
</paper>

		<paper id="1059">
			<definition id="0">
				<sentence>Language models ( LM ) are applied in many natural language processing applications , such as speech recognition and machine translation , to encapsulate syntactic , semantic and pragmatic information .</sentence>
				<definiendum id="0">Language models</definiendum>
				<definiens id="0">applied in many natural language processing applications , such as speech recognition and machine translation , to encapsulate syntactic , semantic and pragmatic information</definiens>
			</definition>
			<definition id="1">
				<sentence>The first-best hypothesis is the Viterbi path in the search space returned from the statistical machine translation decoder .</sentence>
				<definiendum id="0">first-best hypothesis</definiendum>
				<definiens id="0">the Viterbi path in the search space returned from the statistical machine translation decoder</definiens>
			</definition>
			<definition id="2">
				<sentence>Ignoring word order , the hypothesis is converted into a bag-of-words representation , which is then used as a query : } | ) , { ( ) , , ( 1211 TiiilT VwfwwwwQ ∈== L where i w is a word in the vocabulary 1T V of the Top1 hypothesis .</sentence>
				<definiendum id="0">i w</definiendum>
				<definiens id="0">a word in the vocabulary 1T V of the Top1 hypothesis</definiens>
			</definition>
			<definition id="3">
				<sentence>| ) , { ( ) , , ; ; , , ( ,2,1 , ,12,11,1 1 TNiii lNNNlTN Vwfw wwwwwwQ N ∈= = LLL where TN V is the combined vocabulary from all nbest hypotheses and i f is the frequency of i w ’s occurrence in the n-best hypothesis list .</sentence>
				<definiendum id="0">TN V</definiendum>
				<definiens id="0">the combined vocabulary from all nbest hypotheses</definiens>
				<definiens id="1">the frequency of i w ’s occurrence in the n-best hypothesis list</definiens>
			</definition>
			<definition id="4">
				<sentence>An example is shown below , where # phrase indicates the use of the ordered distance operator with varying n : # q= # sum ( # wsum ( 2 eu 2 # phrase ( european union ) ) # wsum ( 12 # phrase ( the united states ) 1 american 1 # phrase ( an american ) ) # wsum ( 4 are 1 is ) # wsum ( 8 markets 3 market ) ) # wsum ( 7 # phrase ( the main ) 5 primary ) ) ; Experiments are carried out on a standard statistical machine translation task defined in the NIST evaluation in June 2002 .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">the use of the ordered distance operator with varying n : # q= # sum</definiens>
			</definition>
			<definition id="5">
				<sentence>BLEU : A Method for Automatic Evaluation of Machine Translation .</sentence>
				<definiendum id="0">BLEU</definiendum>
			</definition>
</paper>

		<paper id="1189">
			<definition id="0">
				<sentence>HITIQA is an interactive opendomain question answering technology designed to allow analysts to pose complex exploratory questions in natural language and obtain relevant information units to prepare their briefing reports .</sentence>
				<definiendum id="0">HITIQA</definiendum>
				<definiens id="0">an interactive opendomain question answering technology designed to allow analysts to pose complex exploratory questions in natural language and obtain relevant information units to prepare their briefing reports</definiens>
			</definition>
			<definition id="1">
				<sentence>It has to be noted that determining “relevant” information is not the same as finding an answer ; indeed we can use relatively simple information retrieval methods ( keyword matching , etc. ) to obtain perhaps 200 “relevant” 1 TREC QA is the annual Question Answering evaluation sponsored by the U.S. National Institute of Standards and Technology www.trec.nist.gov documents from a database .</sentence>
				<definiendum id="0">TREC QA</definiendum>
				<definiens id="0">the annual Question Answering evaluation sponsored by the U.S. National Institute of Standards and Technology www.trec.nist.gov documents from a database</definiens>
			</definition>
			<definition id="2">
				<sentence>The framing process imposes a partial structure on the text passages that allows the system to systematically compare different passages against each other and against the question .</sentence>
				<definiendum id="0">framing process</definiendum>
				<definiens id="0">imposes a partial structure on the text passages that allows the system to systematically compare different passages against each other and against the question</definiens>
			</definition>
			<definition id="3">
				<sentence>HITIQA starts text framing by building a general frame on the seed passages of the clusters and any of the top N ( currently N=10 ) scored passages that are not already in a cluster .</sentence>
				<definiendum id="0">HITIQA</definiendum>
				<definiens id="0">starts text framing by building a general frame on the seed passages of the clusters and any of the top N ( currently N=10 ) scored passages that are not already in a cluster</definiens>
			</definition>
			<definition id="4">
				<sentence>The general frame represents an event or a relation involving any number of entities , which make up the frame’s attributes , such as LOCATION , PERSON , ORGANIZATION , DATE , etc .</sentence>
				<definiendum id="0">general frame</definiendum>
				<definiens id="0">represents an event or a relation involving any number of entities</definiens>
			</definition>
			<definition id="5">
				<sentence>Iraq possesses a few working centrifuges and the blueprints to build them .</sentence>
				<definiendum id="0">Iraq</definiendum>
			</definition>
			<definition id="6">
				<sentence>TRF_OBJECT ( WEAPON ) : uranium FIGURE 5 : A typed goal frame from the Iraq question HITIQA automatically judges a particular data frame as relevant , and subsequently the corresponding segment of text as relevant , by comparison to the Goal frame .</sentence>
				<definiendum id="0">TRF_OBJECT</definiendum>
				<definiens id="0">a particular data frame as relevant , and subsequently the corresponding segment of text as relevant , by comparison to the Goal frame</definiens>
			</definition>
			<definition id="7">
				<sentence>The clarification dialogue is when the user and the system negotiate the information task that needs to be performed .</sentence>
				<definiendum id="0">clarification dialogue</definiendum>
				<definiens id="0">needs to be performed</definiens>
			</definition>
			<definition id="8">
				<sentence>Clarification dialogue will be initiated on these , when all of their general attributes agree with the general attributes of the Goal frame respectively .</sentence>
				<definiendum id="0">Clarification dialogue</definiendum>
				<definiens id="0">all of their general attributes agree with the general attributes of the Goal frame respectively</definiens>
			</definition>
			<definition id="9">
				<sentence>Iraq possesses a few working centrifuges and the blueprints to build them .</sentence>
				<definiendum id="0">Iraq</definiendum>
			</definition>
</paper>

		<paper id="1122">
			<definition id="0">
				<sentence>Named Entity recognition is an important task for today’s natural language applications , but it still suffers from data sparseness .</sentence>
				<definiendum id="0">Entity recognition</definiendum>
				<definiens id="0">an important task for today’s natural language applications , but it still suffers from data sparseness</definiens>
			</definition>
			<definition id="1">
				<sentence>Recently , Named Entity ( NE ) recognition has been getting more attention as a basic building block for practical natural language applications .</sentence>
				<definiendum id="0">Named Entity</definiendum>
			</definition>
			<definition id="2">
				<sentence>First , we picked a rare word , then obtained its document frequency which is the number of articles which contain the word .</sentence>
				<definiendum id="0">document frequency</definiendum>
				<definiens id="0">the number of articles which contain the word</definiens>
			</definition>
			<definition id="3">
				<sentence>Now the ranking score sim ( w ) given to a word pair is calculated as follows : sim ( w ) = simAB ( w ) £simBC ( w ) £simAC ( w ) where simXY ( w ) is the similarity of the distributions between two newspapers X and Y , which can be computed with the formula used in the singleword experiment .</sentence>
				<definiendum id="0">ranking score sim</definiendum>
				<definiendum id="1">simXY ( w )</definiendum>
				<definiens id="0">the similarity of the distributions between two newspapers X and Y , which can be computed with the formula used in the singleword experiment</definiens>
			</definition>
			<definition id="4">
				<sentence>Score sykesville LOCATION 4 1.000 khamad PERSON 4 1.000 zhitarenko PERSON 6 1.000 sirica PERSON 9 1.000 energiyas PRODUCT 4 1.000 hulya PERSON 5 1.000 salvis PERSON 5 0.960 geagea PERSON 27 0.956 bogdanor PERSON 6 0.944 gomilevsky PERSON 6 0.939 kulcsar PERSON 15 0.926 carseats noun 17 0.912 wilsons PERSON 32 0.897 yeud ORGANIZATION 10 0.893 yigal PERSON 490 0.878 bushey PERSON 10 0.874 pardew PERSON 17 0.857 yids PERSON 5 0.844 bordon PERSON 113 0.822 ... ... ... ... katyushas PRODUCT 56 0.516 solzhenitsyn PERSON 81 0.490 scheuer PERSON 9 0.478 morgue noun 340 0.456 mudslides noun 151 0.420 rump noun 642 0.417 grandstands noun 42 0.407 overslept verb 51 0.401 lehrmann PERSON 13 0.391 ... ... ... ... willowby PERSON 3 0.000 unknowable adj 48 0.000 taubensee PERSON 22 0.000 similary ( typo ) 3 0.000 recommitment noun 12 0.000 perorations noun 3 0.000 orenk PERSON 2 0.000 malarkey PERSON 34 0.000 gherardo PERSON 5 0.000 dcis ORGANIZATION 3 0.000 ... ... ... ... merritt PERSON 149 -0.054 echelon noun 97 -0.058 plugging verb 265 -0.058 normalcy noun 170 -0.063 lovell PERSON 238 -0.066 provisionally adv 74 -0.068 sails noun 364 -0.075 rekindled verb 292 -0.081 sublime adj 182 -0.090 afflicts verb 168 -0.116 stan PERSON 994 -0.132 Table 1 : Ranking Result ( Single-word ) 0 1 0 0.2 0.4 0.6 0.8 Likelihood Score Figure 2 : Relationship of the score and the likelihood of being a Named Entity ( Single-word ) .</sentence>
				<definiendum id="0">Ranking Result</definiendum>
			</definition>
			<definition id="5">
				<sentence>Score carseats noun 17 0.9121 tiremaker noun 21 0.8766 officeholders noun 101 0.8053 neurotrophic adj 11 0.7850 mishandle verb 12 0.7369 Table 2 : Errors ( Single-word ) Words NEs All words 966 462 ( 48 % ) sim ( w ) ‚ 0:6 102 92 ( 90 % ) sim ( w ) • 0 511 255 ( 50 % ) Table 3 : Obtained NEs ( Single-word ) Word pairs NEs All word pairs 810 60 ( 7 % ) sim ( w ) ‚ 0:05 27 11 ( 41 % ) sim ( w ) • 0 658 30 ( 5 % ) Table 4 : Obtained NEs ( Multi-word ) repetition of articles .</sentence>
				<definiendum id="0">Errors</definiendum>
				<definiendum id="1">Obtained NEs</definiendum>
				<definiens id="0">Obtained NEs ( Multi-word ) repetition of articles</definiens>
			</definition>
			<definition id="6">
				<sentence>This research was supported in part by the Defense Advanced Research Projects Agency as part of the Translingual Information Detection , Extraction and Summarization ( TIDES ) program , under Grant N66001-001-1-8917 from the Space and Naval Warfare Systems Center , San Diego , and by the National Science Foundation under Grant ITS00325657 .</sentence>
				<definiendum id="0">Extraction</definiendum>
				<definiens id="0">supported in part by the Defense Advanced Research Projects Agency as part of the Translingual Information Detection</definiens>
			</definition>
</paper>

		<paper id="1072">
			<definition id="0">
				<sentence>We propose using LCS-based F-measure to estimate the similarity between two translations X of length m and Y of length n , assuming X is a reference translation and Y is a candidate translation , as follows : R lcs m YXLCS ) , ( = ( 1 ) P lcs n YXLCS ) , ( = ( 2 ) F lcs lcslcs lcslcs PR PR 2 2 ) 1 ( β β + + = ( 3 ) Where LCS ( X , Y ) is the length of a longest common subsequence of X and Y , and β = P lcs /R lcs when ∂F lcs /∂R lcs _=_∂F lcs /∂P lcs .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiendum id="2">LCS</definiendum>
				<definiendum id="3">Y )</definiendum>
				<definiens id="0">a candidate translation</definiens>
				<definiens id="1">the length of a longest common subsequence of X and Y , and β</definiens>
			</definition>
			<definition id="1">
				<sentence>Notice that ROUGE-L is 1 when X = Y since LCS ( X , Y ) = m or n ; while ROUGE-L is zero when LCS ( X , Y ) = 0 , i.e. there is nothing in common between X and Y. One advantage of using LCS is that it does not require consecutive matches but in-sequence matches that reflect sentence level word order as ngrams .</sentence>
				<definiendum id="0">ROUGE-L</definiendum>
				<definiendum id="1">ROUGE-L</definiendum>
				<definiens id="0">that it does not require consecutive matches but in-sequence matches that reflect sentence level word order as ngrams</definiens>
			</definition>
			<definition id="2">
				<sentence>Given two sentences X and Y , the recurrent relations can be written as follows : ( 1 ) If x i = y j Then // the length of consecutive matches at // position i-1 and j-1 k = w ( i-1 , j-1 ) c ( i , j ) = c ( i-1 , j-1 ) + f ( k+1 ) – f ( k ) // remember the length of consecutive // matches at position i , j w ( i , j ) = k+1 ( 2 ) Otherwise If c ( i-1 , j ) &gt; c ( i , j-1 ) Then c ( i , j ) = c ( i-1 , j ) w ( i , j ) = 0 // no match at i , j Else c ( i , j ) = c ( i , j-1 ) w ( i , j ) = 0 // no match at i , j ( 3 ) WLCS ( X , Y ) = c ( m , n ) Where c is the dynamic programming table , 0 &lt; = i &lt; = m , 0 &lt; = j &lt; = n , w is the table storing the length of consecutive matches ended at c table position i and j , and f is a function of consecutive matches at the table position , c ( i , j ) .</sentence>
				<definiendum id="0">c</definiendum>
				<definiendum id="1">w</definiendum>
				<definiendum id="2">f</definiendum>
				<definiens id="0">y j Then // the length of consecutive matches at // position i-1 and j-1 k</definiens>
				<definiens id="1">the table storing the length of consecutive matches ended at c table position i and j , and</definiens>
				<definiens id="2">a function of consecutive matches at the table position</definiens>
			</definition>
			<definition id="3">
				<sentence>Statistics Skip-bigram is any pair of words in their sentence order , allowing for arbitrary gaps .</sentence>
				<definiendum id="0">Statistics Skip-bigram</definiendum>
				<definiens id="0">any pair of words in their sentence order , allowing for arbitrary gaps</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , S1 has the following skip-bigrams : ( “police killed” , “police the” , “police gunman” , “killed the” , “killed gunman” , “the gunman” ) Given translations X of length m and Y of length n , assuming X is a reference translation and Y is a candidate translation , we compute skip-bigrambased F-measure as follows : R skip2 ) 2 , ( ) , ( 2 mC YXSKIP = ( 7 ) P skip2 ) 2 , ( ) , ( 2 nC YXSKIP = ( 8 ) F skip2 2 2 2 22 2 ) 1 ( skipskip skipskip PR PR β β + + = ( 9 ) Where SKIP2 ( X , Y ) is the number of skip-bigram matches between X and Y , β = P skip2 /R skip2 when ∂F skip2 /∂R skip2 _=_∂F skip2 /∂P skip2 , and C is the combination function .</sentence>
				<definiendum id="0">S1</definiendum>
				<definiendum id="1">X</definiendum>
				<definiendum id="2">Y</definiendum>
				<definiendum id="3">SKIP2 ( X , Y )</definiendum>
				<definiendum id="4">C</definiendum>
				<definiens id="0">a candidate translation , we compute skip-bigrambased F-measure as follows : R skip2</definiens>
				<definiens id="1">the number of skip-bigram matches between X</definiens>
			</definition>
			<definition id="5">
				<sentence>AlTemp generates less than 1024 alternative translations for 6 out of the 878 source 3 Linguistic Data Consortium prepared these manual translations as part of the DARPA’s TIDES project .</sentence>
				<definiendum id="0">AlTemp</definiendum>
				<definiens id="0">generates less than 1024 alternative translations for 6 out of the 878 source 3 Linguistic Data Consortium prepared these manual translations as part of the DARPA’s TIDES project</definiens>
			</definition>
			<definition id="6">
				<sentence>ROUGE-S4 ( dark/green cell ) is the best with an ORANGE score of 19.66 % that is statistically equivalent to ROUGE-L and ROUGEW-1.1 ( gray cells ) and is significantly better than BLEUS6 , NIST , PER , and WER .</sentence>
				<definiendum id="0">ROUGE-S4 ( dark/green cell )</definiendum>
			</definition>
			<definition id="7">
				<sentence>AAAAAAAAAAA http : //www.nist.gov/speech/tests/mt/doc Franz Josef Och .</sentence>
				<definiendum id="0">AAAAAAAAAAA http</definiendum>
				<definiens id="0">//www.nist.gov/speech/tests/mt/doc Franz Josef Och</definiens>
			</definition>
			<definition id="8">
				<sentence>Bleu : a Method for Automatic Evaluation of Machine Translation .</sentence>
				<definiendum id="0">Bleu</definiendum>
			</definition>
</paper>

		<paper id="1136">
			<definition id="0">
				<sentence>Candidates can then be selected in one of two ways : ( i ) by comparison with a pre-defined threshold γ ∈ R ( i.e. x is accepted iff g ( x ) ≥ γ ) , resulting in a γ-acceptance set ; ( ii ) by ranking the entire candidate set according to the scores g ( x ) and selecting the n highestscoring candidates , resulting in an n-best list ( where n is either determined by practical constraints or interactively by manual inspection ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">selected in one of two ways : ( i ) by comparison with a pre-defined threshold γ ∈ R ( i.e. x is accepted iff g ( x ) ≥ γ ) , resulting in a γ-acceptance set</definiens>
			</definition>
			<definition id="1">
				<sentence>Following the methodology described by Evert and Krenn ( 2001 ) , German PP-verb combinations were extracted from a chunk-parsed version of the Frankfurter Rundschau Corpus.3 A cooccurrence frequency threshold of 2Namely , Π = nTP · R/n , where nTP stands for the total number of TPs in the candidate set .</sentence>
				<definiendum id="0">nTP</definiendum>
				<definiens id="0">the total number of TPs in the candidate set</definiens>
			</definition>
			<definition id="2">
				<sentence>3The Frankfurter Rundschau Corpus is a German newspaper corpus , comprising ca .</sentence>
				<definiendum id="0">Frankfurter Rundschau Corpus</definiendum>
				<definiens id="0">a German newspaper corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>Each candidate can therefore be represented by its feature vector x ∈ Ω , where Ω is an abstract feature space .</sentence>
				<definiendum id="0">Ω</definiendum>
				<definiens id="0">an abstract feature space</definiens>
			</definition>
			<definition id="4">
				<sentence>First , while ΠA is an unbiased estimator for pia , the variance σ2A can not be estimated from a single experiment.10 Second , ΠA is a discrete variable because both TA and NA are non-negative integers .</sentence>
				<definiendum id="0">ΠA</definiendum>
				<definiens id="0">an unbiased estimator for pia</definiens>
				<definiens id="1">a discrete variable because both TA and NA are non-negative integers</definiens>
			</definition>
			<definition id="5">
				<sentence>Consequently , P ( TA|NA ) should follow a binomial distribution with success probability piA , i.e. P ( TA = k|NA ) =parenleftbigg NA k parenrightbigg · ( piA ) k · ( 1−piA ) NA−k ( 2 ) for k = 0 , ... , NA .</sentence>
				<definiendum id="0">P ( TA|NA</definiendum>
			</definition>
			<definition id="6">
				<sentence>There is much confusion about their validity , though , mainly due to 15The agreement is confirmed by the Kolmogorov test of goodness-of-fit , which does not reject the theoretical model ( 4 ) in either case .</sentence>
				<definiendum id="0">goodness-of-fit</definiendum>
				<definiens id="0">does not reject the theoretical model ( 4 ) in either case</definiens>
			</definition>
			<definition id="7">
				<sentence>R : A language and environment for statistical computing .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">A language and environment for statistical computing</definiens>
			</definition>
</paper>

		<paper id="1081">
			<definition id="0">
				<sentence>; ( 1 ) where Zx is the per-input normalization that makes the probability of all state sequences sum to one ; fk ( yt¡1 ; yt ; x ; t ) is a feature function which is often binary-valued , but can be real-valued , and ‚k is a learned weight associated with feature fk .</sentence>
				<definiendum id="0">Zx</definiendum>
				<definiendum id="1">‚k</definiendum>
				<definiens id="0">the per-input normalization that makes the probability of all state sequences sum to one</definiens>
				<definiens id="1">a feature function which is often binary-valued , but can be real-valued</definiens>
				<definiens id="2">a learned weight associated with feature fk</definiens>
			</definition>
			<definition id="1">
				<sentence>The discounted value is set to be ‚k dck=Me£ 2 where ck is the count of features , M is the bin size set by held out validation , and dae is the ceiling function .</sentence>
				<definiendum id="0">ck</definiendum>
				<definiendum id="1">M</definiendum>
				<definiendum id="2">dae</definiendum>
				<definiens id="0">the count of features</definiens>
			</definition>
			<definition id="2">
				<sentence>In order to increase recall of new words , we consider not only the most likely ( Viterbi ) segmentation , but the segmentations in the top N most likely segmentations ( an N-best list ) , and detect new words according to the above criteria in all N segmentations .</sentence>
				<definiendum id="0">N most likely segmentations</definiendum>
				<definiens id="0">an N-best list</definiens>
			</definition>
			<definition id="3">
				<sentence>Column SITE-AVG is the average F1 performance over the datasets on which a site reported results .</sentence>
				<definiendum id="0">Column SITE-AVG</definiendum>
				<definiens id="0">the average F1 performance over the datasets on which a site reported results</definiens>
			</definition>
			<definition id="4">
				<sentence>Column OUR-AVG is the average F1 performance of our system over the same datasets .</sentence>
				<definiendum id="0">Column OUR-AVG</definiendum>
				<definiens id="0">the average F1 performance of our system over the same datasets</definiens>
			</definition>
			<definition id="5">
				<sentence>S01 is one of the best segmentation systems in mainland China ( Zhang et al. , 2003 ) .</sentence>
				<definiendum id="0">S01</definiendum>
			</definition>
			<definition id="6">
				<sentence>Chinese Lexical Analysis Using Hierarchical Hidden Markov Model .</sentence>
				<definiendum id="0">Chinese Lexical Analysis</definiendum>
				<definiens id="0">Using Hierarchical Hidden Markov Model</definiens>
			</definition>
</paper>

		<paper id="1119">
			<definition id="0">
				<sentence>Back transliteration is the process of restoring transliterated words to the original English words .</sentence>
				<definiendum id="0">Back transliteration</definiendum>
				<definiens id="0">the process of restoring transliterated words to the original English words</definiens>
			</definition>
			<definition id="1">
				<sentence>{ } EL denotes the lattice of all eu 's corresponding to ku 's covering a Japanese word .</sentence>
				<definiendum id="0">EL</definiendum>
				<definiens id="0">the lattice of all eu 's corresponding to ku 's covering a Japanese word</definiens>
			</definition>
			<definition id="2">
				<sentence>ˆ argmax ( ) ( | ) ( | ( | ) d np np dd dd d np np np np P P PP ++ + ++ + ⎧ ⎨ ⎩ ⎫ ⎬ ⎭ = × × ∑∑ E eu ku EE Kku ku eu eu E ( 2.9 ) ( ) 1 0 ( | ) d np P + Kku is 1 when the string of K and ( ) 1 0 d np + ku is the same , and the strings of the ( ) 1 0 d np + ku of all paths in the lattice and the string of the K is the same .</sentence>
				<definiendum id="0">ku</definiendum>
				<definiendum id="1">K</definiendum>
				<definiens id="0">1 when the string of K and ( ) 1 0 d np +</definiens>
				<definiens id="1">the ( ) 1 0 d np + ku of all paths in the lattice and the string of the</definiens>
				<definiens id="2">the same</definiens>
			</definition>
			<definition id="3">
				<sentence>( ) 1 ( ) 1 00 ( ) 1 ( ) 11 00 1 ( | ( | , ) dd d d np np np npi i i P P ++ + +− = = ∏ ku eu ku ku eu ( ) 1 ( ) 1 ( ) ( ) 1 1 ( | , , ) d np start i istartib iendi i Pe + − −+ = ≈ ∏ ku eu ( 2.12 ) where start ( i ) is the first position of the i-th character unit eu i , while end ( i ) is the last position of the i-th character unit eu i ; and b is a constant .</sentence>
				<definiendum id="0">start ( i )</definiendum>
				<definiendum id="1">b</definiendum>
				<definiens id="0">the first position of the i-th character unit eu i</definiens>
				<definiens id="1">the last position of the i-th character unit eu i</definiens>
			</definition>
			<definition id="4">
				<sentence>The feature functions consist of the letter combinations that meet the combinations of the letter positions and are observed at least once in the learning data .</sentence>
				<definiendum id="0">feature functions</definiendum>
			</definition>
			<definition id="5">
				<sentence>Japanese katakana ( romanized katakana ) Created English アシュクロフト ( a shu ku ro fu to ) Ashcroft キルシュシュタイン ( ki ru shu shu ta i n ) Kirschstein スペンサー ( su pe n sa - ) Spencer パウエル ( pa u e ru ) Powell プリンシピ ( pu ri n shi pi ) Principi Table 2 : Example of English words produced .</sentence>
				<definiendum id="0">Japanese katakana</definiendum>
				<definiens id="0">a shu ku ro fu to ) Ashcroft キルシュシュタイン ( ki ru shu shu ta i n ) Kirschstein スペンサー ( su pe n sa - ) Spencer パウエル ( pa u e ru ) Powell プリンシピ ( pu ri n shi pi</definiens>
			</definition>
</paper>

		<paper id="1049">
			<definition id="0">
				<sentence>At the end of the turn , Luigi asks the player whether he wants to play again .</sentence>
				<definiendum id="0">Luigi</definiendum>
				<definiens id="0">asks the player whether he wants to play again</definiens>
			</definition>
			<definition id="1">
				<sentence>rob ( Luigi moves the cups/shells ) rob “So , where is the coin ?</sentence>
				<definiendum id="0">Luigi</definiendum>
				<definiens id="0">moves the cups/shells</definiens>
			</definition>
</paper>

		<paper id="1101">
			<definition id="0">
				<sentence>Whilst , a durative event , e.g. , 盖楼 ( built a house ) , is more complex and its accomplishment as a whole involves a process spreading in time .</sentence>
				<definiendum id="0">Whilst</definiendum>
				<definiens id="0">built a house ) , is more complex and its accomplishment as a whole involves a process spreading in time</definiens>
			</definition>
			<definition id="1">
				<sentence>Passonneau ( Passonneau , 1988 ) , Brent ( Brent , 1990 and Sing ( Sing , 1997 ) determined intra-sentential relations by accounting for temporal or causal connectives .</sentence>
				<definiendum id="0">Passonneau</definiendum>
				<definiens id="0">determined intra-sentential relations by accounting for temporal or causal connectives</definiens>
			</definition>
			<definition id="2">
				<sentence>Webber ( Webber , 1988 ) improved upon the above work by specifying rules for how events are related to one another in a discourse and Sing and Sing defined semantic constraints through which events can be related ( Sing , 1997 ) .</sentence>
				<definiendum id="0">Webber</definiendum>
			</definition>
			<definition id="3">
				<sentence>Its predictive performance is competitive with state-of-theLinguistic Feature Symbol POS Tag Effect Example With/Without punctuations PT Not Applicable Not Applicable Not Applicable Speech verbs VS TI_vs Tense 报告 , 表示 , 称 Trend verbs TR TI_tr Aspect 起来 , 下去 Preposition words P TI_p Discourse Structure/Aspect 当 , 到 , 继 Position words PS TI_f Discourse Structure 底 , 后 , 开始 Verbs with verb objects VV TI_vv Tense/Aspect 继续 , 进行 , 续 Verbs expressing wish/hope VA TI_va Tense 必须 , 会 , 可 Verbs related to causality VC TI_vc Discourse Structure 导致 , 致使 , 引起 Conjunctive words C TI_c Discourse Structure 并 , 并且 , 不过 Auxiliary words U TI_u Aspect 着 , 了 , 过 Time words T TI_t Tense 过去 , 今后 , 今年 Adverbs D TI_d Tense/Aspect/Discourse Structure 便 , 并 , 并未 , 不 Event class EC E0/E1/E2/E3 Event Classification State , Punctual Event , Developing Event , Process Table 1 Linguistic features : eleven temporal indicators and one event class art classifiers , such as C4.5 and SVM ( Friedman , 1997 ) .</sentence>
				<definiendum id="0">不 Event class EC E0/E1/E2/E3 Event Classification</definiendum>
				<definiens id="0">punctuations PT Not Applicable Not Applicable Not Applicable Speech verbs VS TI_vs Tense 报告 , 表示 , 称 Trend verbs TR TI_tr Aspect 起来</definiens>
			</definition>
			<definition id="4">
				<sentence>Then x is classified as :         = ) , ... , , , ,| ( ) , ... , , , ,| ( logmaxarg 2121 2121* n n c ttteecP ttteecP c ( E1 ) where c denotes the classes different from c .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">        = ) , ... , , , ,| ( ) , ... , , , ,| ( logmaxarg 2121 2121* n n c ttteecP ttteecP c ( E1 ) where</definiens>
			</definition>
			<definition id="5">
				<sentence>Thus , we rewrite ) | , ... , ( 21 ctttP n as , , ... , ( 1 111 n ttP ) | , ... , , ... , , , ... , 432 441331221 ctttttt nnn , where j n is the total number of the temporal indicators occurring in the position j .</sentence>
				<definiendum id="0">j n</definiendum>
				<definiens id="0">1 111 n ttP ) | , ... , , ... , , , ... , 432 441331221 ctttttt nnn</definiens>
				<definiens id="1">the total number of the temporal indicators occurring in the position j</definiens>
			</definition>
			<definition id="6">
				<sentence>Accuracy Accuracy Feature Close test Open test 1 Open test 2 Feature Close test Open test 1 Open test 2 VS 53.4 % 48 % 30 % VA 57 % 50 % 37 % VC 56.6 % 56 % 49 % C 62.6 % 52 % 45 % TR 50.2 % 46 % 28 % U 51.8 % 50 % 32 % P 52.4 % 49 % 30 % T 57.2 % 48 % 32 % PS 59 % 53 % 38 % D 59.6 % 55 % 47 % VV 51 % 49 % 29 % EC 72.4 % 69 % 68 % Table 2 Impact of each individual linguistic feature 20 % 30 % 40 % 50 % 60 % 70 % 80 % 90 % Close Test Open Test1 Open Test2 Ac c u r a c y DM UG GFG SRG Figure 2 Comparing DM , UG , GFG and SRG models When the temporal indicators are classified into two groups based on their semantic roles in SRG model , there are three types of linguistic features used in the Bayesian Classifier , i.e. , tense/aspect markers , connective words and event classes .</sentence>
				<definiendum id="0">SRG models</definiendum>
				<definiens id="0">When the temporal indicators are classified into two groups based on their semantic roles in SRG model</definiens>
				<definiens id="1">features used in the Bayesian Classifier , i.e. , tense/aspect markers , connective words and event classes</definiens>
			</definition>
			<definition id="7">
				<sentence>Then the Weighted Bayesian Classifier is :         ) , ... , , , ,| ( ) , ... , , , ,| ( log 2121 2121 n n ttteecP ttteecP         +         = ) | , ( ) | , ( log ) ( ) ( log 21 21 1 ceeP ceeP cP cP λ ( E9 )         +         + ) | , ... , , ( ) | , ... , , ( log ) | , ... , , ( ) | , ... , , ( log 22 2 2 1 22 2 2 1 3 11 2 1 1 11 2 1 1 2 ctttP ctttP ctttP ctttP l l m m λλ In order to estimate the weights , we need a suitable optimization approach to search for the optimal value of ] , , [ 321 λλλ automatically .</sentence>
				<definiendum id="0">Weighted Bayesian Classifier</definiendum>
				<definiens id="0">        +         + ) | , ... , , ( ) | , ... , , ( log ) | , ... , , ( ) | , ... ,</definiens>
			</definition>
			<definition id="8">
				<sentence>Decision Lists for Lexical Ambiguity Resolution : Application to the Accent Restoration in Spanish and French .</sentence>
				<definiendum id="0">Decision Lists for Lexical Ambiguity Resolution</definiendum>
			</definition>
</paper>

		<paper id="1042">
</paper>

		<paper id="1167">
			<definition id="0">
				<sentence>Statistical language models consist of estimating the probability distributions of a word given the history of words so far used .</sentence>
				<definiendum id="0">Statistical language models</definiendum>
				<definiens id="0">consist of estimating the probability distributions of a word given the history of words so far used</definiens>
			</definition>
			<definition id="1">
				<sentence>LSA uses worddocument co-occurrence statistics and a matrix factorization technique called singular value decomposition to derive semantic similarity measure between any two text units words or documents .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">uses worddocument co-occurrence statistics and a matrix factorization technique called singular value decomposition to derive semantic similarity measure between any two text units words or documents</definiens>
			</definition>
			<definition id="2">
				<sentence>Latent semantic analysis ( LSA ) is a statistical , algebraic technique for extracting and inferring relations of expected contextual usage of words in documents ( Landauer et al. , 1998 ) .</sentence>
				<definiendum id="0">Latent semantic analysis</definiendum>
				<definiendum id="1">LSA</definiendum>
			</definition>
			<definition id="3">
				<sentence>If the vocabulary V consists of I words , tagset T consists of J tags and the number of documents in corpus is K , then the matrix will be IJ × K. Let ci j , k denote the frequency of word wi with tag tj in the document dk .</sentence>
				<definiendum id="0">V</definiendum>
			</definition>
			<definition id="4">
				<sentence>Here probability of a sequence Wn of n words is given by P ( Wn ) = summationdisplay t1 ... summationdisplay tn nproductdisplay q=1 P ( wq|tq , Wq−1 , Tq−1 ) P ( tq|Wq−1 , Tq−1 ) ( 5 ) where ti is a tag variable for the word wi .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiens id="0">a tag variable for the word wi</definiens>
			</definition>
			<definition id="5">
				<sentence>Supertags are the elementary structures of Lexicalized Tree Adjoining Grammars ( LTAGs ) ( Bangalore and Joshi , 1999 ) .</sentence>
				<definiendum id="0">Supertags</definiendum>
			</definition>
			<definition id="6">
				<sentence>Generally a list of vocabulary consists of a few hundred function words and a few tens of thousands of content words .</sentence>
				<definiendum id="0">list of vocabulary</definiendum>
			</definition>
			<definition id="7">
				<sentence>A commonly used quality measure for a given model M is related to the entropy of the underlying source and is known as perplexity ( PPL ) .</sentence>
				<definiendum id="0">commonly used quality measure for a given model M</definiendum>
				<definiens id="0">related to the entropy of the underlying source and is known as perplexity ( PPL )</definiens>
			</definition>
			<definition id="8">
				<sentence>Given a word sequence w1 , w2 , ... , wN to be used as a test corpus , the perplexity of a language model M is given by : PPL =exp  − 1N Nsummationdisplay q=1 logP ( M ) ( wq|Wq−1 )   ( 17 ) Perplexity also indicates the ( geometric ) average branching factor of the language according to the modelM and thus indicates the difficulty of a speech recognition task ( Jelinek , 1999 ) .</sentence>
				<definiendum id="0">w2 , ... , wN</definiendum>
				<definiens id="0">a test corpus , the perplexity of a language model M is given by</definiens>
			</definition>
			<definition id="9">
				<sentence>Thus the SVD plays a role in deciphering the syntactic-semantically important dimensions of the information space .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">plays a role in deciphering the syntactic-semantically important dimensions of the information space</definiens>
			</definition>
			<definition id="10">
				<sentence>The superARV language model : Investigating the effectiveness of tightly integrating multiple knowledge sources .</sentence>
				<definiendum id="0">superARV language model</definiendum>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>Parser configurations are represented by triples 〈S , I , A〉 , where S is the stack ( represented as a list ) , I is the list of ( remaining ) input tokens , and A is the ( current ) arc relation for the dependency graph .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">the stack ( represented as a list</definiens>
			</definition>
			<definition id="1">
				<sentence>The function we want to approximate is a mapping f from configurations to parser actions , where each action consists of a transition and ( except for Shift and Reduce ) a dependency type : f : Config → { LA , RA , RE , SH } × ( R ∪ { nil } ) Here Config is the set of all configurations and R is the set of dependency types .</sentence>
				<definiendum id="0">Config</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a mapping f from configurations to parser actions , where each action consists of a transition and ( except for Shift and Reduce ) a dependency type : f : Config → { LA , RA , RE , SH } × ( R ∪ { nil } ) Here</definiens>
				<definiens id="1">the set of all configurations and</definiens>
			</definition>
</paper>

		<paper id="1091">
			<definition id="0">
				<sentence>The decoding problem in Statistical Machine Translation ( SMT ) is a computationally hard combinatorial optimization problem .</sentence>
				<definiendum id="0">SMT )</definiendum>
				<definiens id="0">a computationally hard combinatorial optimization problem</definiens>
			</definition>
			<definition id="1">
				<sentence>( 2 ) Even when the translation model Pr ( f|e ) is as simple as IBM Model 1 and the language model Pr ( e ) is a bigram language model , the decoding problem is NP-hard ( Knight , 1999 ) .</sentence>
				<definiendum id="0">NP-hard</definiendum>
				<definiens id="0">a bigram language model</definiens>
			</definition>
			<definition id="2">
				<sentence>NaiveDecode is a linear time decoding algorithm that computes a suboptimal solution for RELAXED DECODING while NaiveOptimalDecode is an exponential time algorithm that computes the optimal solution .</sentence>
				<definiendum id="0">NaiveDecode</definiendum>
				<definiens id="0">a linear time decoding algorithm that computes a suboptimal solution for RELAXED DECODING while NaiveOptimalDecode is an exponential time algorithm that computes the optimal solution</definiens>
			</definition>
			<definition id="3">
				<sentence>There are 3m/2 candidate sentence lengths for the translation ( l varies from m/2 to 2m ) and both NaiveDecode and Viterbi are O ( m ) .</sentence>
				<definiendum id="0">NaiveDecode</definiendum>
				<definiens id="0">the translation ( l varies from m/2 to 2m ) and both</definiens>
			</definition>
			<definition id="4">
				<sentence>As a consequence , we can write Pr ( f , ˜a|e ) Pr ( e ) as : Pr ( f , ˜a|e ) Pr ( e ) = ξλ lproductdisplay i=1 TiDiNiLi where Li = trigram ( ei|ei−2 , ei−1 ) and λ is the trigram probability of the boundary word .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiens id="0">e ) as : Pr ( f , ˜a|e ) Pr ( e ) = ξλ lproductdisplay i=1 TiDiNiLi where Li = trigram ( ei|ei−2 , ei−1</definiens>
				<definiens id="1">the trigram probability of the boundary word</definiens>
			</definition>
			<definition id="5">
				<sentence>n ( φi|ei ) Table 2 : Pr ( f , ˜a|e ) for IBM Models was not only to evaluate the performance of our algorithms on real data , but also to evaluate how easy it is to code the algorithm and whether a straightforward implementation of the algorithm with no parameter tuning can give satisfactory results .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">algorithms on real data , but also to evaluate how easy it is to code the algorithm and whether a straightforward implementation of the algorithm with no parameter tuning can give satisfactory results</definiens>
			</definition>
</paper>

		<paper id="1180">
			<definition id="0">
				<sentence>Second , CCG is a lexicalised grammar , and only uses a small number of semantically transparent combinatory rules to combine CCG categories .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiens id="0">a lexicalised grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>Type-raising is applied to the categories NP , PP and Sa0 adja1a3a2 NP ( adjectival phrase ) , and is implemented by adding the relevant set of type-raised categories to the chart whenever an NP , PP or Sa0 adja1a3a2 NP is present .</sentence>
				<definiendum id="0">Type-raising</definiendum>
				<definiens id="0">adjectival phrase ) , and is implemented by adding the relevant set of type-raised categories to the chart whenever an NP , PP or Sa0 adja1a3a2 NP is present</definiens>
			</definition>
			<definition id="2">
				<sentence>a7 x ( spokesman ( x ) a8 ( p @ x ) ) where the @ denotes functional application , and the variable p marks the missing information provided by the verb phrase .</sentence>
				<definiendum id="0">a7 x ( spokesman</definiendum>
				<definiens id="0">functional application , and the variable p marks the missing information provided by the verb phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>β-conversion is the process of eliminating all occurrences of functional application by substituting the argument for the λ-bound variables in the functor .</sentence>
				<definiendum id="0">β-conversion</definiendum>
				<definiens id="0">the process of eliminating all occurrences of functional application by substituting the argument for the λ-bound variables in the functor</definiens>
			</definition>
			<definition id="4">
				<sentence>Given bapp ( ’S [ dcl ] ’ , bapp ( ’NP’ , fapp ( ’NP [ nb ] ’ , leaf ( ’NP [ nb ] /N’ , ’the’ ) , fapp ( ’N’ , leaf ( ’N/N’ , school-board’ ) , leaf ( ’N’ , ’hearing’ ) ) ) , fapp ( ’NP\NP’ , bapp ( ’ ( NP\NP ) /S [ dcl ] ’ , leaf ( ’ ( NP\NP ) /NP’ , ’at’ ) , leaf ( ’ ( ( NP\NP ) /S [ dcl ] ) \ ( ( NP\NP ) /NP ) ’ , ’which’ ) ) , bapp ( ’S [ dcl ] ’ , leaf ( ’NP’ , ’she’ ) , fapp ( ’S [ dcl ] \NP’ , leaf ( ’ ( S [ dcl ] \NP ) / ( S [ pss ] \NP ) ’ , ’was’ ) , leaf ( ’S [ pss ] \NP’ , ’dismissed’ ) ) ) ) , fapp ( ’S [ dcl ] \NP’ , leaf ( ’ ( S [ dcl ] \NP ) / ( S [ pss ] \NP ) ’ , ’was’ ) , fapp ( ’S [ pss ] \NP’ , leaf ( ’ ( S [ pss ] \NP ) /PP’ , ’crowded’ ) , fapp ( ’PP’ , leaf ( ’PP/NP’ , ’with’ ) , bapp ( ’NP’ , lex ( ’NP’ , leaf ( ’N’ , ’students’ ) ) , conj ( ’conj’ , ’NP’ , ’NP\NP’ , leaf ( ’conj’ , ’and’ ) , lex ( ’NP’ , leaf ( ’N’ , ’teachers’ ) ) ) ) ) ) ) ) .</sentence>
				<definiendum id="0">bapp</definiendum>
				<definiendum id="1">leaf</definiendum>
				<definiens id="0">NP\NP ) /S [ dcl ] ) \ ( ( NP\NP ) /NP ) ’ , ’which’ )</definiens>
				<definiens id="1">\NP’ , ’dismissed’ ) ) ) ) , fapp ( ’S [ dcl ] \NP’ , leaf ( ’ ( S [ dcl ] \NP ) / ( S [ pss ] \NP ) ’</definiens>
			</definition>
</paper>

		<paper id="1048">
			<definition id="0">
				<sentence>The sentence-level discourse parser uses syntactic information and cue phrases to segment sentences into elementary discourse units and to generate discourse structures of sentences .</sentence>
				<definiendum id="0">sentence-level discourse parser</definiendum>
				<definiens id="0">uses syntactic information and cue phrases to segment sentences into elementary discourse units and to generate discourse structures of sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>The purpose of discourse segmentation is to split a text into elementary discourse units ( edus ) 1 .</sentence>
				<definiendum id="0">discourse segmentation</definiendum>
				<definiens id="0">to split a text into elementary discourse units ( edus ) 1</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , the sentence “Mr. Silas Cathcart built a shopping mall on some land he owns” maps with the segmentation rule ( NP|NP-SBJ &lt; text1 &gt; ( SBAR|RRC &lt; text2 &gt; ) ) In which , NP , SBJ , SBAR , and RRC stand for noun phrase , subject , subordinate clause , and reduce relative clause respectively .</sentence>
				<definiendum id="0">segmentation rule</definiendum>
				<definiens id="0">SBAR|RRC &lt; text2 &gt; ) ) In which , NP , SBJ , SBAR , and RRC stand for noun phrase , subject , subordinate clause</definiens>
			</definition>
			<definition id="3">
				<sentence>As sub-trees corresponding to contiguous text spans are grouped together to form bigger trees , Subtrees contains fewer and fewer members .</sentence>
				<definiendum id="0">Subtrees</definiendum>
				<definiens id="0">contains fewer and fewer members</definiens>
			</definition>
			<definition id="4">
				<sentence>• If two sub-trees are in different paragraphs , the block-level-score of their parent tree is equal to -1000 * ( Li-L0 ) , in which L0 is the paragraph level , Li is the lowest block level that two sub-trees are in the same unit .</sentence>
				<definiendum id="0">Li</definiendum>
				<definiens id="0">in which L0 is the paragraph level</definiens>
			</definition>
			<definition id="5">
				<sentence>In order to evaluate the system , a set of 22 discourse relations ( list , sequence , condition , otherwise , hypothetical , antithesis , contrast , concession , cause , result , causeresult , purpose , solutionhood , circumstance , manner , means , interpretation , evaluation , summary , elaboration , explanation , and joint ) was used.4 The difference among cause , result and cause-result is the nuclearity role of text spans .</sentence>
				<definiendum id="0">cause-result</definiendum>
				<definiens id="0">hypothetical , antithesis , contrast , concession , cause , result , causeresult , purpose , solutionhood , circumstance , manner , means , interpretation , evaluation , summary , elaboration , explanation</definiens>
			</definition>
			<definition id="6">
				<sentence>SPADE includes two probabilistic models that can be used to identify edus and build sentence-level discourse parse trees .</sentence>
				<definiendum id="0">SPADE</definiendum>
				<definiens id="0">includes two probabilistic models that can be used to identify edus and build sentence-level discourse parse trees</definiens>
			</definition>
			<definition id="7">
				<sentence>The RST corpus was also used in Soricut and Marcu ( S &amp; M ) ’s experiment , in which 347 articles were used as the training set We use the F-score version in which precision ( P ) and recall ( R ) are weighted equally , defined as 2*P*R/ ( P+R ) .</sentence>
				<definiendum id="0">RST corpus</definiendum>
				<definiens id="0">was also used in Soricut and Marcu ( S &amp; M ) ’s experiment , in which 347 articles were used as the training set We use the F-score version in which precision ( P ) and recall ( R ) are weighted equally</definiens>
			</definition>
			<definition id="8">
				<sentence>D-LTAG System : Discourse Parsing with a Lexicalized Tree-Adjoining Grammar .</sentence>
				<definiendum id="0">D-LTAG System</definiendum>
			</definition>
</paper>

		<paper id="1063">
			<definition id="0">
				<sentence>0 0.1 0.2 0.3 0.4 0.5 Precision Coverage Lead IGR+MMR+QA IGR+MMR IGR+MMR+QB IGR+MMR+QB+NE System using no qestions System using qestions B4CPB5 CBCWD3D6D8 0 0.1 0.2 0.3 0.4 0.5 Precision Coverage Lead IGR+MMR+QA IGR+MMR IGR+MMR+QB IGR+MMR+QB+NE System using no questions System using questions B4CQB5 C4D3D2CV BYCXCVD9D6CT BIBM BTDACTD6CPCVCT BVD3DACTD6CPCVCT CPD2CS BTDACTD6CPCVCT C8D6CTCRCXD7CXD3D2 D3CU CBCTD2D8CTD2CRCT BXDCD8D6CPCRD8CXD3D2 BXDCCPCRD8 C5CPD8CRCWBM D8CWCT CPDACTD6CPCVCT D6CPD8CXD3 D8CWCPD8 D8CWCT D7D9D1B9 D1CPD6CXCTD7CXD2CRD0D9CSCTCTDCCPCRD8 CPD2D7DBCTD6D7D8D6CXD2CVD7CXD2D1D3CSCTD0CPCQB9 D7D8D6CPCRD8D7B8 BEB5 BXCSCXD8 BWCXD7D8CPD2CRCTBM D8CWCT CPDACTD6CPCVCT D7CRD3D6CT D8CWCPD8 CXD7 CSCTACD2CTCS CQCPD7CTCS D3D2 D8CWCT CTCSCXD8 CSCXD7D8CPD2CRCT BXCSCXD8BWB4B5 CQCTD8DBCTCTD2 CPD2 CPD2D7DBCTD6 D7D8D6CXD2CV BTD2D7 CX CPD2CS CP D7CTD2D8CTD2CRCT D7D8D6CXD2CV CB CPD7 BYD3D6D1D9D0CP B4BLB5BM BVD3DA BXBW B4BTD2D7 CX B5 BP D1CPDC CB C4CTD2B4CBB5 A0BXCSCXD8BWB4CBBNBTD2D7 CX B5 C4CTD2B4BTD2D7 CX B5 B4BLB5 DBCWCTD6CT D8CWCT CUD9D2CRD8CXD3D2 C4CTD2B4B5 D6CTD8D9D6D2D7 D8CWCT D0CTD2CVD8CW D3CU CP D7D8D6CXD2CVBA CCCWCT D0CPCQCTD0 COC0D9D1CPD2B3 CXD2 D8CWCT ACCVD9D6CTD7 CRD3D6D6CTD7D4D3D2CSD7D8D3CPD7CTD8D3CUD7D9D1D1CPD6CXCTD7B8CTCPCRCWD3CUDBCWCXCRCW CXD7 CRD6CTCPD8CTCS CQDD D3D2CT D3CU ACDACT D7D4CTCRCXCPD0CXD7D8D7 DBCWD3 CSD3CTD7 D2D3D8 CRD6CTCPD8CT D8CWCT CRD3D6D6CTD7D4D3D2CSCXD2CVD1D3CSCTD0 CPCQD7D8D6CPCRD8BA Answer Coverage ( Edit Distance ) Answer Coverage ( Exact Match ) Lead Human IGR+MMR+QA IGR+MMR IGR+MMR+QB IGR+MMR+QB+NE System using no questions System using questions B4CPB5 CBCWD3D6D8 Answer Coverage ( Edit Distance ) Answer Coverage ( Exact Match ) Lead Human IGR+MMR+QA IGR+MMR IGR+MMR+QB IGR+MMR+QB+NE System using no questions System using questions B4CQB5 C4D3D2CV BYCXCVD9D6CT BJBM BTDACTD6CPCVCT BTD2D7DBCTD6 BVD3DACTD6CPCVCT CUD3D6 C9D9CTD7D8CXD3D2D7 BKBABF C5CXDCCXD2CV BYCPCRD8D3D6 D3CU D8DBD3 CZCXD2CSD7 D3CU CBCTD2D8CTD2CRCT C1D1D4D3D6D8CPD2CRCT CFCT CRD3D2CSD9CRD8CTCS D8CWCT D7CPD1CT CTDCD4CTD6CXD1CTD2D8D7 CPD7 D8CWCT D4D6CTB9 CRCTCSCXD2CV D7CTCRD8CXD3D2D7 CTDCCRCTD4D8 DACPD6DDCXD2CV CXD2 D8CWCT DACPD0D9CT D3CU D8CWCT D4CPD6CPD1CTD8CTD6 AB CUD6D3D1 BCBABC D8D3 BDBABCBA BYCXCVD9D6CT BK CPD2CS BL D7CWD3DB D8CWCT D4CTD6CUD3D6D1CPD2CRCT D3CU D7CTD2D8CTD2CRCT CTDCD8D6CPCRD8CXD3D2 CPD2CS D8CWCT CPDACTD6CPCVCT CPD2D7DBCTD6 CRD3DACTD6CPCVCT CUD3D6 D5D9CTD7D8CXD3D2D7B8 D6CTD7D4CTCRD8CXDACTD0DDBA BL BWCXD7CRD9D7D7CXD3D2 BLBABD C8CTD6CUD3D6D1CPD2CRCT D3CU C1D1D4D3D6D8CPD2D8 CBCTD2D8CTD2CRCT BXDCD8D6CPCRD8CXD3D2 BTD7 D7CWD3DBD2 CXD2 BYCXCVD9D6CT BI B4CPB5B8 DBCWCTD2 D8CWCT D0CTD2CVD8CW D3CU D7D9D1D1CPD6DD CXD7 COCBCWD3D6D8B3B8 D8CWCT D4CTD6CUD3D6D1CPD2CRCT D3CU D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS B4CXCVD6B7D1D1D6B7D5CPB5 CXD7 CPD0B9 D1D3D7D8 D7CPD1CT CPD7 D8CWCT CQCPD7CTD0CXD2CTD7 CXCVD6B7D1D1D6B7D5CQ CPD2CS 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Coverage Alpha Lead ( Short ) Lead ( Long ) IGR+MMR+QB ( Short ) IGR+MMR+QB ( Long ) IGR+MMR+QB+NE ( Short ) IGR+MMR+QB+NE ( Long ) IGR+MMR+QA ( Short ) IGR+MMR+QA ( Long ) B4CPB5 BTDACTD6CPCVCT BVD3DACTD6CPCVCT 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Precision Alpha Lead ( Short ) Lead ( Long ) IGR+MMR+QB ( Short ) IGR+MMR+QB ( Long ) IGR+MMR+QB+NE ( Short ) IGR+MMR+QB+NE ( Long ) IGR+MMR+QA ( Short ) IGR+MMR+QA ( Long ) B4CQB5 BTDACTD6CPCVCT C8D6CTCRCXD7CXD3D2 BYCXCVD9D6CT BKBM C8CTD6CUD3D6D1CPD2CRCT D3CU CBCTD2D8CTD2CRCT BXDCD8D6CPCRD8CXD3D2 DBCXD8CW D8CWCT C5CXDCCXD2CV BYCPCRD8D3D6 AB CECPD6DDCXD2CV CUD6D3D1 BCBABC D8D3 BDBABC 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Answer Coverage ( Exact Match ) Alpha Lead ( Short ) Lead ( Long ) Human ( Short ) Human ( Long ) IGR+MMR+QB ( Short ) IGR+MMR+QB ( Long ) IGR+MMR+QB+NE ( Short ) IGR+MMR+QB+NE ( Long ) IGR+MMR+QA ( Short ) IGR+MMR+QA ( Long ) B4CPB5 BXDCCPCRD8 C5CPD8CRCW 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Answer Coverage ( Edit Distance ) Alpha Lead ( Short ) Lead ( Long ) Human ( Short ) Human ( Long ) IGR+MMR+QB ( Short ) IGR+MMR+QB ( Long ) IGR+MMR+QB+NE ( Short ) IGR+MMR+QB+NE ( Long ) IGR+MMR+QA ( Short ) IGR+MMR+QA ( Long ) B4CQB5 BXCSCXD8 BWCXD7D8CPD2CRCT BYCXCVD9D6CT BLBM BTDACTD6CPCVCT BTD2D7DBCTD6 BVD3DACTD6CPCVCT DBCXD8CW D8CWCT C5CXDCB9 CXD2CV BYCPCRD8D3D6 AB CECPD6DDCXD2CV CUD6D3D1 BCBABC D8D3 BDBABC CXCVD6B7D1D1D6B7D5CQB7D2CTB8 DBCWCXD0CT CXCVD6B7D1D1D6B7D5CP D3D9D8B9 D4CTD6CUD3D6D1D7 D8CWCT D0CTCPCS D1CTD8CWD3CSBA C1D8 D1CXCVCWD8 CQCT CRD3D2B9 CRD0D9CSCTCSD8CWCPD8B8 CUD3D6D7CWD3D6D8D7D9D1D1CPD6CXCTD7B8DBD3D6CSD7CXD2D5D9CTD7B9 D8CXD3D2D7 CRD3D2DACTDDD7 CTD2D3D9CVCW CXD2CUD3D6D1CPD8CXD3D2 CUD3D6 D7D9D1D1CPB9 D6CXDECPD8CXD3D2BA C7D2 D8CWCT D3D8CWCTD6 CWCPD2CSB8 CXD2 D8CWCT CRCPD7CT D3CU COC4D3D2CVB3B8 D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS CXD7 D4D6CTCSD3D1CXD2CPD2CRCT D3DACTD6 CPD0D0 D3CU CQCPD7CTD0CXD2CTD7 CPD2CS D3D8CWCTD6 D4CPD6D8CXCRCXD4CPD8CXD2CVD7DDD7B9 D8CTD1D7 CPD7 D7CWD3DBD2 CXD2 BYCXCVD9D6CT BI B4CQB5B8 CPD0D8CWD3D9CVCW DBCT CWCPDACT D8D3 D8CPCZCT D2D3D8CXCRCT D3CU D8CWCT CUCPCRD8 D8CWCPD8 D7D3D1CT D3CU D8CWCT D3D8CWCTD6 D7DDD7D8CTD1D7 CSD3 D2D3D8 D9D7CT D8CWCT CXD2CUD3D6D1CPD8CXD3D2 D3CU D5D9CTD7D8CXD3D2D7BA C1D2 CRD3D1D4CPD6CXD7D3D2 DBCXD8CW CXCVD6B7D1D1D6B8 D8CWCT CXD1D4D6D3DACTD1CTD2D8 D3CU D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS CXD7 D6CTB9 D1CPD6CZCPCQD0CTB8 CPD2CS CXD8 D7CWD3DBD7 D8CWCPD8 D8CWCT D7CTD2D8CTD2CRCT DBCTCXCVCWD8 CQDD D8CWCT C9BT CTD2CVCXD2CT DBD3D6CZD7 CTABCTCRD8CXDACTD0DDBA C1D8 CXD7 CPD0D7D3 D6CTD1CPD6CZCPCQD0CT D8CWCPD8 D8CWCT CQCPD7CTD0CXD2CT CXCVD6B7D1D1D6B7D5CQD7CWD3DBD7 CRD3D1D4CPD6CPD8CXDACTD0DD CQCTD8D8CTD6 D4CTD6B9 CUD3D6D1CPD2CRCT D8CWCPD2 D3D8CWCTD6 CQCPD7CTD0CXD2CTD7 CPD2CS D3D8CWCTD6 D4CPD6B9 D8CXCRCXD4CPD8CXD2CV D7DDD7D8CTD1D7BA CCCWCT D6CTCPD7D3D2 D1CPDD CQCT D8CWCPD8 D6CTD0CPD8CXDACTD0DD D1CPD2DD D5D9CTD7D8CXD3D2D7 CPD6CT CPDACPCXD0B9 CPCQD0CT CXD2 D8CWCT CTDACPD0D9CPD8CXD3D2 D7CTD8BA C7D2 D8CWCT D3D8CWCTD6 CWCPD2CSB8 CXCVD6B7D1D1D6B7D5CQB7D2CT CXD7 D6CPD8CWCTD6 DBD3D6D7CT D8CWCPD2 CXCVD6B7D1D1D6B7D5CQBA CBCXD2CRCT D8CWCTD6CT CPD6CT D1CPD2DD D5D9CTD7D8CXD3D2D7 CXD2 D3D2CT D8D3D4CXCRB8 DBCT CSD3 D2D3D8 D7CTD0CTCRD8 D2CPD1CTCS CTD2D8CXD8CXCTD7 CPCRCRD3D6CSCXD2CV D8D3 D5D9CTD7D8CXD3D2 D8DDD4CTD7B8 CPD2CS D9D8CXD0CXDECT CPD0D0 D3CU D2CPD1CTCS CTD2D8CXD8CXCTD7 CUD3D6 D7CTD2D8CTD2CRCT DBCTCXCVCWD8CXD2CVBA C1D8 D8CWCTD6CTB9 CUD3D6CT D1CPDD D2D3D8 CQCT CTABCTCRD8CXDACTBA CFCWCXD0CTB8 CPD7 CUD3D6 COC4D3D2CVB3B8 D8CWCT CPDACTD6CPCVCT D4D6CTCRCXD7CXD3D2 D3CU CXCVD6B7D1D1D6B7D5CP CXD7 D5D9CXD8CT CWCXCVCW B4BCBABIBKBCB5B8 D8CWCT CPDACTD6B9 CPCVCT CRD3DACTD6CPCVCT CXD7 D6CTD0CPD8CXDACTD0DD D0D3DB B4BCBABFBLBDB5BA CCCWCT D6CTCPB9 D7D3D2 CXD7 D8CWCPD8 D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS D8CTD2CSD7 D8D3 CTDCB9 D8D6CPCRD8 D7CTD2D8CTD2CRCTD7 DBCWCXCRCWCWCPDACT D8CWCT D7CPD1CT CRD3D2D8CTD2D8CPD7 D8CWCT D7CTD2D8CTD2CRCTD7 CPD0D6CTCPCSDD D7CTD0CTCRD8CTCSBA BYCXCVD9D6CT BDBC D7CWD3DBD7 D8CWCT CPDACTD6CPCVCT D2D9D1CQCTD6 D3CU CPD0D1D3D7D8 CXCSCTD2D8CXCRCPD0 D7CTD2B9 D8CTD2CRCTD7 CXD2 CP D7D9D1D1CPD6DDBA C1D8 CXD7 CP D4CPD6D8 D3CU D7D9CQCYCTCRD8CXDACT CPD7D7CTD7D7D1CTD2D8 CUD3D6 D7D9D1D1CPD6CXCTD7BA BTCRCRD3D6CSCXD2CV D8D3 D8CWCT g14983g14981g14983 g14983g14981g14988 g14984g14981g14983 g14984g14981g14988 g14985g14981g14983 g14985g14981g14988 g14986g14981g14983 g15005 g14983 g14986 g14983 g14988 g15005 g14983 g14986 g14983 g14989 g15005 g14983 g14986 g14983 g14984 g15005 g14983 g14986 g14983 g14986 g15005 g14983 g14986 g14983 g14991 g15005 g14983 g14986 g14983 g14992 g15005 g14983 g14986 g14983 g14987 g15005 g14983 g14986 g14984 g14984 g15008g15006 g15017 g14978 g15012 g15012 g15017 g14978 g15016 g15000 g15005 g14983 g14986 g14984 g14983 g15011 g15036 g15032 g15035g15013 g15052 g15044 g15033 g15036 g15049 g14967 g15046 g15037 g14967 g15008 g15035 g15036 g15045 g15051 g15040 g15034 g15032 g15043 g14967 g15018 g15036 g15045 g15051 g15036 g15045 g15034 g15036 g15050 g15018g15039g15046g15049g15051 g15011g15046g15045g15038 BYCXCVD9D6CT BDBCBM BTDACTD6CPCVCT C6D9D1CQCTD6 D3CU C1CSCTD2D8CXCRCPD0 CBCTD2D8CTD2CRCTD7 CXD2 CP CBD9D1D1CPD6DD ACCVD9D6CTB8 D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS D7D3D1CTD8CXD1CTD7 D1CXD7D7CTCS CTD0CXD1CXD2CPD8CXD2CVD3CQ DACXD3D9D7D0DD D6CTCSD9D2CSCPD2D8 D7CTD2D8CTD2CRCTD7BA CFCT D8CWCXD2CZ D8CWCPD8 D3D2CT D3CU D6CTCPD7D3D2D7 CXD7 D8CWCT DBCPDD D8D3 D1CTCPD7D9D6CT D7CTD2D8CTD2CRCT D7CXD1CXD0CPD6CXD8DDBA C1D2 C5C5C1B9C5CBB8 DBCT CPCSD3D4D8 D8CWCT CRD3D7CXD2CT D1CTCPD7D9D6CT CQCTD8DBCTCTD2 D7CTD2D8CTD2CRCT DACTCRD8D3D6D7B8 CTCPCRCW CTD0CTD1CTD2D8 D3CU DBCWCXCRCW CXD7 CP DBCTCXCVCWD8 D3CU D2D3D9D2BA CBCXD2CRCT CP D2D3D9D2 D1CPDDCWCPDACT CSCXABCTD6CTD2D8DBCTCXCVCWD8DACPD0D9CTD7 CXD2 CSCXABCTD6B9 CTD2D8CSD3CRD9D1CTD2D8D7B8 D8CWCT D7CXD1CXD0CPD6CXD8DDCQCTD8DBCTCTD2 D8DBD3 D7CTD2B9 D8CTD2CRCTD7 CXD2 CSCXABCTD6CTD2D8 CSD3CRD9D1CTD2D8D7 D1CPDD CQCT D0CTD7D7 D8CWCPD2 BD CTDACTD2 CXCU D8CWCTDD CPD6CT CXCSCTD2D8CXCRCPD0BA C1D8 CXD7 D2CTCRCTD7D7CPD6DD D8D3 D6CTACD2CT D8CWCT CRCPD0CRD9D0CPD8CXD3D2 D1CTD8CWD3CS D3CU D7CXD1CXD0CPD6CXD8DDBA BLBABE C8CTD6CUD3D6D1CPD2CRCT CXD2 D8CTD6D1D7 D3CU BVD3DACTD6CPCVCT D3CU BTD2D7DBCTD6D7 BTCRCRD3D6CSCXD2CV D8D3 BYCXCVD9D6CT BJB8 D8CWCT D4CTD6CUD3D6D1CPD2CRCT D3CU D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS CXD7 CQCTD8D8CTD6 D8CWCPD2 D8CWCPD8 D3CU CQCPD7CTB9 D0CXD2CTD7 CUD3D6 CQD3D8CW COCBCWD3D6D8B3 CPD2CS COC4D3D2CVB3BA C6D3D8CT D8CWCPD8 D8CWCT D7CTD8 D3CU D7D9D1D1CPD6CXCTD7 D0CPCQCTD0CTCS CQDD COC0CDC5BTC6B3 CXD7 CRD6CTCPD8CTCS CQDDD8CWCTACDACT D7D4CTCRCXCPD0CXD7D8D7 DBCXD8CWD3D9D8 D6CTCUCTD6D6CXD2CV D8D3 D5D9CTD7D8CXD3D2D7 CXD2 D8CWCT D8D3D4CXCR CXD2CUD3D6D1CPD8CXD3D2BA BLBABF BXABCTCRD8 D3CU C5CXDCCXD2CV D8DBD3 CZCXD2CSD7 D3CU CBCTD2D8CTD2CRCT C1D1D4D3D6D8CPD2CRCT BYCXCVD9D6CT BK CPD2CS BL D7CWD3DB D8CWCPD8 D8CWCT D7CTD2D8CTD2CRCT CXD1B9 D4D3D6D8CPD2CRCT CSCTD6CXDACTCS CUD6D3D1 D5D9CTD7D8CXD3D2D7B8 D0CXCZCT D5D9CTD7D8CXD3D2D7 D8CWCTD1D7CTD0DACTD7 CPD2CS D8CWCTCXD6 CPD2D7DBCTD6D7B8 CXD7 D4D6CTCSD3D1CXD2CPD2D8 D3DACTD6 D8CWCT D7CTD2D8CTD2CRCT CXD1D4D3D6D8CPD2CRCT CQCPD7CTCS D3D2 C1BZCABA CFCTB8 CWD3DBCTDACTD6B8 CRCPD2 CPD0D7D3 ACD2CS D8CWCPD8 D8CWCTD6CT CXD7 CP D4CTCPCZ CXD2 CTCPCRCW D3CU CRD9D6DACTD7 CPD8 AB BP BCBMBI AO BCBMBKBA CCCWD9D7 DBCT D1CPDD CRD3D2CRD0D9CSCT D8CWCPD8 D1CXDCCXD2CV D8DBD3 CZCXD2CSD7 D3CU CXD1D4D3D6B9 D8CPD2CRCT D8CPCZCTD7 CTABCTCRD8D7 D8D3 D7D3D1CT CSCTCVD6CTCTBA BXD7D4CTCRCXCPD0D0DDB8 CXD8 CXD7 CXD2D8CTD6CTD7D8CXD2CV D8CWCPD8 D8CWCT D4CTCPCZD7 CPD6CT D2D3D8 D0D3CRCPD8CTCS CPD8 D8CWCT D4D3CXD2D8 AB BP BDBMBC CTDACTD2 D8CWD3D9CVCW CXD2 D8CWCT CPD2B9 D7DBCTD6 CRD3DACTD6CPCVCT CRD9D6DACTD7BA C7D2CT D3CU D8CWCT D6CTCPD7D3D2D7 D3CU CXD8 DBD3D9D0CS CQCT D8CWCPD8 D8CWCT C9BT D7DDD7D8CTD1 DBCT CTD1D4D0D3DDCXD7CXD2B9 D7D9ÆCRCXCTD2D8 CXD2 CPCRCRD9D6CPCRDDBA CCCWCT C5CACA BF D3CU D8CWCT C9BT D7DDD7D8CTD1 CXD7 CPCQD3D9D8 BCBABH CUD3D6 D8CWCT D8CTD7D8 D7CTD8D7 D3CU C6CCBVC1CA C9BTBVBD CPD2CS C9BTBVBE BG BA CCCWCT D7CTD2D8CTD2CRCT CXD1D4D3D6D8CPD2CRCT CQCPD7CTCS D3D2 D8CWCT D4D6D3CQCPCQCXD0CXD7D8CXCR CSCXD7D8D6CXCQD9D8CXD3D2 D3CU DBD3D6CSD7 CRCPD2B8 D8CWCTD6CTCUD3D6CTB8 CRD3D1D4CTD2D7CPD8CT CUD3D6 D8CWCT CXD2CPCRCRD9D6CPCRDDBA BDBC CACTD0CPD8CTCS CFD3D6CZ CCCWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS CXD7 D6CTD0CPD8CTCS DBCXD8CW D8DBD3 CZCXD2CSD7 D3CU D7D9D1D1CPD6CXDECPD8CXD3D2 D6CTD7CTCPD6CRCWCTD7BA C7D2CT CXD7 D8CWCT D1D9D0D8CXB9 CSD3CRD9D1CTD2D8 D7D9D1D1CPD6CXDECPD8CXD3D2B8 CPD2CS D8CWCT D3D8CWCTD6 CXD7 D8CWCT D5D9CTD7D8CXD3D2B9CUD3CRD9D7CTCS D7D9D1D1CPD6CXDECPD8CXD3D2BA BTD7 CUD3D6 D1D9D0D8CXB9CSD3CRD9D1CTD2D8 D7D9D1D1CPD6CXDECPD8CXD3D2B8 DBCT CPD6CT D9D7CXD2CV D7CTDACTD6CPD0 CTDCCXD7D8CXD2CV D1CTD8CWD3CSD7BA CFCT CTD1B9 D4D0D3DD D8CWCT DBD3D6CS DBCTCXCVCWD8CXD2CV D1CTD8CWD3CS CQCPD7CTCS D3D2 BF C5CTCPD2 CACTCRCXD4D6D3CRCPD0 CACPD2CZBA BG C9BTBV CXD7 D8CWCT D7CTD6CXCTD7 D3CU CTDACPD0D9CPD8CXD3D2 DBD3D6CZD7CWD3D4D7 CRD3D2CRCTD6D2B9 CXD2CV C9BT D8CTCRCWD2D3D0D3CVCXCTD7 CXD2 C6CCBVC1CABA C1BZCAB4C5D3D6CXB8 BEBCBCBEB5 CPD2CS C5C5CA CUD3D6 D6CTCSD9D2CSCPD2CRDD CRD3D2D8D6D3D0B4BVCPD6CQD3D2CTD0D0 CPD2CS BZD3D0CSD7D8CTCXD2B8 BDBLBLBKB5BA C0CXD6CPD3 CTD8 CPD0BAB4C0CXD6CPD3 CTD8 CPD0BAB8 BEBCBCBDB5 CXD2D7D4CXD6CTCS D9D7 D8D3 D9D8CXD0CXDECT D8CWCT C0CPD2D2CXD2CV DBCXD2CSD3DB CUD9D2CRD8CXD3D2 CUD3D6 D8CTDCD8 D7D9D1D1CPB9 D6CXDECPD8CXD3D2BA C1D2 D8CTD6D1D7 D3CU D8CWCT D5D9CTD7D8CXD3D2B9CUD3CRD9D7CTCS D7D9D1D1CPD6CXDECPB9 D8CXD3D2B8 DBCTCXD2D8D6D3CSD9CRCTD8CWCTCUD3D0D0D3DBCXD2CVD2CTDBD1CTD8CWD3CSD3D0D3B9 CVCXCTD7BM BDB5 CVCTD2CTD6CPD8CXD3D2 D3CU D7D9D1D1CPD6DD D8CWCPD8 CRCPD2 CPD2D7DBCTD6 D8CWCT D1D9D0D8CXD4D0CT D5D9CTD7D8CXD3D2D7B8 CPD2CS BEB5 CXD2D8CTCVD6CPD8CXD3D2 D3CU D3D9D8D4D9D8 D3CU C9BT CTD2CVCXD2CT CXD2D8D3 CRD3D2DACTD2D8CXD3D2CPD0 D7CRCWCTD1CT D3CU CXD1D4D3D6D8CPD2D8 D7CTD2D8CTD2CRCT CTDCD8D6CPCRD8CXD3D2 CQDD D9D7CXD2CV C9BT D7CRD3D6CT CPD7 DBD3D6CS DBCTCXCVCWD8BA BXD7D4CTCRCXCPD0D0DDB8 CPD7 CUCPD6 CPD7 DBCT CZD2D3DBB8 D8CWCTD6CT CPD6CT D3D2D0DD CP CUCTDB D6CTD7CTCPD6CRCWCTD7 D3D2 D8CTDCD8 D7D9D1D1CPD6CXDECPD8CXD3D2 D9D7CXD2CV C9BT D7DDD7D8CTD1D7BA CCCWCT CVD6D3D9D4 D3CU BVD3D0D9D1CQCXCPCDD2CXDACTD6D7CXD8DDCTD1D4D0D3DDD7 CP C9BT D7DDD7D8CTD1CXD2 BWCDBV BEBCBCBFB8 D8CWCTDDB8 CWD3DBCTDACTD6B8 CSCXCS D2D3D8 CSCTD7CRD6CXCQCT D8CWCT CSCTD8CPCXD0 D3CU D8CWCPD8B4C6CTD2CZD3DACP CTD8 CPD0BAB8 BEBCBCBFB5BA BZCPCXDECPD9D7CZCPD7 CTD8 CPD0BAB4BZCPCXDECPD9D7CZCPD7B8 BEBCBCBFB5 CPD0D7D3 CWCPDACT CPD2D2D3D9D2CRCTCS CP D4D6D3CYCTCRD8 CRCPD0D0CTCS COBVD9CQD6CTD4D3D6D8CTD6B3B8 DBCWCXCRCW CPCXD1D7 D8D3 CXD2D8CTCVD6CPD8CT D8CWCT D8CTCRCWD2D3D0D3CVCXCTD7 CXD2CRD0D9CSCXD2CV D5D9CTD7D8CXD3D2 CPD2D7DBCTD6CXD2CV CPD2CS D1D9D0D8CXB9CSD3CRD9D1CTD2D8 D7D9D1D1CPD6CXDECPD8CXD3D2BA CCCWCTDDB8 CWD3DBCTDACTD6B8 CWCPDACT D2D3D8 D4D9CQD0CXD7CWCTCS D8CWCT D4CPD4CTD6D7 CPCQD3D9D8 D8CWCPD8BA CCCWCT CQCPD7CXCR D1CTD8CWD3CSD3D0D3CVDD CUD3D6 D8CWCT D5D9CTD7D8CXD3D2B9 CQCXCPD7CTCS D7D9D1D1CPD6CXDECPD8CXD3D2 CXD7 D8D3 CVCXDACT CWCXCVCWCTD6 DBCTCXCVCWD8 D8D3 DBD3D6CSD7 CXD2 CP D5D9CTD7D8CXD3D2B4CCD3D1CQD6D3D7 CPD2CS CBCPD2CSCTD6B9 D7D3D2B8 BDBLBLBKBN BUCTD6CVCTD6 CPD2CS C5CXD8D8CPD0B8 BEBCBCBCBN C6D3CQCPD8CP CPD2CS CBCTCZCXD2CTB8 BEBCBCBFB5BA C7CZD9D1D9D6CP CTD8 CPD0BAB4C7CZD9D1D9D6CP CPD2CS C5D3CRCWCXDED9CZCXB8 BEBCBCBCB5 CUD3CRD9D7CTCS D3D2 D8CWCT D0CTDCCXCRCPD0 CRCWCPCXD2D7 DBCXD8CW D6CTD7D4CTCRD8 D8D3 DBD3D6CSD7 CXD2 CP D5D9CTD7D8CXD3D2 D7CTD2D8CTD2CRCTBA C0CXD6CPD3 CTD8 CPD0BAB4C0CXD6CPD3 CTD8 CPD0BAB8 BEBCBCBDB5 D4CPDD CPD8D8CTD2D8CXD3D2 D8D3 D2D3D8 D3D2D0DD DBD3D6CSD7 CXD2 CP D5D9CTD7D8CXD3D2 CQD9D8 CPD0D7D3 D2CPD1CTCS CTD2B9 D8CXD8CXCTD7 D8CWCPD8 CRD3D6D6CTD7D4D3D2CS D8D3 D8CWCT D5D9CTD7D8CXD3D2 D8DDD4CTBA CFD9 CTD8 CPD0BAB4CFD9 CTD8 CPD0BAB8 BEBCBCBEB5 CTDCCPD1CXD2CTCSD8CWCT D6CTD0CPD8CXD3D2 CQCTB9 D8DBCTCTD2 D8DDD4CTD7 D3CU D5D9CTD7D8CXD3D2D7 CPD2CS D8CWCT D9D2CXD8 D0CTD2CVD8CW D3CU D8CTDCD8 CUD6CPCVD1CTD2D8 CXD2 D7D9D1D1CPD6DD CVCTD2CTD6CPD8CXD3D2BA C7D9D6 CTDCB9 D4CTD6CXD1CTD2D8D7CSCTD7CRD6CXCQCTCSCXD2 CBCTCRD8CXD3D2 BKB8 CWD3DBCTDACTD6B8 D7CWD3DB D8CWCPD8 D8CWCT D4D6D3D4D3D7CTCSD1CTD8CWD3CSB8 DBCWCXCRCW D9D7CTD7 D8CWCT CXD2CUD3D6B9 D1CPD8CXD3D2 D3CU D8CWCT CPD2D7DBCTD6D7 CUD6D3D1 CP C9BT D7DDD7D8CTD1B8 D3D9D8B9 D4CTD6CUD3D6D1D7 D8CWCT CQCPD7CTD0CXD2CTD7 D8CWCPD8 CSCTD4CTD2CS D3D2D0DD D3D2 D8CWCT CXD2CUD3D6D1CPD8CXD3D2 D3CU D5D9CTD7D8CXD3D2D7BA BDBD BVD3D2CRD0D9D7CXD3D2 C1D2 D3D6CSCTD6 D8D3 D6CTCPD0CXDECT D1D9D0D8CXB9CSD3CRD9D1CTD2D8 D7D9D1D1CPD6CXDECPB9 D8CXD3D2 CUD3CRD9D7CTCS CQDD D1D9D0D8CXD4D0CT D5D9CTD7D8CXD3D2D7B8 DBCT CXD2D8D6D3B9 CSD9CRCTCS CP CRCPD0CRD9D0CPD8CXD3D2 D3CU D7CTD2D8CTD2CRCT CXD1D4D3D6D8CPD2CRCT D9D7B9 CXD2CVCP C9BT D7DDD7D8CTD1BA CFCT CPD0D7D3 D4D6D3D4D3D7CTCS CPD2 CXD2D8CTCVD6CPB9 D8CXD3D2 D3CU CXD8 CXD2D8D3 CP CVCTD2CTD6CXCR D1D9D0D8CXB9CSD3CRD9D1CTD2D8D7D9D1D1CPB9 D6CXDECPD8CXD3D2 D7DDD7D8CTD1BA CCCWCT CTDACPD0D9CPD8CXD3D2 D6CTD7D9D0D8D7 D7CWD3DBCTCS D8CWCPD8 D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS CWCPD7 CQCTD8D8CTD6 D4CTD6CUD3D6B9 D1CPD2CRCT D8CWCPD2 D2D3D8 D3D2D0DD D7CTDACTD6CPD0 CQCPD7CTD0CXD2CTD7 CQD9D8 CPD0D7D3 D3D8CWCTD6 D4CPD6D8CXCRCXD4CPD2D8D7B3 D7DDD7D8CTD1D7 CXD2 C6CCBVC1CABG CCCBBVBF BYD3D6D1CPD0 CAD9D2BA BTD7 D7D8CPD8CTCS CTCPD6D0CXCTD6B8 CXD8 CXD7 D3CQD7CTD6DACTCS D8CWCPD8 D8CWCT D4D6D3B9 D4D3D7CTCSD1CTD8CWD3CSD7D3D1CTD8CXD1CTD7D1CXD7D7CTCSCTD0CXD1CXD2CPD8CXD2CVD3CQB9 DACXD3D9D7D0DD D6CTCSD9D2CSCPD2D8 D7CTD2D8CTD2CRCTD7BA C7D9D6 CUD9D8D9D6CT DBD3D6CZB8 D8CWCTD6CTCUD3D6CTB8 D7CWD3D9D0CSCXD2CRD0D9CSCTD6CTACD2CXD2CVD8CWCTCRCPD0CRD9D0CPD8CXD3D2 D3CU D7CTD2D8CTD2CRCT D7CXD1CXD0CPD6CXD8DDBA BTD2D3D8CWCTD6 D4D3CXD2D8CPD8CXD7D7D9CTCXD7 D8CWCT CRD3D1D4D9D8CPD8CXD3D2CPD0 CRD3D7D8 D3CU D8CWCT C9BT D7DDD7D8CTD1BA C1D2 D8CWCT CRD9D6D6CTD2D8 CXD1D4D0CTD1CTD2D8CPD8CXD3D2B8 D8CWCT D7DDD7D8CTD1 CRCPD0CRD9B9 D0CPD8CTD7 CTDCCPCRD8 D7CRD3D6CTD7 CTDACTD2D0DD CUD3D6 CPD0D0 D3CU DBD3D6CSD7 CXD2 CSD3CRB9 D9D1CTD2D8D7 D8D3 CQCT D7D9D1D1CPD6CXDECTCSBA C1D8 D8CPCZCTD7 CPCQD3D9D8 D8CTD2D7 D3CUD7CTCRD3D2CSD7D4CTD6D3D2CTD5D9CTD7D8CXD3D2D3D2CPDACTD6CPCVCT C8BVCWCPD6CSB9 DBCPD6CTBA BYD3D6D8D9D2CPD8CTD0DDB8 D8CWCT C9BT CTD2CVCXD2CT CWCPD7 D8CWCT CUCTCPB9 D8D9D6CT D3CU CRD3D2D8D6D3D0D0CTCS D7CTCPD6CRCW CXD2 ACD2CSCXD2CVCPD2D7DB CTD6D7 CPD2CS CRCPD2 D8CTD6D1CXD2CPD8CT D8CWCT CRCPD0CRD9D0CPD8CXD3D2 CPCUD8CTD6 D3CQD8CPCXD2CXD2CVD2B9 CQCTD7D8 CPD2D7DBCTD6D7BA CFCT D4D0CPD2 D8D3 D9D8CXD0CXDECT D8CWCT CUCTCPD8D9D6CT CPD2CS D8CWCT CPD4D4D6D3DCCXD1CPD8CT D7CRD3D6CTD7 D8D3 D6CTCSD9CRCT D8CWCT CRD3D7D8BA CCCWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS D7CWD3D9D0CS CQCT CPD0D7D3 CXD1D4D6D3DACTCS D7D3 CPD7 D8D3 CPD0D0D3DB CP D1D3D6CT D2CPD8D9D6CPD0 D7CXD8D9CPD8CXD3D2 DBCWCTD6CT CP D9D7CTD6 CVCXDACTD7 D5D9CTD7D8CXD3D2D7 D3D2CT CQDD D3D2CT CXD2 D8CWCT CXD2D8CTD6CPCRD8CXD3D2 DBCXD8CW CP D7DDD7D8CTD1B8 CPD2CS CPCRCRD3D6CSCXD2CV D8D3 D8CWCT CXD2D4D9D8 D8CWCT D7DDD7D8CTD1 CVD6CPCSD9CPD0D0DD D3D9D8D4D9D8D7 CP D4CPD6D8 D3CU D7D9D1D1CPD6DDCXD2B9 CRD0D9CSCXD2CVCPD2CPD2D7DBCTD6 CQDDD8CPCZCXD2CVCPCRCRD3D9D2D8 D3CU D6CTD0CPD8CXD3D2D7 D8D3 D4D6CTDACXD3D9D7D0DD CSCXD7D4D0CPDDCTCS D4CPD6D8D7 D3CU D7D9D1D1CPD6DDBA CACTCUCTD6CTD2CRCTD7 BTCSCPD1 BUCTD6CVCTD6 CPD2CS CECXCQCWD9 C7BA C5CXD8D8CPD0BA BEBCBCBCBA C9D9CTD6DDB9 D6CTD0CTDACPD2D8 D7D9D1D1CPD6CXDECPD8CXD3D2 D9D7CXD2CV BYBTC9D7BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU D8CWCT BFBKD8CW BTD2D2D9CPD0 C5CTCTD8CXD2CV D3CU D8CWCT BTD7D7D3CRCXCPD8CXD3D2 CUD3D6 BVD3D1B9 D4D9D8CPD8CXD3D2CPD0 C4CXD2CVD9CXD7D8CXCRD7 B4BTBVC4B9BEBCBCBCB5B8 D4CPCVCTD7 BEBLBGDFBFBCBDBA C2CPCXD1CT BVCPD6CQD3D2CTD0D0 CPD2CS C2CPCSCT BZD3D0CSD7D8CTCXD2BA BDBLBLBKBA CCCWCT CDD7CT D3CU C5C5CAB8 BWCXDACTD6D7CXD8DDB9BUCPD7CTCS CACTD6CPD2CZCXD2CV CUD3D6 CACTD3D6CSCTD6CXD2CV BWD3CRD9D1CTD2D8D7 CPD2CS C8D6D3CSD9CRCXD2CV CBD9D1D1CPD6CXCTD7BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU D8CWCT BEBDD7D8 BTD2D2D9CPD0 C1D2D8CTD6D2CPD8CXD3D2CPD0 BTBVC5B9CBC1BZC1CA BVD3D2B9 CUCTD6CTD2CRCTD3D2CACTD7CTCPD6CRCW CPD2CS BWCTDACTD0D3D4D1CTD2D8 CXD2 C1D2CUD3D6D1CPD8CXD3D2 CACTD8D6CXCTDACPD0B8 D4CPCVCTD7 BFBFBHDFBFBFBIBA CCCPCZCPCWCXD6D3 BYD9CZD9D7CXD1CP CPD2CS C5CPD2CPCQD9 C7CZD9D1D9D6CPBA BEBCBCBDBA CCCTDCD8 CBD9D1D1CPD6CXDECPD8CXD3D2 BVCWCPD0D0CTD2CVCT CCCTDCD8 D7D9D1D1CPD6CXDECPD8CXD3D2 CTDACPD0D9B9 CPD8CXD3D2 CXD2 C2CPD4CPD2 B4CCCBBVB5BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU D8CWCT C6BTBTBVC4 BEBCBCBD CFD3D6CZD7CWD3D4 D3D2 BTD9D8D3D1CPD8CXCR CBD9D1D1CPD6CXDECPD8CXD3D2B8 C2D9D2CTBA CAD3CQCTD6D8 BZCPCXDECPD9D7CZCPD7BA BEBCBCBFBA BVD9CQD6CTD4D3D6D8CTD6 DBCTCQ D4CPCVCTBA CWD8D8D4BMBBBBD2D0D4BAD7CWCTCUBACPCRBAD9CZBBCRD9CQD6CTD4D3D6D8CTD6BBCXD2CSCTDCBACWD8D1D0BA CCD7D9D8D3D1D9 C0CXD6CPD3B8 CHD9D8CPCZCP CBCPD7CPCZCXB8 CPD2CS C0CXCSCTCZCX C1D7D3DECPCZCXBA BEBCBCBDBA BTD2 CTDCD8D6CXD2D7CXCR CTDACPD0D9CPD8CXD3D2 CUD3D6 D5D9CTD7D8CXD3D2B9CQCXCPD7CTCS D8CTDCD8 D7D9D1D1CPD6CXDECPD8CXD3D2 D3D2 D5CP D8CPD7CZD7BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU D8CWCT C6BTBTBVC4 BEBCBCBD DBD3D6CZD7CWD3D4 D3D2 BTD9D8D3D1CPD8CXCR CBD9D1D1CPD6CXDECPB9 D8CXD3D2B8 D4CPCVCTD7 BIBDDFBIBKBA CCD7D9D8D3D1D9 C0CXD6CPD3B8 C5CPD2CPCQD9 C7CZD9D1D9D6CPB8 CCCPCZCPCWCXD6D3 BYD9CZD9D7CWCXD1CPB8 CPD2CS C0CXCSCTD8D7D9CVD9 C6CPD2CQCPBA BEBCBCBGBA CCCTDCD8 CBD9D1D1CPD6CXDECPD8CXD3D2 BVCWCPD0D0CTD2CVCT BF DG CCCTDCD8 D7D9D1D1CPD6CXDECPD8CXD3D2 CTDACPD0D9CPD8CXD3D2 CPD8 C6CCBVC1CA CFD3D6CZD7CWD3D4 BG DGBA C1D2 CFD3D6CZCXD2CV C6D3D8CTD7 D3CU D8CWCT BYD3D9D6D8CW C6CCBVC1CA CFD3D6CZD7CWD3D4 C5CTCTD8CXD2CVB8 D4CPCVCTD7 BGBCBJDFBGBDBDB8 C2D9D2CTBA CCCPD8D7D9D2D3D6CX C5D3D6CXB8 CCD3D1D3CWCPD6D9 C7CWD8CPB8 C3CPD8D7D9DDD9CZCX BYD9CYCXCWCPD8CPB8 CPD2CS CADDD9D8CPD6D3 C3D9D1D3D2BA BEBCBCBFBA BTD2 BT A3 D7CTCPD6CRCW CXD2 D7CTD2D8CTD2B9 D8CXCPD0 D1CPD8CRCWCXD2CV CUD3D6 D5D9CTD7D8CXD3D2 CPD2D7DBCTD6CXD2CVBA C1BXC1BVBX CCD6CPD2D7B9 CPCRD8CXD3D2D7 D3D2 C1D2CUD3D6D1CPD8CXD3D2 CPD2CS CBDDD7D8CTD1D7B8 BXBKBIB9BWB4BLB5BMBDBIBHBKDF BDBIBIBKB8 CBCTD4D8CTD1CQCTD6BA CBD4CTCRCXCPD0 C1D7D7D9CT D3D2 CCCTDCD8 C8D6D3CRCTD7D7CXD2CV CUD3D6 C1D2CUD3D6D1CPD8CXD3D2 BTCRCRCTD7D7BA CCCPD8D7D9D2D3D6CX C5D3D6CXBA BEBCBCBEBA C1D2CUD3D6D1CPD8CXD3D2 CVCPCXD2 D6CPD8CXD3 CPD7 D8CTD6D1 DBCTCXCVCWD8 DG D8CWCT CRCPD7CT D3CU D7D9D1D1CPD6CXDECPD8CXD3D2 D3CU CXD6 D6CTD7D9D0D8D7 DG BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU D8CWCT BDBLD8CW C1D2D8CTD6D2CPD8CXD3D2CPD0 BVD3D2CUCTD6CTD2CRCT D3D2 BVD3D1D4D9D8CPD8CXD3D2CPD0 C4CXD2CVD9CXD7D8CXCRD7 B4BVC7C4C1C6BZ BCBEB5B8 D4CPCVCTD7 BIBKBKDFBIBLBGB8 BTD9CVD9D7D8BA BTD2CX C6CTD2CZD3DACPB8 BUCPD6D6DD CBCRCWCXABD1CPD2B8 BTD2CSD6CTDB CBCRCWD0CPCXCZCTD6B8 CBCPD7CWCP BUD0CPCXD6B9BZD3D0CSCTD2D7D3CWD2B8 CACTCVCXD2CP BUCPD6DECXD0CPDDB8 CBCTD6CVCTDD CBCXCVCTD0D1CPD2B8 CECPD7CXD0CTCXD3D7 C0CPD8DECXDACPD7D7CXD0D3CVD0D3D9B8 CPD2CS C3CPD8CWD0CTCTD2 C5CRC3CTD3DBD2BA BEBCBCBFBA BVD3D0D9D1CQCXCP CPD8 D8CWCT BWD3CRD9D1CTD2D8 CDD2CSCTD6D7D8CPD2CSCXD2CV BVD3D2CUCTD6CTD2CRCT BEBCBCBFBA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU BWD3CRD9D1CTD2D8 CDD2CSCTD6B9 D7D8CPD2CSCXD2CV BVD3D2CUCTD6CTD2CRCT BEBCBCBFBA BVCWCXCZCPD7CWCX C6D3CQCPD8CP CPD2CS CBCPD8D3D7CWCX CBCTCZCXD2CTBA BEBCBCBFBA CACTD7D9D0D8D7 D3CU BVCAC4BBC6CHCD D7DDD7D8CTD1 CPD8 BWCDBVB9BEBCBCBF CPD2CS CPD2 CTDCD4CTD6CXD1CTD2D8 D3D2 CSCXDACXD7CXD3D2 D3CU CSD3CRD9D1CTD2D8 D7CTD8D7BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU BWD3CRB9 D9D1CTD2D8 CDD2CSCTD6D7D8CPD2CSCXD2CV BVD3D2CUCTD6CTD2CRCT BEBCBCBFBA C5CPD2CPCQD9 C7CZD9D1D9D6CP CPD2CS C0CPCYCXD1CT C5D3CRCWCXDED9CZCXBA BEBCBCBCBA C9D9CTD6DDB9 CQCXCPD7CTCS D7D9D1D1CPD6CXDECPD8CXD3D2 CQCPD7CTCS D3D2 D0CTDCCXCRCPD0 CRCWCPCXD2CXD2CVBA BVD3D1D4D9D8CPD8CXD3D2CPD0 C1D2D8CTD0D0CXCVCTD2CRCTB8 BDBIB4BGB5BMBHBJBKDFBHBKBHBA C8CPD9D0 C7DACTD6 CPD2CS C2CPD1CTD7 CHCTD2BA BEBCBCBFBA BTD2 CXD2D8D6D3CSD9CRD8CXD3D2 D8D3 BWCDBV BEBCBCBFBM C1D2D8D6CXD2D7CXCR CTDACPD0D9CPD8CXD3D2 D3CU CVCTD2CTD6CXCR D2CTDBD7 D8CTDCD8 D7D9D1D1CPD6CXDECPD8CXD3D2 D7DDD7D8CTD1D7BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU BWD3CRD9D1CTD2D8 CDD2CSCTD6D7D8CPD2CSCXD2CV BVD3D2CUCTD6CTD2CRCTBEBCBCBFBA BTBA CCD3D1CQD6D3D7 CPD2CS C5BA CBCPD2CSCTD6D7D3D2BA BDBLBLBKBA BTCSDACPD2D8CPCVCTD7 D3CU C9D9CTD6DD BUCXCPD7CTCS CBD9D1D1CPD6CXCTD7 CXD2 C1D2CUD3D6D1CPD8CXD3D2 CACTD8D6CXCTDACPD0BA C1D2 C8D6D3CRCTCTCSCXD2CVD7 D3CU D8CWCT BEBDD7D8 BTD2D2D9CPD0 C1D2D8CTD6D2CPD8CXD3D2CPD0 BTBVC5B9 CBC1BZC1CA BVD3D2CUCTD6CTD2CRCT D3D2 CACTD7CTCPD6CRCW CPD2CS BWCTDACTD0D3D4D1CTD2D8 CXD2 C1D2CUD3D6D1CPD8CXD3D2 CACTD8D6CXCTDACPD0B8 D4CPCVCTD7 BEDFBDBCBA C0CPD6D6CXD7 CFD9B8 BWD6CPCVD3D1CXD6 CABA CACPCSCTDAB8 CPD2CS CFCTCXCVD9D3 BYCPD2BA BEBCBCBEBA CCD3DBCPD6CSD7 CPD2D7DBCTD6 CUD3CRD9D7CTCS D7D9D1D1CPD6CXDECPD8CXD3D2BA C1D2 C8D6D3CRCTCTCSB9 CXD2CVD7 D3CU D8CWCT BDD7D8 C1D2D8CTD6D2CPD8CXD3D2CPD0 BVD3D2CUCTD6CTD2CRCT D3D2 C1D2CUD3D6D1CPB9 D8CXD3D2 CCCTCRCWD2D3D0D3CVDD CPD2CS BTD4D4D0CXCRCPD8CXD3D2D7BA</sentence>
				<definiendum id="0">CPCQD7D8D6CPCRD8BA Answer Coverage ( Edit Distance ) Answer Coverage</definiendum>
				<definiendum id="1">D4D6CTB9 CRCTCSCXD2CV D7CTCRD8CXD3D2D7 CTDCCRCTD4D8 DACPD6DDCXD2CV CXD2 D8CWCT DACPD0D9CT D3CU D8CWCT D4CPD6CPD1CTD8CTD6 AB CUD6D3D1 BCBABC D8D3 BDBABCBA BYCXCVD9D6CT BK CPD2CS BL D7CWD3DB D8CWCT D4CTD6CUD3D6D1CPD2CRCT D3CU D7CTD2D8CTD2CRCT CTDCD8D6CPCRD8CXD3D2 CPD2CS D8CWCT CPDACTD6CPCVCT CPD2D7DBCTD6</definiendum>
				<definiens id="0">Precision Coverage Lead IGR+MMR+QA IGR+MMR IGR+MMR+QB IGR+MMR+QB+NE System using no qestions System using qestions B4CPB5 CBCWD3D6D8 0 0.1 0.2 0.3 0.4 0.5 Precision Coverage Lead IGR+MMR+QA IGR+MMR IGR+MMR+QB IGR+MMR+QB+NE System using no questions System using questions B4CQB5 C4D3D2CV BYCXCVD9D6CT BIBM BTDACTD6CPCVCT BVD3DACTD6CPCVCT CPD2CS BTDACTD6CPCVCT C8D6CTCRCXD7CXD3D2 D3CU CBCTD2D8CTD2CRCT BXDCD8D6CPCRD8CXD3D2 BXDCCPCRD8 C5CPD8CRCWBM D8CWCT CPDACTD6CPCVCT D6CPD8CXD3 D8CWCPD8 D8CWCT D7D9D1B9 D1CPD6CXCTD7CXD2CRD0D9CSCTCTDCCPCRD8 CPD2D7DBCTD6D7D8D6CXD2CVD7CXD2D1D3CSCTD0CPCQB9 D7D8D6CPCRD8D7B8 BEB5 BXCSCXD8 BWCXD7D8CPD2CRCTBM D8CWCT CPDACTD6CPCVCT D7CRD3D6CT D8CWCPD8 CXD7 CSCTACD2CTCS CQCPD7CTCS D3D2 D8CWCT CTCSCXD8 CSCXD7D8CPD2CRCT BXCSCXD8BWB4B5 CQCTD8DBCTCTD2 CPD2 CPD2D7DBCTD6 D7D8D6CXD2CV BTD2D7 CX CPD2CS CP D7CTD2D8CTD2CRCT D7D8D6CXD2CV CB CPD7 BYD3D6D1D9D0CP B4BLB5BM BVD3DA BXBW B4BTD2D7 CX B5 BP D1CPDC CB C4CTD2B4CBB5 A0BXCSCXD8BWB4CBBNBTD2D7 CX B5 C4CTD2B4BTD2D7 CX B5 B4BLB5 DBCWCTD6CT D8CWCT CUD9D2CRD8CXD3D2 C4CTD2B4B5 D6CTD8D9D6D2D7 D8CWCT D0CTD2CVD8CW D3CU CP D7D8D6CXD2CVBA CCCWCT D0CPCQCTD0 COC0D9D1CPD2B3 CXD2 D8CWCT ACCVD9D6CTD7 CRD3D6D6CTD7D4D3D2CSD7D8D3CPD7CTD8D3CUD7D9D1D1CPD6CXCTD7B8CTCPCRCWD3CUDBCWCXCRCW CXD7 CRD6CTCPD8CTCS CQDD D3D2CT D3CU ACDACT D7D4CTCRCXCPD0CXD7D8D7 DBCWD3 CSD3CTD7 D2D3D8 CRD6CTCPD8CT D8CWCT CRD3D6D6CTD7D4D3D2CSCXD2CVD1D3CSCTD0</definiens>
				<definiens id="1">BDBABC CXCVD6B7D1D1D6B7D5CQB7D2CTB8 DBCWCXD0CT CXCVD6B7D1D1D6B7D5CP D3D9D8B9 D4CTD6CUD3D6D1D7 D8CWCT D0CTCPCS D1CTD8CWD3CSBA C1D8 D1CXCVCWD8 CQCT CRD3D2B9 CRD0D9CSCTCSD8CWCPD8B8 CUD3D6D7CWD3D6D8D7D9D1D1CPD6CXCTD7B8DBD3D6CSD7CXD2D5D9CTD7B9 D8CXD3D2D7 CRD3D2DACTDDD7 CTD2D3D9CVCW CXD2CUD3D6D1CPD8CXD3D2 CUD3D6 D7D9D1D1CPB9 D6CXDECPD8CXD3D2BA C7D2 D8CWCT D3D8CWCTD6 CWCPD2CSB8 CXD2 D8CWCT CRCPD7CT D3CU COC4D3D2CVB3B8 D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS CXD7 D4D6CTCSD3D1CXD2CPD2CRCT D3DACTD6 CPD0D0 D3CU CQCPD7CTD0CXD2CTD7 CPD2CS D3D8CWCTD6 D4CPD6D8CXCRCXD4CPD8CXD2CVD7DDD7B9 D8CTD1D7 CPD7 D7CWD3DBD2 CXD2 BYCXCVD9D6CT BI B4CQB5B8 CPD0D8CWD3D9CVCW DBCT CWCPDACT D8D3 D8CPCZCT D2D3D8CXCRCT D3CU D8CWCT CUCPCRD8 D8CWCPD8 D7D3D1CT D3CU D8CWCT D3D8CWCTD6 D7DDD7D8CTD1D7 CSD3 D2D3D8 D9D7CT D8CWCT CXD2CUD3D6D1CPD8CXD3D2 D3CU D5D9CTD7D8CXD3D2D7BA C1D2 CRD3D1D4CPD6CXD7D3D2 DBCXD8CW CXCVD6B7D1D1D6B8 D8CWCT CXD1D4D6D3DACTD1CTD2D8 D3CU D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS CXD7 D6CTB9 D1CPD6CZCPCQD0CTB8 CPD2CS CXD8 D7CWD3DBD7 D8CWCPD8 D8CWCT D7CTD2D8CTD2CRCT DBCTCXCVCWD8 CQDD D8CWCT C9BT CTD2CVCXD2CT DBD3D6CZD7 CTABCTCRD8CXDACTD0DDBA C1D8 CXD7 CPD0D7D3 D6CTD1CPD6CZCPCQD0CT D8CWCPD8 D8CWCT CQCPD7CTD0CXD2CT CXCVD6B7D1D1D6B7D5CQD7CWD3DBD7 CRD3D1D4CPD6CPD8CXDACTD0DD CQCTD8D8CTD6 D4CTD6B9 CUD3D6D1CPD2CRCT D8CWCPD2 D3D8CWCTD6 CQCPD7CTD0CXD2CTD7 CPD2CS D3D8CWCTD6 D4CPD6B9 D8CXCRCXD4CPD8CXD2CV D7DDD7D8CTD1D7BA CCCWCT D6CTCPD7D3D2 D1CPDD CQCT D8CWCPD8 D6CTD0CPD8CXDACTD0DD D1CPD2DD D5D9CTD7D8CXD3D2D7 CPD6CT CPDACPCXD0B9 CPCQD0CT CXD2 D8CWCT CTDACPD0D9CPD8CXD3D2 D7CTD8BA C7D2 D8CWCT D3D8CWCTD6 CWCPD2CSB8 CXCVD6B7D1D1D6B7D5CQB7D2CT CXD7 D6CPD8CWCTD6 DBD3D6D7CT D8CWCPD2 CXCVD6B7D1D1D6B7D5CQBA CBCXD2CRCT D8CWCTD6CT CPD6CT D1CPD2DD D5D9CTD7D8CXD3D2D7 CXD2 D3D2CT D8D3D4CXCRB8 DBCT CSD3 D2D3D8 D7CTD0CTCRD8 D2CPD1CTCS CTD2D8CXD8CXCTD7 CPCRCRD3D6CSCXD2CV D8D3 D5D9CTD7D8CXD3D2 D8DDD4CTD7B8 CPD2CS D9D8CXD0CXDECT CPD0D0 D3CU D2CPD1CTCS CTD2D8CXD8CXCTD7 CUD3D6 D7CTD2D8CTD2CRCT DBCTCXCVCWD8CXD2CVBA C1D8 D8CWCTD6CTB9 CUD3D6CT D1CPDD D2D3D8 CQCT CTABCTCRD8CXDACTBA CFCWCXD0CTB8 CPD7 CUD3D6 COC4D3D2CVB3B8 D8CWCT CPDACTD6CPCVCT D4D6CTCRCXD7CXD3D2 D3CU CXCVD6B7D1D1D6B7D5CP CXD7 D5D9CXD8CT CWCXCVCW B4BCBABIBKBCB5B8 D8CWCT CPDACTD6B9 CPCVCT CRD3DACTD6CPCVCT CXD7 D6CTD0CPD8CXDACTD0DD D0D3DB B4BCBABFBLBDB5BA CCCWCT D6CTCPB9 D7D3D2 CXD7 D8CWCPD8 D8CWCT D4D6D3D4D3D7CTCS D1CTD8CWD3CS D8CTD2CSD7 D8D3 CTDCB9 D8D6CPCRD8 D7CTD2D8CTD2CRCTD7 DBCWCXCRCWCWCPDACT D8CWCT D7CPD1CT CRD3D2D8CTD2D8CPD7 D8CWCT D7CTD2D8CTD2CRCTD7 CPD0D6CTCPCSDD D7CTD0CTCRD8CTCSBA BYCXCVD9D6CT BDBC D7CWD3DBD7 D8CWCT CPDACTD6CPCVCT D2D9D1CQCTD6 D3CU CPD0D1D3D7D8 CXCSCTD2D8CXCRCPD0 D7CTD2B9 D8CTD2CRCTD7 CXD2 CP D7D9D1D1CPD6DDBA C1D8 CXD7 CP D4CPD6D8 D3CU D7D9CQCYCTCRD8CXDACT CPD7D7CTD7D7D1CTD2D8 CUD3D6 D7D9D1D1CPD6CXCTD7BA BTCRCRD3D6CSCXD2CV D8D3 D8CWCT</definiens>
			</definition>
</paper>

		<paper id="1183">
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>Word alignment is a challenging task aiming at the identification of translational relations between words and multi-word units in parallel corpora .</sentence>
				<definiendum id="0">Word alignment</definiendum>
				<definiens id="0">a challenging task aiming at the identification of translational relations between words and multi-word units in parallel corpora</definiens>
			</definition>
			<definition id="1">
				<sentence>Word alignment is the task of identifying translational relations between words in parallel corpora with the aim of re-using them in natural language processing .</sentence>
				<definiendum id="0">Word alignment</definiendum>
				<definiens id="0">the task of identifying translational relations between words in parallel corpora with the aim of re-using them in natural language processing</definiens>
			</definition>
			<definition id="2">
				<sentence>A clue matrix summarizes information from various sources that can be used for the identification of translation relations .</sentence>
				<definiendum id="0">clue matrix</definiendum>
				<definiens id="0">summarizes information from various sources that can be used for the identification of translation relations</definiens>
			</definition>
			<definition id="3">
				<sentence>The clue matrix in figure 2 has been obtained for a bitext segment from our English-Swedish test corpus ( the Bellow corpus ) using a set of weighted declarative and estimated clues .</sentence>
				<definiendum id="0">English-Swedish test corpus</definiendum>
				<definiens id="0">the Bellow corpus ) using a set of weighted declarative and estimated clues</definiens>
			</definition>
			<definition id="4">
				<sentence>A general word-to-word alignment L for a given bitext segment with N source language words ( s1s2 ... sN ) and M target language words ( t1t2 ... tM ) can be formally described as a set of links L = { L1 , L2 , ... , Lx } with Lx = [ sx1 , tx2 ] , x1 ∈ { 1 .</sentence>
				<definiendum id="0">general word-to-word alignment L</definiendum>
				<definiens id="0">a set of links L = { L1 , L2 , ...</definiens>
			</definition>
			<definition id="5">
				<sentence>, LDN } is a set of links LDn = bracketleftBig sn , taDn bracketrightBig with aDn ∈ { 1 .</sentence>
				<definiendum id="0">LDN }</definiendum>
				<definiens id="0">a set of links LDn = bracketleftBig sn</definiens>
			</definition>
			<definition id="6">
				<sentence>Gold standards can be re-used for additional test runs which is important when examining different parameter settings .</sentence>
				<definiendum id="0">Gold standards</definiendum>
				<definiens id="0">important when examining different parameter settings</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>Language modeling is the attempt to characterize , capture and exploit the regularities and constraints in a natural language and has been successfully applied to many domains .</sentence>
				<definiendum id="0">Language modeling</definiendum>
				<definiens id="0">the attempt to characterize , capture and exploit the regularities and constraints in a natural language and has been successfully applied to many domains</definiens>
			</definition>
			<definition id="1">
				<sentence>Given m wwwS ... 21 = , an ngram model estimates the log probability of the word string , log , by re-writing Equation ( 2.2 ) : ) ( SP ∏ = − = m i i i wwPwPSP 2 1 11 ) | ( ) ( ) ( ( 2.1 ) By taking a log function to both sides of Equation ( 2.1 ) , we have the log probability of the word string , log : ) ( SP ∑ − = − += 1 2 1 11 ) | ( log ) ( log ) ( log n i i ingram wwPwPSP ∑ = − +− + m ni i nii wwP ) | ( log 1 1 ( 2.6 ) ) ( log ) ( log ) ( log 2 1 = ∑ += m i PwPSP ( 2.2 ) where is the string length , is the i -th word in the string .</sentence>
				<definiendum id="0">ngram model</definiendum>
				<definiens id="0">estimates the log probability of the word string , log</definiens>
			</definition>
			<definition id="2">
				<sentence>That is to say , ) ( ) ( ) ( log ) ( ) ( ) ( log 1 1 1 1 1 1 1 1 i i ni i i ni i i i i wPwP wwP wPwP wwP − +− − +− − − ≈ ( 2.7 ) Obviously , the normal ngram model has the assumption : ) | ( ) | ( 1 1 1 1 − +− − ≈ i nii i i wwPwwP ( 2.3 ) ) 1 , , ( ) 1 , , ( 1 1 1 1 =≈= − +− − dwwMIdwwMI i i nii i ( 2.8 ) For example , in bigram model ( n=2 ) the probability of a word is assumed to depend only on the previous word : where ) ( ) ( ) ( log ) 1 , , ( 1 1 1 11 1 i i i i i i wPwP wwP dwwMI − − − == ) , ( 1 1 i i ww − is the mutual information of the word string pair , and ) ( ) ( ) ( log ) 1 , , 1 1 1 1 1 i i ni i i ni i wPwP wwP dw − +− − +− + == ) i w d ( 1i ni wMI − − , ( 1 1 i ni w − +− is the mutual information of the word string pair .</sentence>
				<definiendum id="0">) ( ) ( )</definiendum>
				<definiens id="0">the probability of a word is assumed to depend only on the previous word : where</definiens>
				<definiens id="1">the mutual information of the word string pair , and )</definiens>
			</definition>
			<definition id="3">
				<sentence>0 ) , , ( =dBAMI ) 1 , , ( ) 1 , , ( === dwXMIdwHMI ii , , 1 idww i = ( MI ) + ( 3.4 ) ) , , ( dBAMI reflects the change of the information content when two word strings and A B are correlated .</sentence>
				<definiendum id="0">dBAMI</definiendum>
				<definiens id="0">reflects the change of the information content when two word strings and A B are correlated</definiens>
			</definition>
			<definition id="4">
				<sentence>Then we can re-write Equation ( 3.3 ) by using Equation ( 3.4 ) , 1 1 − = i wH 1 2 − = i wX N &gt; Using an alternative view of equivalence , an ngram model is one that partitions the data into equivalence classes based on the last n-1 words in the history .</sentence>
				<definiendum id="0">ngram model</definiendum>
				<definiens id="0">one that partitions the data into equivalence classes based on the last n-1 words in the history</definiens>
			</definition>
			<definition id="5">
				<sentence>Adaptive statistical language modeling : A Maximum Entropy Approach .</sentence>
				<definiendum id="0">Adaptive statistical language modeling</definiendum>
				<definiens id="0">A Maximum Entropy Approach</definiens>
			</definition>
</paper>

		<paper id="1194">
			<definition id="0">
				<sentence>The clustering algorithm that we use is an adaptation of the Shared Nearest Neighbors ( SNN ) algorithm presented in ( Ertöz et al. , 2001 ) .</sentence>
				<definiendum id="0">clustering algorithm</definiendum>
			</definition>
			<definition id="1">
				<sentence>The similarity measure between a sense and a synset used for computing precision relies on the Lin’s similarity measure between two synsets : ) 2 ( log ) 1 ( log ) ( log2 ) 2,1 ( sPsP sP sssim + × = ( 1 ) where s is the most specific synset that subsumes s1 and s2 in the WordNet hierarchy and P ( s ) represents the probability of the synset s estimated from a reference corpus , in this case the SemCor corpus .</sentence>
				<definiendum id="0">s</definiendum>
				<definiendum id="1">P ( s )</definiendum>
				<definiens id="0">the most specific synset that subsumes s1 and s2 in the WordNet hierarchy</definiens>
			</definition>
</paper>

		<paper id="1094">
			<definition id="0">
				<sentence>We have created a reference test bed , the ISCORPUS1 ( Amigo et al. , 2004 ) which contains 72 manually generated reports summarizing the relevant information for a given topic contained in a large document set .</sentence>
				<definiendum id="0">ISCORPUS1</definiendum>
			</definition>
			<definition id="1">
				<sentence>Formally : R = jCljjCj Noise =jLnj where C is the set of key concepts manually selected by users ; L is a ( ranked ) list of terms generated by some weighting schema ; Ln is the subset of terms inLwhich do not belong to any key concept ; andCl is the subset of key concepts which are represented by at least one term in the ranked listL .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">L</definiendum>
				<definiendum id="2">; Ln</definiendum>
				<definiendum id="3">andCl</definiendum>
				<definiens id="0">the set of key concepts manually selected by users</definiens>
				<definiens id="1">a ( ranked ) list of terms generated by some weighting schema</definiens>
				<definiens id="2">the subset of terms inLwhich do not belong to any key concept ;</definiens>
				<definiens id="3">the subset of key concepts which are represented by at least one term in the ranked listL</definiens>
			</definition>
			<definition id="2">
				<sentence>TFSYNTAX Using our first experimental result , TFSYNTAX computes the weight of a term as the number of times it appears preceding a verb .</sentence>
				<definiendum id="0">TFSYNTAX</definiendum>
				<definiens id="0">computes the weight of a term as the number of times it appears preceding a verb</definiens>
			</definition>
			<definition id="3">
				<sentence>ASHRAM : Active Summarization and Markup .</sentence>
				<definiendum id="0">ASHRAM</definiendum>
				<definiens id="0">Active Summarization and Markup</definiens>
			</definition>
</paper>

		<paper id="1092">
			<definition id="0">
				<sentence>The semantic distance between two words A and B is based on the notion of nearest common ancestors ( NCA ) between A and B. NCA is defined as the set of nodes that are daughters of c ( A ) ∩ c ( B ) and that are not ancestors in c ( A ) ∩ c ( B ) .</sentence>
				<definiendum id="0">semantic distance between two</definiendum>
				<definiendum id="1">NCA</definiendum>
				<definiens id="0">based on the notion of nearest common ancestors</definiens>
				<definiens id="1">the set of nodes that are daughters of c ( A ) ∩ c ( B ) and that are not ancestors in c ( A ) ∩ c ( B )</definiens>
			</definition>
			<definition id="1">
				<sentence>The activation measure d _ is equal to the mean of the weight of each NCA calculated from A and B  : d  ( A , B ) = ∑ = + n 1i ii ) ) NCA , ( d ) , ( Please , refer to ( Dutoit and Poibeau , 2002 ) for more details and examples .</sentence>
				<definiendum id="0">Please</definiendum>
				<definiens id="0">equal to the mean of the weight of each NCA calculated from A and B  : d  ( A , B ) = ∑ = + n 1i ii )</definiens>
			</definition>
			<definition id="2">
				<sentence>Duclaye F. , Yvon F. and Collin O. ( 2003 ) Learning paraphrases to improve a question answering system .</sentence>
				<definiendum id="0">Learning</definiendum>
				<definiens id="0">paraphrases to improve a question answering system</definiens>
			</definition>
			<definition id="3">
				<sentence>Fellbaum C. ( 1998 ) WordNet : An Electronic Lexical Database , edited by Fellbaum , MIT press .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An Electronic Lexical Database , edited by Fellbaum , MIT press</definiens>
			</definition>
</paper>

		<paper id="1086">
</paper>

		<paper id="1038">
</paper>

		<paper id="1110">
			<definition id="0">
				<sentence>Finally , the language used in spoken dialogue differs from language used in texts .</sentence>
				<definiendum id="0">language</definiendum>
				<definiens id="0">used in spoken dialogue differs from language used in texts</definiens>
			</definition>
			<definition id="1">
				<sentence>Semantic similarity sim between words w1 and w2 is defined as given in Equation 1 : simc1 ; c2 = loglen ( c1 ; c2 ) 2 D ( 1 ) c1 and c2 are concepts corresponding to w1 and w2.1 len ( c1 ; c2 ) is the length of the shortest path between them .</sentence>
				<definiendum id="0">Semantic similarity sim</definiendum>
				<definiendum id="1">w2</definiendum>
				<definiendum id="2">c2 )</definiendum>
				<definiens id="0">1 ) c1 and c2 are concepts corresponding to w1 and w2.1 len ( c1 ;</definiens>
				<definiens id="1">the length of the shortest path between them</definiens>
			</definition>
			<definition id="2">
				<sentence>Formally , semantic relatedness sim between words w1 and w2 is defined by the following equation : simc1 ; c2 = Xscore ( R1 ( c1 ) ; R2 ( c2 ) ) ( 2 ) where R is a set of semantic relations , score ( ) is a function accepting two glosses as input , finding overlaps between them , and returning a corresponding relatedness score .</sentence>
				<definiendum id="0">semantic relatedness sim</definiendum>
				<definiendum id="1">w2</definiendum>
				<definiendum id="2">score ( )</definiendum>
				<definiens id="0">the following equation : simc1 ; c2 = Xscore ( R1 ( c1 ) ; R2 ( c2 ) ) ( 2 ) where R is a set of semantic relations</definiens>
				<definiens id="1">a function accepting two glosses as input , finding overlaps between them , and returning a corresponding relatedness score</definiens>
			</definition>
			<definition id="3">
				<sentence>concepts in the taxonomy ( see Equation 3 ) : simc1 ; c2 = max c2S ( c1 ; c2 ) [ log p ( c ) ] ( 3 ) where S ( c1 ; c2 ) is the set of concepts which subsume both c1 and c2 and log p ( c ) is the negative log likelihood ( information content ) .</sentence>
				<definiendum id="0">c2 )</definiendum>
				<definiendum id="1">p ( c )</definiendum>
				<definiendum id="2">information content</definiendum>
				<definiens id="0">see Equation 3 ) : simc1 ; c2 = max c2S ( c1 ; c2 ) [ log p ( c ) ] ( 3 ) where S ( c1 ;</definiens>
				<definiens id="1">the set of concepts which subsume both c1 and c2 and log</definiens>
			</definition>
			<definition id="4">
				<sentence>The distance between two concepts c1 and c2 is formalized as given in Equation 4 : distc1 ; c2 = IC ( c1 ) + IC ( c2 ) 2 IC ( lso ( c1 ; c2 ) ) ( 4 ) where IC is the information content value of the concept , and lso ( c1 ; c2 ) is the closest subsumer of the two concepts .</sentence>
				<definiendum id="0">IC</definiendum>
				<definiens id="0">the information content value of the concept</definiens>
			</definition>
			<definition id="5">
				<sentence>The semantic similarity score SSfinal for CRUttn and CRD is then defined as the average pairwise semantic similarity between all concepts in CRUttn and CRD : SSfinal = P # CRUttn i=1 P # CRD j=1 SSscore ( i ; j ) # CRUttn # CRD Computing SSfinal results in a list of utterances with scores from the respective scoring methods , Table 4 .</sentence>
				<definiendum id="0">semantic similarity score SSfinal</definiendum>
				<definiens id="0">the average pairwise semantic similarity between all concepts in CRUttn and CRD : SSfinal = P # CRUttn i=1 P # CRD j=1 SSscore ( i ; j ) # CRUttn # CRD Computing SSfinal results in a list of utterances with scores from the respective scoring methods</definiens>
			</definition>
			<definition id="6">
				<sentence>An utterance is a complete unit of speech spoken by a single speaker , while a turn is a joint sequence of utterances produced by one speaker .</sentence>
				<definiendum id="0">utterance</definiendum>
				<definiens id="0">a complete unit of speech spoken by a single speaker</definiens>
				<definiens id="1">a joint sequence of utterances produced by one speaker</definiens>
			</definition>
			<definition id="7">
				<sentence>PP is the number of cases where the individual scoring method and the Gold Standard agree .</sentence>
				<definiendum id="0">PP</definiendum>
			</definition>
			<definition id="8">
				<sentence>ICF contains a list of synsets along with their part of speech and frequency count .</sentence>
				<definiendum id="0">ICF</definiendum>
				<definiens id="0">contains a list of synsets along with their part of speech and frequency count</definiens>
			</definition>
			<definition id="9">
				<sentence>, WordNet : An Electronic Lexical Database , pp .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>Bilingual word alignment is first introduced as an intermediate result in statistical machine translation ( SMT ) ( Brown et al. 1993 ) .</sentence>
				<definiendum id="0">Bilingual word alignment</definiendum>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>Finally , underspecification ( Egg et al. , 2001 ; Gupta and Lamping , 1998 ; Copestake et al. , 2004 ) introduces a new level of representation , which can be computed functionally from a syntactic analysis and encapsulates semantic ambiguity in a way that supports the enumeration of all semantic readings by need .</sentence>
				<definiendum id="0">representation</definiendum>
				<definiens id="0">a syntactic analysis and encapsulates semantic ambiguity in a way that supports the enumeration of all semantic readings by need</definiens>
			</definition>
			<definition id="1">
				<sentence>XDG is a description language over finite labelled graphs .</sentence>
				<definiendum id="0">XDG</definiendum>
				<definiens id="0">a description language over finite labelled graphs</definiens>
			</definition>
			<definition id="2">
				<sentence>A lexicon for the dimension D is a set Lex ⊆ Fea → Val of total feature assignments ( or lexical entries ) .</sentence>
				<definiendum id="0">lexicon for the dimension D</definiendum>
			</definition>
			<definition id="3">
				<sentence>A D-structure , representing an analysis on dimension D , is a triple ( V , E , F ) of a set V of nodes , a set E ⊆V ×V ×Lab of directed labelled edges , and an assignment F : V → ( Fea → Val ) of lexical entries to nodes .</sentence>
				<definiendum id="0">D-structure</definiendum>
			</definition>
			<definition id="4">
				<sentence>An XDG grammar ( ( Labi , Feai , Vali , Prii ) ni=1 , Pri , Lex ) consists of n dimensions , multi-dimensional principles Pri , and a lexicon Lex .</sentence>
				<definiendum id="0">XDG grammar (</definiendum>
				<definiendum id="1">Lex )</definiendum>
				<definiens id="0">consists of n dimensions , multi-dimensional principles Pri</definiens>
			</definition>
			<definition id="5">
				<sentence>An XDG analysis ( V , Ei , Fi ) ni=1 is an element of Ana = Str1×···×Strn where all dimensions share the same set of nodes V .</sentence>
				<definiendum id="0">XDG analysis</definiendum>
			</definition>
			<definition id="6">
				<sentence>Because XDG allows us to write grammars with completely free word order , XDG solving is an NPcomplete problem ( Koller and Striegnitz , 2002 ) .</sentence>
				<definiendum id="0">XDG solving</definiendum>
				<definiens id="0">us to write grammars with completely free word order</definiens>
			</definition>
			<definition id="7">
				<sentence>The semantic lexicon is defined as follows ; “L ( w ) ” should be read as “L ( v ) , where v is a node for the word w” .</sentence>
				<definiendum id="0">semantic lexicon</definiendum>
				<definiendum id="1">“L ( w ) ”</definiendum>
				<definiendum id="2">v</definiendum>
				<definiens id="0">a node for the word w”</definiens>
			</definition>
</paper>

		<paper id="1111">
			<definition id="0">
				<sentence>Once these patterns have been learnt , the algorithm for finding new is-a relations runs in O ( n ) , where n is the number of sentences .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>CBC ( Clustering by Committee ) proposed by Pantel and Lin ( 2002 ) achieves high recall and precision in generating similarity lists of words discriminated by their meaning and senses .</sentence>
				<definiendum id="0">CBC</definiendum>
				<definiens id="0">achieves high recall and precision in generating similarity lists of words discriminated by their meaning and senses</definiens>
			</definition>
			<definition id="2">
				<sentence>We then construct a mutual information vector MI ( e ) = ( mi e1 , mi e2 , … , mi em ) for each word e , where mi ef is the pointwise mutual information between word e and context f , which is defined as : N c N c N c ef m j ej n i if ef mi ∑ ∑ = = × = 1 1 log Table 2 .</sentence>
				<definiendum id="0">mi ef</definiendum>
				<definiens id="0">a mutual information vector MI ( e ) = ( mi e1 , mi e2 , … , mi em ) for each word e</definiens>
				<definiens id="1">the pointwise mutual information between word e and context f</definiens>
			</definition>
			<definition id="3">
				<sentence>TOOL 15 GB ORPUS 1 TB CORPUS POS Tagger 2 days 125 days NP Chunker 3 days 214 days Dependency Parser 56 days 10.2 years Syntactic Parser 5.8 years 388.4 years 772 where n is the number of elements to be clustered , c ef is the frequency count of word e in grammatical context f , and N is the total frequency count of all features of all words .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">c ef</definiendum>
				<definiendum id="2">N</definiendum>
				<definiens id="0">the number of elements to be clustered</definiens>
			</definition>
			<definition id="4">
				<sentence>A committee is a set of representative elements that unambiguously describe the members of a possible class .</sentence>
				<definiendum id="0">committee</definiendum>
				<definiens id="0">a set of representative elements that unambiguously describe the members of a possible class</definiens>
			</definition>
			<definition id="5">
				<sentence>Applying a POS tagger ( Brill 1995 ) gives the following output : Surface Platinum is a precious metal .</sentence>
				<definiendum id="0">Surface Platinum</definiendum>
				<definiens id="0">a precious metal</definiens>
			</definition>
			<definition id="6">
				<sentence>Surface Molybdenum is a metal .</sentence>
				<definiendum id="0">Surface Molybdenum</definiendum>
				<definiens id="0">a metal</definiens>
			</definition>
			<definition id="7">
				<sentence>Multilevel representation is defined as the different levels of a sentence such as the lexical level and POS level .</sentence>
				<definiendum id="0">Multilevel representation</definiendum>
				<definiens id="0">the different levels of a sentence such as the lexical level and POS level</definiens>
			</definition>
			<definition id="8">
				<sentence>The algorithm consists of two parts : calculation of the minimal edit distance and retrieval of an optimal pattern .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiens id="0">consists of two parts : calculation of the minimal edit distance and retrieval of an optimal pattern</definiens>
			</definition>
			<definition id="9">
				<sentence>Since we treat each sentences independently from others , the algorithm runs in linear time O ( n ) over the corpus size , where n is number of sentences in the corpus .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">number of sentences in the corpus</definiens>
			</definition>
			<definition id="10">
				<sentence>The recall of a system A , R A , is given by the following formula : C C R A A = where C A is the number of correct is-a relationships extracted by A and C is the total number of correct is-a relationships in the corpus .</sentence>
				<definiendum id="0">recall of a system A , R A</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">given by the following formula : C C R A A = where C A is the number of correct is-a relationships extracted by A and</definiens>
				<definiens id="1">the total number of correct is-a relationships in the corpus</definiens>
			</definition>
</paper>

		<paper id="1155">
			<definition id="0">
				<sentence>Each TCT describes a translation example ( a pair of bilingual sentences ) .</sentence>
				<definiendum id="0">TCT</definiendum>
			</definition>
			<definition id="1">
				<sentence>( TCT ) Representation TCT structure , as an extension of structure stringtree correspondence representation ( Boitet and Zaharin , 1988 ) , is a general structure that can flexibly associate not only the string of a sentence to its syntactic structure in source language , but also allow the language annotator to explicitly associate the string from its translation in target language for the purpose to describe the correspondences between different languages .</sentence>
				<definiendum id="0">TCT ) Representation TCT structure</definiendum>
				<definiens id="0">a general structure that can flexibly associate not only the string of a sentence to its syntactic structure in source language , but also allow the language annotator to explicitly associate the string from its translation in target language for the purpose to describe the correspondences between different languages</definiens>
			</definition>
			<definition id="2">
				<sentence>While the translation correspondence between the subtree of source sentence and substring in the target sentence is denoted by the interval assigned to the STC ( n ) of each node , e.g. the subtree rooted at shaded node , NP , with interval , STC ( NP ) =1-3 , corresponds to the translation fragment ( substring ) “更衣室” in target sentence .</sentence>
				<definiendum id="0">STC</definiendum>
				<definiens id="0">n ) of each node , e.g. the subtree rooted at shaded node , NP , with interval ,</definiens>
			</definition>
			<definition id="3">
				<sentence>Here , to facilitate such examples representation , we use the Translation Corresponding Tree as the basic annotation structure .</sentence>
				<definiendum id="0">Translation Corresponding Tree</definiendum>
				<definiens id="0">the basic annotation structure</definiens>
			</definition>
</paper>

		<paper id="1107">
			<definition id="0">
				<sentence>Support vector machine ( SVM ) ( Vapnik 95 ) is a technique of machine learning based on statistical learning theory .</sentence>
				<definiendum id="0">Support vector machine</definiendum>
				<definiens id="0">a technique of machine learning based on statistical learning theory</definiens>
			</definition>
			<definition id="1">
				<sentence>min 12 kwk+C0 lP i »i s : t : yi ( w : xi +b ) ‚ 1¡»i »i ‚ 0 ( 1 ) where C0 is the constant and »i is a slack variable for the non-separable case .</sentence>
				<definiendum id="0">C0</definiendum>
				<definiendum id="1">»i</definiendum>
				<definiens id="0">the constant and</definiens>
				<definiens id="1">a slack variable for the non-separable case</definiens>
			</definition>
			<definition id="2">
				<sentence>( 2 ) where fii is the Lagrange multiple , and K ( x0 ; x00 ) is a kernel function , the SVM calculates similarity between two arguments x0 and x00 .</sentence>
				<definiendum id="0">fii</definiendum>
				<definiendum id="1">K</definiendum>
			</definition>
			<definition id="3">
				<sentence>An Input list consists of a sequence of words subsumed by the tree t where each word in the Input list is labelled with the name of all syntactic constituents in t. Let CSTACK be a stack that consists of sub trees in order to rewrite a small tree .</sentence>
				<definiendum id="0">Input list</definiendum>
				<definiens id="0">consists of a sequence of words subsumed by the tree t where each word in the Input list is labelled with the name of all syntactic constituents in t. Let CSTACK be a stack that consists of sub trees in order to rewrite a small tree</definiens>
			</definition>
			<definition id="4">
				<sentence>† REDUCE ( lk ; X ) action pops the lk syntactic trees located at the top of CSTACK and combines them in a new tree , where lk is an integer and X is a grammar symbol .</sentence>
				<definiendum id="0">lk</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">the lk syntactic trees located at the top of CSTACK and combines them in a new tree</definiens>
			</definition>
			<definition id="5">
				<sentence>† RESTORE X action takes the X element in RSTACK and moves it into the Input list , where X is a subtree .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a subtree</definiens>
			</definition>
			<definition id="6">
				<sentence>Figure 1 shows an example of applying a sequence of actions to rewrite the input sentence ( a ; b ; c ; d ; e ) , when each character is a word .</sentence>
				<definiendum id="0">character</definiendum>
				<definiens id="0">a word</definiens>
			</definition>
			<definition id="7">
				<sentence>Figure 1 : An Example of the Rewriting Process SVMs As mentioned above , the action for each conflguration can be decided by using a learning rule , which maps a context to an action .</sentence>
				<definiendum id="0">learning rule</definiendum>
				<definiens id="0">An Example of the Rewriting Process SVMs As mentioned above</definiens>
				<definiens id="1">maps a context to an action</definiens>
			</definition>
			<definition id="8">
				<sentence>Here , a sample in our training data consists of pairs of a feature vector and an action .</sentence>
				<definiendum id="0">data</definiendum>
				<definiens id="0">consists of pairs of a feature vector and an action</definiens>
			</definition>
			<definition id="9">
				<sentence>The conditional probability pfi ( ajc ) is estimated using a variant of probabilistic support vector machine , which is described in the following sections .</sentence>
				<definiendum id="0">conditional probability pfi</definiendum>
				<definiens id="0">estimated using a variant of probabilistic support vector machine , which is described in the following sections</definiens>
			</definition>
			<definition id="10">
				<sentence>Assume that uij are pairwise probabilities of the model subject to the condition that uij = pi= ( pi+pj ) : In ( Hastie 98 ) , the authors proposed to minimize the Kullback-Leibler ( KL ) distance between the rij and uij l ( p ) = X i6=j nijrijlogriju ij ( 4 ) where rij and uij are the probabilities of a pairwise ai and aj in the estimated model and in our model , respectively , and nij is the number of training data in which their classes are ai or aj : To flnd the minimizer of equation ( 6 ) , they flrst calculate @ l ( p ) @ pi = X i6=j nij ( ¡rijp i + 1p i +pj ) : Thus , letting ¢l ( p ) = 0 , they proposed to flnd a point satisfying X j : j6=i nijuij = X j : j6=i nijrij ; kP i=1 pi = 1 ; where i = 1 ; 2 ; : : : k and pi &gt; 0 : Such a point can be obtained by using an algorithm described elsewhere in ( Hastie 98 ) .</sentence>
				<definiendum id="0">nij</definiendum>
				<definiens id="0">a pairwise ai and aj in the estimated model and in our model , respectively , and</definiens>
				<definiens id="1">the number of training data in which their classes are ai or aj : To flnd the minimizer of equation ( 6 ) , they flrst calculate @ l ( p ) @ pi = X i6=j nij</definiens>
			</definition>
			<definition id="11">
				<sentence>Assume that our class labels belong to l groups : M = fm1 ; m2 : : : mi ; : : : ; mlg ; where l is a number of groups and mi is a group e.g. , SHIFT , REDUCE , ... , ASSIGN TYPE .</sentence>
				<definiendum id="0">l</definiendum>
				<definiendum id="1">mi</definiendum>
				<definiens id="0">a group e.g. , SHIFT , REDUCE , ...</definiens>
			</definition>
			<definition id="12">
				<sentence>Score ( s ) = Y ai2d ( s ) p ( aijci ) ( 6 ) where ci is the context in which ai was decided .</sentence>
				<definiendum id="0">Score</definiendum>
				<definiendum id="1">ci</definiendum>
				<definiens id="0">the context in which ai was decided</definiens>
			</definition>
			<definition id="13">
				<sentence>This algorithm uses a breadth-flrst search which does not expand the entire frontier , but instead expands at most the top K scoring incomplete conflgurations in the frontier ; it is terminated when it flnds M completed reduced sentences ( CL is a list of reduced trees ) , or when all hypotheses have been exhausted .</sentence>
				<definiendum id="0">CL</definiendum>
			</definition>
			<definition id="14">
				<sentence>Note that the function get-context ( hi ; j ) obtains the current context of the jth conflguration in hi ; where hi is a heap at step i : The function Insert ( s , h ) ensures that the heap h is sorted according to the score of each element in h : Essentially , in implementation we can use a dictionary of contexts and actions observed from the training data in order to reduce the number of actions to explore for a current context .</sentence>
				<definiendum id="0">hi</definiendum>
				<definiens id="0">The function Insert ( s , h ) ensures that the heap h is sorted according to the score of each element in h : Essentially , in implementation we can use a dictionary of contexts and actions observed from the training data in order to reduce the number of actions to explore for a current context</definiens>
			</definition>
</paper>

		<paper id="1159">
			<definition id="0">
				<sentence>The CSJ is the biggest spontaneous speech corpus in the world , and it is a collection of monologues and dialogues , the majority being monologues such as academic presentations .</sentence>
				<definiendum id="0">CSJ</definiendum>
				<definiens id="0">the biggest spontaneous speech corpus in the world</definiens>
			</definition>
			<definition id="1">
				<sentence>The CSJ includes transcriptions of speeches as well as audio recordings .</sentence>
				<definiendum id="0">CSJ</definiendum>
				<definiens id="0">includes transcriptions of speeches as well as audio recordings</definiens>
			</definition>
			<definition id="2">
				<sentence>Each bunsetsu consists of one or more morphemes .</sentence>
				<definiendum id="0">bunsetsu</definiendum>
			</definition>
			<definition id="3">
				<sentence>0 : Morphological Analysis 1 : Sentence Boundary Detection ( Baseline ) 3 : Dependency Structure Analysis ( Baseline ) 2 : Sentence Boundary Detection ( SVM ) 5 : Sentence Boundary Detection ( Language model ) 6 : Sentence Boundary Detection ( SVM ) 7 : Dependency Structure Analysis ( Again ) clause expression pause duration word 3-gram model pause duration clause expression word information ( A ) ( B ) word Information distance between bunsetsus ( C ) ( A ) + information of dependencies ( B ) + information of dependencies 4 : Dependency Structure Analysis Figure 1 : Outline of dependency structure analysis and sentence boundary detection .</sentence>
				<definiendum id="0">Sentence Boundary Detection</definiendum>
				<definiendum id="1">Sentence Boundary Detection</definiendum>
				<definiendum id="2">Sentence Boundary Detection</definiendum>
				<definiens id="0">Sentence Boundary Detection ( SVM ) 7 : Dependency Structure Analysis ( Again ) clause expression pause duration word 3-gram model pause duration clause expression word information ( A ) ( B ) word Information distance between bunsetsus ( C ) ( A ) + information of dependencies ( B ) + information of dependencies 4 : Dependency Structure Analysis Figure 1 : Outline of dependency structure analysis and sentence boundary detection</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>Ctm : An example-based translation aid system .</sentence>
				<definiendum id="0">Ctm</definiendum>
				<definiens id="0">An example-based translation aid system</definiens>
			</definition>
</paper>

		<paper id="1116">
			<definition id="0">
				<sentence>The major problems are ; AF Words are often abbreviated AF There are many spelling errors AF Case is used inconsistently Shallow processing is suitable for such noisy data , so we used a Markov-model-based tagger , essentially the same as the one described in ( Charniak , 1993 ) in our experiments 2 .</sentence>
				<definiendum id="0">AF Words</definiendum>
				<definiens id="0">suitable for such noisy data</definiens>
			</definition>
			<definition id="1">
				<sentence>3 http : // www.cis.upenn.edu/ treebank/ rank candidate 1 batt 2 batterie 3 bat 4 BTBTBTBT cover 6 batterry 7 BT BT BT BT BT BT BT BT BT BT adapter 8 bezel 9 BT BT BT BT BT BT BT BT BT BT cheque 10 BTBTBTBT screw Table 3 : battery’s Synonymous Expression Candidates from the Entire Corpus Author A rank candidate 1 battery 2 controller 3 BT BT BT BT BT BT BT BT Cover 5 BTBTBTBT screw 6 mark 7 BT BT BT BT BT BT BT BT BT BT cheque 8 diskette 9 checkmark 10 boot Author B rank candidate 1 batt 2 form 3 protector 6 BT BT BT BT BT BT BT BT BT BT adapter 7 mouse 8 BT BT BT BT BT BT BT BT BT BT cheque 9 checkmark 10 process Table 4 : Noise Candidates from Each Author’s Corpus word .</sentence>
				<definiendum id="0">BT BT BT BT BT BT BT BT BT BT cheque</definiendum>
			</definition>
			<definition id="2">
				<sentence>Therefore we consider only syntactic features : dependency pairs , which consist of nouns , verbs , and their relationships .</sentence>
				<definiendum id="0">dependency pairs</definiendum>
			</definition>
			<definition id="3">
				<sentence>Not only synonymous expressions , but abbreviation is one of the most important issues in term aggregation .</sentence>
				<definiendum id="0">abbreviation</definiendum>
				<definiens id="0">one of the most important issues in term aggregation</definiens>
			</definition>
			<definition id="4">
				<sentence>Gasperin ( Gasperin , 2001 ) indicated the specific prepositions are relevant to characterize the significant syntactic contexts used for the measurement of word similarity , considering what prepositions do and do not depend on personal writing style remains as future work .</sentence>
				<definiendum id="0">Gasperin</definiendum>
				<definiens id="0">relevant to characterize the significant syntactic contexts used for the measurement of word similarity</definiens>
			</definition>
</paper>

		<paper id="1190">
			<definition id="0">
				<sentence>Nonlinear principal components ( Diamantaras and Kung , 1996 ) may be defined as follows .</sentence>
				<definiendum id="0">Nonlinear principal components</definiendum>
			</definition>
			<definition id="1">
				<sentence>Then the lth nonlinear principal component of any test vector xt is defined as ylt = Msummationdisplay i=1 ˆαli ( Φ ( xi ) ·Φ ( xt ) ) ( 6 ) where ˆαli is the lth element of ˆαl .</sentence>
				<definiendum id="0">lth nonlinear principal component of any test vector xt</definiendum>
			</definition>
			<definition id="2">
				<sentence>To extract nonlinear principal components efficiently , note that in both Equations ( 5 ) and ( 6 ) the explicit form of Φ ( xi ) is required only in the form of ( Φ ( xi ) ·Φ ( xj ) ) , i.e. , the dot product of vectors in F. This means that we can calculate the nonlinear principal components by substituting a kernel function k ( xi , xj ) for ( Φ ( xi ) ·Φ ( xj ) ) in Equations ( 5 ) and ( 6 ) without knowing the mapping Φ explicitly ; instead , the mapping Φ is implicitly defined by the kernel function .</sentence>
				<definiendum id="0">Φ</definiendum>
			</definition>
			<definition id="3">
				<sentence>The supervised KPCA model significantly outperforms a na¨ıve Bayes model , and a maximum entropy model , which are among the top performing models for WSD .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
				<definiens id="0">are among the top performing models for WSD</definiens>
			</definition>
</paper>

		<paper id="1140">
			<definition id="0">
				<sentence>Another indicator of a simpler POS n-gram grammar in medical narratives is the fact that the absolute number of POS n-gram types common to NEGRA and MED is much lower than for NEGRA and NEWS .</sentence>
				<definiendum id="0">MED</definiendum>
				<definiens id="0">much lower than for NEGRA and NEWS</definiens>
			</definition>
			<definition id="1">
				<sentence>TNT : A statistical part-of-speech tagger .</sentence>
				<definiendum id="0">TNT</definiendum>
				<definiens id="0">A statistical part-of-speech tagger</definiens>
			</definition>
</paper>

		<paper id="1177">
			<definition id="0">
				<sentence>A noun , a3 , is thus described by a set of co-occurrence triples a94 a3a6a15a33a68a16a15a17a95a97a96 and associated frequencies , where a68 is a grammatical relation and a95 is a possible cooccurrence with a3 in that relation .</sentence>
				<definiendum id="0">a68</definiendum>
				<definiendum id="1">a95</definiendum>
				<definiens id="0">a grammatical relation</definiens>
				<definiens id="1">a possible cooccurrence with a3 in that relation</definiens>
			</definition>
			<definition id="1">
				<sentence>If a98a41a31a32a3a99a34 is the set of co-occurrence types a31a32a68a16a15a33a95a100a34 such that a101a102a31a32a3a37a15a17a68a16a15a33a95a100a34 is positive then the similarity between two nouns , a3 and a11 , can be computed as : a27a29a28a30a28a26a31a32a3a37a15a17a11a103a34a76a7 a78 a84a105a104a36a106a55a30a86 a73a16a107 a84a85a5a19a86a109a108 a107 a84 a71 a86 a31a110a101a102a31a32a3a6a15a33a68a16a15a17a95a14a34a54a111a56a101a102a31a32a11a112a15a33a68a16a15a33a95a100a34a87a34 a78 a84a85a104a36a106a55a30a86 a73a12a107 a84a105a5a14a86 a101a102a31a32a3a6a15a33a68a16a15a87a95a100a34a54a111 a78 a84a85a104a36a106a55a30a86 a73a16a107 a84 a71 a86 a101a102a31a32a11a112a15a33a68a16a15a17a95a14a34 where : a101a102a31a32a3a6a15a33a68a16a15a17a95a14a34a14a7a114a113a22a115a117a116a64a118 a31a36a95a76a119a120a3a122a121a46a68a123a34 a118 a31a32a95a112a119a120a68a123a34 A thesaurus entry of size a2 for a target noun a3 is then defined as the a2 most similar nouns to a3 .</sentence>
				<definiendum id="0">thesaurus entry</definiendum>
				<definiens id="0">the set of co-occurrence types a31a32a68a16a15a33a95a100a34 such that a101a102a31a32a3a37a15a17a68a16a15a33a95a100a34 is positive then the similarity between two nouns , a3 and a11 , can be computed as : a27a29a28a30a28a26a31a32a3a37a15a17a11a103a34a76a7 a78 a84a105a104a36a106a55a30a86 a73a16a107 a84a85a5a19a86a109a108 a107 a84 a71 a86 a31a110a101a102a31a32a3a6a15a33a68a16a15a17a95a14a34a54a111a56a101a102a31a32a11a112a15a33a68a16a15a33a95a100a34a87a34 a78 a84a85a104a36a106a55a30a86 a73a12a107 a84a105a5a14a86 a101a102a31a32a3a6a15a33a68a16a15a87a95a100a34a54a111 a78 a84a85a104a36a106a55a30a86 a73a16a107 a84 a71 a86 a101a102a31a32a11a112a15a33a68a16a15a17a95a14a34 where : a101a102a31a32a3a6a15a33a68a16a15a17a95a14a34a14a7a114a113a22a115a117a116a64a118 a31a36a95a76a119a120a3a122a121a46a68a123a34 a118 a31a32a95a112a119a120a68a123a34 A</definiens>
			</definition>
			<definition id="2">
				<sentence>Jiang and Conrath specify a distance measure : a136a6a49a93a137 a71 a31a32a28a117a124a123a15a33a28a30a125a138a34a56a7 a101a54a126a127a31a32a28a123a124a16a34a66a111a139a101a54a126a127a31a36a28a30a125a29a34a140a129a141a125a142a77a56a101a54a126a127a31a36a28a30a143a29a34 , where the third class , a28a30a143 is the most informative , or most specific superordinate synset of the two senses a28a117a124 and a28a30a125 .</sentence>
				<definiendum id="0">a28a30a143</definiendum>
				<definiens id="0">the most informative</definiens>
			</definition>
			<definition id="3">
				<sentence>The Reuters corpus ( Rose et al. , 2002 ) is a collection of about 810,000 Reuters , English Language News stories ( covering the period August 1996 to August 1997 ) .</sentence>
				<definiendum id="0">Reuters corpus</definiendum>
			</definition>
			<definition id="4">
				<sentence>The SPORT corpus consists of 35317 documents ( about 9.1 million words ) .</sentence>
				<definiendum id="0">SPORT corpus</definiendum>
			</definition>
			<definition id="5">
				<sentence>The FINANCE corpus consists of 117734 documents ( about 32.5 million words ) .</sentence>
				<definiendum id="0">FINANCE corpus</definiendum>
			</definition>
</paper>

		<paper id="1174">
			<definition id="0">
				<sentence>Here , “the price” means “the price of a ticket” and “the roof” means “the roof of a house.”</sentence>
				<definiendum id="0">“the price”</definiendum>
			</definition>
			<definition id="1">
				<sentence>Most nouns have their indispensable or requisite entities : “price” is a price of some goods or service , “roof” is a roof of some building , “coach” is a coach of some sport , and “virus” is a virus causing some disease .</sentence>
				<definiendum id="0">“roof”</definiendum>
				<definiendum id="1">“virus”</definiendum>
				<definiens id="0">a coach of some sport , and</definiens>
				<definiens id="1">a virus causing some disease</definiens>
			</definition>
			<definition id="2">
				<sentence>NTT Semantic Feature Dictionary consists of a semantic feature tree , whose 3,000 nodes are semantic features , and a nominal dictionary containing about 300,000 nouns , each of which is given one or more appropriate semantic features .</sentence>
				<definiendum id="0">NTT Semantic Feature Dictionary</definiendum>
				<definiens id="0">consists of a semantic feature tree , whose 3,000 nodes are semantic features , and a nominal dictionary containing about 300,000 nouns , each of which is given one or more appropriate semantic features</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , a Japanese dictionary for children , Reikai Shougaku Kokugojiten , or RSK ( Tajika , 1997 ) , gives the definitions of the word coach and virus as follows1 : coach a person who teaches technique in some sport virus a living thing even smaller than bacteria which causes infectious disease like influenza 1Although our method handles Japanese noun phrases by using Japanese definition sentences , in this paper we use their English translations for the explanation .</sentence>
				<definiendum id="0">RSK</definiendum>
				<definiens id="0">gives the definitions of the word coach and virus as follows1 : coach a person who teaches technique in some</definiens>
			</definition>
			<definition id="4">
				<sentence>Dictionary-based analysis ( DBA ) tries to find a correspondence between Nm and an obligatory case of Nh by utilizing RSK and NTT Semantic Feature Dictionary , by the following process : tion sentences of Nh .</sentence>
				<definiendum id="0">Dictionary-based analysis</definiendum>
				<definiendum id="1">DBA</definiendum>
			</definition>
			<definition id="5">
				<sentence>For the second noun ticket , soccer , which is a nominal modifier of ticket , is examined first .</sentence>
				<definiendum id="0">soccer</definiendum>
				<definiens id="0">a nominal modifier of ticket , is examined first</definiens>
			</definition>
</paper>

		<paper id="1176">
			<definition id="0">
				<sentence>Kubota et al. have extracted Japanese KATAKANA variants by first transforming KATAKANA words to directed graphs based on rewrite rules and by then checking whether the directed graphs contain the same labeled path or not ( Kubota et al. , 1993 ) .</sentence>
				<definiendum id="0">KATAKANA</definiendum>
			</definition>
			<definition id="1">
				<sentence>For example , our system collects three KATAKANA words “ ������~����� ( Ludwig Erhard-1 ) , ” “� ( Soviet ) , ” “������~����� ( Ludwig Erhard-2 ) , ” “��� ( Germany ) ” from the following sentences .</sentence>
				<definiendum id="0">KATAKANA</definiendum>
				<definiens id="0">words “ ������~����� ( Ludwig Erhard-1 ) , ” “� ( Soviet ) , ” “������~����� ( Ludwig Erhard-2 ) , ” “��� ( Germany ) ” from the following sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>Here , N represents the frequency of a word in a context .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the frequency of a word in a context</definiens>
			</definition>
</paper>

		<paper id="1098">
			<definition id="0">
				<sentence>Mutual Information is a common tool to be applied under this situation .</sentence>
				<definiendum id="0">Mutual Information</definiendum>
				<definiens id="0">a common tool to be applied under this situation</definiens>
			</definition>
</paper>

		<paper id="1050">
			<definition id="0">
				<sentence>NOUN CONCRETE ABSTRACT AGENT PLACE CONCRETE HUMAN ORGANIZATION ABSTRACTEVENTABSTRACT RELATION TIMEPOSITIONQUANTITY. . . . Figure 1 : The upper levels of the NTT thesaurus .</sentence>
				<definiendum id="0">NOUN CONCRETE ABSTRACT AGENT PLACE CONCRETE HUMAN ORGANIZATION ABSTRACTEVENTABSTRACT RELATION TIMEPOSITIONQUANTITY.</definiendum>
			</definition>
			<definition id="1">
				<sentence>The closest case component plays an important role to determine the usage of a verb .</sentence>
				<definiendum id="0">closest case component</definiendum>
				<definiens id="0">plays an important role to determine the usage of a verb</definiens>
			</definition>
			<definition id="2">
				<sentence>The score of a matching pattern is defined as the sum of similarities of case assignments .</sentence>
				<definiendum id="0">score of a matching pattern</definiendum>
				<definiens id="0">the sum of similarities of case assignments</definiens>
			</definition>
			<definition id="3">
				<sentence>Appendix A Similarity between examples The similarity between two examples e1 , e2 is calculated using the NTT thesaurus as follows : sim ( e1 , e2 ) = maxx∈s1 , y∈s2 sim ( x , y ) ( 1 ) sim ( x , y ) = 2Ll x +ly where x , y are semantic features , and s1 , s2 are sets of semantic markers of e1 , e2 respectively .</sentence>
				<definiendum id="0">NTT thesaurus</definiendum>
			</definition>
			<definition id="4">
				<sentence>Suppose the result of the case slot alignment of F1 and F2 is as follows : F1 : C11 , C12 , ··· C1l ··· C1m arrowbothv arrowbothv arrowbothv F2 : C21 , C22 , ··· C2l ··· C2n where Cxx denotes a case slot which contains several case examples .</sentence>
				<definiendum id="0">Cxx</definiendum>
				<definiens id="0">a case slot which contains several case examples</definiens>
			</definition>
</paper>

		<paper id="1066">
			<definition id="0">
				<sentence>A word segmentation process is a prerequisite for natural language processing ( NLP ) of non-segmented language family .</sentence>
				<definiendum id="0">word segmentation process</definiendum>
				<definiens id="0">a prerequisite for natural language processing ( NLP ) of non-segmented language family</definiens>
			</definition>
			<definition id="1">
				<sentence>The precision is the percentage of correct answers over extracted candidates .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the percentage of correct answers over extracted candidates</definiens>
			</definition>
			<definition id="2">
				<sentence>The x-axis is the number of hits in the search engine .</sentence>
				<definiendum id="0">x-axis</definiendum>
			</definition>
			<definition id="3">
				<sentence>The y-axis is the number of words which get the number of hits .</sentence>
				<definiendum id="0">y-axis</definiendum>
				<definiens id="0">the number of words which get the number of hits</definiens>
			</definition>
			<definition id="4">
				<sentence>The Unknown Word Problem : a Morphological Analysis of Japanese Using Maximum Entropy Aided by a Dictionary .</sentence>
				<definiendum id="0">Unknown Word Problem</definiendum>
				<definiens id="0">a Morphological Analysis of Japanese Using Maximum Entropy Aided by a Dictionary</definiens>
			</definition>
</paper>

		<paper id="1079">
			<definition id="0">
				<sentence>Hoffman describes the results of SVD within a probabilistic framework .</sentence>
				<definiendum id="0">Hoffman</definiendum>
				<definiens id="0">describes the results of SVD within a probabilistic framework</definiens>
			</definition>
			<definition id="1">
				<sentence>The SVD analysis1 is the product of three matrices U , S and V transpose .</sentence>
				<definiendum id="0">SVD analysis1</definiendum>
			</definition>
			<definition id="2">
				<sentence>In Wan et al. ( 2003 ) we showed that using a combination of traditional TF∗IDF approaches and SVD approaches was useful given that SVD provided additional information about word associations .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">approaches was useful given that SVD provided additional information about word associations</definiens>
			</definition>
</paper>

		<paper id="1149">
</paper>

		<paper id="1171">
			<definition id="0">
				<sentence>Procedure Generate-Next ( Current-Prop-Comb ) if Nextprop = nil then goto Step 2 endif ( 2 ) if redundant ( p , q ) for any p , q ∈ Nextprop ( 3 ) then goto Step 1 endif if subsumes ( Nextprop , Properties-of ( T ) ) for all T ∈ Target and ( 4 ) ¬subsumes ( Nextprop , Props ( D ) ) for some D ∈ Distractors ( Best-Node ) ( 5 ) and ¬ Q ⊇ R , where R = { subsumes ( Properties-of ( P ) , Nextprop ) } , Q = { subsumes ( Properties-of ( P ) , Description ( N ) ) } for all P ∈ Distractors , ( 6 ) some N ∈ successor ( Best-Node ) then return Nextprop ( 7 ) else goto Step 1 endif ( Dominance cut-off ) 2 if ( Score ( Description ( Best-Node ) ) + Score ( Nextprop ) ) ≥ Complexity-limit ( 8 ) then return nil ( Complexity cut-off ) else Nextprop ← Increment-size ( Nextprop ) goto Step 1 endif ( 9 ) Figure 2 .</sentence>
				<definiendum id="0">Procedure Generate-Next</definiendum>
				<definiens id="0">Nextprop , Properties-of ( T ) ) for all T ∈ Target and ( 4 ) ¬subsumes</definiens>
				<definiens id="1">8 ) then return nil ( Complexity cut-off ) else Nextprop ← Increment-size ( Nextprop ) goto Step 1 endif</definiens>
			</definition>
</paper>

		<paper id="1198">
			<definition id="0">
				<sentence>That is , when it is used to replace the locative prepositional complement of a verb ( Locative Prepositional Phrase , or LPP ) , like in : ( 3 ) Cette ville est belle .</sentence>
				<definiendum id="0">LPP</definiendum>
				<definiens id="0">used to replace the locative prepositional complement of a verb ( Locative Prepositional Phrase , or</definiens>
			</definition>
			<definition id="1">
				<sentence>The pronominal adverb ”y” may be anaphorically linked to a LPP ( that is , precisely , to the phrase made of [ prep+NP ] ) , thus referring to the individual introduced by the complete LPP .</sentence>
				<definiendum id="0">LPP</definiendum>
				<definiens id="0">the individual introduced by the complete LPP</definiens>
			</definition>
			<definition id="2">
				<sentence>Some LPPs produce an object f ( X ) where f is the function associated to the locative preposition and X , the object designated or produced by the embedded NP .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">the function associated to the locative preposition and X , the object designated or produced by the embedded NP</definiens>
			</definition>
			<definition id="3">
				<sentence>DRT ( ( Kamp , 1981 ) ) is a theory proposing a discourse representation formalism , essentially oriented towards ( pronominal and others ) reference problems .</sentence>
				<definiendum id="0">DRT</definiendum>
				<definiens id="0">a theory proposing a discourse representation formalism , essentially oriented towards ( pronominal and others ) reference problems</definiens>
			</definition>
			<definition id="4">
				<sentence>P ( ui ) ) ) ) where NP denotes the lambda-expression given from the LPP-embedded NP , Loc Prep is the lambda-expression of locative preposition given above and ui the reference marker introduced by the LPP .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiendum id="1">Loc Prep</definiendum>
				<definiens id="0">the lambda-expression given from the LPP-embedded NP ,</definiens>
				<definiens id="1">the lambda-expression of locative preposition given above and ui the reference marker introduced by the LPP</definiens>
			</definition>
</paper>

		<paper id="1145">
			<definition id="0">
				<sentence>The semantic orientation ( SO ) of a word indicates the direction in which the word deviates from the norm for its semantic group or lexical field ( Lehrer , 1974 ) .</sentence>
				<definiendum id="0">semantic orientation</definiendum>
			</definition>
			<definition id="1">
				<sentence>Turney’s algorithm requires a colossal corpus ( hundred billion words ) indexed by the AltaVista search engine in his experiment .</sentence>
				<definiendum id="0">Turney’s algorithm</definiendum>
			</definition>
			<definition id="2">
				<sentence>PMI is defined as : PMI ( word1 , word2 ) =log2 ( ) ( ) ( ) &amp; ( 21 21 wordpwordp wordwordp ) where p ( word1 &amp; word2 ) is the probability that word1 and word2 co-occur .</sentence>
				<definiendum id="0">PMI</definiendum>
				<definiendum id="1">PMI</definiendum>
				<definiendum id="2">p</definiendum>
			</definition>
			<definition id="3">
				<sentence>Thus the SO of a word , word , is calculated by SO-PMI as follows : SO-PMI ( word ) = ˛Pwordspword pwordwordPMI ) , ( ˛Nwordsnword nwordwordPMI ) , ( where Pwords is a set of 7 positive paradigm words ( good , nice , excellent , positive , fortunate , correct , and superior ) and Nwords is a set of 7 negative paradigm words ( bad , nasty , poor , negative , unfortunate , wrong , and inferior ) .</sentence>
				<definiendum id="0">Nwords</definiendum>
				<definiens id="0">a set of 7 positive paradigm words ( good , nice , excellent , positive , fortunate , correct , and superior )</definiens>
			</definition>
			<definition id="4">
				<sentence>Turney ( 2003 ) used the Alta Vista Advanced search engine with a NEAR operator , which constrains the search to documents that contain the words within ten words of one another , in either order .</sentence>
				<definiendum id="0">NEAR operator</definiendum>
				<definiens id="0">constrains the search to documents that contain the words within ten words of one another</definiens>
			</definition>
			<definition id="5">
				<sentence>Corpus : the LIVAC synchronous corpus ( Tsou et al. , 2000 , http : //www.livac.org ) was used .</sentence>
				<definiendum id="0">Corpus</definiendum>
				<definiens id="0">the LIVAC synchronous corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>The quotation mark ( ‘ ‘ in English ) is to actually express the opposite meaning of words within the mark , i.e. , HONEST means DISHONEST in this case .</sentence>
				<definiendum id="0">HONEST</definiendum>
				<definiens id="0">to actually express the opposite meaning of words within the mark</definiens>
			</definition>
			<definition id="7">
				<sentence>The General Inquirer : A Computer Approach to Content Analysis .</sentence>
				<definiendum id="0">General Inquirer</definiendum>
				<definiens id="0">A Computer Approach to Content Analysis</definiens>
			</definition>
</paper>

		<paper id="1065">
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>The WSJ is a publication that I enjoy reading NP=N N ( S [ dcl ] nNP ) =NP NP=N N ( NPnNP ) = ( S [ dcl ] =NP ) NP ( S [ dcl ] nNP ) = ( S [ ng ] nNP ) ( S [ ng ] nNP ) =NP Figure 1 : Example sentence with CCG lexical categories frequency # cat types # cat tokens in # sentences in 2-21 # cat tokens in # sentences in 00 cut-off 2-21 not in cat set with missing cat 00 not in cat set with missing cat 1 1 225 0 0 12 ( 0.03 % ) 12 ( 0.6 % ) 10 409 1 933 ( 0.2 % ) 1 712 ( 4.3 % ) 79 ( 0.2 % ) 69 ( 3.6 % ) Table 1 : Statistics for the lexical category set An alternative is to use a statistical tagging approach to assign one or more categories .</sentence>
				<definiendum id="0">WSJ</definiendum>
				<definiens id="0">a publication that I enjoy reading NP=N N ( S [ dcl ] nNP ) =NP NP=N N ( NPnNP ) = ( S [ dcl ] =NP ) NP ( S [ dcl ] nNP ) = ( S [ ng ] nNP ) ( S [ ng ] nNP ) =NP Figure 1 : Example sentence with CCG lexical categories frequency # cat types # cat tokens in # sentences in 2-21 # cat tokens in # sentences in 00 cut-off 2-21 not in cat set with missing cat 00 not in cat set with missing cat 1 1 225 0 0 12 ( 0.03 % ) 12 ( 0.6 % ) 10 409 1 933 ( 0.2 % ) 1 712 ( 4.3 % ) 79 ( 0.2 % ) 69 ( 3.6 %</definiens>
			</definition>
			<definition id="1">
				<sentence>The conditional probabilities have the following log-linear form : p ( yjx ) = 1Z ( x ) e P i i fi ( y ; x ) ( 1 ) where fi is a feature , i is the corresponding weight , and Z ( x ) is a normalisation constant .</sentence>
				<definiendum id="0">fi</definiendum>
				<definiendum id="1">Z ( x )</definiendum>
				<definiens id="0">a normalisation constant</definiens>
			</definition>
			<definition id="2">
				<sentence>The sent acc column gives the precentage of sentences whose words are all supertagged correctly .</sentence>
				<definiendum id="0">acc column</definiendum>
				<definiens id="0">gives the precentage of sentences whose words are all supertagged correctly</definiens>
			</definition>
			<definition id="3">
				<sentence>The estimation method maximises the following objective function : L0 ( ) = L ( ) G ( ) ( 2 ) = log mY j=1 P ( d jjS j ) nX i=1 2i 2 2 The data consists of sentences S 1 ; : : : ; S m , together with gold standard normal-form derivations , d1 ; : : : ; dm .</sentence>
				<definiendum id="0">estimation method</definiendum>
			</definition>
			<definition id="4">
				<sentence>L ( ) is the log-likelihood of model , and G ( ) is a Gaussian prior term used to avoid overfitting ( n is the number of features ; i is the weight for feature fi ; and is a parameter of the Gaussian ) .</sentence>
				<definiendum id="0">L ( )</definiendum>
				<definiendum id="1">G ( )</definiendum>
				<definiendum id="2">n</definiendum>
				<definiens id="0">the log-likelihood of model , and</definiens>
				<definiens id="1">a Gaussian prior term used to avoid overfitting (</definiens>
				<definiens id="2">the number of features ; i is the weight for feature fi ; and is a parameter of the Gaussian )</definiens>
			</definition>
			<definition id="5">
				<sentence>The disk usage is the space taken on disk by the charts , and the memory usage is the space taken in memory during the estimation process .</sentence>
				<definiendum id="0">disk usage</definiendum>
				<definiens id="0">the space taken in memory during the estimation process</definiens>
			</definition>
</paper>

		<paper id="1096">
			<definition id="0">
				<sentence>Only groups containing the target , that is x , are chosen because SOG : [ { a , b , c , d , e , f , x } , { a , b , x } , { x } ] → E ( R ( { a , b , c , d , e , f , x } , { a , b , x } ) ) + E ( { a , b , x } ) +E ( R ( { a , b , x } , { x } ) ) + E ( { x } ) → “hidari oku no”+“mittu no tama”+“no uti no migihasi no”+“tama” ( at the back left ) ( three balls ) ( rightmost . . . among ) ( ball ) Figure 3 : An example of surface realization we handle intra-group relations only as mentioned before , and that implies that all groups mentioned in an expression must include the target .</sentence>
				<definiendum id="0">SOG</definiendum>
				<definiens id="0">a , b , x } , { x } ) ) + E ( { x }</definiens>
			</definition>
			<definition id="1">
				<sentence>In this step , the SOG representations introduced in Section 2 are generated from the GL of Step 1 , which generally has a form like ( 3 ) , where G i denotes a group , and G 0 is a group of all the objects .</sentence>
				<definiendum id="0">G 0</definiendum>
				<definiens id="0">a group of all the objects</definiens>
			</definition>
			<definition id="2">
				<sentence>That is , an SOG representation [ G 0 , G 1 , ... , G n−2 , { x } ] can be realized as shown in ( 5 ) , where E ( X ) denotes a linguistic expression for X , R ( X , Y ) denotes a relation between X and Y , and ‘+’isa string concatenation operator .</sentence>
				<definiendum id="0">E ( X )</definiendum>
				<definiendum id="1">Y )</definiendum>
				<definiens id="0">an SOG representation [ G 0 , G 1 , ... , G n−2</definiens>
				<definiens id="1">a linguistic expression for X</definiens>
				<definiens id="2">a relation between X and Y , and ‘+’isa string concatenation operator</definiens>
			</definition>
			<definition id="3">
				<sentence>E ( G 0 ) +E ( R ( G 0 , G 1 ) ) + E ( G 1 ) + ... +E ( R ( G n−2 , { x } ) ) + E ( { x } ) ( 5 ) As described in Section 2.2 , expressions that explicitly mention all the objects obtain lower evaluation values , and expressions using intra-group relations obtain high evaluation values .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">G 0 ) +E ( R ( G 0 , G 1 ) ) + E ( G 1 ) + ... +E ( R ( G n−2 , { x } ) ) + E ( { x } ) ( 5 ) As described in Section 2.2 , expressions that explicitly mention all the objects obtain lower evaluation values</definiens>
			</definition>
			<definition id="4">
				<sentence>Calculation Formula The total score of an SOG representation is calculated by averaging the scores given by functions f 1 and f 2 whose parameters are dimension ratios between two consecutive groups as given in ( 6 ) , where n is the number of groups in the SOG .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of groups in the SOG</definiens>
			</definition>
			<definition id="5">
				<sentence>score ( SOG ) = 1 n −1 { n−3 summationdisplay i=0 f 1 parenleftbigg dim ( G i+1 ) dim ( G i ) parenrightbigg + f 2 parenleftbigg dim ( { x } ) dim ( G n−2 ) parenrightbigg } ( 6 ) The dimension of a group dim is defined as the average distance between the centroid of the group and that of each object .</sentence>
				<definiendum id="0">score ( SOG</definiendum>
			</definition>
			<definition id="6">
				<sentence>Language and Spatial cognition : an interdisciplinary study of the prepositions in English .</sentence>
				<definiendum id="0">Language</definiendum>
				<definiendum id="1">Spatial cognition</definiendum>
				<definiens id="0">an interdisciplinary study of the prepositions in English</definiens>
			</definition>
			<definition id="7">
				<sentence>Simulated perceptual grouping : An application to human-computer interaction .</sentence>
				<definiendum id="0">Simulated perceptual grouping</definiendum>
				<definiens id="0">An application to human-computer interaction</definiens>
			</definition>
</paper>

		<paper id="1137">
			<definition id="0">
				<sentence>String-edit distance ( Wagner and Fischer , 1974 ) ( EDIT ) ( also known as Levenshtein distance ) counts up the number of steps it takes to transform one string into another , where the cost of substitution is the same as the cost of insertion or deletion .</sentence>
				<definiendum id="0">String-edit distance</definiendum>
				<definiendum id="1">EDIT )</definiendum>
			</definition>
			<definition id="1">
				<sentence>In this paper , we consider two specific variants : BIGRAM , which is the most basic formulation , and TRIGRAM-2B.2 SOUNDEX ( Hall and Dowling , 1980 ) is an approximation to phonetic name matching .</sentence>
				<definiendum id="0">BIGRAM</definiendum>
				<definiens id="0">an approximation to phonetic name matching</definiens>
			</definition>
			<definition id="2">
				<sentence>The principal component of ALINE is a function that calculates the similarity of two phonemes that are expressed in terms of about a dozen binary or multi-valued phonetic features ( Place , Manner , Voice , etc. ) .</sentence>
				<definiendum id="0">ALINE</definiendum>
				<definiens id="0">a function that calculates the similarity of two phonemes that are expressed in terms of about a dozen binary or multi-valued phonetic features</definiens>
			</definition>
			<definition id="3">
				<sentence>The Dice coefficient computed for bigrams ( BIGRAM ) is an example of a measure that is demonstrably inappropriate for estimating word similarity .</sentence>
				<definiendum id="0">Dice coefficient computed for bigrams</definiendum>
				<definiendum id="1">BIGRAM )</definiendum>
				<definiens id="0">an example of a measure that is demonstrably inappropriate for estimating word similarity</definiens>
			</definition>
			<definition id="4">
				<sentence>BI-SIM is defined by the following recurrence : a20 a6 a13 a2a22a21 a9 a20 max a6 a20 a6 a13a24a23 a4 a2a22a21 a9 a2 a20 a6 a13 a2a22a21 a23 a4 a9 a2 a20 a6 a13a24a23 a4 a2a22a21 a23 a4 a9 a16 a1 a6a8a7 a11 a25 a2 a7 a11 a2 a13a27a26 a25 a2 a13a27a26 a9 a9 a2 6The scale could be further refined to include more levels of similarity .</sentence>
				<definiendum id="0">BI-SIM</definiendum>
				<definiens id="0">the following recurrence : a20 a6 a13 a2a22a21 a9 a20 max a6 a20 a6 a13a24a23 a4 a2a22a21 a9 a2 a20 a6 a13 a2a22a21 a23 a4 a9 a2 a20 a6 a13a24a23 a4 a2a22a21 a23 a4 a9 a16 a1 a6a8a7 a11 a25 a2 a7 a11 a2 a13a27a26 a25 a2 a13a27a26 a9 a9 a2 6The scale could be further refined to include more levels of similarity</definiens>
			</definition>
			<definition id="5">
				<sentence>PREFIX is a baseline-type similarity measure that returns the length of the common prefix divided by the length of the longer string .</sentence>
				<definiendum id="0">PREFIX</definiendum>
				<definiens id="0">a baseline-type similarity measure that returns the length of the common prefix divided by the length of the longer string</definiens>
			</definition>
			<definition id="6">
				<sentence>LCSR is able to identify pairs where common subsequences are interleaved with dissimilar segments , such as Asparaginase/Pegaspargase , but fails on similar sounding names where the overlap of identical segments is minimal ( Luride/Lortab ) .</sentence>
				<definiendum id="0">LCSR</definiendum>
				<definiens id="0">able to identify pairs where common subsequences are interleaved with dissimilar segments , such as Asparaginase/Pegaspargase , but fails on similar sounding names where the overlap of identical segments is minimal ( Luride/Lortab )</definiens>
			</definition>
</paper>

		<paper id="1083">
			<definition id="0">
				<sentence>342 The end of the Cold War seems to have intensified economic competition and has started to generate serious friction between nations as attempts are made by diplomatic personnel to acquire sensitive trade and technology information or to obtain information on highly classified industrial projects .</sentence>
				<definiendum id="0">Cold War</definiendum>
				<definiens id="0">seems to have intensified economic competition and has started to generate serious friction between nations as attempts are made by diplomatic personnel to acquire sensitive trade and technology information or to obtain information on highly classified industrial projects</definiens>
			</definition>
			<definition id="1">
				<sentence>Interface Average Relevant Average Non-Relevant Interface1 3.83 7.17 Interface2 4.78 5.17 Interface3 5.50 3.50 Interface4 6.17 7.11 Interface5 5.22 4.39 Interface6 6.56 4.28 Table 5 : Average number of relevant and nonrelevant documents / interface As expected , Interface6 ( all features available to users ) gives maximum relevant documents in average .</sentence>
				<definiendum id="0">Interface Average Relevant</definiendum>
				<definiendum id="1">Interface6 (</definiendum>
				<definiens id="0">Average number of relevant and nonrelevant documents / interface As expected</definiens>
				<definiens id="1">all features available to users ) gives maximum relevant documents in average</definiens>
			</definition>
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>The main outcomes of the proposal are threefold : ( 1 ) CCG gains a more flexible and general kind of sign ; ( 2 ) these signs contain multiple levels that interact in a modular fashion and are built via CCG derivations without increasing parsing complexity ; and ( 3 ) we use these signs to simplify previous CCG’s accounts of the effects of word order and prosody on information structure .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiens id="0">gains a more flexible and general kind of sign ; ( 2 ) these signs contain multiple levels that interact in a modular fashion</definiens>
				<definiens id="1">accounts of the effects of word order and prosody on information structure</definiens>
			</definition>
			<definition id="1">
				<sentence>diamondmath allows combination with the application rules and the order-preserving composition rules ( &gt; B and &lt; B ) . × allows limited permutation via the crossed composition rules ( &gt; B× and &lt; B× ) as well as the application rules. Additionally , a permissive modality · allows combination by all rules in the system. However , we suppress the · modality on slashes to avoid clutter. An undecorated slash may thus combine by all rules. There are two further rules of type-raising that turn an argument category into a function over functions that seek that argument : ( &gt; T ) X ⇒ Y/i ( Y\iX ) ( &lt; T ) X ⇒ Y\i ( Y/iX ) The variable modality i on the output categories constrains both slashes to have the same modality. These rules support the following incremental derivation for Marcel proved completeness : ( 1 ) Marcel proved completeness np ( s\np ) /np np &gt; Ts/ ( s\np ) &gt; Bs/np &gt; s This derivation does not display the effect of using modalities in CCG ; see Baldridge ( 2002 ) and Baldridge and Kruijff ( 2003 ) for detailed linguistic justification for this modalized formulation of CCG .</sentence>
				<definiendum id="0">order-preserving composition rules</definiendum>
				<definiendum id="1">composition rules</definiendum>
				<definiens id="0">a permissive modality · allows combination by all rules in the system. However , we suppress the · modality on slashes to avoid clutter. An undecorated slash may thus combine by all rules. There are two further rules of type-raising that turn an argument category into a function over functions that seek that argument : ( &gt; T ) X ⇒ Y/i ( Y\iX ) ( &lt; T ) X ⇒ Y\i ( Y/iX ) The variable modality i on the output categories constrains both slashes to have the same modality. These rules support the following incremental derivation for Marcel proved completeness : ( 1 ) Marcel proved completeness np ( s\np ) /np np &gt; Ts/ ( s\np ) &gt; Bs/np &gt; s This derivation does not display the effect of using modalities in CCG</definiens>
			</definition>
			<definition id="2">
				<sentence>The language for this dimension is defined by the rules for category construction : given a set of atomic categories A , C is a category iff ( i ) C ∈ A or ( ii ) C is of the form A\mB or A/mB with A , B categories and m ∈ { star , diamondmath× , · } .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a category iff ( i ) C ∈ A or ( ii ) C is of the form A\mB or A/mB with A , B categories and m ∈ { star</definiens>
			</definition>
</paper>

		<paper id="1044">
			<definition id="0">
				<sentence>In LTAG , StructLTAG represents the set of derived trees , SatLTAG the set of derived trees with a root in the category sentence and without non terminal leaves .</sentence>
				<definiendum id="0">StructLTAG</definiendum>
				<definiens id="0">the set of derived trees , SatLTAG the set of derived trees with a root in the category sentence and without non terminal leaves</definiens>
			</definition>
			<definition id="1">
				<sentence>The projection PhonLTAG is the canonical projection of a locally ordered tree on its leaves .</sentence>
				<definiendum id="0">projection PhonLTAG</definiendum>
				<definiens id="0">the canonical projection of a locally ordered tree on its leaves</definiens>
			</definition>
			<definition id="2">
				<sentence>In Lambek Grammars ( LG ) , StructLG is the set of partial proofs and these proofs can be represented in the form of incomplete Lambek proof nets labelled with phonological terms ( de Groote , 1999 ) .</sentence>
				<definiendum id="0">Lambek Grammars</definiendum>
				<definiendum id="1">StructLG</definiendum>
				<definiens id="0">the set of partial proofs and these proofs can be represented in the form of incomplete Lambek proof nets labelled with phonological terms</definiens>
			</definition>
			<definition id="3">
				<sentence>SatLG represents the set of complete proof nets with the category sentence as their conclusion and with syntactic categories labelled with words as their hypotheses .</sentence>
				<definiendum id="0">SatLG</definiendum>
			</definition>
			<definition id="4">
				<sentence>Fpol is a polarization of F if : ( i ) For any structure S 2 StructF , pol ( S ) results from associating each label of S with one of the polarities : + , , = , $ ; in others words , labels of Fpol are pairs ( p ; l ) with p a polarity and l a label of F. The set of polarities f+ , , = , $ g is equipped with the operation of uni cation and the subsumption order de ned by Figure 1 .</sentence>
				<definiendum id="0">Fpol</definiendum>
				<definiens id="0">a polarization of F if : ( i ) For any structure S 2 StructF , pol ( S ) results from associating each label of S with one of the polarities : + , , = , $</definiens>
			</definition>
			<definition id="5">
				<sentence>Formally , given a polarized formalism P , we de ne the formalism Pdestr as follows : Any element M of StructPdestr is a multiset of labels .</sentence>
				<definiendum id="0">StructPdestr</definiendum>
				<definiens id="0">a multiset of labels</definiens>
			</definition>
			<definition id="6">
				<sentence>All elements of M are labels of P , except one exactly , the anchor , which is a neutral string .</sentence>
				<definiendum id="0">anchor</definiendum>
				<definiens id="0">a neutral string</definiens>
			</definition>
			<definition id="7">
				<sentence>Destructuring is an abstraction that applies to any polarized formalism but we can design abstractions with lower degree which are speci c to particular formalisms ( see Section 6 ) .</sentence>
				<definiendum id="0">Destructuring</definiendum>
				<definiens id="0">an abstraction that applies to any polarized formalism but we can design abstractions with lower degree which are speci c to particular formalisms</definiens>
			</definition>
			<definition id="8">
				<sentence>Reaching state ( i ; c ) from the initial state ( 0 ; 0 ) means that ( a ) the path taken is of the form S1 ; j1 ; S2 ; j2 ; : : : ; Si ; ji , that is a tagging of the rst i words , ( b ) c is the count of labels l present in the union of the multi-sets abs ( S1 ; j1 ) ; abs ( S2 ; j2 ) ; : : : ; abs ( Si ; ji ) .</sentence>
				<definiendum id="0">ji</definiendum>
				<definiendum id="1">c</definiendum>
			</definition>
			<definition id="9">
				<sentence>Then , three rules are used for lling the chart : initialization : the chart is initialized with items in the form ( i ; i+ 1 ; abs ( Si+1 ; k ) ) ; reduction : if the chart contains an item ( i ; j ; S ) , we add the item ( i ; j ; S0 ) such that S0 is obtained by application of a unary composition rule to S ; concatenation : if the chart contains two item ( i ; j ; S ) and ( j ; k ; S0 ) , we add the item ( i ; k ; S00 ) such that S00 is obtained by application of a binary composition rule to S and S0 .</sentence>
				<definiendum id="0">S )</definiendum>
				<definiens id="0">obtained by application of a unary composition rule to S ; concatenation : if the chart contains two item ( i ; j ;</definiens>
				<definiens id="1">obtained by application of a binary composition rule to S and S0</definiens>
			</definition>
			<definition id="10">
				<sentence>Parsing succeeds if the chart contains an item in the form ( 0 ; n ; S0 ) such that S0 is an element of SatCabs .</sentence>
				<definiendum id="0">S0</definiendum>
				<definiens id="0">an element of SatCabs</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>LFG is a constraint-based linguistic theory ( Bresnan ( 2001 ) , Dalrymple ( 2001 ) ) .</sentence>
				<definiendum id="0">LFG</definiendum>
				<definiens id="0">a constraint-based linguistic theory</definiens>
			</definition>
			<definition id="1">
				<sentence>The level of f-structure encodes the functions of the constituents ( e.g. subject , adjunct ) and morpho-syntactic information , such as case , number , and tense .</sentence>
				<definiendum id="0">level of f-structure</definiendum>
				<definiens id="0">encodes the functions of the constituents ( e.g. subject , adjunct ) and morpho-syntactic information , such as case , number , and tense</definiens>
			</definition>
			<definition id="2">
				<sentence>Functional units Usually , a module consists of pieces of code that belong together in some way ( e.g. they perform similar actions on the input ) .</sentence>
				<definiendum id="0">module</definiendum>
				<definiens id="0">consists of pieces of code that belong together in some way ( e.g. they perform similar actions on the input )</definiens>
			</definition>
			<definition id="3">
				<sentence>A linguistic generalization is a statement about properties that are common to/shared by different constructions .</sentence>
				<definiendum id="0">linguistic generalization</definiendum>
				<definiens id="0">a statement about properties that are common to/shared by different constructions</definiens>
			</definition>
			<definition id="4">
				<sentence>A grammar module consists of a coherent piece of code that encodes such common properties and in this sense represents a functional unit .</sentence>
				<definiendum id="0">grammar module</definiendum>
			</definition>
			<definition id="5">
				<sentence>Clearly , NPfunc represents a functional unit ; the question of whether NPfunc is a black box to other modules , such as the syntactic rule CP , is addressed in the next section .</sentence>
				<definiendum id="0">NPfunc</definiendum>
				<definiens id="0">a functional unit</definiens>
			</definition>
			<definition id="6">
				<sentence>We therefore conclude that macro modules , such as NPfunc , are only defined by property P2 ( functional unit ) , not by property P1 ( black box ) .</sentence>
				<definiendum id="0">NPfunc</definiendum>
				<definiens id="0">functional unit ) , not by property P1 ( black box )</definiens>
			</definition>
			<definition id="7">
				<sentence>A grammar implementation is a complex software project and , hence , often needs to be modified , e.g. to fix bugs , to widen coverage , to reduce overgeneration , to improve performance , or to adapt the grammar to specific applications .</sentence>
				<definiendum id="0">grammar implementation</definiendum>
				<definiens id="0">a complex software project and , hence , often needs to be modified , e.g. to fix bugs , to widen coverage , to reduce overgeneration , to improve performance , or to adapt the grammar to specific applications</definiens>
			</definition>
			<definition id="8">
				<sentence>XSLT operates on the most recent version of the grammar , therefore all grammar-related elements within the output documentation that are generated via XSLT are automatically synchronized to the current grammar ( e.g. snapshots ) .</sentence>
				<definiendum id="0">XSLT</definiendum>
				<definiens id="0">operates on the most recent version of the grammar , therefore all grammar-related elements within the output documentation that are generated via XSLT are automatically synchronized to the current grammar</definiens>
			</definition>
</paper>

		<paper id="1040">
			<definition id="0">
				<sentence>Preference Learning is a simple modification of SVM .</sentence>
				<definiendum id="0">Preference Learning</definiendum>
				<definiens id="0">a simple modification of SVM</definiens>
			</definition>
			<definition id="1">
				<sentence>Each training example for SVM is a pair ( yi ; xi ) , where xi is a vector , yi = +1 means that xi is a positive example , and yi = 1 means that xi is a negative example .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiens id="0">a pair ( yi ; xi )</definiens>
			</definition>
			<definition id="2">
				<sentence>SVM classifies a given test vector x by using a decision function f ( x ) = wf ( x ) + b = ‘X i yi iK ( x ; xi ) + b ; where f ig and b are constants and ‘ is the number of training examples .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiendum id="1">‘</definiendum>
				<definiens id="0">classifies a given test vector x by using a decision function f ( x ) = wf ( x ) + b = ‘X i yi iK ( x ; xi ) + b ; where f ig and b are constants and</definiens>
				<definiens id="1">the number of training examples</definiens>
			</definition>
			<definition id="3">
				<sentence>K ( xi ; xj ) = ( xi ) ( xj ) is a predefined kernel function .</sentence>
				<definiendum id="0">K</definiendum>
			</definition>
			<definition id="4">
				<sentence>C is a soft margin parameter that penalizes misclassification .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a soft margin parameter that penalizes misclassification</definiens>
			</definition>
			<definition id="5">
				<sentence>A PP-Attatchment Resolver ( PPAR ) : This resolver improves the dependency accuracy of prepositions whose part-of-speech tags are IN or TO .</sentence>
				<definiendum id="0">PP-Attatchment Resolver ( PPAR )</definiendum>
				<definiens id="0">This resolver improves the dependency accuracy of prepositions whose part-of-speech tags are IN or TO</definiens>
			</definition>
			<definition id="6">
				<sentence>Left : Left means that wi directly modifies the left word wi 1 and that no word in T modifies wi .</sentence>
				<definiendum id="0">Left</definiendum>
				<definiens id="0">means that wi directly modifies the left word wi 1 and that no word in T modifies wi</definiens>
			</definition>
			<definition id="7">
				<sentence>If fLeft ( x ) is the largest , the word is classified as Left .</sentence>
				<definiendum id="0">fLeft ( x )</definiendum>
			</definition>
			<definition id="8">
				<sentence>DA : Dependency Accuracy , RA : Root Acc. , CR : Complete Rate Table 1 : Effectiveness of the Root-Node Finder Accuracy ( % ) C Preference Learning SVM 72 74 76 78 80 82 Figure 4 : Comparison of SVM and Preference Learning in terms of Dependency Accuracy of prepositions ( Trained with 5,000 sentences ) Figure 4 compares SVM and Preference Learning in terms of the Dependency Accuracy of prepositions .</sentence>
				<definiendum id="0">DA</definiendum>
				<definiens id="0">Comparison of SVM and Preference Learning in terms of Dependency Accuracy of prepositions ( Trained with 5,000 sentences ) Figure 4 compares SVM and Preference Learning in terms of the Dependency Accuracy of prepositions</definiens>
			</definition>
			<definition id="9">
				<sentence>SVM’s performance is unstable for this task , and Preference Learning outperforms SVM .</sentence>
				<definiendum id="0">Preference Learning</definiendum>
				<definiens id="0">outperforms SVM</definiens>
			</definition>
</paper>

		<paper id="1166">
			<definition id="0">
				<sentence>The MDA ( Multilingual Document Authoring ) system ( Dymetman et al. , 2000 ; Brun et al. , 2000 ) follows the WYSIWYM approach , but puts a strong emphasis on the well-formedness of document semantic content .</sentence>
				<definiendum id="0">MDA ( Multilingual Document Authoring ) system</definiendum>
				<definiens id="0">follows the WYSIWYM approach , but puts a strong emphasis on the well-formedness of document semantic content</definiens>
			</definition>
			<definition id="1">
				<sentence>A MDA grammar specifles the possible content representations of a document in terms of trees of typed semantic objects in a formalism inspired from Deflnite Clause Grammars ( Pereira and Warren , 1980 ) .</sentence>
				<definiendum id="0">MDA grammar</definiendum>
				<definiens id="0">specifles the possible content representations of a document in terms of trees of typed semantic objects in a</definiens>
			</definition>
			<definition id="2">
				<sentence>Text strings appearing in the right-hand side of the rules are used together with the strings associated with the present semantic objects to compose the normalized text associated with the described abstract semantic trees .</sentence>
				<definiendum id="0">Text strings</definiendum>
			</definition>
			<definition id="3">
				<sentence>The tick symbol represents a semantic object that dominates a semantic subtree containing no underspeciflcations .</sentence>
				<definiendum id="0">tick symbol</definiendum>
				<definiens id="0">a semantic object that dominates a semantic subtree containing no underspeciflcations</definiens>
			</definition>
			<definition id="4">
				<sentence>The arrow symbol describes a semantic object that does not take part in an underspeciflcation , but which dominates a subtree that contains at least one .</sentence>
				<definiendum id="0">arrow symbol</definiendum>
			</definition>
			<definition id="5">
				<sentence>The exclamation mark symbol denotes a semantic type that is underspecifled , and for which at least two semantic objects are in competition .</sentence>
				<definiendum id="0">exclamation mark symbol</definiendum>
				<definiens id="0">a semantic type that is underspecifled , and for which at least two semantic objects are in competition</definiens>
			</definition>
			<definition id="6">
				<sentence>Machine Translation without a Source Text .</sentence>
				<definiendum id="0">Machine Translation</definiendum>
				<definiens id="0">without a Source Text</definiens>
			</definition>
</paper>

		<paper id="1192">
			<definition id="0">
				<sentence>In this paper , we describe a disambiguation experiment that exploits the ILI information in the corrected wordnets Our methodology consists of the following steps : L1L2 in languages L 1 and L 2 for which there are aligned wordnets , extract all pairs of lexical items that are reciprocal translations : { &lt; W i L1 W j L2 &gt; + } i L1 W j L2 &gt; , extract the ILI codes for the synsets that contain W i L1 and W j L2 respectively to yield two lists of ILI codes , L 1 ILI ( W i L1 ) and L 2 ILI ( W j L2 ) intersection L 1 ILI ( W i L1 ) ∩ L 2 ILI ( W j L2 ) or a pair of ILI codes ILI 1 ∈ L 1 ILI ( W i L1 ) and ILI 2 ∈ L 2 ILI ( W j L2 ) , so that ILI 1 and ILI 2 are the most similar ILI codes ( defined below ) among the candidate pairs ( L 1 ILI ( W i L1 ) ⊗L 2 ILI ( W j L2 ) [ ⊗ = Cartesian product ] .</sentence>
				<definiendum id="0">disambiguation experiment</definiendum>
				<definiendum id="1">ILI</definiendum>
				<definiens id="0">exploits the ILI information in the corrected wordnets Our methodology consists of the following steps : L1L2 in languages L 1 and L 2 for which there are aligned wordnets , extract all pairs of lexical items that are reciprocal translations : { &lt; W i L1 W j L2 &gt; + } i L1 W j L2 &gt; , extract the ILI codes for the synsets that contain W i L1 and W j L2 respectively to yield two lists of ILI codes , L 1 ILI ( W i L1</definiens>
				<definiens id="1">W j L2 ) or a pair of ILI codes ILI 1 ∈ L 1 ILI ( W i L1</definiens>
			</definition>
			<definition id="1">
				<sentence>For each source language and for all occurrences of a specific word in the target language T , we build a matrix of translation equivalents as shown in Table 1 ( eq ij represents the translation equivalent in the i th source language of the j th occurrence of the word in the target language ) .</sentence>
				<definiendum id="0">eq ij</definiendum>
				<definiens id="0">represents the translation equivalent in the i th source language of the j th occurrence of the word in the target language )</definiens>
			</definition>
			<definition id="2">
				<sentence>The VSA matrix Here , VSA ij = L EN ILI ( W EN ) ∩ L i ILI ( W j Li ) , , where L EN ILI ( W EN ) represent the ILI codes of all synsets in which the target word W EN occurs , and L i ILI ( W j Li ) is the list of ILI-codes for all synsets in which the translation equivalent for the j th occurrence of W EN occurs .</sentence>
				<definiendum id="0">VSA ij = L EN ILI</definiendum>
			</definition>
			<definition id="3">
				<sentence>Instead of deriving the clustering tree and guessing at a perfect cut , we stop the clustering algorithm when Z clusters have been created , where Z is the number of senses in which the occurrences of TW i have been used in the text in question .</sentence>
				<definiendum id="0">Z clusters</definiendum>
				<definiendum id="1">Z</definiendum>
				<definiens id="0">the number of senses in which the occurrences of TW i have been used in the text in question</definiens>
			</definition>
			<definition id="4">
				<sentence>The BalkaNet version of the “1984” corpus is encoded as a sequence of translation units ( TU ) , each containing one sentences per language , so that they are reciprocal translations .</sentence>
				<definiendum id="0">TU )</definiendum>
				<definiens id="0">each containing one sentences per language , so that they are reciprocal translations</definiens>
			</definition>
</paper>

		<paper id="1085">
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>derivable loops over all rules Aa0 B C with the symbol A on the left-hand side ( line 11 ) and over all possible end positions m of the rst symbol on the right-hand side of the rule ( line 12 ) .</sentence>
				<definiendum id="0">derivable loops</definiendum>
			</definition>
			<definition id="1">
				<sentence>Viterbi parses for probabilistic context-free grammars ( PCFGs ) could be extracted from context-free 1 parse ( P , N , S , wa3 , ... , wa4 ) 2 recognise ( P , N , wa3 , ... , wa4 ) 3 return build-subtree ( P , N,1 , n , S ) 4 build-subtree ( P , N , b , e , A ) 5 na5 get-node ( b , e , A ) 6 unless de ned n do 7 na5 new-node ( b , e , A ) 8 if b = e anda33 = Aa0a34a6 a8 a10 P do 9 add-analysis ( n , r ) 10 for each rulea33 = Aa0 Ba10 P do 11 if chart [ b ] [ e ] [ B ] = 1 then 12 add-analysis ( n , r ) 13 for each rulea33 = Aa0 B Ca10 P do 14 for ma5 b to e-1 do 15 if chart [ b ] [ m ] [ B ] = 1 and chart [ m+1 ] [ e ] [ C ] = 1 then 16 add-analysis ( n , r , m ) 17 for each analysis a = a1Aa0a35a6 a8a2 of node n do 18 add-child ( n , a , -e ) 19 for each analysis a = a1Aa0 Ba2 of node n do 20 da5 build-subtree ( P , N , b , e , B ) 21 add-child ( n , a , d ) 22 for each analysis a = a1Aa0 B C , ma2 do 23 da5 build-subtree ( P , N , b , m , B ) 24 add-child ( n , a,1 , d ) 25 da5 build-subtree ( P , N , m+1 , e , C ) 26 add-child ( n , a,2 , d ) 27 return n Figure 5 : Parse forest generation parse forests , but BitPar computes them without building the parse forest in order to save space .</sentence>
				<definiendum id="0">Viterbi parses for probabilistic context-free grammars ( PCFGs )</definiendum>
				<definiendum id="1">BitPar</definiendum>
				<definiens id="0">if chart [ b ] [ m ] [ B ] = 1 and chart [ m+1 ] [ e ] [ C ] = 1 then 16 add-analysis ( n , r</definiens>
				<definiens id="1">computes them without building the parse forest in order to save space</definiens>
			</definition>
			<definition id="2">
				<sentence>LoPar is a 1-pass left-corner chart parser which computes the Viterbi parse from the parse forest .</sentence>
				<definiendum id="0">LoPar</definiendum>
				<definiens id="0">a 1-pass left-corner chart parser which computes the Viterbi parse from the parse forest</definiens>
			</definition>
			<definition id="3">
				<sentence>BitPar is faster for all sentence lengths and the growth of the parse times with sentence length is smaller than for LoPar .</sentence>
				<definiendum id="0">BitPar</definiendum>
				<definiens id="0">faster for all sentence lengths and the growth of the parse times with sentence length is smaller than for LoPar</definiens>
			</definition>
			<definition id="4">
				<sentence>Viterbi parsing consists of four steps comprising ( i ) the generation of the chart , ( ii ) top-down ltering of the chart , ( iii ) computation of the Viterbi probabilities , and ( iv ) the extraction of the Viterbi parse .</sentence>
				<definiendum id="0">Viterbi parsing</definiendum>
			</definition>
			<definition id="5">
				<sentence>The empirical runtime complexity ( measured for sentences with up to 50 words ) is better than cubic .</sentence>
				<definiendum id="0">empirical runtime complexity</definiendum>
				<definiens id="0">measured for sentences with up to 50 words ) is better than cubic</definiens>
			</definition>
</paper>

		<paper id="1088">
			<definition id="0">
				<sentence>Reducing the number of features ( i.e. the number of parameters to be estimated by the learning algorithm ) by frequency cutoffs to be in the range of the number of training cases produced good results , although it is to be expected that more intelligent thresholding techniques such as log likelihood ratio will further increase performance .</sentence>
				<definiendum id="0">Reducing the number of features</definiendum>
				<definiens id="0">the number of parameters to be estimated by the learning algorithm</definiens>
			</definition>
			<definition id="1">
				<sentence>Additionally , we plan to investigate the possibility of training different classifiers , each of which contains features from one of the four major feature sets ( function word frequencies , POS trigram frequencies , syntactic production frequencies , semantic feature frequencies ) , and maximally n such features where n is the number of training cases .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of training cases</definiens>
			</definition>
</paper>

		<paper id="1052">
</paper>

		<paper id="1070">
			<definition id="0">
				<sentence>Text categorization is the task of assigning a text1 to one or more of a set of predefined categories .</sentence>
				<definiendum id="0">Text categorization</definiendum>
				<definiens id="0">the task of assigning a text1 to one or more of a set of predefined categories</definiens>
			</definition>
			<definition id="1">
				<sentence>The BoW representation ignores all semantic or conceptual information ; it simply looks at the surface word forms .</sentence>
				<definiendum id="0">BoW representation</definiendum>
				<definiens id="0">ignores all semantic or conceptual information</definiens>
			</definition>
			<definition id="2">
				<sentence>2The tf×idf measure is a standard weighting scheme , where tf i is simply the frequency of word i in the document , and idf is the inverse document frequency , given by Nni where N is the total number of documents in the data , and ni is the number of documents in which word i occurs .</sentence>
				<definiendum id="0">tf i</definiendum>
				<definiendum id="1">idf</definiendum>
				<definiendum id="2">N</definiendum>
				<definiendum id="3">ni</definiendum>
				<definiens id="0">the inverse document frequency , given by Nni where</definiens>
				<definiens id="1">the total number of documents in the data</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus , if we collect the random index vectors into a random matrix R of order c×k , whose row Ri is the k-dimensional index vector for context i , we find that the following relation holds : Gw×k = Fw×cRc×k That is , the Random Indexing context matrix G contains the same information as we get by multiplying the standard cooccurrence matrix F with the random matrix R , where RRT approximates the identity matrix .</sentence>
				<definiendum id="0">Ri</definiendum>
				<definiens id="0">the random index vectors into a random matrix R of order c×k , whose row</definiens>
				<definiens id="1">the following relation holds : Gw×k = Fw×cRc×k That is , the Random Indexing context matrix G contains the same information as we get by multiplying the standard cooccurrence matrix F with the random matrix R , where RRT approximates the identity matrix</definiens>
			</definition>
			<definition id="4">
				<sentence>From the solution of the optimization problem , the weight vector vectorw has an expansion in a subset of the training examples , so classifying a new example vectorz is : f ( vectorz ) = sgn parenleftBigg lsummationdisplay i=1 αiyiK ( vectorxi , vectorz ) +b parenrightBigg ( 1 ) where the αi variables are determined by the optimization procedure and K ( vectorxi , vectorz ) is the inner product between the example vectors .</sentence>
				<definiendum id="0">weight vector vectorw</definiendum>
				<definiens id="0">has an expansion in a subset of the training examples</definiens>
			</definition>
			<definition id="5">
				<sentence>The index vectors consist of 4 to 60 non-zero elements ( ≈ 1 % non-zeros ) , depending on their dimensionality .</sentence>
				<definiendum id="0">index vectors</definiendum>
			</definition>
			<definition id="6">
				<sentence>The smallest of the “BoC categories” is “fuel” , which consists of 13 documents , and for which BoC outperforms BoW representations with 33.33 % versus 30.77 % .</sentence>
				<definiendum id="0">“fuel”</definiendum>
				<definiens id="0">consists of 13 documents , and for which BoC outperforms BoW representations with 33.33 % versus 30.77 %</definiens>
			</definition>
			<definition id="7">
				<sentence>Latent semantic indexing : A probabilistic analysis .</sentence>
				<definiendum id="0">Latent semantic indexing</definiendum>
				<definiens id="0">A probabilistic analysis</definiens>
			</definition>
</paper>

		<paper id="1087">
			<definition id="0">
				<sentence>We differentiate between head coordination ( where term heads are coordinated , e.g. adrenal glands and gonads ) and argument coordination ( where term arguments/modifiers are coordinated , e.g. SMRT and Trip-1 mRNAs ) .</sentence>
				<definiendum id="0">term heads</definiendum>
				<definiendum id="1">argument coordination</definiendum>
				<definiens id="0">where term arguments/modifiers are coordinated</definiens>
			</definition>
			<definition id="1">
				<sentence>Similarly to the estimation of C-values for individual term candidates ( Frantzi et al. , 2000 ) , the formula for calculating the termhoods for synterms is as follows :      ⋅ −⋅ = ∑ ∈ nestednot is CR ) , ( ||log nested is CR , ) ) ( || 1 ) ( ( ||log ) value ( -C 2 2 CRfCR bf T CRfCR c CR TbCR where c denotes a synterm whose elements share a canonical representative ( denoted as CR in the formula ) , f ( CR ) corresponds to the cumulative frequency with which all term candidates from the synterm c occur in a given corpus , |CR| denotes the average length of the term candidates ( the number of constituents ) , and T CR is a set of all synterms whose CRs contain the given CR as a nested substring .</sentence>
				<definiendum id="0">c</definiendum>
				<definiendum id="1">|CR|</definiendum>
				<definiendum id="2">T CR</definiendum>
				<definiens id="0">a synterm whose elements share a canonical representative ( denoted as CR in the formula ) , f ( CR ) corresponds to the cumulative frequency with which all term candidates from the synterm c occur in a given corpus ,</definiens>
				<definiens id="1">the average length of the term candidates ( the number of constituents</definiens>
				<definiens id="2">a set of all synterms whose CRs contain the given CR as a nested substring</definiens>
			</definition>
			<definition id="2">
				<sentence>The evaluation was carried out using the GENIA corpus ( GENIA , 2004 ) , which contains 2,000 abstracts in the biomedical domain with 76,592 manually marked occurrences of terms .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">contains 2,000 abstracts in the biomedical domain with 76,592 manually marked occurrences of terms</definiens>
			</definition>
			<definition id="3">
				<sentence>Since our ATR method produces a ranked list of suggested synterms , we considered precision at fixed rank cut-offs ( intervals ) : precision was calculated as the ratio between the number of correctly recognised terms and the total number of entities recognised in a given interval ( where an interval included all terms from the top ranked synterms ) .</sentence>
				<definiendum id="0">intervals )</definiendum>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>Among all possible target language sentences , we will choose the sentence with the highest probability : ˆeI1 = argmax eI1 'Pr ( eI 1jf J 1 ) “ = argmax eI1 'Pr ( eI 1 ) ¢Pr ( f J 1 je I 1 ) “ This decomposition into two knowledge sources allows for an independent modeling of target language model Pr ( eI1 ) and translation model Pr ( fJ1 jeI1 ) .</sentence>
				<definiendum id="0">¢Pr</definiendum>
			</definition>
			<definition id="1">
				<sentence>A Viterbi alignment ˆA of a specific model is an alignment for which the following equation holds : ˆA = argmax A 'Pr ( fJ 1 ; Aje I 1 ) “ We measure the quality of an alignment model usingthequalityoftheViterbialignmentcompared to a manually produced reference alignment .</sentence>
				<definiendum id="0">Viterbi alignment ˆA</definiendum>
				<definiens id="0">an alignment for which the following equation holds : ˆA = argmax A 'Pr ( fJ 1 ; Aje I 1 ) “ We measure the quality of an alignment model usingthequalityoftheViterbialignmentcompared to a manually produced reference alignment</definiens>
			</definition>
			<definition id="2">
				<sentence>QST ( fp ( fje ) g ) = X f ; e NST ( f ; e ) ¢log p ( f ; e ) P ˜f p ( ˜f ; e ) QTS ( fp ( ejf ) g ) = X f ; e NTS ( f ; e ) ¢log p ( f ; e ) P ˜e p ( f ; ˜e ) To estimate the joint probability using the EM algorithm , we define the auxiliary Q-function as a linear interpolation of the Q-functions for the source-to-target and the target-to-source direction : Qfi ( fp ( f ; e ) g ) = fi¢QST ( fp ( fje ) g ) + ( 1¡fi ) ¢QTS ( fp ( ejf ) g ) = fi¢ X f ; e NST ( f ; e ) ¢logp ( f ; e ) + ( 1¡fi ) ¢ X f ; e NTS ( f ; e ) ¢logp ( f ; e ) ¡fi¢ X e NST ( e ) ¢log X ˜f p ( ˜f ; e ) ¡ ( 1¡fi ) ¢ X f NTS ( f ) ¢log X ˜e p ( f ; ˜e ) The unigram counts N ( e ) and N ( f ) are determined , for each of the two translation directions , by taking a sum of N ( f ; e ) over f and over e , respectively .</sentence>
				<definiendum id="0">QST ( fp</definiendum>
				<definiendum id="1">e NST</definiendum>
				<definiendum id="2">e ) QTS</definiendum>
				<definiendum id="3">e NTS</definiendum>
				<definiendum id="4">X f ; e NST</definiendum>
				<definiendum id="5">e NTS</definiendum>
				<definiendum id="6">N</definiendum>
				<definiens id="0">( f ) are determined , for each of the two translation directions , by taking a sum of N ( f ; e ) over f and over e , respectively</definiens>
			</definition>
			<definition id="3">
				<sentence>As an approximation , we use the following term : ˆp ( f ; e ) = Nfi ( f ; e ) P ˜f ; ˜e Nfi ( ˜f ; ˜e ) This estimate is an exact solution , if the unigram counts for f and e are independent of the translation direction , i.e. NST ( f ) = NTS ( f ) and NST ( e ) = NTS ( e ) .</sentence>
				<definiendum id="0">˜e ) This estimate</definiendum>
				<definiens id="0">an exact solution , if the unigram counts for f and e are independent of the translation direction</definiens>
			</definition>
			<definition id="4">
				<sentence>Here , ¯e denotes the generalization , i.e. the base form , of the word e. The nonnegative value d is the discounting parameter , fi ( e ) is a normalization constant and fl ( f ; ¯e ) is the normalized backing-off distribution .</sentence>
				<definiendum id="0">fi ( e )</definiendum>
				<definiens id="0">the generalization</definiens>
				<definiens id="1">the normalized backing-off distribution</definiens>
			</definition>
			<definition id="5">
				<sentence>The formula for fi ( e ) is : fi ( e ) = 1N ( e ) 0 @ X f : N ( f ; e ) &gt; d d+ X f : N ( f ; e ) •d N ( f ; e ) 1 A = 1N ( e ) X f minfd ; N ( f ; e ) g This formula is a generalization of the one typically used in publications on language modeling .</sentence>
				<definiendum id="0">formula for fi</definiendum>
				<definiens id="0">a generalization of the one typically used in publications on language modeling</definiens>
			</definition>
			<definition id="6">
				<sentence>The backing-off distribution fl ( f ; ¯e ) is estimated using relative frequencies : fl ( f ; ¯e ) = N ( f ; ¯e ) P ˜f N ( ˜f ; ¯e ) Here , N ( f ; ¯e ) denotes the count of the event thatthesourcelanguage wordf andthe target language base form ¯e occur together .</sentence>
				<definiendum id="0">backing-off distribution fl</definiendum>
				<definiendum id="1">N ( f</definiendum>
				<definiendum id="2">¯e )</definiendum>
				<definiens id="0">the count of the event thatthesourcelanguage wordf andthe target language base form ¯e occur together</definiens>
			</definition>
			<definition id="7">
				<sentence>The French–English Canadian Hansards task consists of the debates in the Canadian Parliament .</sentence>
				<definiendum id="0">French–English Canadian Hansards task</definiendum>
			</definition>
			<definition id="8">
				<sentence>S : target-to-source direction ; all numbers in percent ) .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">target-to-source direction ; all numbers in percent )</definiens>
			</definition>
			<definition id="9">
				<sentence>S : target-tosource direction ; all numbers in percent ) .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">target-tosource direction ; all numbers in percent )</definiens>
			</definition>
</paper>

		<paper id="1039">
</paper>

		<paper id="1125">
</paper>

		<paper id="1056">
</paper>

		<paper id="1076">
			<definition id="0">
				<sentence>The phonetic representation of one syllable can be expressed in the form of /C i -V T -C f / , where C i is an initial consonant , V is a vowel , C f is a final consonant and T is a tone which is phonetically attached to the vowel part .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">f</definiendum>
				<definiendum id="2">T</definiendum>
				<definiens id="0">a vowel</definiens>
				<definiens id="1">a final consonant and</definiens>
				<definiens id="2">a tone which is phonetically attached to the vowel part</definiens>
			</definition>
</paper>

		<paper id="1141">
			<definition id="0">
				<sentence>Natural language is an open and very flexible communication system .</sentence>
				<definiendum id="0">Natural language</definiendum>
				<definiens id="0">an open and very flexible communication system</definiens>
			</definition>
			<definition id="1">
				<sentence>Syntax , of course , imposes constraints , e.g. , on word order or the occurrence of particular phrasal types such as PPs or NPs , and lexical semantics imposes , e.g. , selectional constraints on conceptually permitted sorts or types within the context of specific verbs or nouns .</sentence>
				<definiendum id="0">Syntax</definiendum>
				<definiendum id="1">lexical semantics</definiendum>
			</definition>
			<definition id="2">
				<sentence>For example , in the support verb construction ‘zur Verf¨ugung stellen’ ( literal : ‘to put to availabilty’ ; actual : ‘to make available’ ) , the noun ‘Verf¨ugung’ is the semantic core of the expression , whereas the verb only has a support function with some impact on argument structure , causativity or aktionsart .</sentence>
				<definiendum id="0">noun ‘Verf¨ugung’</definiendum>
				<definiens id="0">‘to make available’ ) , the</definiens>
			</definition>
			<definition id="3">
				<sentence>From the XML-marked-up tree output , PPverb complexes were automatically selected in the following way : Taking a particular PP node as a fixed point , either the preceding or the following sibling V node was taken.2 From such a PPverb combination , we extracted and counted both its various heads , in terms of Preposition-Noun-Verb ( PNV ) triples , and all its associated supplements , i.e. , here in this case any additional lexical material which also occurs in the nominal group of the PP , such as articles , adjectives , adverbs , cardinals , etc.3 The extraction of the associated supplements is essential to the linguistic measure described in subsection 3.3 below .</sentence>
				<definiendum id="0">PNV</definiendum>
				<definiens id="0">any additional lexical material which also occurs in the nominal group of the PP , such as articles , adjectives</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , besides a76a78a77a80a79 , we take the relative co-occurrence frequency for a specific PNV triple a32a51a50a52a15a17a16a19a18a99a20a23a22a69a24a27a26a29a28a31a30a82a60 ( a100 being the number of candidate types ( here , 8,644 ) ) a32a51a50a52a15a17a16a101a18a68a20a23a22a25a24a27a26a29a28a73a30a82a60a84a83a31a42 a0 a50a52a15a17a16a19a18a68a20a23a22a69a24a27a26a29a28a31a30a12a60 a62 a20 a102 a65a67a66 a0 a50a52a15a17a16a19a18a21a20a23a22a25a24a27a26a29a28a73a30a52a103a59a60 ( 3 ) and incorporate it as a second factor to a95a104a77a98a97a105a97 : a95a96a77a98a97a84a97a91a50a52a15a17a16a101a18a68a20a23a22a25a24a27a26a29a28a73a30a82a60a105a83a31a42 ( 4 ) a76a78a77a80a79a81a50a52a15a17a16a101a18a68a20a23a22a25a24a27a26a29a28a73a30a82a60a64a106a107a32a51a50a52a15a17a16a19a18a21a20a23a22a25a24a27a26a29a28a31a30a75a60 Standard procedures for evaluating the goodness of collocativity measures usually involve identifying the true positives among the a14 -highest ranked candidates returned by a particular measure .</sentence>
				<definiendum id="0">relative co-occurrence frequency</definiendum>
				<definiens id="0">4 ) a76a78a77a80a79a81a50a52a15a17a16a101a18a68a20a23a22a25a24a27a26a29a28a73a30a82a60a64a106a107a32a51a50a52a15a17a16a19a18a21a20a23a22a25a24a27a26a29a28a31a30a75a60 Standard procedures for evaluating the goodness of collocativity measures usually involve identifying the true positives among the a14 -highest ranked candidates returned by a particular measure</definiens>
			</definition>
			<definition id="5">
				<sentence>Thus , we ran an experiment which took both the PNV triples classified as collocations and the PNV triples classified as non-collocations and counted the numbers of distinct supplements ( referred to as a14 in Subsection 3.3 ) .</sentence>
				<definiendum id="0">PNV triples</definiendum>
				<definiens id="0">classified as collocations and the PNV triples classified as non-collocations</definiens>
			</definition>
			<definition id="6">
				<sentence>PNV Triple NP Supplement Frequency ‘in Griff bekommen’ den/ART Griff/NN 459 ‘to get under control’ Griff/NN 2 den/ART gewerkschaftlichen/ADJA Griff/NN 1 den/ART dramatischen/ADJA Griff/NN 1 den/ART erz¨ahlerischen/ADJA Griff/NN 1 ‘unter Druck geraten’ Druck/NN 560 ‘to get under pressure’ politischen/ADJA Druck/NN 6 erheblichen/ADJA politischen/ADJA Druck/NN 5 teilweise/ADV lebensgef¨ahrlichen/ADJA Druck/NN 1 wachsenden/ADJA Druck/NN 1 noch/ADV st¨arkeren/ADJA Druck/NN 1 schweren/ADJA Druck/NN 1 Table 4 : Collocational PNV Triples with Associated Noun Phrase Supplements 1 10 100 1 10 100 1000 proportion of all PNV-triples ( in % ) number of distinct supplements of PNV-triples Collocations Non-Collocations Figure 3 : Distribution of Supplements for ( Non- ) Collocations in PNV Triples .</sentence>
				<definiendum id="0">PNV-triples</definiendum>
				<definiens id="0">Collocational PNV Triples with Associated Noun Phrase Supplements 1 10 100 1 10 100 1000 proportion of all</definiens>
			</definition>
			<definition id="7">
				<sentence>TNT : A statistical part-of-speech tagger .</sentence>
				<definiendum id="0">TNT</definiendum>
				<definiens id="0">A statistical part-of-speech tagger</definiens>
			</definition>
</paper>

		<paper id="1184">
</paper>

		<paper id="1112">
			<definition id="0">
				<sentence>A major problem in natural language processing ( NLP ) for which no satisfactory solution has been found to date is word sense disambiguation ( WSD ) .</sentence>
				<definiendum id="0">NLP</definiendum>
				<definiens id="0">word sense disambiguation ( WSD )</definiens>
			</definition>
			<definition id="1">
				<sentence>Lemmatization allows for more compact and generalizable data by clustering all inflected forms of an ambiguous word together , an effect already commented on by Yarowsky ( 1994 ) .</sentence>
				<definiendum id="0">Lemmatization</definiendum>
				<definiens id="0">allows for more compact and generalizable data by clustering all inflected forms of an ambiguous word together</definiens>
			</definition>
			<definition id="2">
				<sentence>Lemmatization2 is a method that can be used to reduce the number of wordforms that need to be taken into consideration , as estimation is more reliable for frequently occurring data .</sentence>
				<definiendum id="0">Lemmatization2</definiendum>
			</definition>
			<definition id="3">
				<sentence>Lemmatization reduces all inflected forms of a word to the same lemma .</sentence>
				<definiendum id="0">Lemmatization</definiendum>
				<definiens id="0">reduces all inflected forms of a word to the same lemma</definiens>
			</definition>
			<definition id="4">
				<sentence>Maximum entropy is a general technique for estimating probability distributions from data .</sentence>
				<definiendum id="0">Maximum entropy</definiendum>
				<definiens id="0">a general technique for estimating probability distributions from data</definiens>
			</definition>
			<definition id="5">
				<sentence>A maximum entropy model is thus the model with maximum entropy of all models that satisfy the set of constraints derived from the training data .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
				<definiens id="0">the model with maximum entropy of all models that satisfy the set of constraints derived from the training data</definiens>
			</definition>
			<definition id="6">
				<sentence>Training itself amounts to finding weights for each feature using the following formula : p ( cjx ) = 1Z exp X i=1 n ifi ( x ; c ) where the property function fi ( x ; c ) represents the number of times feature i is used to find class c for event x , and the weights i are chosen to maximise the likelihood of the training data and , at the same time , maximise the entropy of p. Z is a normalizing constant , constraining the distribution to sum to 1 and n is the total number of features .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of times feature i is used to find class c for event x , and the weights i are chosen to maximise the likelihood of the training data and , at the same time , maximise the entropy of p. Z is a normalizing constant</definiens>
				<definiens id="1">the total number of features</definiens>
			</definition>
			<definition id="7">
				<sentence>Decision lists for lexical ambiguity resolution : Application to accent restoration in Spanish and French .</sentence>
				<definiendum id="0">Decision lists</definiendum>
			</definition>
</paper>

		<paper id="1160">
			<definition id="0">
				<sentence>The ECG formalism has , in addition to the usual inheritance hierarchy , an EVOKES relation that makes an outside structure accessible to a schema through a local name .</sentence>
				<definiendum id="0">EVOKES relation</definiendum>
				<definiens id="0">makes an outside structure accessible to a schema through a local name</definiens>
			</definition>
			<definition id="1">
				<sentence>Simulation is a dynamic process which includes executing the x-schemas specified in the SemSpec and propagating belief updates in a belief network ( Jensen 1996 , Narayanan 1999 ) .</sentence>
				<definiendum id="0">Simulation</definiendum>
				<definiens id="0">a dynamic process which includes executing the x-schemas specified in the SemSpec and propagating belief updates in a belief network</definiens>
			</definition>
			<definition id="2">
				<sentence>In traditional terms , ECG resembles a unification grammar like HPSG or LFG and many of the computational insights carry over .</sentence>
				<definiendum id="0">ECG</definiendum>
			</definition>
			<definition id="3">
				<sentence>As a linguistic formalism , ECG combines the idea of Construction Grammar as form-meaning pairings ( Croft 2001 , Fillmore &amp; Kay 1999 , Goldberg 1995 , etc. ) with the embodied semantics of the Cognitive Linguistics tradition ( Fauconnier 1997 , Lakoff 1999 , Langacker 1991 , etc. ) .</sentence>
				<definiendum id="0">ECG</definiendum>
				<definiens id="0">combines the idea of Construction Grammar as form-meaning pairings</definiens>
			</definition>
			<definition id="4">
				<sentence>Computationally , the central ideas involve probabilistic relational models ( Pfeffer and Koller 2000 , etc. ) and active knowledge ( Bailey 1998 , Narayanan 1999 , etc. ) along with their reduction to structured connectionist form and thus to neural models ( Shastri 2002 ) .</sentence>
				<definiendum id="0">probabilistic relational models</definiendum>
				<definiens id="0">active knowledge ( Bailey 1998 , Narayanan 1999 , etc. ) along with their reduction to structured connectionist form and thus to neural models</definiens>
			</definition>
			<definition id="5">
				<sentence>Constructing a Language : A usage-Based Theory of Language Acquisition .</sentence>
				<definiendum id="0">Constructing a Language</definiendum>
			</definition>
</paper>

	</volume>
