<?xml version="1.0" encoding="UTF-8"?>
	<volume id="C65">

		<paper id="1028">
			<definition id="0">
				<sentence>We have defined a schematic representation of'our operators ( called a comb-scheme ) and have then proceeded to describe a numbering technique which allows us to use these operators with a computer .</sentence>
				<definiendum id="0">schematic representation of'our operators</definiendum>
				<definiens id="0">called a comb-scheme ) and have then proceeded to describe a numbering technique which allows us to use these operators with a computer</definiens>
			</definition>
			<definition id="1">
				<sentence>Part four consists of examples : in linguistics ; an example in the logical generation of a flow diagram into a computer program ; and finally , an example of the solution of a mathematical problem ( the arithmetic operations on polynominials of n variables ) .</sentence>
				<definiendum id="0">Part four</definiendum>
			</definition>
			<definition id="2">
				<sentence>confusing the name of a list with elements of the list e. g. @ ABS @ = A B / C / D E F where AB5 is an element ( or word of our alphabet ) ; but @ AB5 @ designates a list .</sentence>
				<definiendum id="0">AB5</definiendum>
				<definiens id="0">an element</definiens>
			</definition>
			<definition id="3">
				<sentence># HAVE-EN $ RO is a schuffling which out of two intercepted words makes a third one , according to the following scheme : I : e.g. $ RO ( A-B-/C-D ) = A-CBD $ LA is a `` junction '' of the two components in one : e.g. SLA ( A-B ) = AB .</sentence>
				<definiendum id="0">RO</definiendum>
				<definiens id="0">a schuffling which out of two</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>First of all we may suppose that , to avery word-form ( shape ) which appeared in the decomposition of some sentence into words , we are able to define its basic fo~n or stem W ( the function f 'refers just to these basic forms ) and its charaqteristic ' c = ( x I , x 2 , ... , xn ) , where n is according to the need a sufficiently great integer and single x j are some gran~matical morphological and eventually even other data referring to the form W. For example x I can be the datum on word-kind , x 2 the datum on case , time , x 7 x 3 on gender , on mood a.s.o. x 4 on number , x 5 on person , x 6 on Naturally we also assume that on the contrary , if it is given the basic form w and prescribed ( of course admissible ) the characteristic c , it is easy to define the starting form ~ $ .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">word-form ( shape ) which appeared in the decomposition of some sentence into words</definiens>
			</definition>
			<definition id="1">
				<sentence>Adjectives are always one-placed predicate a.s.o. Besides the mentioned and in the logic current it is necessary to consider as semantical characteristics data On time and place and probably not yet c uite distinctly defined data referring to the conditions under which the situation is beir~g described ( here belong some adverbial modifier ) .</sentence>
				<definiendum id="0">Adjectives</definiendum>
				<definiens id="0">semantical characteristics data On time and place and probably not yet c uite distinctly defined data referring to the conditions under which the situation is beir~g described ( here belong some adverbial modifier )</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus , we suppose that We know the function k ( analogously like h ) which to any ~ ; ord-form W assigns its logical and semantical characteristic d , thus , k ( W ) = d , while again d = ( yl y2 X 1 , , , ... , y ) where e.g. y is a datum , whether the 2 word W is the logical functor and of what kind~ y is a datum 3 wh~ther the word ~i is predicate and how many-placed , y a datum of what kind the predicate is , y4 whether there is in ~ : l the definition of time and of what kind , ac .</sentence>
				<definiendum id="0">e.g. y</definiendum>
				<definiens id="0">the logical functor and of what kind~ y is a datum 3 wh~ther the word ~i is predicate and how many-placed , y a datum of what kind the predicate</definiens>
			</definition>
			<definition id="3">
				<sentence>Then we have kncwn what syntactical characteristics of words and as far as the word-order is concerned where there are to be found , so that we find out whether the investigated primitive phrases are in the given phrase included° When finishing it for all these words , we shall find it successively for all primitive phrases that in the given phrase are comprised° In such a way is , namely , depicted the analysis of the compound phrase , not composed by the logical means .</sentence>
				<definiendum id="0">primitive phrases</definiendum>
				<definiens id="0">all primitive phrases that in the given phrase are comprised° In such a way is , namely , depicted the analysis of the compound phrase , not composed by the logical means</definiens>
			</definition>
			<definition id="4">
				<sentence>As , sccording to the supposition , there is denoted in every primitve phrase its basic predicate which always stands in front of parantheses in its semantical characteristic ( for instance at Q ( x , y ) Q is the basic predicate ) it is possible to define the semantical dependence among the words of the primitive phrase by the demand that the basic predicate a !</sentence>
				<definiendum id="0">Q</definiendum>
			</definition>
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>1 ÷ 4235 ÷ 41235 ( all men ) ( the men ) ( old men ) ( men on the corner ) ( all the men ) ( all old men ) ( the old men ) ( all the old men ) ( all men on the corner ) ; but not `` 41 + S ÷ 415 ( the men on the corner ) ; but not *42 + 5 ÷ 425 ( old men on the corner ) ; but not *43 + 5 ÷ 435 ( the old men on the corner ) ; but not *423 + 5 ÷ 4235 ( all the old men on the corner ) ; but not `` 4123 + 5 ÷ 41235 With these rules , the Rrammar provides for only one structural assignment to the string : ( all ( the ( old ( men + on the corner ) ) ) ) .</sentence>
				<definiendum id="0">old</definiendum>
				<definiens id="0">the old men ) ( all the old men ) ( all men on the corner</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>The SC is a decimal fraction obtained by dividing the sum of shared SRW for each pair of TWs by the product of the frequencies of the two TWs .</sentence>
				<definiendum id="0">SC</definiendum>
				<definiens id="0">a decimal fraction obtained by dividing the sum of</definiens>
			</definition>
</paper>

		<paper id="1003">
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>Adoptin~ a distinction made by Chomsky , I make the following assertion : A PSG/S will serve as a more or less adequate observational and descriptive representation of the facts covered by a normal PSG ; as far as TG is concerndd , the structure of the transformational model ( how trees mad into trees ) will not be represented adequately on the descriptive ( and perhaps not even on the observational ) level by a PSG/S .</sentence>
				<definiendum id="0">PSG/S</definiendum>
				<definiens id="0">how trees mad into trees</definiens>
			</definition>
			<definition id="1">
				<sentence>Oettinger 1964 : A.G.Oettinger , Automatic Syntactic Analysis and the Pushdown Store , in : PSAM XII ( 1961 ) , 104_29 Sgall 1963 : U°Sgall , The Intermediate Language in Machine Translation and the Theory of Grammar , in : American Documentation Institute , 26th Annual Meeting , Chica_ go , Ill. , 1963 , 41_2 .</sentence>
				<definiendum id="0">Pushdown Store</definiendum>
				<definiens id="0">U°Sgall , The Intermediate Language in Machine Translation and the Theory of Grammar , in : American Documentation Institute , 26th Annual Meeting</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>RY 's status is now computed as : .72 ( , :72 .6 ) 5 .7 T0,3 BABY is the next candidate for MARY 's a'uditor .</sentence>
				<definiendum id="0">BABY</definiendum>
				<definiens id="0">the next candidate for MARY 's a'uditor</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>i. i. I. i Classificatory Criteria 1 ) . . . do menya 4 ) . . . k mttin~u 7 ) . . . u Zin ) r ( A ) \ ] ~efore me ( A ) for the ... ( A ) at Ztna 's ( B ) as far as me ( B ) to the ... ( B ) from Zina Z ) . . . do rassveta meeting 8 ) ... pod kapustu ( A ) before dawn 5 ) ... k nam ( A ) for ca-bbage ( B ) until dawn ( A ) to us ( B ) under cab3 ) ... iz-za stola ( B ) toward us bage ( A ) because of ... 6 ) ... za obedom 9 ) ... za stol ( B ) from behind ( A ) after ( to get ) ... ( A ) at the the table ( B ) during dinner table ( B ) be hind the table Andreyewsky 3 10 ) .</sentence>
				<definiendum id="0">pod kapustu</definiendum>
				<definiendum id="1">k nam</definiendum>
				<definiens id="0">A ) \ ] ~efore me ( A ) for the ... ( A ) at Ztna 's ( B ) as far as me ( B ) to the ... ( B ) from Zina Z )</definiens>
				<definiens id="1">A ) for ca-bbage ( B ) until dawn ( A ) to us ( B ) under cab3 ) ... iz-za stola ( B ) toward us bage ( A ) because of ... 6 ) ... za obedom 9 ) ... za stol ( B ) from behind ( A ) after ( to get ) ... ( A ) at the the table ( B ) during dinner table ( B</definiens>
			</definition>
			<definition id="1">
				<sentence>3 ) is ~ form ( A ) reflexive ( B ) non-reflexive 4 ) generally : ( A ) non-reflexive ( B ) reflexive 5 ) when reflexive , meaning : ( A ) active ( B ) passive 6 ) participial forms : ( A ) active ( B ) passive 7 ) passive participle : ( A ) past ( B ) present 8 ) gerundial forms : ( A ) present ( B ) past 9 ) action ( gerund ) : ( A ) parallel ( B ) sequential I0 ) deverbal nouns : ( A ) in -enle , -ks ( B ) other forms II ) deverbal nouns : ( A ) concrete ( B ) abstract 1Z ) verb used : ( A ) personally ( B ) impersonally 13 ) verb function : ( A ) link , auxillary ( B ) other 14 ) meaning affected by ( A ) governed infinitive ( B ) object ( s ) 15 ) subject preference : ( A ) inanimate ( B ) animate 16 ) verb governs : ( A ) infinitive s ( B ) objects 17 ) object preference : ( A ) animate ( B ) inanimate 18 ) ( A ) motion verb ( broad sense ) ( B ) action perceived 19 ) verb describes : ( A ) action ( B ) state Z0 ) ( A ) beginning ( B ) end of action Andreyewsky 7 21 ) verb is one of : ( A ) being ( B ) becoming ZZ .</sentence>
				<definiendum id="0">) infinitive s ( B</definiendum>
				<definiens id="0">A ) active ( B ) passive 6 ) participial forms : ( A ) active ( B ) passive 7 ) passive participle : ( A ) past ( B ) present 8 ) gerundial forms : ( A ) present ( B ) past 9 ) action ( gerund ) : ( A ) parallel ( B ) sequential I0 ) deverbal nouns : ( A ) in -enle , -ks ( B ) other forms II ) deverbal nouns : ( A ) concrete ( B ) abstract 1Z ) verb used</definiens>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>( i ) Zo +~ w ( s~ ( Zo ) ) s~ ( zo ) is an element of S ( zo ) which is the set of the derived main constituents for zo .</sentence>
				<definiendum id="0">zo )</definiendum>
				<definiens id="0">an element of S ( zo ) which is the set of the derived main constituents for zo</definiens>
			</definition>
			<definition id="1">
				<sentence>/ : z ( `` Pew ) , P ( w : , , ) , P~w.. '</sentence>
				<definiendum id="0">P (</definiendum>
			</definition>
			<definition id="2">
				<sentence>NP1 ~ 1-CM.3-CM Kennedy is the president of the U.S. -- ~ Kennedy , the president of the U.S. , NPI .</sentence>
				<definiendum id="0">Kennedy</definiendum>
				<definiens id="0">the president of the U.S. -- ~ Kennedy , the president of the U.S. , NPI</definiens>
			</definition>
			<definition id="3">
				<sentence>SEMANTIC CATEGORIES ( NOUN ) Human beings ( 300 ) man ( 301 ) family ( 302 ) social ( 303 ) ( 304 ) ( 305 ) Nature ( 340 ) celestial ( 341 ) atmospheric ( 342 ) geographic ( 343 ) minerals ( 344 ) water ( 345 ) Large things ( 360 ) movable ( 361 ) building ( 362 ) parts of 362 ( 363 ) place ( 364 ) Articles ( 370 ) books ( 371 ) foods ( 372 ) furniture ( 373 ) playthings ( 374 ) ( 375 ) Mental action ( 380 ) thinking ( 381 ) feeling ( 382 ) ( 383 ) ( 38~ ) ( 385 ) ( 386 ) Action ( 390 ) ( 387 ) ( 391 ) ( 392 ) ( 393 ) ( 394 ) ( 395 ) boy , child , girl , person , man , woman , Jack , Betty , Nelson brother , company , family , father , friend , people , sister , son , mother king , soldier , god , president specialist , reader , scientist , professional , ( group ) , blind , editor , debutant generation , group sun , moon , earth rain , wind , air river , hill , mountain , road , land , field , sea Mt. Fuji , Kaatskill , Appalachia , Lake Biwa rock , stone , gold , silver water , sea , rain bus , train , car , ship house , church , school , Kyoto Univ. door , window , room road , street , garden book , picture , paper , story , Newsweek , Bible , handbook , library , monograph , article , summary literature , supplement , journal , proceeding , report , volume , tewt-book food , egg , bread , milk , corn , salt , pepper , water , bear table , box , bed , dress ball , teniss processor , machine , computer reason , idea , hope , mind , thought love , life , fear aim , end readiness gratitude , thank , patience , acknowledgement knowledge , thought , view , opinion , reference , aspect , conception , comment , consideration , understanding sense , art , view life , love war question , answer , speech , call , order , judgement , citation , problem example death , existence visit , watch , indication , advance , access , response , change Sakai &amp; Nagao 15 Abstract ( 400 ) ( ~Io ) Sgci @ l terms ( 420 ) ( 430 ) ( ~7o ) ( 396 ) ( 397 ) ( 398 ) ( 399 ) ( 4oi ) ( 4o2 ) ( 403 ) ( 4o~ ) ( 4o5 ) ( ~o6 ) ( ~o7 ) ( 411 ) ( 4~2 ) ( 413 ) ( 414 ) ( 415 ) ( 421 ) ( 422 ) ( 423 ) ( 424 ) ( 425 ) ( 431 ) ( 43a ) ( 433 ) ( 43~ ) ( 435 ) ( 436 ) ( 471 ) ( 4 ?</sentence>
				<definiendum id="0">SEMANTIC CATEGORIES</definiendum>
				<definiendum id="1">NOUN</definiendum>
				<definiendum id="2">Betty</definiendum>
				<definiens id="0">395 ) boy , child , girl , person , man , woman , Jack ,</definiens>
				<definiens id="1">father , friend , people , sister , son , mother king , soldier , god , president specialist , reader , scientist , professional , ( group ) , blind , editor , debutant generation , group sun , moon , earth rain , wind , air river , hill , mountain , road , land , field , sea Mt. Fuji , Kaatskill , Appalachia , Lake Biwa rock , stone , gold , silver water , sea , rain bus , train , car , ship house , church , school , Kyoto Univ. door , window , room road , street , garden book , picture , paper , story , Newsweek , Bible , handbook , library , monograph , article , summary literature , supplement , journal , proceeding , report , volume , tewt-book food , egg , bread , milk , corn , salt , pepper , water , bear table , box , bed , dress ball , teniss processor , machine , computer reason , idea , hope , mind , thought love , life , fear aim , end readiness gratitude , thank , patience , acknowledgement knowledge , thought , view , opinion , reference , aspect , conception , comment , consideration , understanding sense , art , view life , love war question , answer , speech , call , order , judgement , citation , problem example death , existence visit , watch , indication , advance , access , response</definiens>
			</definition>
			<definition id="4">
				<sentence>SEMANTIC CATEGORIES ( ADJECTIVE ) Qualifyin~ state of the object outward ( 530 ) color ( 531 ) shape ( 532 ) length ( 533 ) height ( 534 ) extent ( 535 ) size ( 53~ ) ( 537 ) black , blue , gree~ , red , white round , plain long , short deep , high , low wide , narrow large , little , small , big , least single , individual , numerous , multiple Sakai 2 , Nagao 16 subjective ( 550 ) beauty ( 551 ) fair ( 552 ) free ( 553 ) full ( 555 ) internal ( 570 ) material ( 571 ) weight ( 572 ) hardness ( 573 ) temperature ( 574 ) new , old ( 575 ) soft , ( 576 ) social state ( 590 ) wealth ( 591 ) position ( 592 ) fact ( 593 ) restruction ( 594 ) ( 595 ) ( 596 ) ( 597 ) mental state ( 600 ) sentiment intimacy time ( 620 ) valuation ( 640 ) good , bad abstruct ( 660 ) ( 601 ) ( 602 ) ( 603 ) ( 604 ) ( 605 ) ( ( 621 ) ( 622 ) ( 623 ) ( 641 ) ( 642 ) ( 643 ) ( 661 ) relation ( 670 ) ( 680 ) ( 662 ) ( 663 ) ( 664 ) ( 665 ) ( 671 ) ( 672 ) ( 673 ) ( 674 ) ( 675 ) ( 681 ) ( 682 ) ( 683 ) beautiful , pretty fair , clear , fine free , fresh full , complete Undisputed gold , light , heavy hard , soft cold , warm , hot new , old , fresh soft , swee , fresh rich , poor , cheep , modest great , deep % rue , correct , natural free , strict , major skilled , detailed commercial , available neighboring glad , happy , sad dear , ready , desirable , familiar aware , wary , afraid active , attractive proud fast , quick ready late , recent , current , present , final good , bad , right , modest , valuable very , immense natural general , collective , common , particular , special , comprehensive , standard , specific next , certain present , absent , conventional related , informed , concerned complex , detailed , bound , complate right , left close , near , intermediate direct , conclusive , extensive individual possible , impossible , necessary , enough digital , linguistic , automatic spectral , t technical , scientific leterary , professional world wide Sakai &amp; Nagao 17 TABLE 2 .</sentence>
				<definiendum id="0">SEMANTIC CATEGORIES</definiendum>
				<definiendum id="1">ADJECTIVE</definiendum>
				<definiens id="0">clear , fine free , fresh full , complete Undisputed gold , light , heavy hard , soft cold , warm , hot new , old , fresh soft , swee , fresh rich , poor , cheep , modest great , deep % rue , correct , natural free , strict , major skilled , detailed commercial , available neighboring glad , happy , sad dear</definiens>
				<definiens id="1">specific next , certain present , absent , conventional related , informed , concerned complex , detailed , bound , complate right , left close , near , intermediate direct , conclusive , extensive individual possible , impossible , necessary , enough digital , linguistic , automatic spectral , t technical , scientific leterary , professional world wide Sakai &amp; Nagao</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>the whole sentence /i.e. not of the form of the rules , but of the strategy of their application/ is the problem where to begin the analysis , i.e. at which word of the sentence \ [ 4\ ] .</sentence>
				<definiendum id="0">application/</definiendum>
				<definiens id="0">the problem where to begin the analysis</definiens>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>Notwithstanding a number of philosophical objections , the semantic atom is an operationally feasible support for a lexicon which is a semantic subset of all possible meanings and at the same time , exhausts the vocabulary of a language .</sentence>
				<definiendum id="0">semantic atom</definiendum>
				<definiens id="0">a semantic subset of all possible meanings and at the same time , exhausts the vocabulary of a language</definiens>
			</definition>
			<definition id="1">
				<sentence>A semantic atom is a ciently specified to remove completely defined unit concept suffiall ambiguity .</sentence>
				<definiendum id="0">semantic atom</definiendum>
				<definiens id="0">a ciently specified to remove completely defined unit concept suffiall ambiguity</definiens>
			</definition>
			<definition id="2">
				<sentence>P ( cc ) is a function of time and satisfies the following differential equation : where i and j are languages , ~ and ¢ mean `` belongs to '' and `` does not belong to '' respectively , and ~ ) is the union of c~ and the set containing only the language j .</sentence>
				<definiendum id="0">P ( cc )</definiendum>
				<definiendum id="1">~ )</definiendum>
				<definiens id="0">the union of c~ and the set containing only the language j</definiens>
			</definition>
			<definition id="3">
				<sentence>This is obtained by setting the ( logarithmic ) derivative of probability to zero so that 0 = A-k ' NK-A + ( Nl ) k ' x l-x i + ( N-l ) x where A = k ' + Zk s + 3k s + ... + Nk N .</sentence>
				<definiendum id="0">logarithmic</definiendum>
				<definiens id="0">A = k ' + Zk s + 3k s + ... + Nk N</definiens>
			</definition>
</paper>

		<paper id="1030">
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>An elementary neighborhood is the set of all contexts equivalent to one context .</sentence>
				<definiendum id="0">elementary neighborhood</definiendum>
				<definiens id="0">the set of all contexts equivalent to one context</definiens>
			</definition>
			<definition id="1">
				<sentence>A distribution class can be defined as a set of strings whose complete neighborhoods are related to a given set of contexts in a specified way .</sentence>
				<definiendum id="0">distribution class</definiendum>
				<definiens id="0">a set of strings whose complete neighborhoods are related to a given set of contexts in a specified way</definiens>
			</definition>
			<definition id="2">
				<sentence>Each acceptable string is an undefined term .</sentence>
				<definiendum id="0">acceptable string</definiendum>
			</definition>
			<definition id="3">
				<sentence>nQ are broW &lt; ell o.~. Any o. ~ ... ... . ~ ~. -~ ~ , I ... ... .. s 3~ a sLrin Z is called a se &amp; ~nent , it may be either continuous or U~CO~uoZnUOGo. ~ discoP.tiZlUOUS sec ' , ' , ~enL consists of a few nar~s se.narated from each otl.er. Each o~ , z~t of se &lt; ' : : : e : &lt; % : :s Ca~__~ , ~ a fra-~ , ,lent which is necessarily con'~inuous ( ~-az-l &lt; er-i.~-.odes~ itdl ) . ~. boll ~el { ~ : ... ... ... ( , ~_ , ,. , , , ~ , . Let r be a strin~ an &amp; ~eL s be a seonenu of r. ~ : ,e s~.~ , ~ r may be continuous or discontinuous. ; lhe other : taru~ c of z '' _~s called the co~-'~c.~.~ of s ... ... ~.~.~u ... . ~.~ Lf.eZ : i We ; .sa~ , r c ~.s &amp; i % ~c , .. , .z. , ~ , _~u.~ , ~ OOl % Le\ ] &lt; L O- '' S~ or c is ... ... . -~ acc~i~u~m~ to s. • . , f , ~ &gt; .</sentence>
				<definiendum id="0">~eL s</definiendum>
				<definiens id="0">consists of a few nar~s se.narated from each otl.er. Each o~ , z~t of se &lt; '</definiens>
			</definition>
			<definition id="4">
				<sentence>If all the contexts in y become acceptable strings when s is supplied to them , then the set y defines a property of s. We call the set y an acceptable neighborhood of s. If y is an acceptable neighborhood of strings Sl , s 2 , s 3 , for instance , then we say y is an acceptable neighborhood of S = set ( sl , s2 , s3 ) , and we consider the set y represents a syntactic property common to all the strings in S. ~ote that our neighborhood is not the same as the okrjestnostj ( Kulagina , 1958 ) .</sentence>
				<definiendum id="0">set y</definiendum>
				<definiens id="0">y become acceptable strings when s is supplied to them , then the set y defines a property of s. We call the set y an acceptable neighborhood</definiens>
				<definiens id="1">an acceptable neighborhood of S = set ( sl</definiens>
			</definition>
			<definition id="5">
				<sentence>&lt; ig : :'.ta~F ' • . o._. We zlave seen above Bhat a co : ; : piete ; ; eishborhood x : c ( : ~ ) is ir.~erpreted in te : m ; ~s of y : c ( s ) and z : ~ &lt; u ) . : ' , 'e ca'~ ex~pect ~s ) and `` '' ~e a ~kL ; : ray re-~-~ese=zazmon O7 a s ' , mp.er aria more specific syntactic func-cion , if C ( r ) : c ( s ) O c ( t ) , c ( ~ ) / c ( t ) , c ( ~ ) I o , c ( ~ ) I o , then , for some c in C ( s ) and some c in C ( t ) , we have c. noz ecv c~. \ ] o hood , leads us to a concept of the ultimate unit of syntactic function. Given the elementary neighborhood e ( i ) with c. as an element is defined ! a context ci , as e ( i ) = set ( c : c eqv c. ) . l Since the equivalence is symmetric , reflexive and transitive , any two distinct ele : : ; e-=~ary neizhborhoods have no elements in common. ~ an element c in x ~s a : : , emoer of e ( i ) ~ then e ( i ) r : : , b~cause x is co'.rSie~e ' '' ~. in `` • ~a.~ an element c x ; then there ms an e ( i ) such \ ] _ that • ( ) . C ~ e i x : Ue ( i ) for all ek~ ) 's ~=ving at leas~ one element in x. Every elementary Sakai i0 neighborhood is complete. An intersection of complete neighborhoods is complete. Every union of elementary neighborhoods is a complete neighborhood. 2 '' Distribution Class. We have thus far discussed the syntactic function of symbol strings in terms of their acceptable contexts. A context is an environmental condition in which a string occurs. Given a context , we can classify the strings into two distinct categories : the one is a class of strings that can occur in the given environment and the other is the class of strings that can not occur therein. If there exists at least one context c in which both s and t can occur , then c ~C ( s ) and c ~C ( t ) , that is c ~ C ( s ) N C ( t ) # O. We define the set of all strings t , that can replace s in some contexts , as G ( C ( s ) ) = set ( t : C ( t ) N C ( s ) # 0 ) . We introduce a convention A ( = ) B which means that the intersection of the two sets A and B is not empty : G ( C ( s ) ) = set ( t : C ( t ) ( = ) C ( s ) ) . Suppose a string t can occur wherever s can occur , but s can not always occur in the contexts accepted by t. In this case , c ( t ) o C ( s ) . We define H ( C ( s ) ) = set ( t : C ( t ) O C ( s ) ) . The distribution class I ( C ( s ) ) is a set of all the strings t that can be always replaced by s : I ( C ( s ) ) = set ( t : C ( t ) c C ( s ) ) . That the two strings s and t are mutually replaceable means that s can occur wherever t can occur and conversely t can occur wherever s can occur. In other words , any context c is accepted by t , if and only if it is accepted by s : c g C ( t ) if and only if c ~C ( s ) , or C ( t ) = C ( s ) . We indicate the set of such strings t by J ( C ( s ) ) = set ( t : C ( t ) = C ( s ) ) . Other distribution classes are defined as sets of strings whose complete neighborhoods are related to a certain complete neighborhood in a specified way. Let x be an arbitrary complete neighborhood. The simple types of Sakai ll distribution classes mentioned above are written as G ( x ) = set ( t : C ( t ) ( = ) x ) , H ( x ) = set ( t : C ( t ) 2 x ) , I ( x ) = set ( t : C ( t ) ~x ) , J ( x ) = set ( t : C ( t ) = x ) . A distribution class is said to be real if it is not empty , and imaginary if it is empty. able strings and only these. and their contexts Suppose , for instance , that a language consists of the acceptthey are ( flying/red/making ) planes , a ( flying/red ) saucer is an object , ( flying/making ) planes is an industry , We observe the strings s I = flying , s 2 = red , s 3 = making c I = they are ( ) planes , c 2 = a ( ) saucer is an object , c 3 = ( ) planes is an industry. The complete neighborhoods of the strings are C ( s l ) = C ( flying ) = set ( cl , c2~c3 ) , C ( s 2 ) = C ( red ) = set ( cl , c2 ) , C ( s 3 ) = C ( making ) = set ( cl , c3 ) . The distribution classes are determined by these neighborhoods. types above are given in the table below. i : s I C ( s. ) G ( C ( s. ) ) I ( c ( s. ) ) l l l ! i : flying ( Cl , C2 , C 3 ) ( Sl , S2 , S 3 ) ( s l ) ( Sl , S2 , S3 ) 2 : red ( Cl , C 2 ) ( Sl , S2 , S3 ) ( Sl , S 2 ) ( s 2 ) 3 : making ( ci , c3 ) ( Sl , S2 , S3 ) ( Sl , S3 ) ( s 3 ) The simple J ( C ( s. ) ) l ( s a ) ( s 3 ) Sakai 12 The elementary neighborhoods e ( i ) = set ( c : c eqv ci ) , i = i , 2 , 3 are found by consulting the table below , where `` + '' on the i-th row and J-th column means `` cj is acceptable to si '' . : c I c 2 .c~ Sl : + ÷ + s2 : + + s3 : + + e ( 1 ) = set ( c : c eqv c I ) = set ( cl ) , e ( 2 ) = set ( c2 ) , e ( 3 ) = set ( c3 ) . Therefore , C ( s l ) = e ( 1 ) ~e ( 2 ) ~ e ( 3 ) , C ( s 2 ) = e ( 1 ) U e ( 2 ) , C ( s~ ) = e ( 1 ) U e ( 3 ) . , i. ( i ) J ( x ) = H ( x ) , q Z ( x ) ; ( 2 ) H ( x ) U z ( x ) ~_ G ( x ) , Proof. ( 1 ) t ~ J ( x ) , if and only if C ( t ) = x , `` C ( t ) ~ x and `` t 6 H ( x ) and `` t ~ H ( x ) N i ( x ) . ( 2 ) t 6_ H ( x ) U Z ( x ) , if and only if t ~ H ( x ) or `` C ( t ) ~ x x # O. C ( t ) c x , t 6 I ( x ) , t d i ( x ) , or C ( t ) : 'x , for x / O , then C ( t ) ( = ) x if and only if t ~ G ( x ) . transitive. ~erefore , J ( x ) = J ( y ) if and only if J ( x ) ( = ) J ( y ) . This means that any two different sets have no elements in common and , consequently , that every element belongs to one and only one set of the form J ( x ) . 7e3o If X is an elementary neighborhood , then G ( x ) = set ( t : C ( t ) ( = ) x ) = set ( t : C ( t ) ~ x ) m = : ~ ( x ) if x/ O ; I ( x ) = set ( t : C ( t ) C x ) = set ( t : C ( t ) = x ) : J ( x ) , so that C ( t ) is also elementary. then if Sakai 13 If x is any complete neighborhood and if C ( t ) is elementary for all t , G ( x ) = set ( t : C ( t ) ( = ) x ) = set ( t : C ( t ) ~ x ) m = I ( x ) ; H ( x ) = set ( t : C ( t ) D x ) m = set ( t : C ( t ) = x ) : J ( x ) x / O , so that x is also elementary. empty , then 7-4. If ( 1 ) ( 2 ) ( 3 ) Proof. ( 1 ) if and only if I ! I ! I ! ( 2 ) if and only if I ! G ( x ) = ~ ( x ) = I ( x ) = J ( x ) . X = y U z , then G ( x ) = G ( y ) U G ( z ) , H ( x ) = a ( y ) ~ ~ ( z ) , I ( x ) ~ i ( y ) O I ( z ) . t ~ G ( x ) = G ( y ~ z ) , C ( t ) ( = ) x = y ~ z , c ( t ) ( : ) y or c ( t ) ( : ) z , t ~ G ( y ) or t ~ G ( z ) , t 6 G ( y ) U G ( z ) . t £ H ( x ) , C ( t ) ox = yUz , C ( t ) 2Y and C ( t ) _Oz , t6H ( y ) and t~ ( z ) , It ( 3 ) if and only if then if and only if ~.~A. ( l ) ( 2 ) Proof. ( l ) if and only if l ! then if and only if ( 2 ) if and only if T ! 11 I ! t ~H ( y ) ~H ( z ) . t~I ( y ) U I ( z ) , c ( t ) ~ y or c ( t ) ~ y ~ z : x , t £ Z ( x ) . If x : yN z , then G ( x ) ~ G ( y ) ~ G ( z ) , Z ( x ) = Z ( y ) N Z ( z ) . C ( t ) ~ z , t £ G ( x ) , C ( t ) ~ x # O , c ( t ) ~ y ~ z / o , C ( t ) ~ { y # 0 and t ~G ( y ) ~d ( z ) . t ~ I ( x ) , c ( t ) C_x = yAz , C ( t ) ~y and , C ( t ) ~ z , t ~ I ( y ) and t ~ I ( z ) , tEl ( y ) ~ Z ( z ) . -- -- -~ r n Sakai 14 Concatenation. Cqncatenation of Strings. Let p be a string and let r I , r 2 , c~t ) ~ z # 0 , be segments of p which do not mutually overlap. A segment t consisting of r l , r 2 , -- - , rn is the concatenation of these segments. It is a segment of p , consisting of fragments of -- arranged in their relative order in the original string p. It r l , r 2 , , r n is convenient to assign a definite notational order to a concatenation in order to specify the arrangement of fragments. Let r l , r 2 , -- - , r n be segments of p with no fragments in common. c ( r ) of r in p , p l l i = i , 2 , -- - , n correspond uniquely to the segments ri , 'l~e contexts respectively , and so does c ( t ) to P the concatenation Sakai 15 We write t = rlr2 -- -r n. Cp ( ri ) Cp ( r2 ) -- -Cp ( r n ) = Cp ( t ) if and only if t = rlr2 -- -rn in Let a , b , c , -- be elements of sets. p. We call an ordered string of these elements a concatenation. Let A , B , C , -- be sets. We define the concatenation , of sets as AB -- -D = set ( ab -- -d : a~ A , b ~B , -- - , d ~ D ) . In our present discussion , the elements are either all strings or all contexts. lawing discussions can be easily generalized to longer concatenations. An unambiguous concatenation , ABCD for instance , is considered as one of the three binary concatenations A ( BCD ) , ( AB ) ( CD ) , ( ABC ) D when the discussion is strictly binary. In a morphographemic description , however , this is not very important. One may assume one of these three acceptable and discard the other two as unacceptable. In a morphotactic description , some one of these three will be chosen so as to make the whole description of the language simpler. If any one of the sets which constitute a concatenation is empty , then the concatenation is also empty. We assume that the binary concatenations required by the grammar are ( AB ) ( CD ) , A ( BC ) , ( BC ) D and only these. The possible binary tree structures of ABCD are covered by ABCD = A ( BCD ) U ( AB ) ( CD ) U ( ABC ) D. Since we are to handle binary concatenations only , we consider two concatenations of elements are different if their structures are not the same : Then , the condition yields ( i ) ( 2 ) ( 3 ) By assumDtion , ( AB ) ( CD ) N A ( BCD ) = O , ( AB ) ( CD ) ~ ( ABC ) D = O. ABCD : ( AB ) ( CD ) ( AB ) ( CO ) I O , ~erefore , ( 4 ) 45 ) because Similarly , ( 6 ) ( 7 ) From ( 2 ) , By ( 7 ) and ( 6 ) , or , ( 8 ) From ( 3 ) , By ( 4 ) and ( 5 ) , ( 9 ) Sakai 16 A ( ~C ) J O , ( A~ ) C : O , A ( BC ) N ( , ~ ) C : O. BCD = B ( CD ) \ [ _ ) ( BC ) D = ( BC ) D , ( BC ) D ~ O , B ( CD ) : O. A ( BCD ) : A ( B ( CD ) h ) ( Be ) D ) : O. A ( BCD ) : 0 0 A ( ( BC ) D ) : o , A # O , ( ~C ) O # O , A ( ( BC ) O ) : O. ( ABC ) D : ( A ( BC ) O ( AB ) C ) D : O. ( ABC ) D = ( A ( BC ) ~ O ) O : ( A ( BC ) ) D = O , A ( BC ) # O , D # O , ( A ( BC ) ) D = 0. Now , we can describe the syntax of these strings in terms of binary concatenations only , if we establish the rules numbered from ( 1 ) to ( 9 ) . ( 1 ) AB = CD , if and only if A = C and B = D , because , for any ab in AB , AB = CD if and only if Cab ~ AB if and only if ab~ CD ) `` ( ( a ~ A , b @ B ) if and only if ( a ~ C , b~ D ) ) I ! ( a ) because if and only if I , II r ! ( 3 ) Similarly , ( 4 ) because if and only if V ! 11 ( a~ A if and only if a ~ C , bE B if and only if b ~ D ) A = C and B = D. A ( BU C ) = ABU AC , ab ~ A ( B U C ) a 6A an~ b6BUC ( a ~ A and b ~B ) or ab 6 AB or ab 6 AC ab ~ AB ~ AC. ( AOB ) C : ACUBC. ABDCD= ( Af\ ] C ) ( BDD ) , ab ~ AB tO CO ab ~ AB and ab ~ CD a ~ A and b ~ B and a~ A~C and ( a ~ A and b 6 C ) a &amp; C b~B~D and b ~ D strings r and s , such that C ( r ) : x and C ( s ) = y. By definition , Sakai 17 `` ab ~ ( A N C ) ( B lq D ) . Concatenation of Complete Neighborhoods.. If the distribution classes J ( x ) and J ( y ) are real , then there exist p ( r i ) = -- -r. -- -l with the segment r. in it is acceptable if and only if p ( r ) ... . r -- is acceptable , and the string p ( s. ) ... . 2° -- 3 3 .is acceptable if and only if p ( s ) ... . s -- is acceptable. Suppose P ( ris j ) = -- -ri -- -sj -- is a string with both r. and s. in it. Any such string ix acceptable if and l j only if the string p ( r.s ) : -- -r. -- -s -- l l is acceptable , and P ( ris ) is acceptable if and only if p ( rs ) ... . r -- -s -- is acceptable. ~nerefore , P ( ris j ) is acceptable if and only if p ( rs ) is acceptable. That is C ( ris j ) = C ( rs ) . We define the concatenation C ( r ) C ( s ) of complete neighborhoods as the complete I % neighborhood C ( rs ) of the concatenated strings. Generally , we put xy : c ( rs ) , r ~ J ( x ) , s 6 J ( y ) for any com~plete neighborhoods x and y , where J ( x ) and J ( y ) may be real or imaginary. Note , however , that if x : C ( r ) , y : c ( s ) , C ( r i ) = x for all rl in J ( x ) and C ( sj ) = y for all s3 in J ( y ) . Any string Sakai 18 then xy = C ( rs ) , while xy = C ( rs ) does not always result in x : C ( r ) or y = C ( s ) . We have generalized and transferred the concatenation of strings to concatenated sets of strings and then to concatenated complete neighborhoods. The complete neighborhood representation provides us with a less complicated approach , especially when the strings are syntactically ambiguous. The distribution class J ( x ) means the narrowest classification of strings and no further subclassification is possible , while its complete neighborhood x can be subclassified if x is not an elementary neighborhood. If rg J ( x ) and x = y Uz , then we can talk about imaginary strings r ' and r '' , such that C ( r ' ) = y and C ( r '' ) = z. These imaginary strings , always referred to implicitly in terms of distribution classes , can be discussed explicitly in terms of complete neighborhoods. xy : c ( r ) c ( s ) of complete neighborhoods and the complete neighborhood z : C ( rs ) . ~ % e former means a set consisting of concatenated contexts. The properties of the language is introduced when it is written in the form xy= z or C ( r ) C ( s ) : C ( rs ) , where the property x of r and the property y of s result in another property z of rs. Thus , z can be an empty set even if neither x nor y is empty , and ambiguous even if neither x nor y is ambiguous. neighborhood in a unified way. We saw that a complete neighborhood x can be represented by a union of elementary neighborhoods e ( i ) : x = Oe ( i ) with x ~ e ( i ) ~ O. Let us introduce coefficients x ( i ) , such that x ( i ) : o if = i if and no other cases possibly occur. x ( i ) e ( i ) = e ( i ) =0 e ( i ) , Ox =o , e ( i ) -x ; We put if x¢i ) : l , if x ( i ) : o. Sakai 19 In virtue of these coefficients , we can write ( 1 ) If then If then ~\ ] erefore , for we have ( 2 ) If then x = Dx ( i ) e ( i ) , y = ~y ( j ) e ( j ) , z = Uz ( k ) e ( k ) . z=xOy , x U Y = ( U x ( i ) e ( i ) ) U ( Oy ( j ) e ( j ) ) = U ( x ( k ) + y ( k ) ) e ( k ) = U z ( k ) e ( k ) . e ( k ) c_ x or e ( k ) ~ y , e ( k ) ~_ z. x ( k ) + y ( k ) = z ( k ) , 0~-0=0 , l+O =0 +l= 1 +l= 1. z = xy , z = ( Ux ( i ) e ( i ) ) ( ~y ( j ) e ( j ) ) = DU x ( i ) y ( j ) e ( i ) e ( j ) = UU z ( i , j ) e ( i ) e ( j ) . By the definition of concatenation , e ( i ) e ( j ) ~ xy if and only if That is , if and only if Therefore , for we have e ( i ) C x and z ( i , j ) = 1 x ( i ) = y ( j ) = 1. x ( i ) y ( j ) = z ( i , j ) , 1Xl=l , e ( j ) c y. Writing we have if and only if e ( i ) e ( j ) ~ z Therefore , for the expression z ( i , j ) a ( i , j , k ) = z ( k ) , we have 1 X 1 = l , e ( i ) e ( j ) = Ua ( i , j , k ) e ( k ) '' Z = xy = U~ z ( i , j ) e ( i ) e ( j ) : UUU z ( i , j ) a ( i , j , k ) e ( k ) = Uz ( k ) e ( k ) , e ( k ) ~ z and e ( k ) ~ e ( i ) e ( j ) . ( 3 ) A concatenation of two elementary neighborhoods is a complete neighborhood , and it is also a union of elementary neighborhoods : Sakai 20 10. i0. i. be cause if and only if 11 I ! then , if and only if l0.2. because if and only if II It II I ! then if and only if lo._.._5.5. because if and only if II It II I1 then if and only if 10.4. because if and only if 11 ! I then if and only if Concatenation of Distribution Classes. G ( u ) G ( v ) ~G ( uv ) , r~ £ G ( u ) ~ ( v ) r £ G ( u ) and s £ G ( v ) C ( r ) N U / 0 and C ( s ) ~ V / 0 ( C ( r ) ~ u ) ( C ( s ) ~ v ) = C ( r ) C ( s ) N uv / o C ( rs ) ~uvJ0 rs £G ( uv ) . H ( u ) H ( v ) c ~ ( uv ) , rs E ~ ( u ) ~ ( v ) r ~ H ( u ) and s g H ( v ) C ( r ) D u and C ( s ) ~ v C ( r ) ~ u =u and ~C ( s ) ~ v = v ( C ( r ) ~ u ) ( C ( s ) N v ) = C ( r ) C ( s ) N uv : uv C ( r ) C ( s ) ~ uv C ( rs ) 2 uv rs ~ H ( uv ) . I ( u ) I ( v ) ~ I ( uv ) , rs £ I ( u ) I ( v ) r ~ I ( u ) and s ~ I ( v ) C ( r ) c u and C ( s ) ~ v C ( r ) ~ u = C ( r ) and C ( s ) ~ v = C ( s ) ( C ( r ) ~ u ) ( C ( s ) D v ) : C ( r ) C ( s ) D uv : C ( r ) C ( s ) C ( r ) C ( s ) c uv m C ( rs ) c uv N rs 6 I ( uv ) . J ( u ) J ( v ) C J ( uv ) , rs ~ J ( u ) J ( v ) r ~ J ( u ) and C ( r ) = u and C ( r ) C ( s ) = uv C ( rs ) : uv rs £ J ( uv ) . s 6 J ( v ) C ( s ) = v Sakai 21 i ! . Rules for Recognition and Generation. Each rule of a grammar indicates the arrangement of a few items to be concatenated , accompanied by some other necessary informations. We assume the items arranged in a rule are either complete neighborhoods or distribution classes. Let us see what happens during the generation and recognition of a string of symbols. In case a grammar is given in terms of complete neighborhoods , the input text is converted to a string of complete neighborhoods before the syntactic analysis begins. At the very end of generation , a terminal node accompanied by a complete neighborhood x is replaced by a string s whose complete neighborhood C ( s ) shares at least one elementary neighborhood with x. ~nen the syntactic rules are expressed in terms of sets of strings , the input text to be analyzed is replaced by a string of distribution classes. If a symbol string belongs to more than two sets of strings , their meet replaces the symbol string. At the end of a generation , the synthesized output string is obtained by replacing the set of strings on @ ach terminal node by a string which is a member of the ' set. ll.1. An acceptable string can be generated and analyzed making use of a tree with its nodes marked by complete neighborhoods. The expansion of a node z to a concatenation xy of nodes x and y implies z ~ xy , because otherwise further expansion of x and y may yield a structure which can not be accepted by z. Transformational rules can be a } ? plied more freely because a transformation does not imply such a restriction. However , attention ahould be paid not to add any other contexts to the complete neighborhoods attached to the nodes already generated. Finally , each terminal node is replaced by a lexical element. ~ % e string obtained after applying all the obligatory rules must be an acceptable string. ~ne analysis is carried out by testing all the possible transformations and trying all the possible contractions. At any rate , both generation and analysis can be carried out if we have a set of rules which gives concatenation z = x -- -y for any x , -- - , y of the language , and the transform y ( 1 ) y ( 2 ) -- -y ( n ) of any string x ( 1 ) x ( 2 ) -- -X ( m ) of complete neighborhoods. ll.2. Acceptable strings are also generated by starting from the node P ( O ) which is the set of all acceptable strings. It is replaced by its subset P ( 1 ) P ( 2 ) -- -P ( i ) -- -P ( m ) ~ P ( O ) which is a concatenation of nodes P ( i ) 's. Each node P ( i ) also represents a set of strings , and it may or may not be replaced again by P ( il ) -- -P ( ij ) -- -P ( in ) ~ P ( i ) . Sakai 22 On each step of expansion , a choice is made by taking a subset of strings. ~e possible choice becomes narrower and narrower. It is expected that the string obtained by applying obligatory rules and by replacing each terminal node by a lexical element is an acceptable string. ~is is not always true if the replacement of a node is independent of the other nodes already generated. % his difficulty is overcome by executing a syntactic analysis after every step of expansion. If the analysis does not prove the possibility of obtaining an acceotable string , another subset should be chosen as a candidate. ~ne check by analysis should be tried after a transformation if it is a local or a generalized one. All the nodes , terminal and non-terminal , are sets of symbol strings. A generated string of nodes is analyzed by tracing back the path of generation. If the analysis goes back to P ( O ) which covers the whole string , the generation is acceptable , and not acceptable if otherwise. Any given string can be analyzed by applying rules to the string , in this case , however , the tree structure is not known. Rules should be tested on every possible combination of terminal and non-terminal nodes , so that the whole string may be covered by a single node and the possible derivational history may be accounted for by the concatenationai and transformational rules. 11.3. ~ihe Rules for generation and those for recognition are essentially the same. They may be prepared in terms of complete neighborhoods or distribution classes. ~le rules will be prepared without any formal ambiguity if their definitions are carefully observed. Some formal systems are given in the following pages as examples of sin : pie types of grammar. ... . Re , ,resen~.~ &lt; ~on ~ Concatenation Rklles ! 2. Conu~lete Neighborhood ~ ~-~ c ~ , . We say a set of concatenation rules is con~plete if it gives the concatenation Z = xy of any complete neighborhoods x and y of the language. It is not necessary , however , to list all the ioossible x 's and y's. Much less number of rules can cover all ~he ~ossible com ! iete nei~3hborhoods if their use is y rcper ! y pro gramme d. We consider a rule f ( uv ; w ) represents a relation between the concatenated complete neighborhoods uv and another complete neighborhood w. Each rule Sakai 23 uv ( = ) w , UV : D W , UV ~ W , will give information to xy if x ( = ) u and y ( = ) v : ( xN u ) ( yNv ) : xy uv ; which is a part of xy = z. In order to obtain th~ given concatenation xy , we determine a set R ( xy ) of rules applicable to xy. Each rule is decided whether or not it is applicable to xy by the condition g , so that f ( uv ; w ) 6 R ( xy ) if and only if g ( x ; u ) and g ( y ; v ) . ~ % e term w is read out of the rules in R ( xy ) so that z = xy may be determined , it is obvious that there exist certain restrictions in choosing the type f of rules , the condition g for determining R ( xy ) , and the procedure of finding z. We have to specify these three for the grammar to be written. When the complete neighborhood z is given and its expansion xy is to be found , the set E ( z ) of applicable rules is determined by the condition h ( z ; w ) : R ( z ) = set ( f ( uv ; w ) : h ( z ; w ) ) . The situation is a little complicated in this case. We can possibly expect a case where both z = xlY 1 and z = x2Y 2 are true under the condition x I ~ x 2 = 0 and/or Yl ~ Y2 = O. Note that this is not the case of formal concatenation of sets N CO = ( A N C ) ( BN O ) . The concatenations xiY I and x2Y 2 happened to be z by the syntactic reason of the language being studied. A storage space is assigned to each xiY i as soon as any rule in R ( z ) proves a possibility , and xiY i is modified every time a rule is applied to it. However , if x. ~ x. and Yi ~Yj ' i ~ then either xiY i or xjyj is just trivial. The choice depends upon the type of rules and the program which applies the rules to the text. Finally , we have a set of x i~ accompanied by the subset R ( z ; i ) of R ( z ) . Possible types of rules for this purpose will not be discussed here , because the principle is similar to the case of finding z from x and y. In order to see some properties of rules , we assume simple forms of f ( uv ; w ) : Sakai 24 ( i ) if and only if T ! ( a ) if and only if I ! I'I ( 3 ) similarly , if and only if UV = W. The condition g will be assumed simply as ( = ) , o_ , c_ , or =. The condition of constituents can be replaced by a condition imposed on the whole concatenation : xy ( = ) uv xyNuv = ( x~ u ) ( yDv ) /0 x ( = ) u and y ( = ) v ; xy E uv xyZ uv = ( x~ u ) ( y Nv ) = uv ( 4 ) if and only if u=xNu xDu xy ~_ uv X~ U xy = UV X = U and v = y ~ v and y~ v ; and y ~ v ; and y = v. 12.1. Suppose we have the rules of the form uv ( = ) w , applicable to xy if x ( = ) u and y ( = ) v. Then , for such a rule , we have xy ( = ) uv ( = ) w. We can also assume the rules are applicable if xy ~ uv , xy ~_ uv , xy = UV. We can not decide which part of w belongs to uv , unless some other information is available. 12.2. then 12.2.1. UV ~ W be applicable to xy if and only if x ~ u and y ~_ v. ~en xy ~ uv~w. This is true for any rule in R ( xy ) = set ( uv ~ w : xy~uv ) . If each rule represents the relation uv~ w u ( x~ u ) ( y~v ) = xy~ uv~xyn w. Let the rules of the form If the set R ( x~ has sufficient rules to give xy : Uw , we can find xy by simply taking the union of all the w 's in R ( xy ) . 12~2,2. If the rule~ are applicable to xy when Sakai 25 x ~_ u and y c_ v , xy c uv = w. We le % ow that a concatenation xy of any two neighborhoods is broken then doom to the concatenations of elementary neighborhoods e ( i ) e ( j ) and that each e ( i ) e ( j ) is represented as a union of elementary neighborhoeds. If x = e ( 1 ) , y = e ( 2 ) 0 e ( 3 ) ~ e ( 4 ) , for instance , and if we have the rules e ( 1 ) e ( 2 ) ~ e ( 5 ) 0 e ( 6 ) , e ( 1 ) e ( 3 ) ~ e ( 5 ) and e ( 1 ) e ( 4 ) ~ e ( 6 ) , then xy ~ e ( 5 ) U e ( 6 ) . These rules will be broken down as e ( 1 ) e ( 2 ) ~ e ( 5 ) e ( 1 ) e ( 2 ) ~ e ( 6 ) e ( 1 ) e ( 3 ) ~ e ( 5 ) e ( i ) e ( 4 ) ~ e ( 6 ) , and then contracted as e ( l ) ( e ( 2 ) ( + ) e ( 3 ) ) D e ( 5 ) e ( 1 ) ( e ( 2 ) ( t ) e ( 4 ) ) ~ e ( 6 ) , where the symbol ( + ) means an alternative choice. ~e number of elementary neighborhoods increases rapidly as the linguistic analysis becomes more precise , and hence a grammar prepared in terms of e~ementary neighborhoods comprises a great number of entries. However , this type of rules is preferred when a particular technique is available on machine ( Opler et al. , 1963 ) . 12_~.. Let us consider a set of rules of the form uv ~ W. We assume a rule is applicable to xy if x ( : ) u and y ( : ) v. We have , then , u ) ( y v ) : xyOuv xy w. Sakai 26 12.3.1. Suppose the rules of the form uv _~w are applicable to xy if and only if x ~ u and y ~ v. For all the rules in the set R ( xy ) of applicable rules , we have xy ~_ uv c w. 12.3.2. Let the set R ( xy ) of applicable rules be R ( xy ) = set ( uv~ w : x ~ u , y~ v ) . Then , for each rule in R ( xy ) , we have xy ~ uv ~ w. Taking all the rules in R ( xy ) , we can expect xy = Dw , and , if the set of rules is prepared so as to meet this condition , we can find xy by taking the intersection of w 's in R ( xy ) . 12.4. Let the rules be given in the form UV = W~ and let R ( xy ) be the set of rules such that x ( = ) u and y ( = ) v. 12.4.1. If R ( xy ) is the set of all the rules satisfying the condition x o u and y ~_ v , then we have xy ~ uv = w for all the rules in R ( xy ) . Then , xy ~_ Uuv = U w , where the union is to cover all the rules in R ( xy ) ; if the rules are prepared so that xy = U uv , then we can find the concatenation simD1y by taking the union of w 's of the rules in R ( xy ) . 12.4.2. if the rules are pre~fared so that they may be applied to xy when x ~_ u and y C v , then xy ~_ uv = w. If xy = ~ uv is true for all the rules in R ( xy ) , then we can find the desired concatenation by xy = Nw. 12.4.3. T= ~ the rules are represented in terms of elementary neighborhoods in Sakai 27 the form e ( i ) e ( j ) = w ( i , j ) , then , in virtue of the coefficients x ( i ) and y ( j ) , we have x ~ U = X ~ e ( i ) = x ( i ) e ( i ) , y ~ v y S e ( j ) ' ) e ( j ) = = ykj , ( X D u ) ( y~ V ) = x ( i ) y ( j ) e ( i ) e ( j ) . Therefore , a rule is applicable to ~y if x ( i ) = y ( j ) = i. The result z = xy is obtained as the union of all the w ( i , j ) 's of the applicable rules : z = Uw = ~x ( i ) y ( j ) w ( i4j ) . 12.5. The rules are prepared and used more freely according to the given condition and requirement. In the following scheme ( S'akai , 1961 ) , a complete neighborhood is represented by a code consisting of a number of digits and each digit is checked , modifiedand transferred independently. Suppose x and y are given and their concatenation z = xy is required. Both x and y can be syntactically ambiguous and their ambiguity is to be reduced in the course of finding z. Initially , z is assumed to be the set of all the possible contexts , x , y and z are transferred to a temporary storage space ( xl , Yl , Zl ) . A rule is applicable if x ( = ) u , y ( = ) v and z ( = ) w , and the set ( xl , Yl , Z l ) is modified everytime a rule is applied. If a rule proves x I ( = ) u , Yl ( = ) v , z I0 w = O , then the rule is not applied to this set , and another set ( x2 , Y2 , Z2 ) is stored in another storage space as another possible result. All the applicable rules are applied one after another to all the possible sets of ( xi , Yi , Zi ) . Similar procedure is repeated over again on two languages simultaneously , so that the syntactic structure can be transferred from the tree structure in one language to that of another language. ~he form of the tree is preserved but their nodes are marked by the labels specific to each language , input , intermediate or output language. 13. Distribution Class Representation of Concatenation Rules. Possible concatenation of a language can be formulated as concatenated sets of strings. Let R = set ( r : h ( r ) ) Sakai 28 and S = set ( s : h ( s ) ) be sets of strings satisfying the conditions h ( r ) and h ( s ) , respectively , and let their concatenation have the property k ( rs ) , so that rs E T = set ( t : k ( t ) ) . We consider the concatenation rules of the form RS ~ T , which reads : if • then r 6 R and s £ S , rs K T. The point of this representation is that , and s 6 S h~ S i~ -- OS k , then as many rules are applicable to rs and they give rs E N -- S % : The intersection T ' has less number of elements and , if the rules are precise , the character of the strings in it is determined as precisely as required. Of course , these procedures are not to be done by listing up all the members of the sets. Each set in the rules is represented by a code. Every entry of the lexicon has a code and it can be determined whether or not the string belongs to any given set. These codes are to be generated and attached to rs to indicate that it belongs to the set T'. Practically , it is convenient to classify the strings in terms of their complete neighborhoods : R = set ( r : h ( C ( r ) ; u ) ) = R ( u ) , S = set ( s : h ( C ( s ) ; v ) ) = S ( v ) , T = set ( t : k ( C ( t ) ; w ) ) = T ( w ) . A grammar of concatenation will be given as a set of rules of the form R ( u ) S ( v ) c with a relation f ( uv ; w ) , and the rules can be described in a number of different ways according to the choice of R ( u ) S ( v ) , T ( w ) and f ( uv ; w ) . In order to see the principle , we simplify the situation by making use of the distribution classes G , H , I and J , and by assuming the relation f ( uv ; w ) as uv ( = ) w , UV~ W~ Sakai 29 EV ~ w , or uv = w. lhe type of T ( w ) is chosen so that the grammar may describe the language adequately. 13.___~1. G Renresentation. If then then If then then If then If then Put ~ ( u ) = G ( u ) , r E G ( u ) , s E G ( v ) , rs E G ( u ) G ( v ) ~ G ( uv ) , C ( rs ) ( = ) uv ( = ) w. r ~ G ( u ) , s ~ G ( v ) , uv ~ w , rs E G ( u ) G ( v ) c G ( uv ) , C ( rs ) ( : ) uv ~ w. r E G ( u ) , s ~ ~ ( v ) , uv ~ w , rs 6 S ( u ) G ( v ) C G ( uv ) c G ( w ) . r E G ( u ) , s g G ( v ) , uv = w , rs ~G ( u ) G ( v ) ~ G ( UV ) = G ( w ) . s ( v ) = G ( v ) . uv ( = ) w , necessarily elementary. 13.2. H Re-oresentation. Put ~ ( u ) = : ~ ( u ) , S ( v ) = ~ ( v ) . Even if a few rules are applicable to rs in these cases , that is , rs E G ( w~ ) ~ G ( w i ) ~ -- ~ G ( wx ) , we have no simple way to find C ( rs ) from w's. We can not specify a set of less members which adequately indic'ates the property of rs , unless more specific information is available. 13.1.1. Suppose , however , u and v are elementary. If C ( r ) ( = ) u and C ( s ) ( = ) v , then C ( r ) ~ u , C ( s ) ~v. That is , r ~ G ( u ) = H ( u ) , s ~G ( v ) = H ( v ) . For further discussion , see `` H Representation '' , where u or v is not necessarily elementary. 13.1.2. Assume C ( r ) and C ( s ) are elementary. If C ( r ) ( = ) u and C ( s ) ( = ) v , then C ( r ) ~ u and C ( s ) ~ v. That is , r ~ l ( u ) and s E I ( v ) . For further discussion , see `` I Representation '' , where no neighborhoods are if then .z,3.2..l. then then then then We put If r ~ H ( u ) , s 6H ( v ) , rs 6 H ( u ) ~ ( v ) _~ H ( uv ) . uv ( = ) w , rs ~ H ( u ) H ( v ) ~ H ( uv ) , C ( r~ ) o_ uv ( = ) w , C ( rs ) ( = ) w , rs 6 G ( w ) . S~ &lt; ai 30 ~ ( w ) = Q ( w ) . However , there is no simple procedure of finding the intersection of G ( w ) 's. We can not specify the features of the strings by finding more rules applicable to rs , unless more specific informa { ion is available. 13.2.2. If uv ~ w , then rs ~ H ( u ) H ( v ) ~ H ( uv ) ~ H ( w ) , because H ( uv ) = H ( w U wi ) = H ( w ) ~ H ( w ' ) ~ H ( w ) . We put T ( w ) = H ( w ) to have the rules of the form If a number of rules are applicable and rs £ H ( uh ) ~ ( v h ) c_ X ( w , n ) rs 6 H ( ui ) H ( v i ) ~-H ( w i ) rs ~ X ( uk ) ~ : ( v k ) c_ ~ ( wk ) , then rs £ H ( w h ) ~ H ( w i ) ~ -- OH ( w k ) = : ~ ( wh C wi U -- Owk ) ' then C ( rs ) O_ w h U w iU -- Ow k '' The rules of this type are essentially the same as the rules of complete neighborhoods xy ~ uv ~ w , although they are encoded as the sets of strings ; 13.2. 7 . If uv ~_ w , then C ( rs ) ~_ uv~_ w , then rs 6 G ( w ) . 13.2.4. Put UV = W. Then rs ~ H ( u ) H ( v ) ~ H ( uv ) = H ( w ) . Sakai 31 The situation is the same as the case above , where uv ~ w. 13.3. , I , Re , presentation. , Put R ( u ) = i ( u ) , S ( v ) = l ( v ) . If r £ i ( u ) , s 6 i ( v ) , then rs ~ I ( u ) I ( v ) ~ l ( uv ) . ! 3.3.1. If uv ( = ) w , then C ( rs ) c uv ( = ) w. No relationship is relevant between C ( rs ) and w. 13.3.2. If urn_w , then C ( rs ) c uv ~ w. m No definite T ( w ) is available , such that I ( u ) l ( v ) ~_ T ( w ) . 13._~3.. We consider the rules of tie type i ( u ) I ( v ) with uv ~ w. If r£ i ( u ) , s£1 &lt; v ) , then rs { I ( uv ) = i ( w ) . If a nmmber of rules are applicable to rs , then rs £ I ( w h ) N I ( wi ) ~ -- O I ( wk ) = I ( w h ~ w i~ -- ~Wk ) . % herefore , the rules of this type are equivalent to those of the type xy C uv C w. 13.3.4. Put • Then UV = W , rs ~ I ( u ) i ( v ) ~ I ( uv ) = I ( w ) . This is the same to the case mentioned above. 13.4. J Reoresentation. Put ~ ( u ) = J ( u ) , S ( v ) = J ( v ) . This type of grammar is not practical because every real distribution class J of the language must be listed in the rules , k~ : is condition corresponds to the com } ~lete neighborhood representation of rules f ( uv ; w ) applicable to xy only if x = u and y = v. 13.5. Practically , the rules can be written more freely and the program can be more flexible and efficient , provided that a more sophisticated Sakai 32 scheme is introduced to the G Representation and the condition f ( uv ; w ) . ~is is realized by representing the sets of strings by codes , so that the union and the intersection of any two sets are determined by the operation on the codes. 14. Some Remarks on Transformation. 14.1. It is generally agreed that we generate acceptable strings by starting with an axiom and expanding it repeatedly into a string of constituents. This procedure is taken care of by concatenation rules. After generating one or more strings by this procedure , they are transformed to yield another string. Let us imagine another function of our normative device. We give it a pair r = ( r ' , r '' ) of acceptable strings r ' = r ' ( 1 ) r ' ( 2 ) -- -r ' ( i ' ) -- -r ' ( m ' ) and r '' = r '' ( 1 ) r '' ( 2 ) -- -r '' ( i '' ) -- -r '' ( m '' ) . The pair r will be referred to as a string r = r ( 1 ) r ( 2 ) -- -r ( i ) -- -r ( m ) with m = m ' + m '' . We put m '' = 0 if the string r '' is absent. We then give it another acceptable string s = s ( 1 ) s ( 2 ) -- -s ( j ) -- -s ( n ) , and ask it whether or not the string s as an expression is true if both r ' and r '' are true. If the device says `` yes '' , we consider the string s is generated from r by a transformation. We call r the original string and s its orano_o~.n. If it says ~'no '' , no such transformation exists. Conversely , we ask it whether or not r ' and r '' are true if s is true. If the device says T~Xr~f ~ , we consider an inverse transformation exists , such that s is expressed by r ' and r '' . We can find many cases in which the device would say `` yes '' for transformation but `` no '' for inverse transformation. Some information is supposed to have been lost in generating the string s , which can not be retrieved unless appropriate , possibly non-linguistic , information is supplied. ~ % is situation is beyond the scope of Syntaetics. A transformation or an inverse transformation is called singularly if r '' in r is absent , and it is a generalized one if both r ' and r '' are present. If it is an embedding transformation , r ' and r '' are called matrix and constituent strings , respectively. If we understand the transformation in the sense mentioned above , the transfer of syntactic structure from one language to another is also a transSakai 33 formation ( Gross , 1962 ) . 14.2. If it is known that r is transfor~ed to s , then ... .. ~n~o fact ms used to generate a particular string. If r is known to be an inverse transform of s , then this is used to recognize s , giving a possible derivational history. if no other such transformations are found , r is the only nearest history. Otherwise , the ambiguous history is to be accounted for by other rules. If we find r and s such that r is true if and only if s is true , then we say r and s are equivalent and write r eqv s. Obviously , this equivalence is symmetric , reflexive , and transitive. A transformation that transforms a string into an equivalent string is called an equivalence transformation , if we have a grammar consisting of equivalence transformations only , it can be used for both synthesis and analysis. Let us confine ourselves to the equivalence transformations in order to simplify the discussion , and assume we have a set of rules or a normative device. A generalized transformation transforms a oair r = ( r ' r '' ) of strings into one strin~ s. ~e inverse transformation by the same rule dissolves a string s into a pair of strings ( r ' , r '' ) . ~en , r ' or r '' is regarded as an s , and , if we find an appropriate rule , it is again dissolved into two acceptable strings. By repeating the same , we have a number of equivalence relations which can be arranged as a tree : s eqv ( r ( 1 ) , r ( 2 ) ) ; r ( 1 ) eqv ( r ( ll ) , r ( 12 ) ) ; r ( 2 ) eqv ( r ( 21 ) , r ( 22 ) ) ; r ( ll ) eqv ( r ( lll ) , r ( ll2 ) ) ; r ( 12 ) eqv ( r ( 121 ) , r ( 122 ) ) ; If an acceptable string t can no longer be dissolved into two acceptable strings , we call t a terminal or an atomic acceptable string. ~nroughout this procedure , the strings are expected to become shorter and simpler , because equivalent information is expressed by many separate strings. It will be still possible to transform an atomic string to another atomic string by means of a singulary transformation. We have different atomic strings which are mutually equivalent. We may pick up one of them and call it a kernel string. 1~e sequence of inverse transformations is not always uniquely determined. There can be other orders of dissolving a given string into atomic strings. We can make the grammar less redundant by studying the possible sequences of Sakai 34 inverse transformations. If the rules are all equivalence rules , there is no theoretical problem of ambiguity• ~ne investigation of these problems requires quite a different treatment , and will not be included in this paper. 14.3. Sometimes , it is considered more linguistically reasonable to assume `` S ~rln~ or that a string is not acceptable but its transform is an acceptable ~ `` ~ ~. a constituent of an acceptable string , in some other cases , a s~ing may be an acceptable string and its transform may not be an acceptable string or a constituent thereof In other wo~as , a transformation is applied to an unacceptable string or a transformation results in an m % acceptable string. We may prepare the rules in such a way that a sequence of obligatory transformations is contracted to a single ~ale. This seems formally simpler and consistent. However~ it will result in a more entangled system of grammar. We admit some of such strings as potentially acceptable and indicate it by a marker , This convention is somet~nes useful not merely as a technique but also as a consistent and more plausible derivation of acceptable strings. It is known that a string of a Chinese dialect marked potentially acceptable for the derivation of apparently inconsistent strings is quite acceptable in another dialect ( Wang , 1964 ) . 14.4. A generalized transformational rule consists of terms u and v , where u = ( u ' , u '' ) = u ( 1 ) u ( 2 ) -- -u ( i ) -- -u ( m ) , u ' = u , ( 1 ) u ' ( 2 ) -- -u ' ( i ' ) -- -u ' ( m ' ) , u '' = u , ( 1 ) u '' ( 2 ) -- -u '' ( i '' ) -- -u '' ( m '' ) , m = m r. ~ m ~r , u becomes v~ v = v ( ! ) v ( 2 ) -- -v ( j ) -- -v ( n ) . Most rules are accompanied by a number of restrictions imposed on the original strings and their transforms as well as some manipulations of strings. ~ese are classified into a few types and subroutines are to be prepared for them. Some of the operations are listed below , which have been picked up sporadically from the rules for generating Chinese strings ( Hasimoto , 1964 ) . ( 0 ) A routine supervising the subroutines takes care of the whole procedure of applying the rules to a string , if the rules are prepared in a definite format , they are automatically checked and applied to the given string. ( I ) Certain segments r ( h ) and r ( i ) in the original string must or must not share a certain feature in common and/or a segment r ( j ) must or must not have a certain feature. Sakai 35 ( 2 ) The segment r ( i ) of the original string and the segment ~ ( o ) of the transform must or must not have the same feature specified by the rule. ( 3 ) Some segments in the transform must satisfy the condition similar to ( I ) . ( 4 ) Absence and/or presence of particular segments must be ~ cne c~ed. ( 5 ) Positions of certain segments in the string must be found. ( 6 ) A check of the derivational history somet~les decides the recursive application of the rule~ ( 7 ) The tree structure must or must not be changed by the final procedure of a transformation. ~. No rule describes a transformation of an individual string r into an individual string s. The rule says , if the string r has the feature u : u ( 1 ) u ( 2 ) -- -u ( i ) -- -u ( m ) , then it is transformed to another string s which has the feature v : v ( 1 ) v ( 2 ) -- -v ( j ) -- -v ( n ) . What are these features ? They must be defined on the basis of the answers of our normative device. The program must be consistent with the features defined. Once a program is written and decided to be used , the program is the definition. If the program is modified , the rules and the lexicon are to be modified. Since the transformations are applied to P-markers , a string is considered to be a tree-like string , if it is a linear string of terminal nodes , the other non-terminal nodes and the branches are to be determined by virtue of the concatenation rules. We consider the labels u ( i ) and v ( j ) are complete neighborhoods , if the concatenation rules are written in terms of complete neighborhoods. If the concatenation rules are written in terms of distribution classes , u ( i ) 's and v ( j ) 's are considered to be distribution classes. 14.6. The complete neighborhoods are defined on the basis of concatenated strings and we have to associate them with the labels given to the nodes of our transformational rules in order that the kernel strings can be transformed. Let us see what happens when the nodes are assumed to be complete neighborhoods. Let p = ( p ' , p '' ) be a pair of acceptable strings p ' and p '' , and let r = r ( 1 ) -- -r ( i ) -- -r ( m ) be a segment of p. The pair p is transformed by T into Sakai 36 q = T ( p ) , and the segment appears in q as s = s ( 1 ) -- -s ( j ) -- -s ( n ) . Some strings may have been added and some others may have been deleted. Put x ( i ) : C ( r ( i ) ) , x : C ( r ) ~ y ( j ) = C ( s ( j ) ) , y : C ( s ) . By definition , x : x ( 1 ) -- -x ( i ) -- -x ( m ) , y = y ( 1 ) -- -y ( j ) -- -y ( n ) . Any string belongs to one and only one distribution class J. instead of Therefore , T ( r ( 1 ) -- -r ( i ) -- -r ( n ) ) = s ( 1 ) -- -s ( j ) -- -s ( n ) , we write T ( J ( x ( 1 ) ) -- -J ( x ( i ) ) -- -J ( x ( m ) ) ) = J ( y ( 1 ) ) -- -J ( y ( j ) ) -- -J ( y ( n ) ) . Since all the elements in a J has the same complete neighborhood , we rewrite the above as T ( x ( 1 ) -- -x ( i ) -- -x ( m ) ) = y ( 1 ) -- -y ( j ) -- -y ( n ) . This is rewritten again by breaking down in the form X = x ( 1 ) -- -x ( i ) -- -x ( m ) , y : T ( x ) = y ( 1 ) -- -y ( j ) -- -y ( n ) . If we have a complete set of rules which gives the concatenation of any complete neighborhoods of the language , then we can find the complete neighborhood x. The transformation takes place when x is changed to y. The string y is to be generated in virtue of the information brought forward from x and the structural requirement of y itself. A transformation is then interpreted as : ~ne complete neighborhood x of the node dominating the string x ( ! ) -- -x ( i ) -- -x ( m ) of complete neighborhoods is transformed to another complete neighborhood y of the node dominating the string y ( 1 ) -- -y ( j ) -- -y ( n ) . Sakai 37 This interpretation , however , suggests a few problems , 14_~. We know that J ( x ( 1 ) ) -- -J ( x ( i ) ) -- -J ( x ( m ) ) ( J ( x ) , J ( y ( 1 ) ) -- -J ( y ( j ) ) -- -J ( y ( n ) ) m J ( Y ) '' The statement `` x is transformed to y '' is a generalization of the original fact , and this generalization is not always true. The text should be checked before a transformational rule is applied to it. Some separate steps for this purpose will save the machine time. ( 1 ) ( 2 ) ( 3 ) 14.8. A text to be parsed must consist of segments specified by the rule. The correct segmentation can be done by finding the tree structure of the ! text. Therefore , the concatenation rules must be prepared so as to ~ account for the structure of any acceptable strinG. Not all the trees of the specified form undergo the inverse transformation so that the derivational history may be traced back. The nodes are labeled. A tree of a form can correspond to a number of trees whose nodes have different labels. When a string is being synthesized , the text is given as a pair of Pmarkers. A rule can be applied only if the P-markers meet the condition specified by the rule. We may regard the structure mentioned above as a representation of derivational history. The history can be recorded by listing all the derivational steps the string has experienced. This representation , however , will be redundant and inefficient , because it is likely to occur that an identical series of transformations is applied to strings of different history. On the other hand , it is also possible that the strings p and q of different histories result in an identical string s by a transformation and the string s is ambiguous in that the s from p can undergo a sequence of transformations and the s from q another ; thus the structure itself can not be an absolutely reliable marker. We think it more practical to associate the rules with the features in the P-marker to which the rules are applied. '~lese features should correspond to the series of transformations applicable to the P-marker in case of synthesis and the series of inverse transformations in case of analysis. We have some rules with notes on the type of transformations to which the resultant strings may be exposed ( Hasimoto , 1964 ) . 15. Complete Neighborhppds and Transformational. Rules. Let us assume u ( i ) 's and v ( j ) 's are complete neighborhoods. Saka± 38 ~. Two strings r and s may replace th~ same non-terminal node to yield a longer acceptable string. However , when a transformation T is to be applied , they must hav~ the specified structure ; thu~ the str ! n~ p with r a~ a ~e~ment in it may be transformed by T , while the string q which differs from p only in that it has the segment s in the place of r may not. The lack of q by T means C ( r ) / C ( s ) . 1_~,2. Because of this complexity involved in natural languages , we encounter a difficulty when we try to prepare a set of syntactic data for practical purposes. We refine the definition of complete neighborhood in such a way that C ( r ) of a string r is the set of all contexts of r which appear in the strings to which no transformations have ever been applied during their derivation. The difference between r and s is found in their internal structure , if the machine is given only the input string to be parsed. In order to indicate this difference , we put c ( r ) U O ( r ) = where C ( r ) is defined over ~. , e sez of kernel strings , D ( r ) is defined over the set of transforms , E ( r ) is defined over the set of kernel strings and transforms. Let c ( i ) be an elementary neighborhood defined over the set of kernel strings , and let r be a real or imaginary string such that C ( r ) = o ( i ) . Let d ( i ; j ) be the elementary neighborhood defined over the set of all the possible transforms of which r is a segment , where j corresponds to the possible sequence of transformations. Putting c ( i ) ~ d ( i ; j ) = e ( i ; j ) , we have the elementary neighborhood e ( i ; j ) defined over the set of kernel strings and transforms. These e ( i ; j ) 's are no longer necessarily disjoint : e ( i ; j ) ~e ( i ; j ' ) ~ c ( i ) . l_l_l~. ~e separation of kernel strings and transforms still involves a considerable complexity. Let q be a transform. It is a transform generated by a transformation in a sequence of transformations and it can be an original string to be transformed by the following transformation. A transformation is accompanied by the set P of original strings and the set Q of transforms : P = set ( p : T is applicable to p ) , Sakai 39 Q = set ( q : q = T ( p ) , p in P ) . We simplify the situation by defining the complete neighborhoods over P and over Q. The feature of T is shown more explicitly in this way. Let A be a node and imagine a derivation by the context sensitive rules A ~ &gt; BC B F / -- -C c -- &gt; G / B -- where the s~nbols are assumed to be complete neighborhoods .</sentence>
				<definiendum id="0">; eishborhood x : c ( : ~ )</definiendum>
				<definiendum id="1">, c ( ~ ) I o , c ( ~ ) I o</definiendum>
				<definiendum id="2">distribution class I ( C ( s ) )</definiendum>
				<definiendum id="3">acceptthey are ( flying/red/making ) planes</definiendum>
				<definiendum id="4">a ( flying/red ) saucer</definiendum>
				<definiendum id="5">flying/making ) planes</definiendum>
				<definiendum id="6">( ) planes , c 2 = a ( ) saucer</definiendum>
				<definiendum id="7">c2 ) , C (</definiendum>
				<definiendum id="8">C ( s. ) G ( C ( s. ) ) I ( c ( s. ) ) l l l ! i : flying ( Cl , C2 , C 3 ) ( Sl , S2 , S 3 ) ( s l ) ( Sl , S2 , S3 ) 2 : red ( Cl , C 2 ) ( Sl , S2 , S3 ) ( Sl , S 2 )</definiendum>
				<definiendum id="9">c3 ) ( Sl , S2 , S3 ) ( Sl , S3 ) ( s 3 ) The simple J ( C ( s. ) ) l (</definiendum>
				<definiendum id="10">, C (</definiendum>
				<definiendum id="11">i. ( i ) J ( x ) = H ( x ) , q Z ( x ) ; ( 2 ) H ( x ) U z ( x ) ~_ G</definiendum>
				<definiendum id="12">`` t ~ H ( x ) N i ( x )</definiendum>
				<definiendum id="13">H ( x ) U Z</definiendum>
				<definiendum id="14">t ~H ( y ) ~H ( z ) . t~I ( y ) U I</definiendum>
				<definiendum id="15">- , rn</definiendum>
				<definiendum id="16">r n</definiendum>
				<definiendum id="17">( BCD ) , ( AB ) ( CD ) , ( ABC</definiendum>
				<definiendum id="18">By assumDtion , ( AB ) ( CD ) N A ( BCD ) = O , ( AB ) ( CD ) ~ ( ABC</definiendum>
				<definiendum id="19">Sakai 16 A ( ~C ) J O , ( A~ ) C : O , A ( BC ) N ( , ~ ) C</definiendum>
				<definiendum id="20">, ( BC</definiendum>
				<definiendum id="21">B ( CD ) : O. A ( BCD )</definiendum>
				<definiendum id="22">A ( BU C ) = ABU AC , ab ~ A ( B U C ) a 6A an~ b6BUC</definiendum>
				<definiendum id="23">Sakai 17 `` ab ~ ( A N C )</definiendum>
				<definiendum id="24">P ( ris )</definiendum>
				<definiendum id="25">C ( rs ) . We define the concatenation C ( r ) C ( s )</definiendum>
				<definiendum id="26">class J ( x )</definiendum>
				<definiendum id="27">% e former</definiendum>
				<definiendum id="28">C ( r ) C ( s ) : C ( rs</definiendum>
				<definiendum id="29">C ( s ) N uv / o C ( rs ) ~uvJ0 rs £G ( uv ) . H ( u ) H</definiendum>
				<definiendum id="30">C ( s ) N uv : uv C ( r ) C ( s ) ~ uv C</definiendum>
				<definiendum id="31">uv rs ~ H ( uv ) . I ( u ) I ( v ) ~ I ( uv ) , rs £ I ( u ) I ( v ) r ~ I</definiendum>
				<definiendum id="32">C ( s ) C ( r ) C ( s ) c uv m C ( rs ) c uv N rs 6 I ( uv ) . J ( u ) J ( v ) C J</definiendum>
				<definiendum id="33">w )</definiendum>
				<definiendum id="34">w )</definiendum>
				<definiendum id="35">f ( uv ; w ) : h ( z ; w )</definiendum>
				<definiendum id="36">situation</definiendum>
				<definiendum id="37">Yl , Zl ) . A rule</definiendum>
				<definiendum id="38">T ( w</definiendum>
				<definiendum id="39">f ( uv ; w )</definiendum>
				<definiendum id="40">, k~</definiendum>
				<definiendum id="41">pair r</definiendum>
				<definiendum id="42">r</definiendum>
				<definiendum id="43">write T ( J ( x ( 1 ) ) -- -J ( x ( i ) ) -- -J ( x</definiendum>
				<definiendum id="44">) -- -J ( x ( i ) ) -- -J ( x ( m ) ) ( J ( x ) , J (</definiendum>
				<definiendum id="45">c ( r ) U O</definiendum>
				<definiens id="0">:'.ta~F ' • . o._. We zlave seen above Bhat a co : ; : piete ;</definiens>
				<definiens id="1">ir.~erpreted in te : m ; ~s of y : c ( s ) and z : ~ &lt; u ) . : ' , 'e ca'~ ex~pect ~s ) and `` '' ~e a ~kL ; : ray re-~-~ese=zazmon O7 a s ' , mp.er aria more specific syntactic func-cion , if C ( r ) : c ( s ) O c ( t ) , c ( ~ ) / c ( t )</definiens>
				<definiens id="2">for some c in C ( s ) and some c in C ( t ) , we have c. noz ecv c~. \ ] o hood , leads us to a concept of the ultimate unit of syntactic function. Given the elementary neighborhood e ( i ) with c. as an element is defined ! a context ci , as e ( i ) = set ( c : c eqv c. ) . l Since the equivalence is symmetric , reflexive and transitive , any two distinct ele : : ; e-=~ary neizhborhoods have no elements in common. ~ an element c in x ~s a : : , emoer of e ( i ) ~ then e ( i ) r : : , b~cause x is co'.rSie~e ' '' ~. in `` • ~a.~ an element c x ; then there ms an e ( i ) such \ ] _ that • ( ) . C ~ e i x : Ue ( i ) for all ek~ ) 's ~=ving at leas~ one element in x. Every elementary Sakai i0 neighborhood is complete. An intersection of complete neighborhoods is complete. Every union of elementary neighborhoods is a complete neighborhood. 2 '' Distribution Class. We have thus far discussed the syntactic function of symbol strings in terms of their acceptable contexts. A context is an environmental condition in which a string occurs. Given a context , we can classify the strings into two distinct categories : the one is a class of strings that can occur in the given environment and the other is the class of strings that can not occur therein. If there exists at least one context c in which both s and t can occur , then c ~C ( s ) and c ~C ( t ) , that is c ~ C ( s ) N C ( t ) # O. We define the set of all strings t , that can replace s in some contexts , as G ( C ( s ) ) = set ( t : C ( t ) N C ( s ) # 0 ) . We introduce a convention A ( = ) B which means that the intersection of the two sets A and B is not empty : G ( C ( s ) ) = set ( t : C ( t ) ( = ) C ( s ) ) . Suppose a string t can occur wherever s can occur , but s can not always occur in the contexts accepted by t. In this case , c ( t ) o C ( s ) . We define H ( C ( s ) ) = set ( t : C ( t ) O C ( s ) )</definiens>
				<definiens id="3">a set of all the strings t that can be always replaced by s : I ( C ( s ) ) = set ( t : C ( t ) c C ( s ) ) . That the two strings s and t are mutually replaceable means that s can occur wherever t can occur and conversely t can occur wherever s can occur. In other words , any context c is accepted by t , if and only if it is accepted by s : c g C ( t ) if and only if c ~C ( s ) , or C ( t ) = C ( s ) . We indicate the set of such strings t by J ( C ( s ) ) = set ( t : C ( t ) = C ( s ) ) . Other distribution classes are defined as sets of strings whose complete neighborhoods are related to a certain complete neighborhood in a specified way. Let x be an arbitrary complete neighborhood. The simple types of Sakai ll distribution classes mentioned above are written as G ( x ) = set ( t : C ( t ) ( = ) x ) , H ( x ) = set ( t : C ( t ) 2 x ) , I ( x ) = set ( t : C ( t ) ~x ) , J ( x ) = set ( t : C ( t ) = x ) . A distribution class is said to be real if it is not empty , and imaginary if it is empty. able strings and only these. and their contexts Suppose , for instance , that a language consists of the</definiens>
				<definiens id="4">an industry , We observe the strings s I = flying , s 2 = red , s 3 = making c I = they are</definiens>
				<definiens id="5">an object , c 3 = ( ) planes is an industry. The complete neighborhoods of the strings are C ( s l ) = C ( flying ) = set ( cl , c2~c3 ) , C ( s 2 ) = C ( red ) = set ( cl ,</definiens>
				<definiens id="6">s 3 ) = C ( making ) = set ( cl , c3 ) . The distribution classes are determined by these neighborhoods. types above are given in the table below. i : s I</definiens>
				<definiens id="7">s 2 ) 3 : making ( ci ,</definiens>
				<definiens id="8">s a ) ( s 3 ) Sakai 12 The elementary neighborhoods e ( i ) = set ( c : c eqv ci ) , i = i , 2 , 3 are found by consulting the table below , where `` + '' on the i-th row and J-th column means `` cj is acceptable to si '' . : c I c 2 .c~ Sl : + ÷ + s2 : + + s3 : + + e ( 1 ) = set ( c : c eqv c I ) = set ( cl ) , e ( 2 ) = set ( c2 ) , e ( 3 ) = set ( c3 ) . Therefore</definiens>
				<definiens id="9">s l ) = e ( 1 ) ~e ( 2 ) ~ e ( 3 ) , C ( s 2 ) = e ( 1 ) U e ( 2 ) , C ( s~ ) = e ( 1 ) U e ( 3 ) . ,</definiens>
				<definiens id="10">( x ) , Proof. ( 1 ) t ~ J ( x ) , if and only if C ( t ) = x , `` C ( t ) ~ x and `` t 6 H ( x ) and</definiens>
				<definiens id="11">( x ) , if and only if t ~ H ( x ) or `` C ( t ) ~ x x # O. C ( t ) c x , t 6 I ( x ) , t d i ( x ) , or C ( t ) : 'x , for x / O , then C ( t ) ( = ) x if and only if t ~ G ( x ) . transitive. ~erefore , J ( x ) = J ( y ) if and only if J ( x ) ( = ) J ( y ) . This means that any two different sets have no elements in common and , consequently , that every element belongs to one and only one set of the form J ( x ) . 7e3o If X is an elementary neighborhood , then G ( x ) = set ( t : C ( t ) ( = ) x ) = set ( t : C ( t ) ~ x ) m = : ~ ( x ) if x/ O ; I ( x ) = set ( t : C ( t ) C x ) = set ( t : C ( t ) = x ) : J ( x ) , so that C ( t ) is also elementary. then if Sakai 13 If x is any complete neighborhood and if C ( t ) is elementary for all t , G ( x ) = set ( t : C ( t ) ( = ) x ) = set ( t : C ( t ) ~ x ) m = I ( x ) ; H ( x ) = set ( t : C ( t ) D x ) m = set ( t : C ( t ) = x ) : J ( x ) x / O , so that x is also elementary. empty , then 7-4. If ( 1 ) ( 2 ) ( 3 ) Proof. ( 1 ) if and only if I ! I ! I ! ( 2 ) if and only if I ! G ( x ) = ~ ( x ) = I ( x ) = J ( x ) . X = y U z , then G ( x ) = G ( y ) U G ( z ) , H ( x ) = a ( y ) ~ ~ ( z ) , I ( x ) ~ i ( y ) O I ( z ) . t ~ G ( x ) = G ( y ~ z ) , C ( t ) ( = ) x = y ~ z , c ( t ) ( : ) y or c ( t ) ( : ) z , t ~ G ( y ) or t ~ G ( z ) , t 6 G ( y ) U G ( z ) . t £ H ( x ) , C ( t ) ox = yUz , C ( t ) 2Y and C ( t ) _Oz , t6H ( y ) and t~ ( z ) , It ( 3 ) if and only if then if and only if ~.~A. ( l ) ( 2 ) Proof. ( l ) if and only if l ! then if and only if ( 2 ) if and only if T ! 11 I !</definiens>
				<definiens id="12">( z ) , c ( t ) ~ y or c ( t ) ~ y ~ z : x , t £ Z ( x ) . If x : yN z , then G ( x ) ~ G ( y ) ~ G ( z ) , Z ( x ) = Z ( y ) N Z ( z ) . C ( t ) ~ z , t £ G ( x ) , C ( t ) ~ x # O , c ( t ) ~ y ~ z / o , C ( t ) ~ { y # 0 and t ~G ( y ) ~d ( z ) . t ~ I ( x ) , c ( t ) C_x = yAz , C ( t ) ~y and , C ( t ) ~ z , t ~ I ( y ) and t ~ I ( z ) , tEl ( y ) ~ Z ( z ) . -- -- -~ r n Sakai 14 Concatenation. Cqncatenation of Strings. Let p be a string and let r I , r 2 , c~t ) ~ z # 0 , be segments of p which do not mutually overlap. A segment t consisting of r l , r 2 , --</definiens>
				<definiens id="13">the concatenation of these segments. It is a segment of p , consisting of fragments of -- arranged in their relative order in the original string p. It r l</definiens>
				<definiens id="14">convenient to assign a definite notational order to a concatenation in order to specify the arrangement of fragments. Let r l , r 2 , -- - , r n be segments of p with no fragments in common. c ( r ) of r in p , p l l i = i , 2 , -- - , n correspond uniquely to the segments ri , 'l~e contexts respectively , and so does c ( t ) to P the concatenation Sakai 15 We write t = rlr2 -- -r n. Cp ( ri ) Cp ( r2 ) -- -Cp ( r n ) = Cp ( t ) if and only if t = rlr2 -- -rn in Let a , b , c , -- be elements of sets. p. We call an ordered string of these elements a concatenation. Let A , B , C , -- be sets. We define the concatenation , of sets as AB -- -D = set ( ab -- -d : a~ A , b ~B , -- - , d ~ D ) . In our present discussion , the elements are either all strings or all contexts. lawing discussions can be easily generalized to longer concatenations. An unambiguous concatenation , ABCD for instance , is considered as one of the three binary concatenations A</definiens>
				<definiens id="15">a morphographemic description , however , this is not very important. One may assume one of these three acceptable and discard the other two as unacceptable. In a morphotactic description , some one of these three will be chosen so as to make the whole description of the language simpler. If any one of the sets which constitute a concatenation is empty , then the concatenation is also empty. We assume that the binary concatenations required by the grammar are ( AB ) ( CD ) , A ( BC ) , ( BC ) D and only these. The possible binary tree structures of ABCD are covered by ABCD = A ( BCD ) U ( AB ) ( CD ) U ( ABC ) D. Since we are to handle binary concatenations only , we consider two concatenations of elements are different if their structures are not the same : Then , the condition yields ( i ) ( 2 ) ( 3 )</definiens>
				<definiens id="16">) D = O. ABCD : ( AB ) ( CD ) ( AB ) ( CO ) I O , ~erefore , ( 4 ) 45 ) because Similarly , ( 6 ) ( 7 ) From ( 2 ) , By ( 7 ) and ( 6 ) , or , ( 8 ) From ( 3 ) , By ( 4 ) and ( 5 )</definiens>
				<definiens id="17">O. BCD = B ( CD ) \ [ _ ) ( BC ) D = ( BC ) D</definiens>
				<definiens id="18">A ( B ( CD ) h ) ( Be ) D ) : O. A ( BCD ) : 0 0 A ( ( BC ) D ) : o , A # O , ( ~C ) O # O , A ( ( BC ) O ) : O. ( ABC ) D : ( A ( BC ) O ( AB ) C ) D : O. ( ABC ) D = ( A ( BC ) ~ O ) O : ( A ( BC ) ) D = O , A ( BC ) # O , D # O , ( A ( BC ) ) D = 0. Now , we can describe the syntax of these strings in terms of binary concatenations only , if we establish the rules numbered from ( 1 ) to ( 9 ) . ( 1 ) AB = CD , if and only if A = C and B = D , because , for any ab in AB , AB = CD if and only if Cab ~ AB if and only if ab~ CD ) `` ( ( a ~ A , b @ B ) if and only if ( a ~ C , b~ D ) ) I ! ( a ) because if and only if I , II r ! ( 3 ) Similarly , ( 4 ) because if and only if V ! 11 ( a~ A if and only if a ~ C , bE B if and only if b ~ D ) A = C and B = D.</definiens>
				<definiens id="19">a ~ A and b ~B ) or ab 6 AB or ab 6 AC ab ~ AB ~ AC. ( AOB ) C : ACUBC. ABDCD= ( Af\ ] C ) ( BDD ) , ab ~ AB tO CO ab ~ AB and ab ~ CD a ~ A and b ~ B and a~ A~C and ( a ~ A and b 6 C ) a &amp; C b~B~D and b ~ D strings r and s , such that C ( r ) : x and C ( s ) = y. By definition ,</definiens>
				<definiens id="20">B lq D ) . Concatenation of Complete Neighborhoods.. If the distribution classes J ( x ) and J ( y ) are real , then there exist p ( r i ) = -- -r. -- -l with the segment r. in it is acceptable if and only if p ( r ) ... . r -- is acceptable , and the string p ( s. ) ... . 2° -- 3 3 .is acceptable if and only if p ( s ) ... . s -- is acceptable. Suppose P ( ris j ) = -- -ri -- -sj -- is a string with both r. and s. in it. Any such string ix acceptable if and l j only if the string p ( r.s ) : -- -r. -- -s -- l l is acceptable , and</definiens>
				<definiens id="21">acceptable if and only if p ( rs ) ... . r -- -s -- is acceptable. ~nerefore , P ( ris j ) is acceptable if and only if p ( rs ) is acceptable. That is C ( ris j ) =</definiens>
				<definiens id="22">of complete neighborhoods as the complete I % neighborhood C ( rs ) of the concatenated strings. Generally , we put xy : c ( rs ) , r ~ J ( x ) , s 6 J ( y ) for any com~plete neighborhoods x and y , where J ( x ) and J ( y ) may be real or imaginary. Note , however , that if x : C ( r ) , y : c ( s ) , C ( r i ) = x for all rl in J ( x ) and C ( sj ) = y for all s3 in J ( y ) . Any string Sakai 18 then xy = C ( rs ) , while xy = C ( rs ) does not always result in x : C ( r ) or y = C ( s ) . We have generalized and transferred the concatenation of strings to concatenated sets of strings and then to concatenated complete neighborhoods. The complete neighborhood representation provides us with a less complicated approach , especially when the strings are syntactically ambiguous. The distribution</definiens>
				<definiens id="23">means the narrowest classification of strings and no further subclassification is possible , while its complete neighborhood x can be subclassified if x is not an elementary neighborhood. If rg J ( x ) and x = y Uz , then we can talk about imaginary strings r ' and r '' , such that C ( r ' ) = y and C ( r '' ) = z. These imaginary strings , always referred to implicitly in terms of distribution classes , can be discussed explicitly in terms of complete neighborhoods. xy : c ( r ) c ( s ) of complete neighborhoods and the complete neighborhood z : C ( rs ) . ~</definiens>
				<definiens id="24">means a set consisting of concatenated contexts. The properties of the language is introduced when it is written in the form xy= z or</definiens>
				<definiens id="25">) , where the property x of r and the property y of s result in another property z of rs. Thus , z can be an empty set even if neither x nor y is empty , and ambiguous even if neither x nor y is ambiguous. neighborhood in a unified way. We saw that a complete neighborhood x can be represented by a union of elementary neighborhoods e ( i ) : x = Oe ( i ) with x ~ e ( i ) ~ O. Let us introduce coefficients x ( i ) , such that x ( i ) : o if = i if and no other cases possibly occur. x ( i ) e ( i ) = e ( i ) =0 e ( i ) , Ox =o , e ( i ) -x ; We put if x¢i ) : l , if x ( i ) : o. Sakai 19 In virtue of these coefficients , we can write ( 1 ) If then If then ~\ ] erefore , for we have ( 2 ) If then x = Dx ( i ) e ( i ) , y = ~y ( j ) e ( j ) , z = Uz ( k ) e ( k ) . z=xOy , x U Y = ( U x ( i ) e ( i ) ) U ( Oy ( j ) e ( j ) ) = U ( x ( k ) + y ( k ) ) e ( k ) = U z ( k ) e ( k ) . e ( k ) c_ x or e ( k ) ~ y , e ( k ) ~_ z. x ( k ) + y ( k ) = z ( k ) , 0~-0=0 , l+O =0 +l= 1 +l= 1. z = xy , z = ( Ux ( i ) e ( i ) ) ( ~y ( j ) e ( j ) ) = DU x ( i ) y ( j ) e ( i ) e ( j ) = UU z ( i , j ) e ( i ) e ( j ) . By the definition of concatenation , e ( i ) e ( j ) ~ xy if and only if That is , if and only if Therefore , for we have e ( i ) C x and z ( i , j ) = 1 x ( i ) = y ( j ) = 1. x ( i ) y ( j ) = z ( i , j ) , 1Xl=l , e ( j ) c y. Writing we have if and only if e ( i ) e ( j ) ~ z Therefore , for the expression z ( i , j ) a ( i , j , k ) = z ( k ) , we have 1 X 1 = l , e ( i ) e ( j ) = Ua ( i , j , k ) e ( k ) '' Z = xy = U~ z ( i , j ) e ( i ) e ( j ) : UUU z ( i , j ) a ( i , j , k ) e ( k ) = Uz ( k ) e ( k ) , e ( k ) ~ z and e ( k ) ~ e ( i ) e ( j ) . ( 3 ) A concatenation of two elementary neighborhoods is a complete neighborhood , and it is also a union of elementary neighborhoods : Sakai 20 10. i0. i. be cause if and only if 11 I ! then , if and only if l0.2. because if and only if II It II I ! then if and only if lo._.._5.5. because if and only if II It II I1 then if and only if 10.4. because if and only if 11 ! I then if and only if Concatenation of Distribution Classes. G ( u ) G ( v ) ~G ( uv ) , r~ £ G ( u ) ~ ( v ) r £ G ( u ) and s £ G ( v ) C ( r ) N U / 0 and C ( s ) ~ V / 0 ( C ( r ) ~ u ) ( C ( s ) ~ v ) = C ( r )</definiens>
				<definiens id="26">( v ) c ~ ( uv ) , rs E ~ ( u ) ~ ( v ) r ~ H ( u ) and s g H ( v ) C ( r ) D u and C ( s ) ~ v C ( r ) ~ u =u and ~C ( s ) ~ v = v ( C ( r ) ~ u ) ( C ( s ) N v ) = C ( r )</definiens>
				<definiens id="27">( u ) and s ~ I ( v ) C ( r ) c u and C ( s ) ~ v C ( r ) ~ u = C ( r ) and C ( s ) ~ v = C ( s ) ( C ( r ) ~ u ) ( C ( s ) D v ) : C ( r ) C ( s ) D uv : C ( r )</definiens>
				<definiens id="28">( uv ) , rs ~ J ( u ) J ( v ) r ~ J ( u ) and C ( r ) = u and C ( r ) C ( s ) = uv C ( rs ) : uv rs £ J ( uv ) . s 6 J ( v ) C ( s ) = v Sakai 21 i ! . Rules for Recognition and Generation. Each rule of a grammar indicates the arrangement of a few items to be concatenated , accompanied by some other necessary informations. We assume the items arranged in a rule are either complete neighborhoods or distribution classes. Let us see what happens during the generation and recognition of a string of symbols. In case a grammar is given in terms of complete neighborhoods , the input text is converted to a string of complete neighborhoods before the syntactic analysis begins. At the very end of generation , a terminal node accompanied by a complete neighborhood x is replaced by a string s whose complete neighborhood C ( s ) shares at least one elementary neighborhood with x. ~nen the syntactic rules are expressed in terms of sets of strings , the input text to be analyzed is replaced by a string of distribution classes. If a symbol string belongs to more than two sets of strings , their meet replaces the symbol string. At the end of a generation , the synthesized output string is obtained by replacing the set of strings on @ ach terminal node by a string which is a member of the ' set. ll.1. An acceptable string can be generated and analyzed making use of a tree with its nodes marked by complete neighborhoods. The expansion of a node z to a concatenation xy of nodes x and y implies z ~ xy , because otherwise further expansion of x and y may yield a structure which can not be accepted by z. Transformational rules can be a } ? plied more freely because a transformation does not imply such a restriction. However , attention ahould be paid not to add any other contexts to the complete neighborhoods attached to the nodes already generated. Finally , each terminal node is replaced by a lexical element. ~ % e string obtained after applying all the obligatory rules must be an acceptable string. ~ne analysis is carried out by testing all the possible transformations and trying all the possible contractions. At any rate , both generation and analysis can be carried out if we have a set of rules which gives concatenation z = x -- -y for any x , -- - , y of the language , and the transform y ( 1 ) y ( 2 ) -- -y ( n ) of any string x ( 1 ) x ( 2 ) -- -X ( m ) of complete neighborhoods. ll.2. Acceptable strings are also generated by starting from the node P ( O ) which is the set of all acceptable strings. It is replaced by its subset P ( 1 ) P ( 2 ) -- -P ( i ) -- -P ( m ) ~ P ( O ) which is a concatenation of nodes P ( i ) 's. Each node P ( i ) also represents a set of strings , and it may or may not be replaced again by P ( il ) -- -P ( ij ) -- -P ( in ) ~ P ( i ) . Sakai 22 On each step of expansion , a choice is made by taking a subset of strings. ~e possible choice becomes narrower and narrower. It is expected that the string obtained by applying obligatory rules and by replacing each terminal node by a lexical element is an acceptable string. ~is is not always true if the replacement of a node is independent of the other nodes already generated. % his difficulty is overcome by executing a syntactic analysis after every step of expansion. If the analysis does not prove the possibility of obtaining an acceotable string , another subset should be chosen as a candidate. ~ne check by analysis should be tried after a transformation if it is a local or a generalized one. All the nodes , terminal and non-terminal , are sets of symbol strings. A generated string of nodes is analyzed by tracing back the path of generation. If the analysis goes back to P ( O ) which covers the whole string , the generation is acceptable , and not acceptable if otherwise. Any given string can be analyzed by applying rules to the string , in this case , however , the tree structure is not known. Rules should be tested on every possible combination of terminal and non-terminal nodes , so that the whole string may be covered by a single node and the possible derivational history may be accounted for by the concatenationai and transformational rules. 11.3. ~ihe Rules for generation and those for recognition are essentially the same. They may be prepared in terms of complete neighborhoods or distribution classes. ~le rules will be prepared without any formal ambiguity if their definitions are carefully observed. Some formal systems are given in the following pages as examples of sin : pie types of grammar. ... . Re , ,resen~.~ &lt; ~on ~ Concatenation Rklles ! 2. Conu~lete Neighborhood ~ ~-~ c ~ , . We say a set of concatenation rules is con~plete if it gives the concatenation Z = xy of any complete neighborhoods x and y of the language. It is not necessary , however , to list all the ioossible x 's and y's. Much less number of rules can cover all ~he ~ossible com ! iete nei~3hborhoods if their use is y rcper ! y pro gramme d. We consider a rule f ( uv ;</definiens>
				<definiens id="29">represents a relation between the concatenated complete neighborhoods uv and another complete neighborhood w. Each rule Sakai 23 uv ( = ) w , UV : D W , UV ~ W , will give information to xy if x ( = ) u and y ( = ) v : ( xN u ) ( yNv ) : xy uv ; which is a part of xy = z. In order to obtain th~ given concatenation xy , we determine a set R ( xy ) of rules applicable to xy. Each rule is decided whether or not it is applicable to xy by the condition g , so that f ( uv ; w ) 6 R ( xy ) if and only if g ( x ; u ) and g ( y ; v ) . ~ % e term w is read out of the rules in R ( xy ) so that z = xy may be determined , it is obvious that there exist certain restrictions in choosing the type f of rules , the condition g for determining R ( xy ) , and the procedure of finding z. We have to specify these three for the grammar to be written. When the complete neighborhood z is given and its expansion xy is to be found , the set E ( z ) of applicable rules is determined by the condition h ( z ;</definiens>
				<definiens id="30">a little complicated in this case. We can possibly expect a case where both z = xlY 1 and z = x2Y 2 are true under the condition x I ~ x 2 = 0 and/or Yl ~ Y2 = O. Note that this is not the case of formal concatenation of sets N CO = ( A N C ) ( BN O ) . The concatenations xiY I and x2Y 2 happened to be z by the syntactic reason of the language being studied. A storage space is assigned to each xiY i as soon as any rule in R ( z ) proves a possibility , and xiY i is modified every time a rule is applied to it. However , if x. ~ x. and Yi ~Yj ' i ~ then either xiY i or xjyj is just trivial. The choice depends upon the type of rules and the program which applies the rules to the text. Finally , we have a set of x i~ accompanied by the subset R ( z ; i ) of R ( z ) . Possible types of rules for this purpose will not be discussed here , because the principle is similar to the case of finding z from x and y. In order to see some properties of rules , we assume simple forms of f ( uv ; w ) : Sakai 24 ( i ) if and only if T ! ( a ) if and only if I ! I'I ( 3 ) similarly , if and only if UV = W. The condition g will be assumed simply as ( = ) , o_ , c_ , or =. The condition of constituents can be replaced by a condition imposed on the whole concatenation : xy ( = ) uv xyNuv = ( x~ u ) ( yDv ) /0 x ( = ) u and y ( = ) v ; xy E uv xyZ uv = ( x~ u ) ( y Nv ) = uv ( 4 ) if and only if u=xNu xDu xy ~_ uv X~ U xy = UV X = U and v = y ~ v and y~ v ; and y ~ v ; and y = v. 12.1. Suppose we have the rules of the form uv ( = ) w , applicable to xy if x ( = ) u and y ( = ) v. Then , for such a rule , we have xy ( = ) uv ( = ) w. We can also assume the rules are applicable if xy ~ uv , xy ~_ uv , xy = UV. We can not decide which part of w belongs to uv , unless some other information is available. 12.2. then 12.2.1. UV ~ W be applicable to xy if and only if x ~ u and y ~_ v. ~en xy ~ uv~w. This is true for any rule in R ( xy ) = set ( uv ~ w : xy~uv ) . If each rule represents the relation uv~ w u ( x~ u ) ( y~v ) = xy~ uv~xyn w. Let the rules of the form If the set R ( x~ has sufficient rules to give xy : Uw , we can find xy by simply taking the union of all the w 's in R ( xy ) . 12~2,2. If the rule~ are applicable to xy when Sakai 25 x ~_ u and y c_ v , xy c uv = w. We le % ow that a concatenation xy of any two neighborhoods is broken then doom to the concatenations of elementary neighborhoods e ( i ) e ( j ) and that each e ( i ) e ( j ) is represented as a union of elementary neighborhoeds. If x = e ( 1 ) , y = e ( 2 ) 0 e ( 3 ) ~ e ( 4 ) , for instance , and if we have the rules e ( 1 ) e ( 2 ) ~ e ( 5 ) 0 e ( 6 ) , e ( 1 ) e ( 3 ) ~ e ( 5 ) and e ( 1 ) e ( 4 ) ~ e ( 6 ) , then xy ~ e ( 5 ) U e ( 6 ) . These rules will be broken down as e ( 1 ) e ( 2 ) ~ e ( 5 ) e ( 1 ) e ( 2 ) ~ e ( 6 ) e ( 1 ) e ( 3 ) ~ e ( 5 ) e ( i ) e ( 4 ) ~ e ( 6 ) , and then contracted as e ( l ) ( e ( 2 ) ( + ) e ( 3 ) ) D e ( 5 ) e ( 1 ) ( e ( 2 ) ( t ) e ( 4 ) ) ~ e ( 6 ) , where the symbol ( + ) means an alternative choice. ~e number of elementary neighborhoods increases rapidly as the linguistic analysis becomes more precise , and hence a grammar prepared in terms of e~ementary neighborhoods comprises a great number of entries. However , this type of rules is preferred when a particular technique is available on machine ( Opler et al. , 1963 ) . 12_~.. Let us consider a set of rules of the form uv ~ W. We assume a rule is applicable to xy if x ( : ) u and y ( : ) v. We have , then , u ) ( y v ) : xyOuv xy w. Sakai 26 12.3.1. Suppose the rules of the form uv _~w are applicable to xy if and only if x ~ u and y ~ v. For all the rules in the set R ( xy ) of applicable rules , we have xy ~_ uv c w. 12.3.2. Let the set R ( xy ) of applicable rules be R ( xy ) = set ( uv~ w : x ~ u , y~ v ) . Then , for each rule in R ( xy ) , we have xy ~ uv ~ w. Taking all the rules in R ( xy ) , we can expect xy = Dw , and , if the set of rules is prepared so as to meet this condition , we can find xy by taking the intersection of w 's in R ( xy ) . 12.4. Let the rules be given in the form UV = W~ and let R ( xy ) be the set of rules such that x ( = ) u and y ( = ) v. 12.4.1. If R ( xy ) is the set of all the rules satisfying the condition x o u and y ~_ v , then we have xy ~ uv = w for all the rules in R ( xy ) . Then , xy ~_ Uuv = U w , where the union is to cover all the rules in R ( xy ) ; if the rules are prepared so that xy = U uv , then we can find the concatenation simD1y by taking the union of w 's of the rules in R ( xy ) . 12.4.2. if the rules are pre~fared so that they may be applied to xy when x ~_ u and y C v , then xy ~_ uv = w. If xy = ~ uv is true for all the rules in R ( xy ) , then we can find the desired concatenation by xy = Nw. 12.4.3. T= ~ the rules are represented in terms of elementary neighborhoods in Sakai 27 the form e ( i ) e ( j ) = w ( i , j ) , then , in virtue of the coefficients x ( i ) and y ( j ) , we have x ~ U = X ~ e ( i ) = x ( i ) e ( i ) , y ~ v y S e ( j ) ' ) e ( j ) = = ykj , ( X D u ) ( y~ V ) = x ( i ) y ( j ) e ( i ) e ( j ) . Therefore , a rule is applicable to ~y if x ( i ) = y ( j ) = i. The result z = xy is obtained as the union of all the w ( i , j ) 's of the applicable rules : z = Uw = ~x ( i ) y ( j ) w ( i4j ) . 12.5. The rules are prepared and used more freely according to the given condition and requirement. In the following scheme ( S'akai , 1961 ) , a complete neighborhood is represented by a code consisting of a number of digits and each digit is checked , modifiedand transferred independently. Suppose x and y are given and their concatenation z = xy is required. Both x and y can be syntactically ambiguous and their ambiguity is to be reduced in the course of finding z. Initially , z is assumed to be the set of all the possible contexts , x , y and z are transferred to a temporary storage space ( xl ,</definiens>
				<definiens id="31">applicable if x ( = ) u , y ( = ) v and z ( = ) w , and the set ( xl , Yl , Z l ) is modified everytime a rule is applied. If a rule proves x I ( = ) u , Yl ( = ) v , z I0 w = O , then the rule is not applied to this set , and another set ( x2 , Y2 , Z2 ) is stored in another storage space as another possible result. All the applicable rules are applied one after another to all the possible sets of ( xi , Yi , Zi ) . Similar procedure is repeated over again on two languages simultaneously , so that the syntactic structure can be transferred from the tree structure in one language to that of another language. ~he form of the tree is preserved but their nodes are marked by the labels specific to each language , input , intermediate or output language. 13. Distribution Class Representation of Concatenation Rules. Possible concatenation of a language can be formulated as concatenated sets of strings. Let R = set ( r : h ( r ) ) Sakai 28 and S = set ( s : h ( s ) ) be sets of strings satisfying the conditions h ( r ) and h ( s ) , respectively , and let their concatenation have the property k ( rs ) , so that rs E T = set ( t : k ( t ) ) . We consider the concatenation rules of the form RS ~ T , which reads : if • then r 6 R and s £ S , rs K T. The point of this representation is that , and s 6 S h~ S i~ -- OS k , then as many rules are applicable to rs and they give rs E N -- S % : The intersection T ' has less number of elements and , if the rules are precise , the character of the strings in it is determined as precisely as required. Of course , these procedures are not to be done by listing up all the members of the sets. Each set in the rules is represented by a code. Every entry of the lexicon has a code and it can be determined whether or not the string belongs to any given set. These codes are to be generated and attached to rs to indicate that it belongs to the set T'. Practically , it is convenient to classify the strings in terms of their complete neighborhoods : R = set ( r : h ( C ( r ) ; u ) ) = R ( u ) , S = set ( s : h ( C ( s ) ; v ) ) = S ( v ) , T = set ( t : k ( C ( t ) ; w ) ) = T ( w ) . A grammar of concatenation will be given as a set of rules of the form R ( u ) S ( v ) c with a relation f ( uv ; w ) , and the rules can be described in a number of different ways according to the choice of R ( u ) S ( v ) ,</definiens>
				<definiens id="32">the situation by making use of the distribution classes G , H , I and J , and by assuming the relation f ( uv ; w ) as uv ( = ) w , UV~ W~ Sakai 29 EV ~ w , or uv = w. lhe type of T ( w ) is chosen so that the grammar may describe the language adequately. 13.___~1. G Renresentation. If then then If then then If then If then Put ~ ( u ) = G ( u ) , r E G ( u ) , s E G ( v ) , rs E G ( u ) G ( v ) ~ G ( uv ) , C ( rs ) ( = ) uv ( = ) w. r ~ G ( u ) , s ~ G ( v ) , uv ~ w , rs E G ( u ) G ( v ) c G ( uv ) , C ( rs ) ( : ) uv ~ w. r E G ( u ) , s ~ ~ ( v ) , uv ~ w , rs 6 S ( u ) G ( v ) C G ( uv ) c G ( w ) . r E G ( u ) , s g G ( v ) , uv = w , rs ~G ( u ) G ( v ) ~ G ( UV ) = G ( w ) . s ( v ) = G ( v ) . uv ( = ) w , necessarily elementary. 13.2. H Re-oresentation. Put ~ ( u ) = : ~ ( u ) , S ( v ) = ~ ( v ) . Even if a few rules are applicable to rs in these cases , that is , rs E G ( w~ ) ~ G ( w i ) ~ -- ~ G ( wx ) , we have no simple way to find C ( rs ) from w's. We can not specify a set of less members which adequately indic'ates the property of rs , unless more specific information is available. 13.1.1. Suppose , however , u and v are elementary. If C ( r ) ( = ) u and C ( s ) ( = ) v , then C ( r ) ~ u , C ( s ) ~v. That is , r ~ G ( u ) = H ( u ) , s ~G ( v ) = H ( v ) . For further discussion , see `` H Representation '' , where u or v is not necessarily elementary. 13.1.2. Assume C ( r ) and C ( s ) are elementary. If C ( r ) ( = ) u and C ( s ) ( = ) v , then C ( r ) ~ u and C ( s ) ~ v. That is , r ~ l ( u ) and s E I ( v ) . For further discussion , see `` I Representation '' , where no neighborhoods are if then .z,3.2..l. then then then then We put If r ~ H ( u ) , s 6H ( v ) , rs 6 H ( u ) ~ ( v ) _~ H ( uv ) . uv ( = ) w , rs ~ H ( u ) H ( v ) ~ H ( uv ) , C ( r~ ) o_ uv ( = ) w , C ( rs ) ( = ) w , rs 6 G ( w ) . S~ &lt; ai 30 ~ ( w ) = Q ( w ) . However , there is no simple procedure of finding the intersection of G ( w ) 's. We can not specify the features of the strings by finding more rules applicable to rs , unless more specific informa { ion is available. 13.2.2. If uv ~ w , then rs ~ H ( u ) H ( v ) ~ H ( uv ) ~ H ( w ) , because H ( uv ) = H ( w U wi ) = H ( w ) ~ H ( w ' ) ~ H ( w ) . We put T ( w ) = H ( w ) to have the rules of the form If a number of rules are applicable and rs £ H ( uh ) ~ ( v h ) c_ X ( w , n ) rs 6 H ( ui ) H ( v i ) ~-H ( w i ) rs ~ X ( uk ) ~ : ( v k ) c_ ~ ( wk ) , then rs £ H ( w h ) ~ H ( w i ) ~ -- OH ( w k ) = : ~ ( wh C wi U -- Owk ) ' then C ( rs ) O_ w h U w iU -- Ow k '' The rules of this type are essentially the same as the rules of complete neighborhoods xy ~ uv ~ w , although they are encoded as the sets of strings ; 13.2. 7 . If uv ~_ w , then C ( rs ) ~_ uv~_ w , then rs 6 G ( w ) . 13.2.4. Put UV = W. Then rs ~ H ( u ) H ( v ) ~ H ( uv ) = H ( w ) . Sakai 31 The situation is the same as the case above , where uv ~ w. 13.3. , I , Re , presentation. , Put R ( u ) = i ( u ) , S ( v ) = l ( v ) . If r £ i ( u ) , s 6 i ( v ) , then rs ~ I ( u ) I ( v ) ~ l ( uv ) . ! 3.3.1. If uv ( = ) w , then C ( rs ) c uv ( = ) w. No relationship is relevant between C ( rs ) and w. 13.3.2. If urn_w , then C ( rs ) c uv ~ w. m No definite T ( w ) is available , such that I ( u ) l ( v ) ~_ T ( w ) . 13._~3.. We consider the rules of tie type i ( u ) I ( v ) with uv ~ w. If r£ i ( u ) , s£1 &lt; v ) , then rs { I ( uv ) = i ( w ) . If a nmmber of rules are applicable to rs , then rs £ I ( w h ) N I ( wi ) ~ -- O I ( wk ) = I ( w h ~ w i~ -- ~Wk ) . % herefore , the rules of this type are equivalent to those of the type xy C uv C w. 13.3.4. Put • Then UV = W , rs ~ I ( u ) i ( v ) ~ I ( uv ) = I ( w ) . This is the same to the case mentioned above. 13.4. J Reoresentation. Put ~ ( u ) = J ( u ) , S ( v ) = J ( v ) . This type of grammar is not practical because every real distribution class J of the language must be listed in the rules</definiens>
				<definiens id="33">the com } ~lete neighborhood representation of rules f ( uv ; w ) applicable to xy only if x = u and y = v. 13.5. Practically , the rules can be written more freely and the program can be more flexible and efficient , provided that a more sophisticated Sakai 32 scheme is introduced to the G Representation and the condition f ( uv ; w ) . ~is is realized by representing the sets of strings by codes , so that the union and the intersection of any two sets are determined by the operation on the codes. 14. Some Remarks on Transformation. 14.1. It is generally agreed that we generate acceptable strings by starting with an axiom and expanding it repeatedly into a string of constituents. This procedure is taken care of by concatenation rules. After generating one or more strings by this procedure , they are transformed to yield another string. Let us imagine another function of our normative device. We give it a pair r = ( r ' , r '' ) of acceptable strings r ' = r ' ( 1 ) r ' ( 2 ) -- -r ' ( i ' ) -- -r ' ( m ' ) and r '' = r '' ( 1 ) r '' ( 2 ) -- -r '' ( i '' ) -- -r '' ( m '' )</definiens>
				<definiens id="34">a string r = r ( 1 ) r ( 2 ) -- -r ( i ) -- -r ( m ) with m = m ' + m '' . We put m '' = 0 if the string r '' is absent. We then give it another acceptable string s = s ( 1 ) s ( 2 ) -- -s ( j ) -- -s ( n ) , and ask it whether or not the string s as an expression is true if both r ' and r '' are true. If the device says `` yes '' , we consider the string s is generated from r by a transformation. We call r the original string and s its orano_o~.n. If it says ~'no '' , no such transformation exists. Conversely , we ask it whether or not r ' and r '' are true if s is true. If the device says T~Xr~f ~ , we consider an inverse transformation exists , such that s is expressed by r ' and r '' . We can find many cases in which the device would say `` yes '' for transformation but `` no '' for inverse transformation. Some information is supposed to have been lost in generating the string s , which can not be retrieved unless appropriate , possibly non-linguistic , information is supplied. ~ % is situation is beyond the scope of Syntaetics. A transformation or an inverse transformation is called singularly if r '' in r is absent , and it is a generalized one if both r ' and r '' are present. If it is an embedding transformation , r ' and r '' are called matrix and constituent strings , respectively. If we understand the transformation in the sense mentioned above , the transfer of syntactic structure from one language to another is also a transSakai 33 formation ( Gross , 1962 ) . 14.2. If it is known that r is transfor~ed to s , then ... .. ~n~o fact ms used to generate a particular string. If r is known to be an inverse transform of s , then this is used to recognize s , giving a possible derivational history. if no other such transformations are found ,</definiens>
				<definiens id="35">the only nearest history. Otherwise , the ambiguous history is to be accounted for by other rules. If we find r and s such that r is true if and only if s is true , then we say r and s are equivalent and write r eqv s. Obviously , this equivalence is symmetric , reflexive , and transitive. A transformation that transforms a string into an equivalent string is called an equivalence transformation , if we have a grammar consisting of equivalence transformations only , it can be used for both synthesis and analysis. Let us confine ourselves to the equivalence transformations in order to simplify the discussion , and assume we have a set of rules or a normative device. A generalized transformation transforms a oair r = ( r ' r '' ) of strings into one strin~ s. ~e inverse transformation by the same rule dissolves a string s into a pair of strings ( r ' , r '' ) . ~en , r ' or r '' is regarded as an s , and , if we find an appropriate rule , it is again dissolved into two acceptable strings. By repeating the same , we have a number of equivalence relations which can be arranged as a tree : s eqv ( r ( 1 ) , r ( 2 ) ) ; r ( 1 ) eqv ( r ( ll ) , r ( 12 ) ) ; r ( 2 ) eqv ( r ( 21 ) , r ( 22 ) ) ; r ( ll ) eqv ( r ( lll ) , r ( ll2 ) ) ; r ( 12 ) eqv ( r ( 121 ) , r ( 122 ) ) ; If an acceptable string t can no longer be dissolved into two acceptable strings , we call t a terminal or an atomic acceptable string. ~nroughout this procedure , the strings are expected to become shorter and simpler , because equivalent information is expressed by many separate strings. It will be still possible to transform an atomic string to another atomic string by means of a singulary transformation. We have different atomic strings which are mutually equivalent. We may pick up one of them and call it a kernel string. 1~e sequence of inverse transformations is not always uniquely determined. There can be other orders of dissolving a given string into atomic strings. We can make the grammar less redundant by studying the possible sequences of Sakai 34 inverse transformations. If the rules are all equivalence rules , there is no theoretical problem of ambiguity• ~ne investigation of these problems requires quite a different treatment , and will not be included in this paper. 14.3. Sometimes , it is considered more linguistically reasonable to assume `` S ~rln~ or that a string is not acceptable but its transform is an acceptable ~ `` ~ ~. a constituent of an acceptable string , in some other cases , a s~ing may be an acceptable string and its transform may not be an acceptable string or a constituent thereof In other wo~as , a transformation is applied to an unacceptable string or a transformation results in an m % acceptable string. We may prepare the rules in such a way that a sequence of obligatory transformations is contracted to a single ~ale. This seems formally simpler and consistent. However~ it will result in a more entangled system of grammar. We admit some of such strings as potentially acceptable and indicate it by a marker , This convention is somet~nes useful not merely as a technique but also as a consistent and more plausible derivation of acceptable strings. It is known that a string of a Chinese dialect marked potentially acceptable for the derivation of apparently inconsistent strings is quite acceptable in another dialect ( Wang , 1964 ) . 14.4. A generalized transformational rule consists of terms u and v , where u = ( u ' , u '' ) = u ( 1 ) u ( 2 ) -- -u ( i ) -- -u ( m ) , u ' = u , ( 1 ) u ' ( 2 ) -- -u ' ( i ' ) -- -u ' ( m ' ) , u '' = u , ( 1 ) u '' ( 2 ) -- -u '' ( i '' ) -- -u '' ( m '' ) , m = m r. ~ m ~r , u becomes v~ v = v ( ! ) v ( 2 ) -- -v ( j ) -- -v ( n ) . Most rules are accompanied by a number of restrictions imposed on the original strings and their transforms as well as some manipulations of strings. ~ese are classified into a few types and subroutines are to be prepared for them. Some of the operations are listed below , which have been picked up sporadically from the rules for generating Chinese strings ( Hasimoto , 1964 ) . ( 0 ) A routine supervising the subroutines takes care of the whole procedure of applying the rules to a string , if the rules are prepared in a definite format , they are automatically checked and applied to the given string. ( I ) Certain segments r ( h ) and r ( i ) in the original string must or must not share a certain feature in common and/or a segment r ( j ) must or must not have a certain feature. Sakai 35 ( 2 ) The segment r ( i ) of the original string and the segment ~ ( o ) of the transform must or must not have the same feature specified by the rule. ( 3 ) Some segments in the transform must satisfy the condition similar to ( I ) . ( 4 ) Absence and/or presence of particular segments must be ~ cne c~ed. ( 5 ) Positions of certain segments in the string must be found. ( 6 ) A check of the derivational history somet~les decides the recursive application of the rule~ ( 7 ) The tree structure must or must not be changed by the final procedure of a transformation. ~. No rule describes a transformation of an individual string r into an individual string s. The rule says , if the string r has the feature u : u ( 1 ) u ( 2 ) -- -u ( i ) -- -u ( m ) , then it is transformed to another string s which has the feature v : v ( 1 ) v ( 2 ) -- -v ( j ) -- -v ( n ) . What are these features ? They must be defined on the basis of the answers of our normative device. The program must be consistent with the features defined. Once a program is written and decided to be used , the program is the definition. If the program is modified , the rules and the lexicon are to be modified. Since the transformations are applied to P-markers , a string is considered to be a tree-like string , if it is a linear string of terminal nodes , the other non-terminal nodes and the branches are to be determined by virtue of the concatenation rules. We consider the labels u ( i ) and v ( j ) are complete neighborhoods , if the concatenation rules are written in terms of complete neighborhoods. If the concatenation rules are written in terms of distribution classes , u ( i ) 's and v ( j ) 's are considered to be distribution classes. 14.6. The complete neighborhoods are defined on the basis of concatenated strings and we have to associate them with the labels given to the nodes of our transformational rules in order that the kernel strings can be transformed. Let us see what happens when the nodes are assumed to be complete neighborhoods. Let p = ( p ' , p '' ) be a pair of acceptable strings p ' and p '' , and let r = r ( 1 ) -- -r ( i ) -- -r ( m ) be a segment of p. The pair p is transformed by T into Sakai 36 q = T ( p ) , and the segment appears in q as s = s ( 1 ) -- -s ( j ) -- -s ( n ) . Some strings may have been added and some others may have been deleted. Put x ( i ) : C ( r ( i ) ) , x : C ( r ) ~ y ( j ) = C ( s ( j ) ) , y : C ( s ) . By definition , x : x ( 1 ) -- -x ( i ) -- -x ( m ) , y = y ( 1 ) -- -y ( j ) -- -y ( n ) . Any string belongs to one and only one distribution class J. instead of Therefore , T ( r ( 1 ) -- -r ( i ) -- -r ( n ) ) = s ( 1 ) -- -s ( j ) -- -s ( n ) , we</definiens>
				<definiens id="36">m ) ) ) = J ( y ( 1 ) ) -- -J ( y ( j ) ) -- -J ( y ( n ) ) . Since all the elements in a J has the same complete neighborhood , we rewrite the above as T ( x ( 1 ) -- -x ( i ) -- -x ( m ) ) = y ( 1 ) -- -y ( j ) -- -y ( n ) . This is rewritten again by breaking down in the form X = x ( 1 ) -- -x ( i ) -- -x ( m ) , y : T ( x ) = y ( 1 ) -- -y ( j ) -- -y ( n ) . If we have a complete set of rules which gives the concatenation of any complete neighborhoods of the language , then we can find the complete neighborhood x. The transformation takes place when x is changed to y. The string y is to be generated in virtue of the information brought forward from x and the structural requirement of y itself. A transformation is then interpreted as : ~ne complete neighborhood x of the node dominating the string x ( ! ) -- -x ( i ) -- -x ( m ) of complete neighborhoods is transformed to another complete neighborhood y of the node dominating the string y ( 1 ) -- -y ( j ) -- -y ( n ) . Sakai 37 This interpretation , however , suggests a few problems , 14_~. We know that J ( x ( 1 )</definiens>
				<definiens id="37">y ( 1 ) ) -- -J ( y ( j ) ) -- -J ( y ( n ) ) m J ( Y ) '' The statement `` x is transformed to y '' is a generalization of the original fact , and this generalization is not always true. The text should be checked before a transformational rule is applied to it. Some separate steps for this purpose will save the machine time. ( 1 ) ( 2 ) ( 3 ) 14.8. A text to be parsed must consist of segments specified by the rule. The correct segmentation can be done by finding the tree structure of the ! text. Therefore , the concatenation rules must be prepared so as to ~ account for the structure of any acceptable strinG. Not all the trees of the specified form undergo the inverse transformation so that the derivational history may be traced back. The nodes are labeled. A tree of a form can correspond to a number of trees whose nodes have different labels. When a string is being synthesized , the text is given as a pair of Pmarkers. A rule can be applied only if the P-markers meet the condition specified by the rule. We may regard the structure mentioned above as a representation of derivational history. The history can be recorded by listing all the derivational steps the string has experienced. This representation , however , will be redundant and inefficient , because it is likely to occur that an identical series of transformations is applied to strings of different history. On the other hand , it is also possible that the strings p and q of different histories result in an identical string s by a transformation and the string s is ambiguous in that the s from p can undergo a sequence of transformations and the s from q another ; thus the structure itself can not be an absolutely reliable marker. We think it more practical to associate the rules with the features in the P-marker to which the rules are applied. '~lese features should correspond to the series of transformations applicable to the P-marker in case of synthesis and the series of inverse transformations in case of analysis. We have some rules with notes on the type of transformations to which the resultant strings may be exposed ( Hasimoto , 1964 ) . 15. Complete Neighborhppds and Transformational. Rules. Let us assume u ( i ) 's and v ( j ) 's are complete neighborhoods. Saka± 38 ~. Two strings r and s may replace th~ same non-terminal node to yield a longer acceptable string. However , when a transformation T is to be applied , they must hav~ the specified structure ; thu~ the str ! n~ p with r a~ a ~e~ment in it may be transformed by T , while the string q which differs from p only in that it has the segment s in the place of r may not. The lack of q by T means C ( r ) / C ( s ) . 1_~,2. Because of this complexity involved in natural languages , we encounter a difficulty when we try to prepare a set of syntactic data for practical purposes. We refine the definition of complete neighborhood in such a way that C ( r ) of a string r is the set of all contexts of r which appear in the strings to which no transformations have ever been applied during their derivation. The difference between r and s is found in their internal structure , if the machine is given only the input string to be parsed. In order to indicate this difference</definiens>
			</definition>
			<definition id="6">
				<sentence>A syntactic function is called a complete neighborhood if it is defined as a set of contexts .</sentence>
				<definiendum id="0">syntactic function</definiendum>
				<definiens id="0">a set of contexts</definiens>
			</definition>
			<definition id="7">
				<sentence>Suppose a concatenation rule f ( uv ; w ) is to be applied to a text xyof complete neighborhoods to determine z = xy , and the complete neighborhoods are represented by the indices in the form x = ( a ( x ) ; b ( x ) ; -- - ; n ( x ) ) , y = ( a ( y ) ; b ( y ) ; -- - ; n ( y ) ) , z = ( a ( z ) ; b ( z ) ; -- - ; n ( z ) ) , u : ( a ( u ) ; b ( u ) ; -- - ; n ( u ) ) , v = ( a ( v ) ; b ( v ) ; -- - ; n ( v ) ) , w = ( a ( w ) ; b ( w ) ; v -- ; n ( w ) ) .</sentence>
				<definiendum id="0">w )</definiendum>
				<definiens id="0">to be applied to a text xyof complete neighborhoods to determine z = xy , and the complete neighborhoods are represented by the indices in the form x = ( a ( x</definiens>
			</definition>
			<definition id="8">
				<sentence>Parker-Rhodes , A. F. : A New Model of Syntactic Description , 1961 International Conference on Machine Translation of Languages and Applied Language ~alysis , Her Majesty 's Stationary Office , London .</sentence>
				<definiendum id="0">A. F.</definiendum>
				<definiens id="0">A New Model of Syntactic Description , 1961 International Conference on Machine Translation of Languages</definiens>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>Type B Format i : B Interpretation : The current branch is optional Type B Format 2 : B + ( Tree Address ) Interpretation : The current branch is optional only if the node at the Tree Address is present ( if + is used ) or absent ( if is used ) ° Type DB Format I : DB Interpretation : The current branch is optionally deletable @ Type DB Format 2 : DB + ( Tree Address ) Interpretation : The current branch is optionally deletable only if the node at the Tree Address is present ( if + is used ) or absent ( if is used ) Type DD Format i : DD Interpretation : The current branch is obligatorily deletable .</sentence>
				<definiendum id="0">B Interpretation</definiendum>
				<definiendum id="1">Interpretation</definiendum>
				<definiendum id="2">DD Interpretation</definiendum>
				<definiens id="0">The current branch is optional Type B Format 2 : B + ( Tree Address ) Interpretation : The current branch is optional only if the node at the Tree Address is present ( if + is used ) or absent ( if is used ) ° Type DB Format I : DB</definiens>
				<definiens id="1">DB + ( Tree Address ) Interpretation : The current branch is optionally deletable only if the node at the Tree Address is present ( if + is used</definiens>
			</definition>
			<definition id="1">
				<sentence>When this happens , the analysis is terminated , and the sentence is labeled `` non-grammatical '' o Returning to the main routine ( CLEANUP is a subroutine used repeatedly during the main routine ) , the next step is condition testing .</sentence>
				<definiendum id="0">CLEANUP</definiendum>
				<definiens id="0">a subroutine used repeatedly during the main routine</definiens>
			</definition>
</paper>

		<paper id="1009">
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>/5/WAHRNEHMEN/5/ HAT MIT /5/NEHMEN/5/ ZU TUN UND DRUECKT EINEN AKTIVEN ANTEIL UNSERES ICH AN DER AUSWAHL AUS DER SUMME MDEGLICHER ERFAHRbNGEN AUSo CORPUS DI 74001001 7400|002 7400\ ] C003 74DOIC04 74001005 74301006 74001 C007 74302001 76302002 7~.302003 7ft 302004 74302005 743020006 7 ' ( 302 ( 307 7'~ 302008 74 ) 02009 7'~ 302010 74 302011 7~ 302012 74 ) 02013 74 ) 02014 74 302015 74 303001 74 ) 03002 74 303003 74 ) 03004 74 ) 03005 7~ ) 03r~06 7~ 303D07 74 ) 03~OB 74 \ ] 04001 7~ ) 04002 7~i ) 04003 7~ ) 041004 74 ' ' ,0z~005 74 ) 0~306 7z~ ) 040007 74 ) 04 ; 08 74 ) 04309 74 ) 04010 74 ) 041311 7~ ) 051301 74 ) 051302 74 \ ] 053003 74 ) 05 304 74 ) 005 005 76 10~306 74 ) 0~:007 APPENDIX B TOSH ENGLISH CORPUS DISPLAY SPLAY HUMAN TRANSLATION THE ONLY BODILY CONDITIONS UNDER WHICH CONSCIOUSNESS IS POSSIBLE ARE QUITE DIVERSE AND THE PROBLEM OF CONNECTING THE PSYCHIC WITH THE STRUCTURE OF OUR BRAIN IS SO COMPLEX THAT IN AN ESSAY ONE CAN ONLY SELECT A PARTIAL PROBLEM .</sentence>
				<definiendum id="0">/5/WAHRNEHMEN/5/ HAT MIT /5/NEHMEN/5/ ZU TUN UND DRUECKT EINEN AKTIVEN ANTEIL UNSERES ICH AN DER AUSWAHL AUS DER SUMME MDEGLICHER ERFAHRbNGEN AUSo CORPUS</definiendum>
			</definition>
			<definition id="1">
				<sentence>ThAT WHICH WE FIND DIRECTLY IN OURSELVES/2/ ATTENTIVENESS AS A TERM FOR A FORCE WHICH IS AT FIRST INEXPLICABLE , WHICH DRAWS AWAY OUR CONSCIOUSNESS FROM MOST OBJECTS OF OUR ENVIRONMENT AND DIRECTS IT TOWARD A SINGLE PROCESS/2/ FINALLY , THINGS WHICH MEET OUR SENSE ORGANS ( E.G. NOISES ) AND , AS wE DEFINITELY KNOW/ SEND A , ~2 CORPUS DISPLAY 740050008 74005C009 740005010 760005011 7400050L2 740005013 7400005014 740050015 7~00050016 REPORTS FROM THEM TO OUR BRAIN , BUT DO NOT PENETRATE INTO CONSCIOUSNESS WITHIN OUR BRAIN , AND THUS REMAIN UNCONSCIOUS .</sentence>
				<definiendum id="0">WHICH WE FIND DIRECTLY IN OURSELVES/2/ ATTENTIVENESS AS A TERM FOR A FORCE WHICH</definiendum>
				<definiendum id="1">THINGS WHICH MEET OUR SENSE ORGANS ( E.G. NOISES</definiendum>
				<definiens id="0">IS AT FIRST INEXPLICABLE , WHICH DRAWS AWAY OUR CONSCIOUSNESS FROM MOST OBJECTS OF OUR ENVIRONMENT AND DIRECTS IT TOWARD A SINGLE PROCESS/2/ FINALLY</definiens>
			</definition>
			<definition id="2">
				<sentence>PARTLY , ITS THOUGHTS DIFFER A LITTLE FROM THE AUTHOR/6/S , WHICH IS UNDERSTANDABLE MERELY THROUGH THE FACT THAT THE AUTHOR PRODUCED THESE THOUGHTS , AND FURTHERMORE CONSIDERS THEM CORRECT , WHILE THE READER IS THE RECEIVING PARTY AND THEREFORE THE /5/MEDITATOR , /5/ AND~ HOPEFULLY , DOES NOT IN THE PROCESS LOSE THE COMPULSION TO EXAMINE WHAT HE IS BEING TOLD AS TO ITS CORRECTNESS .</sentence>
				<definiendum id="0">FURTHERMORE</definiendum>
				<definiens id="0">IS UNDERSTANDABLE MERELY THROUGH THE FACT THAT THE AUTHOR PRODUCED THESE THOUGHTS , AND</definiens>
			</definition>
			<definition id="3">
				<sentence>THAT WHICH WE FIND DIRECTLY IN US/2/ ATTENTIVENESS AS A TERM FOR A FORCE WHICH IS AT FIRST INEXPLICABLE WHICH DRAWS AWAY OUR CON£CIOUSNESS FROM MOST OBJECTS OF OUR ENVIRONMENT AND DIRECTS IT TOWARD A SINGLE PROCESS/2/ FINALLY , THINGS WHICH MEET OUR SENSE ORGANS ( E.G. NOISES ) AND , AS WE DEFINITELY KNOW , SEND MESSAGES FROM THEM TO OUR BRAIN , BUT DO NOT PENETRATE INTO CONSCIOUSNESS IN OUR BRAIN , THUS REMAIN UNCONSCIOUS .</sentence>
				<definiendum id="0">WHICH WE FIND DIRECTLY IN US/2/ ATTENTIVENESS AS A TERM FOR A FORCE WHICH</definiendum>
				<definiendum id="1">THINGS WHICH MEET OUR SENSE ORGANS ( E.G. NOISES</definiendum>
				<definiens id="0">IS AT FIRST INEXPLICABLE WHICH DRAWS AWAY OUR CON£CIOUSNESS FROM MOST OBJECTS OF OUR ENVIRONMENT AND DIRECTS IT TOWARD A SINGLE PROCESS/2/ FINALLY</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence># yes I I Base P-marker i no Derived P-marker produced by G2 not produced By G T • Transformational Language Recognizer ( 2 ) Diagram 2 Kuno-6 P-marker in the course of generation of the given sentence .</sentence>
				<definiendum id="0">Transformational Language Recognizer</definiendum>
				<definiens id="0">no Derived P-marker produced by G2 not produced By G T •</definiens>
			</definition>
			<definition id="1">
				<sentence>The base P-marker , the set of inversely applied transformational rules , and phonological rules contained in the dictionary entries constitute the analysis of the input sentence .</sentence>
				<definiendum id="0">base P-marker</definiendum>
				<definiens id="0">the set of inversely applied transformational rules , and phonological rules contained in the dictionary entries constitute the analysis of the input sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>The predictive analyzer uses a predictive grammar G ' whose rules ( called `` predictive rules '' ) are of the following form : &lt; Z , c &gt; ~Z , c ~ `` 'Y Yl '' m ' m &gt; 1 .</sentence>
				<definiendum id="0">predictive analyzer</definiendum>
				<definiens id="0">uses a predictive grammar G ' whose rules ( called `` predictive rules '' ) are of the following form : &lt; Z , c &gt; ~Z</definiens>
			</definition>
			<definition id="3">
				<sentence>5 can be automatically constructed given the initial symbol S. To each prediction in each rule of the predictive grammar is assigned a set of ordered pairs ( x , y ) where y indicates the name of a node and x the branch number of y in a P-marker .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">indicates the name of a node and x the branch number of y in a P-marker</definiens>
			</definition>
			<definition id="4">
				<sentence>fulfills the prediction A , Rule i0 is usedt Rule i0 &lt; A~ ad~ I AND A i m , , ( x÷l , AND ) ( ~2 , A ) '' { ( x , y ) } for the fulfilled prediction is ( 223 , A ) ; therefore , ( x+l~ AND ) and ( x+2 , A ) are changed into ( 224 , AND ) and ( 225 , A ) , respectively ( 224 = 223 + i , 225 = 223 + 2 ) , and are stored in the PDS with the corresponding predictions AND and A. If the predicate has four adjectives as in `` young and beautiful and intelligent and bright , '' Rule i0 will be used again for the processing of `` intelligent. '' This Kuno-27 time , max x = 225. Therefore , new predictions AND and A will be stored in the PDS with the new ordered pairs ( 226 , AND ) and ( 227 , A ) , respectively. It should now be noted that the concatenation operation x~m plays the role of generating a subtree whose initial node has the branch number max x , while x+ m plays the role of adding a branch to the right of a branch whose branch number is x , and whose immediately dominating node also dominates the added branch. What are the salient differences between the transformational analysis system ( see Sec. 2 ( ii ) of this paper ) proposed by the MITRE group and Petrick ( to be referred to as M-P system ) and the one proposed in the present paper ( to be referred to as K-system ) ? The M-P system is based on the condition that a transformational grammar is given. A context-free analysis component is automatically constructed on the basis of the transformational grammar ; the context-free analysis component assigns one or more derived P-markers to a sentence to be analyzed ; transformational rules are applied inversely to each P-marker step by step until the base P-markers of the sentence are obtained. For example , after a derived P-marker is assigned to `` He met a beautiful girl. '' , the M-P system will compare the P-marker with the derived See the second footnote on page 4Kuno~-28 constituent structure indices of transformational rules , and find that this derived P-marker is the result of the transformational rule which places an adjective in front of a noun. Therefore , by applying this rule inversely , an intermediate P-marker corresponding to `` # He met a girl beautiful # '' is obtained. Next , this new P-marker is compared with derived constituent structure of transformational rules , and it is found that this is the result of the transformational rule which deletes a relative pronoun and a copula. Therefore , by applying this rule inversely , an intermediate P-marker corresponding to `` # He met a girl who was beautiful # '' is obtained. Next , this intermediate P-marker is compared with the derived constituent structure indices of transformational rules again and is identified as being the result of a relativization rule. Therefore , the rule is applied inversely , and a new P-marker corresponding to `` # He met a girl # the girl was beautiful # '' is obtained , which in turn is identified as originating from a rule which places an embedded # S # dominated by DET after the noun. A new P-marker corresponding to `` # He met a # the girl was beautiful # girl # '' is thus obtained. AZ'ter comparing this P-marker again with rules in the transformational component , it is found that there is no rule whose derived constituent structure index matches the P-marker. It is also found that the P-marker is derivable from the phrase-structure component of the transformational grammar. Thus , the P-marker is identified as being a base P-marker , and forward application of the transformations which were inversely applied confirms that it is in fact the base P-marker of the sentence under analysis. Kuno-29 With regard to the K system , on the other hand , a predictive grammar which accepts all the sentences of a given transformational grammar G T ( and probably nonsentences in addition ) is manually compiled. A derived P-marker assigned to a given sentence by the predictive grammar is usually not equal to the derived P-marker which is assigned to the same sentence by 9 '' The mapping of such a distorted P-marker into the base P-marker is not performed step by step through intermediate P-markers as is the case with the M-P system. Instead , it is performed in one step by means of ordered pairs. For example , the fact that the predictive rule &lt; lq ? , art~ ! A N has been used for assigning a distorted P-marker to the sentence `` He met a beautiful girl. '' indicates immediately that an embedded sentence which constitutes a relative clause is involved here , that the subject of the embedded sentence is the same as a noun ( `` girl '' in our example ) which fulfills N of the predictive rule , and that the adjective ( `` beautiful u ) which fulfills A is the predicate adjective of the embedded sentence. The predictive rule has associated with it a set of ordered pairs which draws a subtle of the base P-marker image of this NP. The summation of such subtrees drawn by all the rules used for obtaining the distorted P-maker yields the base P-maker of the sentence. The K system does not achieve this one-step mapping without cost. The sacrifice is paid in the simplicity of the context-free Kuno30 analysis component. For example , in order to obtain desired base P-markers for ( i ) ( ii ) ( iii ) Look at the girl who is dancing the mazurka. This is the girl whom everyone likes. This is the glrl by whom he was ruined. the predictive grammar must have three different rules pertaining to a noun phrase initiated by the definite article `` the. '' Each rule specifies a different position , in the embedded sentence , of the predicted N ( see circled N 's in Fig. ll ) . Rule ( i ) : &lt; NP , the &gt; ( xll , the ) ( x.U , ~ ) ( x~3 , s ) ( x.U~ , # ) ( xl31 , m~ ) ( xl3111 , the ) N ( x2 , N ) ( x1312 , N ) KELsb j ( x13 , R ) Rule ( i-a ) Rule ( ii ) &lt; RELsb.I , who &gt; 1 A VP ( x2 , v ? )</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">A ) , respectively. It should now be noted that the concatenation operation x~m plays the role of generating a subtree whose initial node has the branch number max x , while x+ m plays the role of adding a branch to the right of a branch whose branch number is x , and whose immediately dominating node also dominates the added branch. What are the salient differences between the transformational analysis system</definiens>
				<definiens id="1">the context-free analysis component assigns one or more derived P-markers to a sentence to be analyzed ; transformational rules are applied inversely to each P-marker step by step until the base P-markers of the sentence</definiens>
				<definiens id="2">in turn is identified as originating from a rule which places an embedded # S # dominated by DET after the noun. A new P-marker corresponding to</definiens>
				<definiens id="3">derivable from the phrase-structure component of the transformational grammar. Thus , the P-marker is identified as being a base P-marker , and forward application of the transformations which were inversely applied confirms that it is in fact the base P-marker of the sentence under analysis. Kuno-29 With regard to the K system , on the other hand , a predictive grammar which accepts all the sentences of a given transformational grammar G T ( and probably nonsentences in addition ) is manually compiled. A derived P-marker assigned to a given sentence by the predictive grammar is usually not equal to the derived P-marker which is assigned to the same sentence</definiens>
				<definiens id="4">constitutes a relative clause is involved here , that the subject of the embedded sentence is the same as a noun ( `` girl '' in our example ) which fulfills N of the predictive rule , and that the adjective ( `` beautiful u ) which fulfills A is the predicate adjective of the embedded sentence. The predictive rule has associated with it a set of ordered pairs which draws a subtle of the base P-marker image of this NP. The summation of such subtrees drawn by all the rules used for obtaining the distorted P-maker yields the base P-maker of the sentence. The K system does not achieve this one-step mapping without cost. The sacrifice is paid in the simplicity of the context-free Kuno30 analysis component. For example</definiens>
			</definition>
			<definition id="5">
				<sentence>Ordered pair ( ( x+l ) 2 , be ) indicates that i is to be numerically added to max x , and 2 is to be concatenated to the right of the sum .</sentence>
				<definiendum id="0">Ordered pair</definiendum>
				<definiens id="0">to be concatenated to the right of the sum</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>LRS is a large-capacity system designed especially to support research in computational linguistics , It currently has the capability of performing several types of generalized translation , and of transferring information among any number of languages through the use of interlingual descriptions .</sentence>
				<definiendum id="0">LRS</definiendum>
				<definiens id="0">a large-capacity system designed especially to support research in computational linguistics</definiens>
			</definition>
			<definition id="1">
				<sentence>ACS is a generalized classification system which can be applied to non-linguistic as well as linguistic problems .</sentence>
				<definiendum id="0">ACS</definiendum>
				<definiens id="0">a generalized classification system which can be applied to non-linguistic as well as linguistic problems</definiens>
			</definition>
			<definition id="2">
				<sentence>We assume , in the morphological problem , that the objects to be classified are lexical units ( whether phonetic or orthographic ) and that concatenation is the constitutive relation .</sentence>
				<definiendum id="0">concatenation</definiendum>
				<definiens id="0">the objects to be classified are lexical units ( whether phonetic or orthographic )</definiens>
			</definition>
			<definition id="3">
				<sentence>latrix C C = ( ci~ j ) such that rain k ) where m is the number ( ni k'n~'~ of columns ( rows ) in the Ci , j k=l normalized reduced matrix F. Discussion : The frequency matrix which forms the incidence data for the experiment is a table showing how many times an object i coincides with an object j. Reducing the matrix by removing columns which are all zero on all off-diagonal cells , deletes from the set of objects those objects for Pendergraft , Dale 8-3 which there are no coincidence data .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">The frequency matrix which forms the incidence data for the experiment is a table showing how many times an object i coincides with an object j. Reducing the matrix by removing columns</definiens>
			</definition>
			<definition id="4">
				<sentence>Connection matrix C is a symmetric matrix which describes the relation of object i to object j based on the normalized incidence data .</sentence>
				<definiendum id="0">Connection matrix C</definiendum>
				<definiens id="0">a symmetric matrix which describes the relation of object i to object j based on the normalized incidence data</definiens>
			</definition>
			<definition id="5">
				<sentence>Matrix C constitutes the data for the next stage of processing• Phase 2 : Locating GR-Clumps Definitions C : Connection Hatrix computed in Phase i. U : Universe set ( set of objects characterized in connection matrix C. ) A : A subset of U. ~ : U-A=~ , complement of A. x : An element of U. An element of A ( al , a2 , ai : ~i : An element of ~ ( KI , ~2 ) ( Note : r+t=m ) • .</sentence>
				<definiendum id="0">Matrix C</definiendum>
				<definiendum id="1">a2</definiendum>
				<definiens id="0">constitutes the data for the next stage of processing• Phase 2 : Locating GR-Clumps Definitions C : Connection Hatrix computed in Phase i. U : Universe set ( set of objects characterized in connection matrix C. ) A : A subset of U. ~ : U-A=~ , complement of A. x : An element of U. An element of A ( al ,</definiens>
			</definition>
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>Sgall 2 I.I In the works of N. ~homsky , P.M.Postal , J.J.Katz and others there are formulated three zeneral aims of generative grammar : a ) the grammar generatesf all and only the grammatical sentences of the doscribed languase , in the senBe of a mathem , ~tical enumeration of the set of grammatical sentences ; b ) the grammar automatically ascribes to each generated sentence a structural d~scription , not contradictory to the intuitive evidence of native speakers~ if the same sentence is generated by the grammar in ~ different ways , ~ different structural descriptions a~e ascribed to it~ c ) the grammar is a description of the mechanism the user of the language has internalized and uses in the process of language co~2 .</sentence>
				<definiendum id="0">generative grammar</definiendum>
				<definiens id="0">a description of the mechanism the user of the language has internalized and uses in the process of language co~2</definiens>
			</definition>
			<definition id="1">
				<sentence>As to weak generative power , it has to generate not only the sets of strings gene2ated by a context-free phrase structure grammar , but also at least set of all strings of the form xa_~x , where ~ is a symbol o~he the output vocabulary and ~ is any string of such symbols not containing ~ ; cf. , in a somewhat different formulation , /12/ .</sentence>
				<definiendum id="0">~</definiendum>
				<definiens id="0">generate not only the sets of strings gene2ated by a context-free phrase structure grammar</definiens>
				<definiens id="1">a symbol o~he the output vocabulary</definiens>
				<definiens id="2">any string of such symbols not containing ~ ; cf. , in a somewhat different formulation</definiens>
			</definition>
			<definition id="2">
				<sentence>_xx '' and only them ( where ~ '' is the reflection of ~ ) , and the second part can consist of the following rules ( symbolized here as done by Evey , with some simplification ; denotes any symbol of the input alphabet other than ~ ) : input p inn .</sentence>
				<definiendum id="0">~ ''</definiendum>
				<definiens id="0">symbolized here as done by Evey , with some simplification</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>The L3 language consists of a limited set of canonical forms that ease the problem of establishing meaning equivalence of premises .</sentence>
				<definiendum id="0">L3 language</definiendum>
				<definiens id="0">consists of a limited set of canonical forms that ease the problem of establishing meaning equivalence of premises</definiens>
			</definition>
			<definition id="1">
				<sentence>where L2 is a subset of L1 .</sentence>
				<definiendum id="0">L2</definiendum>
				<definiens id="0">a subset of L1</definiens>
			</definition>
			<definition id="2">
				<sentence>The syntax ~T contains a set of transformations designed for the purposes of isolating premises and specifying logical connectives .</sentence>
				<definiendum id="0">syntax ~T</definiendum>
				<definiens id="0">contains a set of transformations designed for the purposes of isolating premises and specifying logical connectives</definiens>
			</definition>
			<definition id="3">
				<sentence>The processor consists of an alphabet A , where : A = N u D u PN u ADJ u VEQu VTRu VINu VFAC U VAUX o PREPu ADVu THANu ADJC with the sets representing : N : noun D : determiner PN : pronoun ADJ : adjective VEQ : verb equational VTR : verb transitive VIN : verb intransitive VFAC : verb factitive VAUX : verb auxiliary PREP : prepos it ion ADV : adverb ADJC : comparative adjective THAN : Than Manelski &amp; Krulee 8 Although the task of the assignment of word classes is that of the linguist , in general , if X i and Xj are sets comprising A we expect xi x j for i J where ~ represents the empty set .</sentence>
				<definiendum id="0">processor</definiendum>
				<definiendum id="1">ADV</definiendum>
				<definiens id="0">consists of an alphabet A , where : A = N u D u PN u ADJ u VEQu VTRu VINu VFAC U VAUX o PREPu ADVu THANu ADJC with the sets representing : N : noun D : determiner PN : pronoun ADJ : adjective VEQ : verb equational VTR : verb transitive VIN : verb intransitive VFAC : verb factitive VAUX : verb auxiliary PREP : prepos it ion</definiens>
				<definiens id="1">sets comprising A we expect xi x j for i J where ~ represents the empty set</definiens>
			</definition>
			<definition id="4">
				<sentence>The occurrence of an element of the alphabet in more than one word class is known as homography and is common to the natural languages .</sentence>
				<definiendum id="0">occurrence of an element</definiendum>
			</definition>
			<definition id="5">
				<sentence>Interrogative sentences : Is John coming home ?</sentence>
				<definiendum id="0">Interrogative sentences</definiendum>
			</definition>
			<definition id="6">
				<sentence>TCOM : operates on strings in the following domain only : ( i ) • .</sentence>
				<definiendum id="0">TCOM</definiendum>
				<definiens id="0">operates on strings in the following domain</definiens>
			</definition>
			<definition id="7">
				<sentence>Later we will discuss how the processor discovers the L3 ( predicate function ) mapping of an L2 string .</sentence>
				<definiendum id="0">L3</definiendum>
				<definiens id="0">predicate function ) mapping of an L2 string</definiens>
			</definition>
			<definition id="8">
				<sentence>( ii ) ( iii ) ( iv ) ( v ) ( vi ) ( vii ) ( viii ) ( i~ ) PRED is home ( ARG John ) PRED is tall ( ARG John ) FRED is a man ( ARG~ PRED is taller than ( ARG John , ARG Peter ) PRED win ( ARG The Dodgers ) PRED win seldom ( ARG The Dodgers ) PRED loves ( ARG Tall Johns ARG Mary ) PRED saw at the track ( ARG John , ARG Peter ) PRED elected ( ARG John , ARG Peter , ~LRG the chairman ) One special characteristic of the mapping should be noted .</sentence>
				<definiendum id="0">~LRG</definiendum>
				<definiens id="0">a man ( ARG~ PRED is taller than ( ARG John , ARG Peter ) PRED win ( ARG The Dodgers ) PRED win seldom ( ARG The Dodgers ) PRED loves ( ARG Tall Johns ARG Mary ) PRED saw at the track ( ARG John , ARG Peter ) PRED elected ( ARG John</definiens>
			</definition>
			<definition id="9">
				<sentence>PRED ( AR % ARG ) is the current form .</sentence>
				<definiendum id="0">PRED</definiendum>
				<definiens id="0">the current form</definiens>
			</definition>
			<definition id="10">
				<sentence>G3 is one of a set of sub-routines , including G13 , G17 , GI4 and GI5 , designed to notify the programmer that the strings were not found to be meaning equivalent and briefly indicate the reason .</sentence>
				<definiendum id="0">G3</definiendum>
				<definiens id="0">one of a set of sub-routines , including G13 , G17 , GI4 and GI5 , designed to notify the programmer that the strings were not found to be meaning equivalent and briefly indicate the reason</definiens>
			</definition>
			<definition id="11">
				<sentence>G10 attempts to reduce differences by finding permutations of the differing ARGMODs .</sentence>
				<definiendum id="0">G10</definiendum>
				<definiens id="0">attempts to reduce differences by finding permutations of the differing ARGMODs</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>Thus , let us define a `` grammar of size ( m , p ) S as a grammar whose rules are constructed of strings ( on either side of the rewriting rule 's arrows ) such that no string contains more than m occurrences of letters and such that the non $ Definitions and proofs of theorems can be found in the appendix .</sentence>
				<definiendum id="0">p ) S</definiendum>
				<definiens id="0">a grammar whose rules are constructed of strings ( on either side of the rewriting rule 's arrows ) such that no string contains more than m occurrences of letters</definiens>
			</definition>
			<definition id="1">
				<sentence>A rewriting rule is a rule of the form PhQ-*PHQ where P , Q , h , and H are ( possibly empty* ) strings .</sentence>
				<definiendum id="0">rewriting rule</definiendum>
				<definiens id="0">a rule of the form PhQ-*PHQ where P , Q , h</definiens>
			</definition>
			<definition id="2">
				<sentence>A derivation of a string S n in a grammar G is a sequence of strings S 1 , ... , S n such that S 1 is S and such that S i +1 is the result of replacing some sequence of letters L in S i by a sequence of letters L ' such that L -- L ' is one of the grammar rules of G. The language generated by a grammar G is the set of all strings M such that there exists a derivation of M in G , and such that M consists of only letters in the terminal vocabulary of G. Two sets of grammars that generate the same sets of languages are said to have t_he same generative power .</sentence>
				<definiendum id="0">derivation of a string S n</definiendum>
				<definiens id="0">a sequence of strings S 1 , ... , S n such that S 1 is S and such that S i +1 is the result of replacing some sequence of letters L in S i by a sequence of letters L ' such that L -- L ' is one of the grammar rules of G. The language generated by a grammar G is the set of all strings M such that there exists a derivation of M in G , and such that M consists of only letters in the terminal vocabulary of G. Two sets of grammars that generate the same sets of languages are said to have t_he same generative power</definiens>
			</definition>
			<definition id="3">
				<sentence>Theorem h ( a ) The set of grammars , none of whose rules contain more than four letters , has the same generative power as the set of context-sensitive grammars .</sentence>
				<definiendum id="0">Theorem h</definiendum>
				<definiens id="0">a ) The set of grammars , none of whose rules contain more than four letters , has the same generative power as the set of context-sensitive grammars</definiens>
			</definition>
			<definition id="4">
				<sentence>Kugel 11 Theorem 4 : The sets of languages generated by grammar systems of size ( mxp ) , where mxp = y , define a hierarchy of languages L such that ( a ) L 0 is the Y set of context-free languages , ( b ) L. ~ L. for j sufficiently greater than i , and 1 j ( c ) such that the sum of the L is the set of context-sensitive languages .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">The sets of languages generated by grammar systems of size ( mxp )</definiens>
			</definition>
			<definition id="5">
				<sentence>Y Proof : The set of languages whose strings are of the form PhP , where h is a fixed string and P are arbitrary strings on a given alphabet A , are contextsensitive and not context-free ( 6 ) .</sentence>
				<definiendum id="0">h</definiendum>
				<definiens id="0">The set of languages whose strings are of the form PhP</definiens>
				<definiens id="1">a fixed string and P are arbitrary strings on a given alphabet A , are contextsensitive and not context-free ( 6 )</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>So the following composition rule is proved ane used : If ~Lvp ' ~Vp are two normal algorithms with the properties ( i ) an~ ( ii ) then for every O g ~ /the set of initial strings/ we have Abraham 5 where ~ is a normal algorithm with the scheme • , ,here { , ~ek/p i \ [ , ~ are symbols put in one-to-one correspondence to the symbols from V V /an~ different from them and between them/ ; ~ is the list of the rules of the al @ orithm ~ with every ~ changed to ~ .</sentence>
				<definiendum id="0">~</definiendum>
				<definiens id="0">a normal algorithm with the scheme •</definiens>
			</definition>
			<definition id="1">
				<sentence>A matrix grammar is a quintuple G : ( v , , F , where is a context-free frammar an @ ~ F* is a finite ' set of matrices /called matrix rules/ @ eflne @ ~ as follows : ( 1 ) f* .</sentence>
				<definiendum id="0">matrix grammar</definiendum>
				<definiendum id="1">F*</definiendum>
				<definiens id="0">a quintuple G : ( v , , F , where is a context-free frammar an @ ~</definiens>
			</definition>
</paper>

		<paper id="1026">
</paper>

		<paper id="1025">
</paper>

	</volume>
