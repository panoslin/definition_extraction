<?xml version="1.0" encoding="UTF-8"?>
	<volume id="W99">

		<paper id="0206">
			<definition id="0">
				<sentence>We used IPAL dictionary ( IPAL 87 ) as a verb case frame dictionary .</sentence>
				<definiendum id="0">IPAL dictionary</definiendum>
				<definiens id="0">a verb case frame dictionary</definiens>
			</definition>
</paper>

		<paper id="0409">
			<definition id="0">
				<sentence>One of the typical problems of Natural Language Processing ( NLP ) is the explosive property of the parser and this is aggravated in an Intelligent Language Tutoring System ( ILTS ) because the grammar is unconstrained and admits even more analyses .</sentence>
				<definiendum id="0">Intelligent Language Tutoring System</definiendum>
				<definiens id="0">the explosive property of the parser</definiens>
			</definition>
			<definition id="1">
				<sentence>The Student Model keeps a record of students ' performance history which provides information essential to the analysis of multiple parses , multiple errors , and the level of interaction with the student .</sentence>
				<definiendum id="0">Student Model</definiendum>
				<definiens id="0">keeps a record of students ' performance history which provides information essential to the analysis of multiple parses , multiple errors</definiens>
			</definition>
			<definition id="2">
				<sentence>A parse of a sentence is a collection of phrase descriptors .</sentence>
				<definiendum id="0">parse of a sentence</definiendum>
			</definition>
			<definition id="3">
				<sentence>For each grammar constraint , the Student Model keeps a counter which , at any given instance in the evaluation process , falls in the range of one of the three learner levels , given in ( 6a ) ( c ) .</sentence>
				<definiendum id="0">Student Model</definiendum>
				<definiens id="0">keeps a counter which , at any given instance in the evaluation process</definiens>
			</definition>
			<definition id="4">
				<sentence>Assuming that the choice between the two parses were arbitrary , sentence structure ( 7a ) where er is the object of the sentence contains an error and would yield the feedback This is not the correct case for the direct object .</sentence>
				<definiendum id="0">er</definiendum>
				<definiens id="0">the object of the sentence contains an error</definiens>
			</definition>
			<definition id="5">
				<sentence>The task for an Intelligent Language Tutor is to develop an error filtering mechanism that incorporates language teaching pedagogy .</sentence>
				<definiendum id="0">Intelligent Language Tutor</definiendum>
				<definiens id="0">to develop an error filtering mechanism that incorporates language teaching pedagogy</definiens>
			</definition>
			<definition id="6">
				<sentence>Von is a dative preposition and Urlaub is a masculine noun .</sentence>
				<definiendum id="0">Von</definiendum>
				<definiendum id="1">Urlaub</definiendum>
				<definiens id="0">a dative preposition and</definiens>
			</definition>
			<definition id="7">
				<sentence>In the German Tutor , the Analysis Module generates instructional feedback of different levels of specificity .</sentence>
				<definiendum id="0">German Tutor</definiendum>
				<definiens id="0">the Analysis Module generates instructional feedback of different levels of specificity</definiens>
			</definition>
			<definition id="8">
				<sentence>The Student Model keeps a record of students ' previous performance history which provides information essential to the analysis of multiple parses , multiple errors , and the level of interaction with the student .</sentence>
				<definiendum id="0">Student Model</definiendum>
				<definiens id="0">keeps a record of students ' previous performance history which provides information essential to the analysis of multiple parses , multiple errors</definiens>
			</definition>
</paper>

		<paper id="0210">
			<definition id="0">
				<sentence>In this work , we present an Interlingual ( formal language without ' ambiguity ) mechanism proposal based on the second technique .</sentence>
				<definiendum id="0">Interlingual</definiendum>
				<definiens id="0">formal language without ' ambiguity</definiens>
			</definition>
			<definition id="1">
				<sentence>The input of each process is a grammar defined by means of the grammatical formalism SUG ( Slot Unification Grammar ) Ferrfindez et al. ( 1997 ) , Ferrhndez ( 1998a ) .</sentence>
				<definiendum id="0">SUG</definiendum>
				<definiens id="0">Slot Unification Grammar ) Ferrfindez et al. ( 1997 )</definiens>
			</definition>
			<definition id="2">
				<sentence>I + List of antecedents : np ( conc ( singular ) , X , `` the stadium '' ) , np ( conc ( plural ) , Y , `` people '' ) Anaphor : pron ( conc ( plural ) , Z , `` they '' ) + Final Slot Structure of the Anaphor : pron ( conc ( plural ) , np ( conc ( plural ) , Y , `` ~ '' ) + Transintion of the SS of the Anaphor into Spanish pron ( conc ( singular ) , np ( conc ( feminine , singular ) , X , `` 'genre '' ) , `` ~sta '' ) El estadio estaba lleno de gentei .</sentence>
				<definiendum id="0">np ( conc</definiendum>
				<definiens id="0">plural ) , Z , `` they '' ) + Final Slot Structure of the Anaphor</definiens>
			</definition>
			<definition id="3">
				<sentence>pronoun is an animal or a thing we will translate it into it .</sentence>
				<definiendum id="0">pronoun</definiendum>
				<definiens id="0">an animal or a thing we will translate it into it</definiens>
			</definition>
			<definition id="4">
				<sentence>~ ( literally : To Peter him saw yesterday ) I saw Peter yesterday • f~ of the initial sentence in Spanish : sentencePP ( pp ( prep ( A ) , np ( eedro ) ) , pron ( Io ) , verb ( vO , freeWord ( ayer ) ) SS of the verb : verb ( cone ( sing , firstPerson , pas0 , Z , `` m ~ ' ) ÷ Final Slot Structure of the lniti~ sentence in Spanish : sentencePP ( pron ( yo ) , verb ( w ' ) , pp ( prep ( A ) , np ( Pedro ) ) , freeWnrd ( ayer ) ) Translation of the sentence into English : sentencePP ( pron ( / ) , verb ( saw ) , np ( Peter ) , freeWord ( yesterday ) ) Figure 8 .</sentence>
				<definiendum id="0">freeWnrd</definiendum>
				<definiens id="0">m ~ ' ) ÷ Final Slot Structure of the lniti~ sentence in Spanish</definiens>
				<definiens id="1">( ayer ) ) Translation of the sentence into English : sentencePP ( pron ( / ) , verb ( saw ) , np ( Peter</definiens>
			</definition>
</paper>

		<paper id="0312">
			<definition id="0">
				<sentence>The discourse tagging system presented here is based on and harmonious linked to an annotation system , which consists of a set of signs and symbols as follows : Discourse tagging and document annotation signs : to indicate the communicative function of a sequence of discourse , which is ultimately to become a piece of a document .</sentence>
				<definiendum id="0">annotation system</definiendum>
				<definiendum id="1">discourse</definiendum>
				<definiens id="0">consists of a set of signs and symbols as follows : Discourse tagging and document annotation signs : to indicate the communicative function of a sequence of</definiens>
			</definition>
			<definition id="1">
				<sentence>Document annotation symbols , therefore , represent different modes of information conversion ( from a discourse ) which may be packaged with the originating context , and activated at a later time .</sentence>
				<definiendum id="0">Document annotation symbols</definiendum>
				<definiens id="0">represent different modes of information conversion</definiens>
			</definition>
			<definition id="2">
				<sentence>Information is added by as a significant expansion and linked with other relevant discourse sequences or documents .</sentence>
				<definiendum id="0">Information</definiendum>
				<definiens id="0">a significant expansion and linked with other relevant discourse sequences or documents</definiens>
			</definition>
			<definition id="3">
				<sentence>It means that any discourse and document is the result of an information packaging process , and that the specific discourse and document under consideration is organised in the most unconstrained way , as the result of many information conversion operations .</sentence>
				<definiendum id="0">document</definiendum>
				<definiens id="0">the result of an information packaging process , and that the specific discourse and document under consideration is organised in the most unconstrained way</definiens>
			</definition>
</paper>

		<paper id="0506">
			<definition id="0">
				<sentence>king the correctness of entries , for transcriptions , etc These tools are patametrlzed by resources ( e g , HTML templates , grammars for transcriptions ) that are loaded at runtlme A dlctlonary can be accessed mteractwely through an HTML browser ( also parametnzed by a set of HTML templates ) Natural Language Processing tools such as parser do not access the database Instead , a dlcuonary ~s compded tn a compact binary format that allows fast lunt~me access to entries The dlcuonary compder can build several indexes to look-up entrtes m the compiled dictionary Runttme indexes are compressed tries that provide random access to a compact binary dtcttonary file The hngulst works with a source dictionary where each dlcttonary entry is structured as a set of sub-entries An entry can for example group together senses for the same lemma , different categories together for the same form , dfffelent lemmas m the same denvatlonal famdy , etc An entry has a unique key ( a Umcode string ) and a tree of sub-entries At each node o1 '' the tree , we attach a feature structure which encodes lexlcal lnlormatlon The feature structure must follow 39 On Some Aspects of Lextcal Standardization the type definmons specified in the dlctmnary schema The tree ot sub-entries defines an inheritance hleraichy Logically , only the leaves are actual entries the compiler traverses the tree of sub-entries , computing inheritance , and generating the compded dlctmnary from the set of leaves I `` key'__ .</sentence>
				<definiendum id="0">HTML</definiendum>
				<definiens id="0">templates , grammars for transcriptions</definiens>
				<definiens id="1">a unique key ( a Umcode string</definiens>
			</definition>
			<definition id="1">
				<sentence>ape the checking done by the parser as well as the type-checking mechanism plovided by the Typed Feature Structure engine For example , all headwords must be written using the alphabet of the language and other characters would not be allowed This kind of checks must be added specifically for each dxctlonary through the Implementation ot a checker class that is used by the database before adding entries in a dictionary An optmnal defaulter can also be provided for a given dictionary the defaulter analyzes a dictmnary entry and apphes default rules to fill m m , ssmg reformation For example , ff a feature number with value Plural IS hlled for a noun , the noun is an irregular plural , otherwise , it is a regular noun and the number feature is not further specified , or , it the dictionary specifies a gender only for femm , ne nouns , the defaulter might add a masculine gender when tt is not specified Entries m the database m , ght have such missing mformatmn However , our Typed Feature Structure engine does not provide defaults and a runume dlctmnary must include explicitly all the defaults the defaulter is used by the compiler to fill in default mformauon and produce a compiled dlctmnary where all reformation is expl , cttly expanded The compilation process is done as follows on each entry ( 1 ) Apply dictionary-specific checks using the checker class ( if defined ) ( 2 ) Apply the defaulter to augment the dictionary entry and solve all the defaults Note that the checker and the defaulter work on the tree of sub-entries , not on mdwidual feature structures ( 3 ) Move all reformation down to the leaves of the tree of sub-entries ( compute inheritance ) ( 4 ) Expand macro defimtions ( 5 ) Comp , le a feature structure for each leaf of the sense tree ( 7 ) Use type inference to , nfer the most specific type for each sub-~eature structure within a feature structure ( 8 ) Type check the feature structures m a feature structure , expand the types of all sub-teatuie structures by unifying m the defimtion of the type 40 m On Some Aspects of Lexwal Standas dtzauon Relauonships between lexlcal entries are modeled using binary hnks ( relauons ) , used to describe synonymy relations , denvatmns relauons , translanon relauons ( see Sectmn 1 4 ) , thesaurus relatmns , etc Any relatmn defined in the d~ctlonary schema must inherit from the Relation type Relations can be given an arbitrarily complex internal structure and can bear reformation A relatmon Is formally defined as Relatlon = \ [ dom Entry , range Entry\ ] , For example , , n a relaUon that specifies a cross-reference defined freely by the lexicographer , the domain feature will point to the entry which is the source of the relatmn and the target entry ( range feature ) will be ldenufied by prowdmg the key of that entry as m # 0= \ [ key ~ ' arm '' , ... . xre f \ [ dom # O , range \ [ key `` armament '' \ ] , note `` Collectlve for arm `` \ ] \ ] A d~ctlonmy browser could Interpret these relations by generating hypelhnks between entries for example A dlct , onary also contains rules whlch specify producuve relations within an entry ( see Sect , on 1 3 ) or among entries within multiple dlctmnanes or still within a single dlcUonary ( see Section 1 4 ) The type Relation is used in the definition ot translation relat , ons , transfer rules and lex~cal rules each of these rules are defined as sub-types of Relate .</sentence>
				<definiendum id="0">noun</definiendum>
				<definiendum id="1">n a relaUon</definiendum>
				<definiens id="0">the type-checking mechanism plovided by the Typed Feature Structure engine For example , all headwords must be written using the alphabet of the language and other characters would not be allowed This kind of checks must be added specifically for each dxctlonary through the Implementation ot a checker class that is used by the database before adding entries in a dictionary An optmnal defaulter can also be provided for a given dictionary the defaulter analyzes a dictmnary entry and apphes default rules to fill m m , ssmg reformation For example , ff a feature number with value Plural IS hlled for a noun</definiens>
				<definiens id="1">a regular noun and the number feature is not further specified , or , it the dictionary specifies a gender only for femm , ne nouns , the defaulter might add a masculine gender when tt is not specified Entries m the database m , ght have such missing mformatmn However , our Typed Feature Structure engine does not provide defaults and a runume dlctmnary must include explicitly all the defaults the defaulter is used by the compiler to fill in default mformauon and produce a compiled dlctmnary where all reformation is expl , cttly expanded The compilation process is done as follows on each entry ( 1 ) Apply dictionary-specific checks using the checker class ( if defined ) ( 2 ) Apply the defaulter to augment the dictionary entry and solve all the defaults Note that the checker and the defaulter work on the tree of sub-entries</definiens>
				<definiens id="2">Type check the feature structures m a feature structure , expand the types of all sub-teatuie structures by unifying m the defimtion of the type 40 m On Some Aspects of Lexwal Standas dtzauon Relauonships between lexlcal entries are modeled using binary hnks ( relauons ) , used to describe synonymy relations</definiens>
				<definiens id="3">thesaurus relatmns , etc Any relatmn defined in the d~ctlonary schema must inherit from the Relation type Relations can be given an arbitrarily complex internal structure and can bear reformation A relatmon Is formally defined as Relatlon = \ [ dom Entry</definiens>
				<definiens id="4">A d~ctlonmy browser could Interpret these relations by generating hypelhnks between entries for example A dlct , onary also contains rules whlch specify producuve relations within an entry ( see Sect , on 1 3 ) or among entries within multiple dlctmnanes or still within a single dlcUonary ( see Section 1 4 ) The type Relation is used in the definition ot translation relat , ons , transfer rules and lex~cal rules each of these rules are defined as sub-types of Relate</definiens>
			</definition>
			<definition id="2">
				<sentence>~ F , gure 4 A Habanera Browser for a Persmn-Enghsh dleUonary Since most Web browsers do not support mput methods for languages other than Enghsh , mput of character strings ~s done using a transcr , ptlon A set of transcription tables can be defined by the user and selected m the browser when inputting some character strmg for e g headwords However , Web browsers support the display of almost any major language I and Umcode strings can be dtrectly embedded m HTML documents Habanera also provide import/export functions The format o1 '' a dlcttonary file uses a textual syntax for feature structure ( the one used in the examples ) The dictionary file encoding is UTF-8 The d , ctlonartes developed at CRL shared the same generic structure Each language specific dictionary refines the shared schema by add , ng language specific , nformation ( e g , a specific inventory of morphosyntactlc features ) The data ot a monohngual dtctlonary is a set of entr , es corresponding to word senses as descrtbed m ( Meyer et al. 1990 ) and ( Onyshkevych and N1renburg , 1994 ) We distinguish between computational features that are used by NLP components such as parsers ( form , gram , sem , synSem , trans , rel , lexRule , usg ) .</sentence>
				<definiendum id="0">Habanera Browser</definiendum>
			</definition>
			<definition id="3">
				<sentence>closs-reference ( xref ) and note ( note ) The features present for each sub-entry are EntryElements = \ [ form Form , gram Grammar , s em TMR , synSem SynSemMap , trans Translat zons , rel LexzcalRelat zons , lexRule LexzcalRules , usg Usage , def Strzng , eg Example , etym Strzng , xref Xref , note Strzng\ ] , The computational features used by NLP components are the following 1 form mformatton related to the orthographic form of the word and its morphology ( includes morphologtc .</sentence>
				<definiendum id="0">lexRule LexzcalRules</definiendum>
				<definiens id="0">EntryElements = \ [ form Form , gram Grammar , s em TMR</definiens>
			</definition>
			<definition id="4">
				<sentence>a\ ] features and morphological variants ) , 2 gram mformaUon related to the syntactic behawor of the word ( includes POS and subcategonzatlon ln/ormauon ) , 42 On Some Aspects of Le rical Standardlzanon 3 trans a cross-reference to one or more enmes In a target dicnonary , 4 sere semantic mapping to a conceptual structure , 5 synsem mforrnatlon on syntax-semantic linking , 6 rel reformation on paradigmatic ( synonyms , antonyms , ) and syntagmatlc ( collocations , co-occurrences , ) relations , 7 lexRule specification of productive lexlcal relations among entries within a dictionary ( e g , productive morphological derivations ) , 8 usg restrictions on the usage of some word ( domain , geographical , temporal , ) In the remainder of this section , we present the structure ot the form and gram features ( see Zajac et als 98 for a description of other features ) The form feature records information about the type of word whether the word is a full word , and acronym , or an abbreviation These types are introduced since typically acronyms and abbrewauons are processed differently from ordinary words , for example dunng a tokemzation phase ( see e g Grefenstette 94 ) and words or compounds are processed during or after a morphological analysm the dictionary compiler will produce different runhme dictionaries that include different hnds of information as needed by the various components of the system The orthography feature records the citation form of the word as well as a list of variants There could also be addmonal information such as capitalization , hyphenation or syllabification ( a useful information tot an English morphological analyzer for example ) The morphology records three different kinds of information morphological information that is attached to the word and stored In the lexicon ( e g , gender Information ) , inflectional information that is typically computed by a morphological analyzer ( and passed to the syntactic analyzer ) , and denvatlonal information that could be either precomputed in the lexicon or dynamically computed by a morphological analyzer In our lexical model , we require that each dictionary includes as lexical morphological reformation the part-of-speech ( using the pos feature ) and the indication if the word has a regular morphology or not ( using the Boolean regular feature ) Irregular forms are listed In the dictionary if the value of the regular feature is False This feature is plovlded to handle simple cases where a given class of words has only one inflectional paradigm English noun for example can be defined as having only one paradigm for the number inflection , where phonological variants ale handled by the morphological processor and anything that falls out of the domain of the morphological processor will be treated as an irregular form Note that the dictionary schema must allow for the inclusion of all inflected forms for irregulars If the linguist has to define inflectional paradigms , as it is the case in many languages , these paradigms must also be specified m the dictionary schema and should allow for the specification ot various stems involved For example , one might consider that English verbs have two paradigms , one where all forms are derived from the citations \ [ orm ( want , wants , wanted , wanted , wanting ) modulo phonological changes , one class where some forms must be specified m the lexicon ( take , takes , took , taken , takang ) , and a class of irregulars ( be , is , was , been , being ) Therefore , English verbs could be classified as regular or irregular , and for regular , they fall m one of two paradigms The readel will have noticed that the morphological model used in the lexicon must be compatible with the model Implemented by any morphological processor using the d~cuonary Our experience has shown that ~t ~s not always tnvml to reconcile a morphological analyzer developed independently from a dictionary with the dictionary The structure ot the form feature must therefore include the following elements \ [ type Full I Abbrevlatlon I Acronym , orth \ [ clt Strlng , // The cltatlon form varlants List\ ] , // Optlonally , syllablflcatlon , capltallzatlon , etc morph \ [ lex \ [ pos POS , regular Boolean\ ] , infl InflectlonalFeatures , // Always unspecxfled xn the dlctlonary derlv DerlvatlonalStructure \ ] \ ] For example , the form structute of an English entry might look like 43 aa i \ [ \ ] ae .</sentence>
				<definiendum id="0">English verbs</definiendum>
				<definiens id="0">2 gram mformaUon related to the syntactic behawor of the word ( includes POS and subcategonzatlon ln/ormauon</definiens>
				<definiens id="1">synonyms , antonyms , ) and syntagmatlc ( collocations , co-occurrences , ) relations , 7 lexRule specification of productive lexlcal relations among entries within a dictionary ( e g , productive morphological derivations</definiens>
				<definiens id="2">a description of other features ) The form feature records information about the type of word whether the word is a full word , and acronym , or an abbreviation These types are introduced since typically acronyms and abbrewauons are processed differently from ordinary words , for example dunng a tokemzation phase ( see e g Grefenstette 94 ) and words or compounds are processed during or after a morphological analysm the dictionary compiler will produce different runhme dictionaries that include different hnds of information as needed by the various components of the system The orthography feature records the citation form of the word as well as a list of variants There could also be addmonal information such as capitalization , hyphenation or syllabification ( a useful information tot an English morphological analyzer for example ) The morphology records three different kinds of information morphological information that is attached to the word and stored In the lexicon ( e g , gender Information ) , inflectional information that is typically computed by a morphological analyzer ( and passed to the syntactic analyzer ) , and denvatlonal information that could be either precomputed in the lexicon or dynamically computed by a morphological analyzer In our lexical model</definiens>
				<definiens id="3">lexical morphological reformation the part-of-speech ( using the pos feature ) and the indication if the word has a regular morphology or not ( using the Boolean regular feature ) Irregular forms</definiens>
				<definiens id="4">the number inflection , where phonological variants ale handled by the morphological processor and anything that falls out of the domain of the morphological processor will be treated as an irregular form Note that the dictionary schema must allow for the inclusion of all inflected forms for irregulars If the linguist has to define inflectional paradigms</definiens>
				<definiens id="5">the following elements \ [ type Full I Abbrevlatlon I Acronym , orth \ [ clt Strlng , // The cltatlon form varlants List\ ] , // Optlonally , syllablflcatlon , capltallzatlon , etc morph \ [ lex \ [ pos POS , regular Boolean\ ] , infl InflectlonalFeatures</definiens>
			</definition>
			<definition id="5">
				<sentence>i aa m m I i 1 On Some Aspects of Lextcal Standardzzatton # 0=\ [ key # k= '' brlng '' , form orth exp # k , sense # i=\ [ morph \ [ lex \ [ pos eng Type MalnVerb , regular True , paradlgm i , slmplePast `` brought '' , pastPartlclple `` brought '' \ ] \ ] \ ] \ ] wheretheteatu~s ~rlnflectlonaland denvattonmformatton a~ leftunspectfied The gram feature groups all information related to the syntactic behavior ot the word The grammai teature gram contains as required features the part-of-speech information ( feature pos ) and the subcategonzatton frame ( teature frame ) The frame feature encodes the subcategonzatlon frame of the predicate expressed as a hst of phrasal types The grammar feature may include addmonal features such as the subcategory , for example Mass/Countable for nouns , or Intransmve/Transmve for verbs , although this Is typically better represented by defimng the appropriate sub-types tot each part-of-speech Additionally , an reflectional feature J.nfl Is also defined for use by syntactic processors the value of this feature ts shared with morphology During processing , a morphological analyzer will produce a set of mflecuonal features and make them available to syntax through the feature gram J-nfl Conversely , a syntactic generator will produce a set of mflecuonal features for iexlcal heads and make them available to the morphological generator The Grammar feature ( path gram m an entry ) has type Gram This type is defined as Gram = \ [ pos POS , frame List , infl MorphInf lectlon\ ] , For example , the followmg ( partml ) entry specifies two subcategonzatlon frames for the noun `` announcement '' \ [ key `` announc ement '' , gram \ [ pos N , sense gram frame &lt; NpComp\ [ head `` that '' \ ] &gt; , sense gram frame &lt; NpObl \ [ head `` of '' \ ] &gt; \ ] \ ] Standardizing lexicons represent an interesting intellectual and practical endeavor Past experience at CRL m developing , processing and using many large lexicons for several tasks , including machme-translauon systems , machine-aided translation tools , and mformatmn processmg systems shows that a first set of dlfhculttes hes m the lack of a standard format that Is flexible enough to cover many dlffeient languages and applications , but sutficlently l lgid to enable the use of a single lexlcal toolset shared across all these languages and apphcatlons This problems have been addressed by developing a generic dictionary software architecture that is now use to manage several large d , cuonartes designed for machine-aided translation as well as for machine translauon The second set of problems is almost as acute as the first It is very difficult to start des , gnmg a sound lexlcal architecture from scratch , hst the all the features that must be present for a variety of NLP apphcauons , predict the interaction between the various sub-structures , and predict the needs of the various NLP tools that would be access , ng the dlcuonary This has been done many times at CRL and thin knowledge is m part incorporated in the generic standard lexical structure briefly presented , n Secuon 3 When developing a new dictionary , the linguist must use a pie-defined dtcuonary entry structure and follow a set of gmdelmes for defining the language-specific features This guarantees that the dlctlonary can be developed and maintained us , rig a standard dictionary management toolset , and that the reformat , on contained in the dictionary can actually be used for a variety of NLP at~phcauons which requllements are not always obv , ous for a non-expert The construction o !</sentence>
				<definiendum id="0">frame feature</definiendum>
				<definiendum id="1">phrasal</definiendum>
				<definiens id="0"># k= '' brlng '' , form orth exp # k , sense # i=\ [ morph \ [ lex \ [ pos eng Type MalnVerb , regular True , paradlgm i , slmplePast `` brought '' , pastPartlclple `` brought '' \ ] \ ] \ ] \ ] wheretheteatu~s ~rlnflectlonaland denvattonmformatton a~ leftunspectfied The gram feature groups all information related to the syntactic behavior ot the word The grammai teature gram contains as required features the part-of-speech information ( feature pos ) and the subcategonzatton frame</definiens>
				<definiens id="1">encodes the subcategonzatlon frame of the predicate expressed as a hst of</definiens>
				<definiens id="2">use by syntactic processors the value of this feature ts shared with morphology During processing , a morphological analyzer will produce a set of mflecuonal features and make them available to syntax through the feature gram J-nfl Conversely , a syntactic generator will produce a set of mflecuonal features for iexlcal heads and make them available to the morphological generator The Grammar feature ( path gram m an entry</definiens>
				<definiens id="3">Gram = \ [ pos POS , frame List , infl MorphInf lectlon\ ] , For example , the followmg ( partml ) entry specifies two subcategonzatlon frames for the noun `` announcement '' \ [ key `` announc ement '' , gram \ [ pos N , sense gram frame &lt; NpComp\ [ head `` that '' \ ] &gt; , sense gram frame &lt; NpObl \ [ head `` of '' \ ] &gt; \ ] \ ] Standardizing lexicons represent an interesting intellectual and practical endeavor Past experience at CRL m developing , processing and using many large lexicons for several tasks , including machme-translauon systems , machine-aided translation tools , and mformatmn processmg systems shows that a first set of dlfhculttes hes m the lack of a standard format that Is flexible enough to cover many dlffeient languages and applications , but sutficlently l lgid to enable the use of a single lexlcal toolset shared across all these languages and apphcatlons This problems have been addressed by developing a generic dictionary software architecture that is now use to manage several large d , cuonartes designed for machine-aided translation as well as for machine translauon The second set of problems is almost as acute as the first It is very difficult to start des , gnmg a sound lexlcal architecture from scratch , hst the all the features that must be present for a variety of NLP apphcauons , predict the interaction between the various sub-structures , and predict the needs of the various NLP tools that would be access , ng the dlcuonary This has been done many times at CRL and thin knowledge is m part incorporated in the generic standard lexical structure briefly presented , n Secuon 3 When developing a new dictionary , the linguist must use a pie-defined dtcuonary entry structure and follow a set of gmdelmes for defining the language-specific features This guarantees that the dlctlonary can be developed and maintained us , rig a standard dictionary management toolset , and that the reformat , on contained in the dictionary can actually be used for a variety of NLP at~phcauons which requllements are not always obv</definiens>
			</definition>
</paper>

		<paper id="0408">
</paper>

		<paper id="0300">
</paper>

		<paper id="0309">
			<definition id="0">
				<sentence>Fortunately for our purposes , coreference information can be expressed using the relations used to express anaphoric information , which makes it possible to develop schemes in which both types of information can be encoded , as we will see below .</sentence>
				<definiendum id="0">coreference information</definiendum>
				<definiens id="0">makes it possible to develop schemes in which both types of information can be encoded</definiens>
			</definition>
			<definition id="1">
				<sentence>DRAMA recommends to annotate all noun phrases , whether or not they introduce discourse'entities .</sentence>
				<definiendum id="0">DRAMA</definiendum>
				<definiens id="0">recommends to annotate all noun phrases , whether or not they introduce discourse'entities</definiens>
			</definition>
			<definition id="2">
				<sentence>The first proposed extension to the Core Scheme consists of a new set of elements introduced in order to annotate references to the visual situation .</sentence>
				<definiendum id="0">Core Scheme</definiendum>
				<definiens id="0">consists of a new set of elements introduced in order to annotate references to the visual situation</definiens>
			</definition>
</paper>

		<paper id="0510">
			<definition id="0">
				<sentence>and eachjudgement takes a minute So automatic methods are needed to find matches automatically or at least to narrow down the candidates for matching In this paper , we investigate a simple statistical method for matching two ontologms The method can appl~ to any ontologms which are formulated from ls-a relationships In our experiments , we used EDR and \VotdNet Tins ~ork is sumlar to the work in ( UtL~ama and Hashlda 1997 ) They defined the task as the MWM ( Maximum V~elgnt klatch ) of bipartite graphs , an approach which is bas~cally common to most ontology matching schemes The information they used is partially fuzzy , i e for calculating the distance between two nodes , they used the information from each node and its neighborhood , not distinguishing between mformatmn from parent and child nodes However , since the structure of the ontologms ( the relation between parent and children ) is slgmficant , it might be better to utilize such structural reformation In our experiments , we will focus on this issue , rather than trying to achieve a higher performance The importance of parent , child and grandchild information will be examined We will conduct several experiments with or without some of the mformatlon It is also important to dlsco~er what welghtmg balance gives good matches First we will briefly explain the ontologms we used m our experiments The EDR Concept Dmtlonary contains 400,000 concepts hsted m the Japanese and Enghsh Word Dmtlonanes of 200,000 words each The EDR Concept Dictionary is one of the five types of EDR dictionaries , the others are the Word Dmtlonarms for English and Japanese the Blhngual Dictionary , the Coocurrence Dictionary , and the Techmcal Telmmology Dxctlonar } The EDR Concept Dictionary consists of three sub-dmuonanes the Headconcept Dlctxonaz } contains concept explanations m natural language ( both m Engh~h and Japanese ) , ~the Concept Classification Dmuonar } contains a set of ls-a relationships , and the Concept Description Dictionary contains pairs of concepts that have certain semantic relationships other than ls-a relationship 1 e object , agent 9oal , zmplement a-object ( object of a particular attribute ) , place , scene and cause The Concept Classification Dmtlonar~ classifies all the 400 000 concepts based on their meaning A polysemous ~ord is put into several word ciassffieatmns ( concepts ) As multiple inheritance l~ allowed , the entire structure is not a tree but a DAG ( directed acychc graph ) There are 6,000 intermediate nodes and the maximum depth is 16 2 2 WordNet WordNet ( Wordnet ) is an English ontology The nodes are represented by a set of synonym words ( called ' s ?</sentence>
				<definiendum id="0">eachjudgement</definiendum>
				<definiens id="0">takes a minute So automatic methods are needed to find matches automatically or at least to narrow down the</definiens>
			</definition>
			<definition id="1">
				<sentence>&lt; elephant &gt; Thls is one of the typlcal problems of ontolog } deslgn , how detail concepts should be mtrocuced Also , there is a translatlon problem m EDR , , e sometimes there , s words or a descnptmn m only one language There are some other `` reasons why the number of parent-matches , s so small • Some nodes m EDR have no words assoclated wlth them Thls is how the EDR Class , ficatlon Dmtlonary was deslgned It ~s based on the classfficat , on of words into some predefined boxes , and not creating hmrarchy of words It would be better to use the concept descnptlons of the dlctlonary , although it is not clear how to compare a s ) nset ( set of words ) and a descnptlon Also , we mlght be able to use mformatlon written m Japanese when there , s no Enghsh word but there are Japanese words • WordNet uses a synset to represent a node , whereas EDR 's node Is pnmarlly represented by a descriptlon , there could be differences caused by thls The average numbers of words m a node are also different There were no chlldren-matches , whmh are complete matches where the words m the child nodes are also the same The closest matches m Experiment-2 and 3 are the following EDR parent ( * ) year children school year WordNet parent ( * ) year children anomallstlc year , lunar year , school year , academlc year , solar year , troplcal year , astronomlcal year , equinoctial year ( There are actually 4 child nodes ) 3 2 2 Evaluatmn As ~t ~s lmposs~ble to evaluate all the results , ~e selected four ranges ( rank 1 to 20 , 501 to 520 , 2001 to 2020 , and 9001 to 9020 ) and the data m these ranges was evaluated manually E~aluatmn ~as done by putting the matches into three categories • A Two nodes are completel : y the same concept • B Other than A and C • C Two nodes me completely d~fferent concepts Category B includes several different things , including partml matches and ambiguous cases b3 the manual evaluatmn However , the number of results m th~s category was not so large , so ~t should not affeSt the overall evaluatmn Table 3 shows the evaluatmn result The columns represent the four ranges and the each row represents one of the e , ght experiments An element has 71 Experiment 1-20 501-520 2001-2020 9001-90201 ( 00 , 10,00,00 ) 2 ( 00 , 07,03 , 00 ) 3 ( 00 , 05,05 , 00 ) 4 ( 00,03,07 , 00 ) 5 ( 03 , o 7 , o o , oo ) 6 ( 02,05,03,00 ) 7 ( 02,06,02,00 ) 8 ( 02 , 05,02,01 ) 311116 8/1111 611/13 6/1113 611113 6/1113 211117 101317 10/1/9 7/1/12 11/1/8 6/1/13 11/1/8 6/1/13 11/1/8 6/1/13 4/2/14 3/3/14 3/3/14 4/4/12 2/3/15 2/3/15 2/3/15 2/3/15 5/4/11 1/2/17 i'/2/17 5/5/10 6/5/9 5/9/6 1/7/12 5/6/9 Table 3 Evaluauon Result .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">no words assoclated wlth them Thls is how the EDR Class , ficatlon Dmtlonary was deslgned It ~s based on the classfficat</definiens>
				<definiens id="1">y the same concept • B Other than A and C • C Two nodes me completely d~fferent concepts Category B includes several different things</definiens>
			</definition>
			<definition id="2">
				<sentence>Eneko Aglrre and German Rlgau , `` A Proposal for Word sense Dmamb , guatmn using Conceptional distance '' Proc of the 1st Internatzonal Conference on Recent Advances m natural Language Processing 1995 EDRElectromc D1ctmnary Version 1 5 Techmcal Guide EDR TR2-O07 , 1996 Eduard Hovy `` Creating a Large Ontology '' , ANSI Ad Hoc Group on Ontology , Stanford Umversity , 1996 George Miller `` WordNet A lex , cal database for English '' Communzcatzons of the ACM , 38 { 1i ) pp39-~1 , 1995 Hldeo Mlyoshl , Ken j , Sugiyama , Masah~ro Kobayash , and Takano Ogmo `` An Overview of the EDR Electronic D , ctionary and the Current Status of Its Utflmatmn '' , Proc o/COLING-g6 , 1996 Takano Ogmo , Hldeo Mlyoshl , Masahlro Kobayashl , Fumlhlto Nmhmo and Junhch , Tsuju `` An Experiment on Matching EDR Concept Classfficahon Dictionary with WordNet ' , Proc o/IJICAI-97 , 1997 Tom O'Hara , Kaw Mahesh and Serge , Nlrenburg , `` LexlcalAcqu~sltmn with WordNet and the Mlkrokosmos Ontolog ) '' Proc o/the COLING/ACL Workshop on Usage of WordNet m Natural Language Processzng Systems t998 Pangloss Project ( InformaUon Scmnces Insutute ( ISl ) / Uinvermty of Southern Cahforma ( USC ) ) homepage `` http//www , s , edu/natural-language/nlp .</sentence>
				<definiendum id="0">Takano Ogmo</definiendum>
				<definiens id="0">An Overview of the EDR Electronic D , ctionary and the Current Status of Its Utflmatmn ''</definiens>
			</definition>
</paper>

		<paper id="0102">
</paper>

		<paper id="0314">
			<definition id="0">
				<sentence>Traum 's approach to utterance segmentation is to segment utterances based on the presence of prosodic evidence such as pauses and boundary tones , and on changes of speaker .</sentence>
				<definiendum id="0">segmentation</definiendum>
				<definiens id="0">to segment utterances based on the presence of prosodic evidence such as pauses and boundary tones , and on changes of speaker</definiens>
			</definition>
			<definition id="1">
				<sentence>Traum uses a special grounding tag , CONTINUE , when a prosodically-segraented utterance is not an independent grounding act , but rather part of the same grounding act as a previous utterance by the same speaker .</sentence>
				<definiendum id="0">Traum</definiendum>
				<definiens id="0">uses a special grounding tag , CONTINUE , when a prosodically-segraented utterance is not an independent grounding act , but rather part of the same grounding act as a previous utterance by the same speaker</definiens>
			</definition>
			<definition id="2">
				<sentence>Repairs are attempts to fix an utterance through correction or clarification .</sentence>
				<definiendum id="0">Repairs</definiendum>
				<definiens id="0">attempts to fix an utterance through correction or clarification</definiens>
			</definition>
			<definition id="3">
				<sentence>Corrections reject an utterance and offer a replacement .</sentence>
				<definiendum id="0">Corrections</definiendum>
				<definiens id="0">reject an utterance and offer a replacement</definiens>
			</definition>
</paper>

		<paper id="0607">
			<definition id="0">
				<sentence>Our tagging model is a maximum entropy ( ME ) model of the following form : K P ( tlh ) = 7 I~ ~ k ( h't ) p° ( 1 ) k=0 where : t is tag we are predicting ; h is the history ( all prior words and tags ) of t ; 7 is a normalization coefficient that en~L r-TK \ ] k ( h , t ) sures : ~t=oTllk=o ak P0 = 1 ; L is the number of tags in our tag set ; ak is the weight of trigger fk ; fk are trigger functions and f~e { 0 , 1 } ; P0 is the default tagging model ( in our case , the uniform distribution , since all of the information in the model is specified using ME constraints ) .</sentence>
				<definiendum id="0">tagging model</definiendum>
				<definiendum id="1">h</definiendum>
				<definiendum id="2">L</definiendum>
				<definiendum id="3">ak</definiendum>
				<definiendum id="4">P0</definiendum>
				<definiens id="0">a maximum entropy ( ME ) model of the following form : K P ( tlh</definiens>
				<definiens id="1">the history ( all prior words and tags ) of t</definiens>
				<definiens id="2">the number of tags in our tag set ;</definiens>
				<definiens id="3">the weight of trigger fk ; fk are trigger functions and f~e { 0 , 1 } ;</definiens>
				<definiens id="4">the default tagging model ( in our case , the uniform distribution , since all of the information in the model is specified using ME constraints )</definiens>
			</definition>
			<definition id="1">
				<sentence>For each of our trigger predictors , s is defined below : Bigram and trigram triggers : s is the presence of a particular tag as the first tag in the bigram pair , or the presence of two particular tags ( in a particular order ) as the first two tags of a trigram triple .</sentence>
				<definiendum id="0">s</definiendum>
				<definiens id="0">the presence of a particular tag as the first tag in the bigram pair , or the presence of two particular tags ( in a particular order</definiens>
			</definition>
			<definition id="2">
				<sentence>A tag family is the set of all tags sharing a given semantic category .</sentence>
				<definiendum id="0">tag family</definiendum>
				<definiens id="0">the set of all tags sharing a given semantic category</definiens>
			</definition>
			<definition id="3">
				<sentence>Beyond skeleton parsing : producing a comprehensive large-scale general-English treebank with full grammatical analysis .</sentence>
				<definiendum id="0">Beyond skeleton parsing</definiendum>
				<definiens id="0">producing a comprehensive large-scale general-English treebank with full grammatical analysis</definiens>
			</definition>
</paper>

		<paper id="0609">
			<definition id="0">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>SEXTANT : Extracting semantics from raw text implementation details .</sentence>
				<definiendum id="0">SEXTANT</definiendum>
				<definiens id="0">Extracting semantics from raw text implementation details</definiens>
			</definition>
</paper>

		<paper id="0512">
			<definition id="0">
				<sentence>The Inter-Lingual-Index ( ILI ) m the EuroWordNet architecture is an mltmlly unstructured fund of concepts whmh functions as the hnk between the vanous language wordnets The ILI concepts originate from WordNetl 5 , and have been restructured on the basls of aspects of the internal structure of WordNet , hnks between WordNet and other resources , and multflmgual mapping between the wordnets This leads to a dtfferentmtlon of the status of ILI concepts , a reductmn of the Wordnet polysemy , and a greater connectivity between the wordnets The restructured ILI represents the first step towards a standardized set of word meanings , ts a worhng platform for further development and testing , and can be put to use m NLP tasks such as ( multdmgual ) mformatmn remeval EuroWordNet ( LE2-4003 , LE4-8328 ) develops a multflmgual database with wordnets for 8 different European languages Enghsh , Dutch , Spamsh , Italran , German , French , Czech and Estoman Further collaboratmns have been estabhshed with wordnet builders for Portuguese , Swedish , Basque , Catalan , Russmn , Greek and Damsh , who wolk according to the EuroWo~dNet specfficatmns Each of the wordnets ~s structured as the Prmceton Wordnet ( Fellbaum , 1998 ) m terms of sets of synonymous words or so-called synsets between which basic semantic relatmns me expressed The synsets are based on the lexmahzatmns and expressions m each language Each wordnet therefore can be seen as a umque language-specffic stIucture In additmn to the lelatlons bet~een s : rnsets there Is also a relatmn to a so-called Inter-Lingual-Index This Inter-Lingual-Index ( ILI ) is an unstructmed fund of concepts , so-called ILI-records , w~th the sole purpose of hnkmg synsets across languages Synsets that are hnked to the same ILI-record can be said to be eqmvalent across two languages By means of the ILI it ts thus possible to go from one wordnet to the other and to compare the lextcahzatmn patterns across languages The characterxstlcs of the ILI are defined b~ ~ts functmn to provide an efficient mapping across the meanings m the wordnets for the different languages Two major reqmrements follow from this • the ILl should have a certain level of granularity , • the ILI should be the superset of concepts that occur across languages The first reqmrement is necessar ) to make the hnkmg of meamngs easmr If many speclahzed meanmgs and Interpretations are gwen it is more dtfficult to find mappings from a language-specffic wordnet to the index The second reqmrement is necessary to be able to express an equivalence relatmn across synsets m two wordnets for which there ts no eqmvalent m other wordnets ImtmUy , the ILI has been based on WordNetl 5 It is however a well-known problem that sensedlfferentmtmn ts ver ) inconsistent w~thm and across resources including WordNetl 5 On the bas~s of the above criteria and by companng the sensedlfferentiat~on across the ~ordnets we haze therefore begun to adapt the ILI Four major rex ls~ons of the ILI are derived from these • grouping sense-dlfferentlauons between which there xs a s~stematm pol~sem~ telatmn e g meton~ m~ , • grouping sense-d~fferentmttons that can be represented by more general sense-group • adding sense-d~fferent~atmns ol concept~ that occur m two wordnets but not m % otd.Netl 5 * dlfferentmtmg the status of the ILl-lecold , m terms of umversaht .</sentence>
				<definiendum id="0">ILI</definiendum>
				<definiendum id="1">ILI</definiendum>
				<definiens id="0">such as ( multdmgual ) mformatmn remeval EuroWordNet ( LE2-4003 , LE4-8328 ) develops a multflmgual database with wordnets for 8 different European languages Enghsh , Dutch , Spamsh , Italran , German , French , Czech and Estoman Further collaboratmns have been estabhshed with wordnet builders for Portuguese , Swedish , Basque , Catalan , Russmn , Greek and Damsh , who wolk according to the EuroWo~dNet specfficatmns Each of the wordnets ~s structured as the Prmceton Wordnet ( Fellbaum , 1998 ) m terms of sets of synonymous words or so-called synsets between which basic semantic relatmns me expressed The synsets are based on the lexmahzatmns and expressions m each language Each wordnet</definiens>
				<definiens id="1">an unstructmed fund of concepts</definiens>
			</definition>
			<definition id="1">
				<sentence>makes WSD fundamentall : r d~fferent flora morphological dtsamb~guatmn or tagging techmques ( Wllks , 1998 ) If rumple tagging techniques can be apphed to lmge corpora ( umformlv across languages ) thin mformatmn ~ould be used to demve stat~sttcal mformatmn on the usage of an mmal set of word meamngs ( posmbly m different languages ) Informatmn on usage could then be used to further standardize the set of word meanrags It w~ll be clea~ that the above measurements depart flom WordNetl 5 as a standardized set There are two biases that may follow from thin First of all the cross-hngual mapping of synsets or ~ozd senses may be mlploved if mconmstent sense-d~fferentmtlon is somehow dealt ~lth Secondl ) , a um~ersal h~t can not just be based on Enghsh We thus ha~e to conmder the status of s ) nsets m the other languages that could not be matched ~th WordNet 1 5 s~nsets Both aspects will &amp; scussed m the next t~o sections Sense dmtmctlons m Wordnetl 5 are often too finegrained for WSD purposes ~hich makes it chfficult to trek ~ordnets for polysemous words -klso the systematic relatedness between ~ord senses has not been made exphclt m WordNet The clusteimg of WordNet demved concepts rote larger conceptual chunks that represent meaning at a higher or more underspecffied level of semantm descnptmn enhances the lnterconnectwlty of wordnets and can be be put to use in NLP apphcations such as Informatmn retrteval We have dmtmgu~shed two types of these clusters which &amp; ffer m their semantic characteristics The3 are metonymy and 9enerahzat : on and ~lll be ( hscussed m the following subsecttons 3 1 Metonymy Meton~ m~ can be defined as a ( semi- ) product ~ e lex~cal semanuc ~elatmn between t~o concept t~pes o~ classes that belong to incompatible or otthogonal types ( t } pe shift ) This relation often has a dnectmnaht3 from a base sense to a de~ed sense OtheI terms used for this phenomenon ate regular polysemy ( Apresjan 1973 ) sense extenszon ( Copestake 1995 ) and transfers of meamng ( Numbelg 1996 ) The lelated concepts ate lexlcahzed b ?</sentence>
				<definiendum id="0">makes WSD fundamentall</definiendum>
				<definiens id="0">r d~fferent flora morphological dtsamb~guatmn or tagging techmques ( Wllks , 1998 ) If rumple tagging techniques can be apphed to lmge corpora ( umformlv across languages ) thin mformatmn ~ould be used to demve stat~sttcal mformatmn on the usage of an mmal set of word meamngs ( posmbly m different languages</definiens>
				<definiens id="1">~hich makes it chfficult to trek ~ordnets for polysemous words -klso the systematic relatedness between ~ord senses has not been made exphclt m WordNet The clusteimg of WordNet demved concepts rote larger conceptual chunks that represent meaning at a higher or more underspecffied level of semantm descnptmn enhances the lnterconnectwlty of wordnets</definiens>
			</definition>
			<definition id="2">
				<sentence>finegrained regular polvsemm relations that are s~ stematlcall } encoded as sense distractions of 105 ~otds in WotdNet -k fe~ examples Under the unique begmne~ combmatmn artifact substance ~e found the relatmn fabr : c/textzle fibre ( cotton , alpaca fleece horsehaw wool ) , Under the unique beginner combination artifact group ~e found the relatmn buzldmg orgamzatwn ( academy body chamber room estabhshment school umve~s~ty club ) It must be mentmned that some of these metonymlc patterns are co~ered in a manually cleated table of 105 node pans m WordNetl 5 ( 226 in WordNetl 6 ) that functmns as the basts for the ' Relatives ' '' search m WordNet All words with senses that are hypon : ~nuc to both nodes in a pair are g~ouped in the WordNet interface when smnlanty of meaning rs queried Hosteler thls groupmg does not provide labels such as the ones above , no~ does it guarantee that a cluster on the basis of one node pair is homogeneous As a verification of the cross-hngmstm ~ahdlt~ of the regular polysemm patterns these language specffic patterns can be projected from their somce language onto the other EuroWordNet languages and it can be mvestrgated whether they have correspondmg lemcahzation patterns If the metonymrc pattern occurs m several languages v , e have stronger evidence for the um~ersallty of the metonymic pattern If there are no rdentlcal lenlcahzauons found m an~ other target language , or , m our case target language woidnet , thele are three possibihtm~ 1 the metonymic pattern is language specffic and is not reahsed as a polysemous ~ord m the target language For example , the Dutch kantoor is synonymous to the English office m the sense ~here plofessional or clerical duties ale performed ' , but its sense distractions can not nmrot the sytematm polysemic relation m English ~lth a job m an organization or hmiaich } ' by another word or compound or derivation ~elated to the word with the potentially missing sense For example , the Dutch vetch : grog has the sense ( `` an assocratron of people w~th smnlar interests '' ) The Enghsh eqmvalent is club for whlch there rs another sense m VVbrdnet ( 'a bmldmg occupmd by a club ' ) This Is not a felicitous sense extenmon for the Dutch veremgrag , because the favoured lexicahzat~on is the compound veremgmgshuzs whose head denotes a building tern are all valid senses of the same ~old m the talget language , but one or more of them ha~e not ?</sentence>
				<definiendum id="0">Enghsh eqmvalent</definiendum>
				<definiendum id="1">VVbrdnet</definiendum>
				<definiens id="0">relations that are s~ stematlcall } encoded as sense distractions of 105 ~otds in WotdNet -k fe~ examples Under the unique begmne~ combmatmn artifact substance ~e found the relatmn fabr : c/textzle fibre ( cotton , alpaca fleece horsehaw wool ) , Under the unique beginner combination artifact group ~e found the relatmn buzldmg orgamzatwn ( academy body chamber room estabhshment school umve~s~ty club ) It must be mentmned that some of these metonymlc patterns are co~ered in a manually cleated table of 105 node pans m WordNetl 5 ( 226 in WordNetl 6 ) that functmns as the basts for the ' Relatives ' '' search m WordNet All words with senses that are hypon : ~nuc to both nodes in a pair are g~ouped in the WordNet interface when smnlanty of meaning rs queried Hosteler thls groupmg does not provide labels such as the ones above , no~ does it guarantee that a cluster on the basis of one node pair is homogeneous As a verification of the cross-hngmstm ~ahdlt~ of the regular polysemm patterns these language specffic patterns can be projected from their somce language onto the other EuroWordNet languages and it can be mvestrgated whether they have correspondmg lemcahzation patterns If the metonymrc pattern occurs m several languages v , e have stronger evidence for the um~ersallty of the metonymic pattern If there are no rdentlcal lenlcahzauons found m an~ other target language , or , m our case target language woidnet , thele are three possibihtm~ 1 the metonymic pattern is language specffic and is not reahsed as a polysemous ~ord m the target language For example</definiens>
			</definition>
			<definition id="3">
				<sentence>HYPERONY\I and EQ_CAUSES to l~ N1 5 and therefore do not have to be added as a new ILI concept The reroaming cases are too difficult to judge , and more information is needed to understand the intended concept For verbs ~e thus expect that the number of new ILIs will be relatively low First of all , there not many synsets that do not have translations ( compared to nouns ) and secondly , unmatched verbal s~nsets often can be linked somehow exhaustively meanings in NLP The ILI provides a language-neutral conceptual map for -especially multlllngualNLP apphcauons For instance , a multlhngual text collect , on can be indexed m terms of the ILI records , obtaining a uniform representatmn for documents , regardless of their particular languages Such a representation can be used to perform language-independent Text Retrieval This approach d , ffers substantlall~ from the mainstream Cross-Language Text Retl m~al strategy , namely translating the quer ) , nto the target languages , using blhngual dictionaries , bdmgual corpora or Machine Translation s } stems Some advantages of indexing ~th ILI records are • It dlstmgumhes different senses of a ~ord , m any language , • It conflates synonym terms within and across languages , • It scales up to more than two languages better than query translat , on approaches , • Terms can be related not only by ldentttt , but on the basis of mote sophmhcated relations ( Cross Part-of-Speech relatmns , hyponymy , meronymy , etc ) `` Thin allo~s for more sophisticated , and language-independent ~eightmg and retrieval In spite of its appeal , this approach Is challenging because • It demands accurate ~ord-sense dlsamb~guat~on to restrict the possible ILl records fol a given telm , • It should explmt El~ N conceptual lelatlons to associate Strongl ) related terms that differ in POS ( through XPOS lelatlons ) For instance , a standard IR system does not dlstlnguish between the verbal and nominal form of deszgn which can be an advantage m many letmeval sltuatmns But in EWN they are mapped to different synsets m different hierarchms Onl ) XPOS relations ( absent in WordNet ) permit to establish the applopmate connectmn , 87 Monohngual Expemments Text Manual WSD First sense AR No WSD Manual quemes Wnl.5 3 !</sentence>
				<definiendum id="0">HYPERONY\I</definiendum>
				<definiens id="0">bdmgual corpora or Machine Translation s } stems Some advantages of indexing ~th ILI records are • It dlstmgumhes different senses of a ~ord , m any language , • It conflates synonym terms within and across languages</definiens>
			</definition>
			<definition id="4">
				<sentence>expansmn Manual WSD Al : t No WSD Manual quemes EWN 23 9 32 1 ( +34 5 % ) 21 1 ( -11 9 % ) 20 7 ( -13 2 % ) 31 i ( +30 1 % ) ILI = 32 0 ( +33 9 % ) 20 7 ( -13 2 % ) 20 5 ( -14 2 % ) 31 1 ( +30 1 % ) Table 5 Information Retrieval experiments w~th dxfferent WSD strategms Strongl : ~ related meanings of a word that usually discriminate the same context ( through ILI clustermgs ) • It has a higher computatmnal cost ( at indexing ume ) to map documents mto the ILI We have conducted some experiments to test a ) how dlfferent WSD strategms affect premsmn/recall figures , and b ) how ILI clustermg may affect indexing and retrieval performance We have used a varmtmn on the IR-SEMCOR test collectmn described m ( Gonzalo et al , 1998 ) This test collectlon , adapted from Semcor , is small for current IR standards ( 3Mb excluding all tags , shghtly bigger than the standard TIME collectmn ) , but Is fully semantmally tagged This feature permits comparing the performance of manual versus automatic sense d~samb~guatmn / sense filtering The set of queries ~s avadable and hand-tagged m Enghsh and Spamsh , permitting monohngual and Cross-Language ( Spanmh to Enghsh ) remeval The results are shown for a number of different mdexatmns of the IR-SEMCOR collection , with and ~lthout using the actual ILI clusters There are three full d , samb , guatwn strategms m whmh evet~ noun term is represented as a smgle synset The rest are sense filtenng strategies that return the list of mo~e likely synsets for ever ) noun term Vv'ords other than nouns are left unchanged The disamblguation strategies ale Manual retmns s : ~nset assigned b~ IR-SEMCOR tags F~rst sense Returns F~rst sense m Wordnet 1 5 ( not applicable on Spanish querms ) , AR ( Agnre-Pdgau ) An implementation of the Agtrte-R~gau WSD algorithm ( Agtrre and Rlgau , 1996 ) , that has the advantages of a ) bemg unsuperwsed and b ) being applicable on any language , provided there ~s a WordNet for ~t Th~s algorithm g~ves a ~elghtmg for the candidate senses , rather than just picking one of them and discarding the rest In the expernnent ~e take all the senses with maximal ~elght Its WSD performance Is lower than the Fust Sense heunstm , especmlly d~sambtguatmg quertes , as the d~samb~guation context Is nmch smaller , No WSD A noun term ~s represented ~th all its possible s~nsets , Manual queries Combines the No WSD strategy for documents and the Manual strategy for queries This ls a plausible combination of efficmnt document indexing ( no dlsambiguatlon is reqmred ) with interactive retrieval ( userassisted dlsamblguatlon ) Table 4 shows how the ILI clustermgs reduce amb~gmty m the representatmn of the documents for each of the indexing strategms The first column m the table shows the number of clustered occurrences of noun synsets against the total number of noun synsets The second column sho~s the number of reductmns performed on ambiguous terms ( that Is on terms that are not fully disamblguated and ale thus represented as a list of s : ynsets ) One leduction means , e g that a ~ord represented as a dfi : ferent s } nsets is now represented as n 1 different s~ nsets The number of clustered s~nsets is qmte high , gl~en the small size of ILI noun clusters In palticular the ambigmty reduction ls ~er ?</sentence>
				<definiendum id="0">Manual queries</definiendum>
				<definiens id="0">w~th dxfferent WSD strategms Strongl : ~ related meanings of a word that usually discriminate the same context ( through ILI clustermgs ) • It has a higher computatmnal cost ( at indexing ume ) to map documents mto the ILI We have conducted some experiments to test a ) how dlfferent WSD strategms affect premsmn/recall figures , and b ) how ILI clustermg may affect indexing</definiens>
				<definiens id="1">Combines the No WSD strategy for documents</definiens>
			</definition>
			<definition id="5">
				<sentence>s Umversal systematic polysemy and level of granularity Unlvexsal POS Non-predictable Core meamngs Independent Language and Language specific Productive dmvatmns domain specific reahzatmns m and compounds hnked lexlcahzatmns that do grammabcal exhaustwely not occur m a large forms vmaety of languages Frgure 1 From WordNet to ILI the manually dlsamblguated collections The Cross-Language track rs especially promising , with a gain of 34 5 % over the standard techtuque ( translatmn of the query using POS taggrog and brhngual dlctronary expansion ) • Although the Agrrre-Rrgau algorithm performs much worse than the First Sense heunstzc m terms of WSD accuracy , It gzves shghtly better results for IR , as it JuSt filters the most unhkelv senses This rs experimental evidence m favor of evaluating WSD algorrthms wrthzn concrete tasks , m addmon to general-purpose evaluations such as the SENSEVAL one • The last column ' ( ' manual queries '' ) corresponds to expansion to all s : ~nsets m the documents ( no dlsambzguatron ) and manual drsamb~guatlon of the query Thrs method improves Closs-Language Retrieval by 30~c ( comparable to full manual indexing ) , and degrades onl~ 7~ from monohngual to bilingual retrmval ( standard degradatron rs 30-60c~ ) This suggests that EWN can be ~er ) useful m mteractr e ~etrze~al settmgs ( where the user rs graded through a drsambtguatmn process ) even ff the database has not been dzsambrguated at all • The results using the ILI clusters are similar or shghtly worse than without clustering A possrble reason is that the ILI clusters and the clusters needed for IR do not exactly match It would be probably beneficial to further drstmgmsh types of clustering according to their abrlrty to identzf~ , co-occurrmg senses of a word , m a slmllar vem to Bultelaar 's white and black dot operators ( Burtelaar , 1998 ) These operators dlstmguzsh related senses that tend to co-occur simultaneously ( such as book as wmtten work or phys : cal object ) and related senses that occur m different contexts ( such as gate as movable barnet or computer cwcud ) Obviously , the first ones are optimal candidates for clustering in Informatmn Retrieval apphc~tmns A more refined t } polog~ , of ILI clustermgs m general , seems requrred to use different clustermg t~ pes for dzfferent tasks We described the building of a um~ ersal hst of meanmgs m EuroV~oLdNet the so-called Intez-LmgualIndex ( ILI ) , foz ~hlch ~ , brdnetl 5 ~as taken ~a starting point The ILI should plo~rde an efficmnt mapping between concepts across languages For that purpose rt should have a certain granularity and completeness ~tth respect to the sensedzfferenttatron found m the wordnets for drfferent languages We provided emputcal evldence for a more umver89 sal and efficmnt level of sense-dlfferentmtmn based on structural properttes of the wordnets and their multflmgual mapping and ahgnment This has lead to a typology of sense-d~stmctmns , where the status of ILI-records can be dlfferentmted along the followmg hnes • Umversahty In how many languages does the concept occur ?</sentence>
				<definiendum id="0">ILI</definiendum>
				<definiens id="0">manual queries '' ) corresponds to expansion to all s : ~nsets m the documents ( no dlsambzguatron</definiens>
				<definiens id="1">comparable to full manual indexing )</definiens>
				<definiens id="2">senses of a word , m a slmllar vem to Bultelaar 's white and black dot operators</definiens>
				<definiens id="3">cal object ) and related senses that occur m different contexts ( such as gate as movable barnet or computer cwcud</definiens>
			</definition>
</paper>

		<paper id="0802">
			<definition id="0">
				<sentence>denotes any single character , and t B denotes the string defined by t minus those defined by B. A.'B is the transduction of t into B. '+ ' is a morpheme boundary , and the hash-sign is the end of word symbol .</sentence>
				<definiendum id="0">hash-sign</definiendum>
				<definiens id="0">any single character , and t B denotes the string defined by t minus those defined by B. A.'B is the transduction of t into B. '+ ' is a morpheme boundary</definiens>
				<definiens id="1">the end of word symbol</definiens>
			</definition>
			<definition id="1">
				<sentence>\ ] n. werk+Te werkte worked\ [ PAST , sa\ ] o. hoor+Te hoorde heard\ [ PAST , SG\ ] p. blaf+Te blafte barked\ [ pAsT , SG\ ] q. leev+Te leefde lived\ [ PAST , SG\ ] Figure 3 : Dutch verbal inflection structed for computing the surface form of abstract verbal stem forms and combinations of a stem and a verbal inflection suffix ( see figure 3 ) .</sentence>
				<definiendum id="0">verbal inflection suffix</definiendum>
				<definiens id="0">verbal inflection structed for computing the surface form of abstract verbal stem forms and combinations of a stem and a</definiens>
			</definition>
			<definition id="2">
				<sentence>Examples ( i-l ) illustrate several other irregularities in present tense and infinitive forms that need to be captured .</sentence>
				<definiendum id="0">Examples</definiendum>
			</definition>
			<definition id="3">
				<sentence>Examples ( n-q ) , finally , illustrate past tense formation of weak verbal stems .</sentence>
				<definiendum id="0">Examples</definiendum>
				<definiens id="0">illustrate past tense formation of weak verbal stems</definiens>
			</definition>
			<definition id="4">
				<sentence>HDRUG provides a description language for feature constraints , allows rules , lexical entries , and 'schemata ' or 'principles ' to be visualised in the form of feature matrices , and provides an environment for processing example sentences which supports the display of derivation trees and partial parse results ( chart items ) .</sentence>
				<definiendum id="0">HDRUG</definiendum>
				<definiens id="0">provides a description language for feature constraints , allows rules , lexical entries , and 'schemata ' or 'principles ' to be visualised in the form of feature matrices , and provides an environment for processing example sentences which supports the display of derivation trees and partial parse results ( chart items</definiens>
			</definition>
			<definition id="5">
				<sentence>FSA Utilities : A toolbox to manipulate finite-state automata .</sentence>
				<definiendum id="0">FSA Utilities</definiendum>
				<definiens id="0">A toolbox to manipulate finite-state automata</definiens>
			</definition>
</paper>

		<paper id="0903">
			<definition id="0">
				<sentence>Commonly used corpus-based models depend on co-occurrence patterns of words to determine similarity .</sentence>
				<definiendum id="0">corpus-based models</definiendum>
				<definiens id="0">depend on co-occurrence patterns of words to determine similarity</definiens>
			</definition>
			<definition id="1">
				<sentence>The sense disambiguation system assigns an appropriate sense to an ambiguous verb by computation of similarity between its object in a sentence and its sense indicators .</sentence>
				<definiendum id="0">sense disambiguation system</definiendum>
				<definiens id="0">assigns an appropriate sense to an ambiguous verb by computation of similarity between its object in a sentence and its sense indicators</definiens>
			</definition>
			<definition id="2">
				<sentence>That is , d ( n ) = &lt; p ( vlln ) , p ( v21n ) , ... , p ( vwiIn ) &gt; ( 1 ) freq ( vi , n ) ( 2 ) p ( vi\ [ n ) /req ( vj , n ) where I VI is the number of verbs used as transitive verb in training corpus , and freq ( v , n ) is the frequency of verb v that takes noun n as direct object .</sentence>
				<definiendum id="0">I VI</definiendum>
				<definiendum id="1">freq</definiendum>
				<definiendum id="2">n )</definiendum>
				<definiens id="0">d ( n ) = &lt; p ( vlln ) , p ( v21n ) , ... , p ( vwiIn ) &gt; ( 1 ) freq ( vi , n ) ( 2 ) p ( vi\ [ n ) /req ( vj , n ) where</definiens>
				<definiens id="1">the number of verbs used as transitive verb in training corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>A verb distribution is a vector of nouns that appears as the verb 's direct object .</sentence>
				<definiendum id="0">verb distribution</definiendum>
			</definition>
			<definition id="4">
				<sentence>We define the verb 1 i is an allomorph of ka and lul is an allomorph of ul 2The symbol `` - '' in the Korean sentence represents the morpheme boundary .</sentence>
				<definiendum id="0">lul</definiendum>
				<definiens id="0">an allomorph of ul 2The symbol `` - '' in the Korean sentence represents the morpheme boundary</definiens>
			</definition>
			<definition id="5">
				<sentence>The relative entropy is an information-theoretic measure of how two probability distributions differ .</sentence>
				<definiendum id="0">relative entropy</definiendum>
				<definiens id="0">an information-theoretic measure of how two probability distributions differ</definiens>
			</definition>
			<definition id="6">
				<sentence>Given two probability distributions p and q , their relative entropy is defined as p ( x ) D ( p H q ) = p ( x ) lo9 -- 7-T ( 6 ) q ( x ) ( 3 ) ( 4 ) ( 5 ) 20 where we define Ologq °= 0 and otherwise plogo~ = c~ .</sentence>
				<definiendum id="0">relative entropy</definiendum>
				<definiens id="0">p ( x ) D ( p H q ) = p ( x ) lo9 -- 7-T ( 6 ) q ( x ) ( 3 ) ( 4 ) ( 5 ) 20 where we define Ologq °= 0 and otherwise plogo~ = c~</definiens>
			</definition>
			<definition id="7">
				<sentence>execute OR operation with all distributions for the verbs vi where p ( vitn2 ) &gt; 0 and p ( vilnl ) = 0 in the noun distribution d ( n2 ) and make new distribution , dv2 .</sentence>
				<definiendum id="0">execute OR operation with all distributions for</definiendum>
				<definiens id="0">the verbs vi where p ( vitn2 ) &gt; 0</definiens>
			</definition>
</paper>

		<paper id="0804">
			<definition id="0">
				<sentence>The Thistle tree-editing suite ( Calder , 1998 ) is a well-developed interactive tool for working with linguistic representations such as trees and AVMs is a more sophisticated alternative .</sentence>
				<definiendum id="0">Thistle tree-editing suite</definiendum>
				<definiendum id="1">AVMs</definiendum>
				<definiens id="0">a well-developed interactive tool for working with linguistic representations such as trees and</definiens>
			</definition>
			<definition id="1">
				<sentence>The client prefixes each request by one of the keywords parse , tree , and avm .</sentence>
				<definiendum id="0">client</definiendum>
				<definiens id="0">prefixes each request by one of the keywords parse , tree , and avm</definiens>
			</definition>
</paper>

		<paper id="0708">
			<definition id="0">
				<sentence>Parameters are initially estimated from parsed corpora , annotated in terms of the non-terminal set used by the DCG .</sentence>
				<definiendum id="0">Parameters</definiendum>
				<definiens id="0">estimated from parsed corpora , annotated in terms of the non-terminal set used by the DCG</definiens>
			</definition>
			<definition id="1">
				<sentence>The likelihood probability describes how well we can encode the training set in terms of the model .</sentence>
				<definiendum id="0">likelihood probability</definiendum>
				<definiens id="0">describes how well we can encode the training set in terms of the model</definiens>
			</definition>
			<definition id="2">
				<sentence>Each value can now be encoded with a prefix code of -log ( P ( v Ifi ) bits in length .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
			<definition id="3">
				<sentence>Hence , instead of encoding an integer i in log* ( / ) bits ( as , for example , Keller and Lutz roughly do \ [ 18\ ] ) , we encode it in log* ( Z i ) bits , where Z is a mlmber larger than any frequency .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiens id="0">a mlmber larger than any frequency</definiens>
			</definition>
			<definition id="4">
				<sentence>( 6 ) rEG is the description length of the paranaeters .</sentence>
				<definiendum id="0">rEG</definiendum>
			</definition>
			<definition id="5">
				<sentence>C is a constant ensuring that the prior sums to one ; F is the set of features used to describe categories : \ ] r \ ] is the length of a DCG rule r seen f ( r ) times .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">F</definiendum>
				<definiens id="0">a constant ensuring that the prior sums to one ;</definiens>
				<definiens id="1">the set of features used to describe categories : \ ] r \ ] is the length of a DCG rule r seen f ( r ) times</definiens>
			</definition>
			<definition id="6">
				<sentence>A Memory-Based Approach to Learning Shallow Natural Language Patterns .</sentence>
				<definiendum id="0">Memory-Based Approach</definiendum>
				<definiens id="0">to Learning Shallow Natural Language Patterns</definiens>
			</definition>
			<definition id="7">
				<sentence>Learning unification-based grammars using the Spoken English Corpus .</sentence>
				<definiendum id="0">Learning unification-based</definiendum>
			</definition>
			<definition id="8">
				<sentence>Quantiative Evaluation of Explanation-Based Learning as an Optimisation Tool for a Large-Scale Natural Language System .</sentence>
				<definiendum id="0">Quantiative Evaluation of Explanation-Based Learning</definiendum>
				<definiens id="0">an Optimisation Tool for a Large-Scale Natural Language System</definiens>
			</definition>
</paper>

		<paper id="0908">
			<definition id="0">
				<sentence>Thus , the classifier parameters consist of the class prior probabilities and the class-conditioned word probabilities .</sentence>
				<definiendum id="0">classifier parameters</definiendum>
				<definiens id="0">consist of the class prior probabilities and the class-conditioned word probabilities</definiens>
			</definition>
			<definition id="1">
				<sentence>For every word wt in the vocabulary V , P ( wtlcj ) indicates the frequency that the classifier expects word wt to occur in documents in class cj .</sentence>
				<definiendum id="0">P ( wtlcj )</definiendum>
				<definiens id="0">indicates the frequency that the classifier expects word wt to occur in documents in class cj</definiens>
			</definition>
			<definition id="2">
				<sentence>Let N ( wt , di ) be the count of the number of times word we occurs in document di , and define P ( cj\ [ di ) E { 0 , 1 } , as given by the document 's class label .</sentence>
				<definiendum id="0">N ( wt</definiendum>
				<definiendum id="1">di</definiendum>
				<definiens id="0">the count of the number of times word we occurs in document di , and define P ( cj\ [ di ) E { 0 , 1 } , as given by the document 's class label</definiens>
			</definition>
			<definition id="3">
				<sentence>Then , the estimate of the probability of word wt in class cj is : 1 + ~a , ~v N ( wt , di ) P ( cjldi ) P ( wtlc~ ) = IVl + N ( w. , di ) e ( cjldi ) `` ( 1 ) The class prior probability parameters are set in the same way , where ICI indicates the number of classes : P ( cj ) = 1 + Ea , ev P ( cjldi ) ICl + IVl ( 2 ) Given an unlabeled document and a classifier , we determine the probability that the document belongs in class cj using Bayes ' rule and the naive Bayes assumption -- that the words in a document occur independently of each other given the class .</sentence>
				<definiendum id="0">ICI</definiendum>
				<definiens id="0">The class prior probability parameters are set in the same way</definiens>
			</definition>
			<definition id="4">
				<sentence>~lcj ) '' ( 3 ) k~l Empirically , when given a large number of training documents , naive Bayes does a good job of classifying text documents ( Lewis , 1998 ) .</sentence>
				<definiendum id="0">naive Bayes</definiendum>
				<definiens id="0">a good job of classifying text documents</definiens>
			</definition>
			<definition id="5">
				<sentence>In implementation , EM is an iterative two-step process .</sentence>
				<definiendum id="0">EM</definiendum>
				<definiens id="0">an iterative two-step process</definiens>
			</definition>
			<definition id="6">
				<sentence>More formally , let { pl ( wt\ [ cj ) , ... , pk ( wtlcj ) } be word probability estimates , where pl ( wt\ [ cj ) is the maximum likelihood estimate using training data just in the leaf , P2 ( wtlcj ) is the maximum likelihood estimate in the parent using the training data from the union of the parent 's children , pk-1 ( w~lcj ) is the estimate at the root using all the training data , and pk ( wtlcj ) is the uniform estimate ( Pk ( wtlcj ) = 1/IVI ) .</sentence>
				<definiendum id="0">... , pk</definiendum>
				<definiens id="0">the maximum likelihood estimate using training data just in the leaf</definiens>
				<definiens id="1">the maximum likelihood estimate in the parent using the training data from the union</definiens>
				<definiens id="2">the estimate at the root using all the training data</definiens>
			</definition>
</paper>

		<paper id="0504">
			<definition id="0">
				<sentence>In this article we present our conception of dtathesls alternations and how they intervene m the definmon of a model of lexlcal entnes We consider that dmthesls alternations are the syntactic realizations of opposmons of a more general semantic nature We will see how they interact with other components such as event structure and how different semannc classes of pre &amp; cates at~se from that interaction The work of Levm ( 1993 ) presents a classification of the alternations in which the Enghsh verbs parttclpate This author presents 8 groups in which she differentiates several subgroups The first three include the greater number of structures and seem to follow generahzatlon criteria The other alternations are classified in a more random fashion since either very specific groups of alternauons are proposed or non-semantically related alternations are gtouped together Other authols have made exphctt the subcategonzanon frames m which verbs can participate without using pmr assocmtmn In these cases a hst of the structures In which a verb pamclpates is presented Gtoss 's ( 1975 ) and Samt-Dtzler 's ( 1996 ) work Is an example of such a methodology applied to French In it , one of the structures in each class is granted priority From our point of v~ew , it ts of interest to dehm~t a class according to the partlclpatmn of ~ts members m a given structure provided that this constructmn illustrates some semantic characteristics shared by the verbs W~th th~s ~dea m mind , we also point to the work of Wdlems ( 1981 ) This author considers that the members of a semannc class do not necessarily share the same syntactm charactenmcs and that factors such as the degree of concretmn of the verb and the morphosyntactlc composmon must be taken into account It ~s of considerable Interest to contemplate th~s type of phenomena m order to overcome the obstacle found with classifications based on the number and type of arguments The authors who focus on the syntacncsemantic structures , such as Dev~s M~irquez ( 1993 ) , consider that each one of the &amp; fferent syntactic structures that a verb takes has a different meaning and that a semantic opposmon Is thereby estabhshed among the &amp; ffeient frames • With regard to the representation of information , NLP oriented formalisms usually Include reformation about the subcategonzatmn reqmred by the verb It can be shown by declaring the list of structures m which the verb participates ( Sager 1981 ) , or these structures can also be generated from one frame as is the case of the LFG ( Kaplan &amp; Bresnan 1982 ) , GPSG ( Gazdar et al 1985 ) , and HPSG ( Pollard &amp; Sag 1987 ) We propose that given a type hierarchy of verb entries , the rules that account for syntactic behavior regarding alternations have to be associated to the representative type of a verb group m order to express interesting hngmst~c generahzatlons In these types , the participation of a set of verbs m a particular alternation and the mechanism required to express ~t must be spemhed Works carried out along these lines are those of Sanfillppo ( 1990 ) and Taul6 ( 1995 ) w~thm the Acqmlex project Our initial hypothesis ~s that the syntax and the semantics of lexlcal ~tems are Interrelated ( Levm &amp; Pinker 1991 , Levm 1993 , Levm &amp; Rappaport 1995 ) These authors consider that 2:3 verbs can be semantically classified based on the meaning they share The hypothesis is that the verbs of a semant\ [ c class will share the same syntactic behavior Hence , each semantic class is assocmted w~th the constructions m which the verbs of that group participate In our approach , we consider that relevant semantic information can be deduced from the syntactic behavior Thus , our semantic analysis includes a syntactic study of the subcategonzation frames m which different verbs can be found For this reason , m contrast to the above mentioned authors , we do not Infer syntactic behavior from the semantic characterization but rather it is syntax that helps us to complete this semantic description We also conslder that this relation can be formahzed , and that it is essential for the charactenzatlon of the entries The three elements around which the information that makes up the verbal lex~cal entry is organized are meaning components , event structure and diathesis alternations W~th regard to meanmg components , we draw principally from Talmy ( 1985 ) Accordmg to this author , these components play a central role in defining verbal semantic classes In our approach we have defined a small group of semantic components that we have organized into several levels The levels range from the mole general to the more specific The hrst level is common to all the predicates and accounts for Entity The second level serves us to distinguish events from states 0nly the first ones can have an Imttator At a third level we specify those components relevant for grouping verbs into semantic classes Change , Attitude , Tranaference , etc The components considered at a more specific level allow us to characterize pledicates , but not to define new classes hzstrument , etc From the standpoint of leahzatlon , they can be expressed , ,a the le-_cal item ' ( e g La pared se desplom6 / The wall crashed ) or else syntagmattcally ( eg El plfnclpe se transform6 en rana / The prince turned mto a frog ) As concerns event structure , we follow Parsons ' ( 1990 ) and Pustelovsky 's ( 1995 ) \ ] By IlledOS of \ [ e'~tcdhz , ltlol't Int .</sentence>
				<definiendum id="0">HPSG</definiendum>
				<definiens id="0">the syntactic realizations of opposmons of a more general semantic nature We will see how they interact with other components such as event structure and how different semannc classes of pre &amp; cates at~se from that interaction The work of Levm ( 1993 ) presents a classification of the alternations in which the Enghsh verbs parttclpate This author presents 8 groups in which she differentiates several subgroups The first three include the greater number of structures and seem to follow generahzatlon criteria The other alternations are classified in a more random fashion since either very specific groups of alternauons are proposed or non-semantically related alternations are gtouped together Other authols have made exphctt the subcategonzanon frames m which verbs can participate without using pmr assocmtmn In these cases a hst of the structures In which a verb pamclpates is presented Gtoss 's ( 1975 ) and Samt-Dtzler 's ( 1996 ) work Is an example of such a methodology applied to French In it , one of the structures in each class is granted priority From our point of v~ew , it ts of interest to dehm~t a class according to the partlclpatmn of ~ts members m a given structure provided that this constructmn illustrates some semantic characteristics shared by the verbs W~th th~s ~dea m mind</definiens>
				<definiens id="1">the members of a semannc class do not necessarily share the same syntactm charactenmcs and that factors such as the degree of concretmn of the verb and the morphosyntactlc composmon must be taken into account It ~s of considerable Interest to contemplate th~s type of phenomena m order to overcome the obstacle found with classifications based on the number and type of arguments The authors who focus on the syntacncsemantic structures , such as Dev~s M~irquez ( 1993 ) , consider that each one of the &amp; fferent syntactic structures that a verb takes has a different meaning and that a semantic opposmon Is thereby estabhshed among the &amp; ffeient frames • With regard to the representation of information , NLP oriented formalisms usually Include reformation about the subcategonzatmn reqmred by the verb It can be shown by declaring the list of structures m which the verb participates ( Sager 1981 ) , or these structures can also be generated from one frame as is the case of the LFG ( Kaplan &amp; Bresnan 1982 )</definiens>
				<definiens id="2">the participation of a set of verbs m a particular alternation and the mechanism required to express ~t must be spemhed Works carried out along these lines are those of Sanfillppo ( 1990 ) and Taul6 ( 1995 ) w~thm the Acqmlex project Our initial hypothesis ~s that the syntax and the semantics of lexlcal ~tems are Interrelated ( Levm &amp; Pinker 1991 , Levm 1993 , Levm &amp; Rappaport 1995 ) These authors consider that 2:3 verbs can be semantically classified based on the meaning they share The hypothesis is that the verbs of a semant\ [ c class will share the same syntactic behavior Hence</definiens>
				<definiens id="3">relevant semantic information can be deduced from the syntactic behavior Thus , our semantic analysis includes a syntactic study of the subcategonzation frames m which different verbs can be found For this reason</definiens>
				<definiens id="4">Infer syntactic behavior from the semantic characterization but rather it is syntax that helps us to complete this semantic description We also conslder that this relation can be formahzed , and that it is essential for the charactenzatlon of the entries The three elements around which the information that makes up the verbal lex~cal entry is organized are meaning components , event structure and diathesis alternations W~th regard to meanmg components</definiens>
				<definiens id="5">common to all the predicates and accounts for Entity The second level serves us to distinguish events from states 0nly the first ones can have an Imttator At a third level we specify those components relevant for grouping verbs into semantic classes Change , Attitude , Tranaference , etc The components considered at a more specific level allow us to characterize pledicates , but not to define new classes hzstrument , etc From the standpoint of leahzatlon , they can be expressed , ,a the le-_cal item ' ( e g La pared se desplom6 / The wall crashed ) or else syntagmattcally ( eg El plfnclpe se transform6 en rana / The prince turned mto a frog ) As concerns event structure</definiens>
			</definition>
			<definition id="1">
				<sentence>orporatloN or e\ [ qe It t. : ln be undel stood works These authors consider that an event can be decomposed into a subatomic structure m whxch the temporal relatJons established between the subevents and the partlclpants are descnbed In this sense , several patterns of eventual behavior have been established They mteract with the other elements that constitute our model Finally , our model ptesents mfotmat~on about diathesis alternations This is the ~ublect of this paper and acts as the basis for the vetb classlficat~on we present here We have formalized this reformation in the Plrdptdes Lextcal Knowledge Base ( PLKB ) m the form ot modules In It , the types corresponding to each one of the modules that form the entry have been made explicit Also , the dmthesls alternations have been dealt with as lex~cal rules An extra module , FORLOG , has been defined to account for the relation between semantics and syntax , connecting all the mformatton to be found Our starting point for the study of alternations is Levm 's ( 1993 ) work Unlike this author , we think that it Is important to take mto account only those very general alternations ( middle , causative-mchoatlve ) , that explain relevant syntactic behavior and that leally highlight the relation between syntax and semantxcs Those constructxons that are very specific and m which veiy few velbs pattlclpate , such as Obhgarotw Adverb ( 8 5 ) , have been left aside In our proposal we understand dtatheses as one of the syntagmatlc expressions of a semantic opposmon Dlathesis alternations are thus pairs of structures ( or diatheses ) related to each other by one of these oppositions With this concept m mind we have considered the existence of three possible oppositions depending on whether there is a change of focus m the participants ( Change of focus and Underspecificatlon ) or there Is a change m the event structure ( Aspectual Opposition ) For example , the sentences ( 1 ) a Elena cerr6 la puerta ( Elena closed the dool ) b La puerta se cerr6 ( The door closed ) are related by a change of focus opposition whereas in ( a ) the cause that provokes the event 23 is expressed , m ( b ) the change undertaken by the entity is focahzed On the other hand , sentences such as ( 2 ) a Juan coml6 pescado ( Juan ate fish ) b Juan coral6 ( Juan ate ) are related by means of an underspeclficat~on opposition of ( b ) with respect to ( a ) Lastly , the aspectual opposmon ~s illustrated in the following examples in which an event ( a ) is related w~th a state ( b ) ( 3 ) a Sara pinta un retrato ( S as painting a portraat ) b Sara pinta muy bten ( Sara paints very well ) We start from the hypothes~s that these oppositions are general and mterhngulstlc in nature and that , therefore , the corresponding syntagmatlc realizations m each language have to be defined It ~s thus possible to estabhsh translation relations between the languages at a semantic level and for each meaning opposmon it wdl thereby be feasible to predict the syntactic structures that can express it ( Fermindez and Martf 98 ) For example , Basque incorporates the cause by means of a morphological process as can be seen m the examples below ( 4 ) a Kanpalak .</sentence>
				<definiendum id="0">corresponding syntagmatlc realizations</definiendum>
				<definiens id="0">lex~cal rules An extra module , FORLOG , has been defined to account for the relation between semantics and syntax , connecting all the mformatton to be found</definiens>
			</definition>
</paper>

		<paper id="0410">
			<definition id="0">
				<sentence>Each partner is working on his own language and building specific tests ( at the present : i Association pour le traitement automatique des langues ( ASSTRIL ) for French , Consorzio Lexicon Ricerche from the University of Salerno , for Italian &amp; Piidagogische Hochschule Karlsruhe and Universit~t Mtinehen for German .</sentence>
				<definiendum id="0">ASSTRIL</definiendum>
				<definiens id="0">working on his own language and building specific tests</definiens>
			</definition>
			<definition id="1">
				<sentence>From a technical point of view , EVALING uses a Multithreaded Automation Object .</sentence>
				<definiendum id="0">EVALING</definiendum>
				<definiens id="0">uses a Multithreaded Automation Object</definiens>
			</definition>
			<definition id="2">
				<sentence>A script , which uses linguistic tools ( INTEX programs , local grammars , dictionaries and linguistic descriptions ) evaluates the sentences .</sentence>
				<definiendum id="0">script</definiendum>
				<definiens id="0">uses linguistic tools ( INTEX programs , local grammars , dictionaries and linguistic descriptions ) evaluates the sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>The software INTEX includes a graphic editor ( FSGraph ) which allows ergonomic designing of FSTs ( which are graphically represented as graphs ) .</sentence>
				<definiendum id="0">INTEX</definiendum>
				<definiens id="0">includes a graphic editor ( FSGraph ) which allows ergonomic designing of FSTs ( which are graphically represented as graphs )</definiens>
			</definition>
			<definition id="4">
				<sentence>The level assessment depends on the length in number of words , presence of a modality ( interrogative or not ) , lexical complexity and presence or absence of a negation , conjunction , relative pronoun .</sentence>
				<definiendum id="0">level assessment</definiendum>
				<definiens id="0">depends on the length in number of words , presence of a modality ( interrogative or not ) , lexical complexity and presence or absence of a negation , conjunction , relative pronoun</definiens>
			</definition>
			<definition id="5">
				<sentence>NCR is a link to a graph that repeats the possibility to have a negation , conjunction or relative pronoun .</sentence>
				<definiendum id="0">NCR</definiendum>
				<definiens id="0">a link to a graph that repeats the possibility to have a negation , conjunction or relative pronoun</definiens>
			</definition>
			<definition id="6">
				<sentence>ROCHE , E. and SCHABES Y. , editors ( 1997 ) FiniteState Language Processing , MIT Press , Cambridge , Mass./London RUSSELL M. , HANEY W. ( 1997 ) Testing Writing on Computers : An Experiment Comparing Student Performance on Tests Conduced via Computer and via Paper-and-Pencil .</sentence>
				<definiendum id="0">Computers</definiendum>
				<definiens id="0">An Experiment Comparing Student Performance on Tests Conduced via Computer and via Paper-and-Pencil</definiens>
			</definition>
</paper>

		<paper id="0702">
			<definition id="0">
				<sentence>The probability of a symbol s with respect to this model M and to a context c can be estimated by : f ( s , M , c ) p ( slM , c ) = ( 4 ) \ ] ( U , c ) The inIormation of a symbol s with respect to the model M and to a context c is defined by : I ( s\ ] U , c ) = -log2 p ( slU , c ) ( 5 ) Intuitively , information can be considered as the surprise of the model about the symbol s after having seen the context c. The more the symbol is unexpected from the model 's experience , the higher is the value of information \ [ Shannon and Weaver , 1949\ ] • The entropy of a context c with respect to this model M expresses the expected value of information , and is defined by : g ( Af , c ) = Zp ( s\ ] M , c ) I ( slM , c ) ( 6 ) sEE Monitoring entropy and information across a corpus shows that maxima often correspond with word 3Note that blanks become `` BL '' and new-lines become `` NL '' .</sentence>
				<definiendum id="0">M , c ) p</definiendum>
				<definiens id="0">U , c ) The inIormation of a symbol s with respect to the model M and to a context c is defined by : I ( s\ ] U , c ) = -log2 p ( slU , c ) ( 5 ) Intuitively , information can be considered as the surprise of the model about the symbol s after having seen the context c. The more the symbol is unexpected from the model 's experience , the higher is the value of information \ [ Shannon and Weaver</definiens>
				<definiens id="1">expresses the expected value of information , and is defined by : g ( Af , c ) = Zp ( s\ ] M , c ) I ( slM , c ) ( 6 ) sEE Monitoring entropy and information across a corpus shows that maxima often correspond with word 3Note that blanks become `` BL '' and new-lines become `` NL ''</definiens>
			</definition>
</paper>

		<paper id="0112">
			<definition id="0">
				<sentence>His Segmented DRT ( SDRT ) uses a tree-like representation for the discourse sUuctui~ I Centering Theory ( CD proposes a//st structure for the entities one preferably refers to in subsequent sentences .</sentence>
				<definiendum id="0">SDRT )</definiendum>
				<definiens id="0">uses a tree-like representation for the discourse sUuctui~ I Centering Theory ( CD proposes a//st structure for the entities one preferably refers to in subsequent sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>3 Negation is a standard example that does not allow a reference to a discourse entity in the prevous sentence : ( 2 ) No man walks in the park .</sentence>
				<definiendum id="0">Negation</definiendum>
				<definiens id="0">a standard example that does not allow a reference to a discourse entity in the prevous sentence : ( 2 ) No man walks in the park</definiens>
			</definition>
			<definition id="2">
				<sentence>A function has to be designed that tells us how to store data on the hashing list .</sentence>
				<definiendum id="0">function</definiendum>
				<definiens id="0">has to be designed that tells us how to store data on the hashing list</definiens>
			</definition>
			<definition id="3">
				<sentence>In DRT , a DRS consists of the domain of discourse referents and the set of conditions , imposed on the referents .</sentence>
				<definiendum id="0">DRS</definiendum>
			</definition>
			<definition id="4">
				<sentence>A continuation of the center ( Cp ( Ui ) = Cs ( Ui+t ) ) is the preferred and most coherent constellation according to this theory .</sentence>
				<definiendum id="0">continuation of the center</definiendum>
				<definiens id="0">the preferred and most coherent constellation according to this theory</definiens>
			</definition>
</paper>

		<paper id="0405">
			<definition id="0">
				<sentence>The relaxed grammar specifies a noun phrase with determiner and optional adjective phrase but relaxes the target language restrictions on gender and number agreement among determiner , noun , and adjective and on position of adjective .</sentence>
				<definiendum id="0">relaxed grammar</definiendum>
				<definiens id="0">specifies a noun phrase with determiner and optional adjective phrase but relaxes the target language restrictions on gender and number agreement among determiner , noun , and adjective and on position of adjective</definiens>
			</definition>
			<definition id="1">
				<sentence>The LCS is an interlingual framework for representing semantic elements that have syntactic reflexes3 LCSs have been ported from English into a variety of languages , including Spanish , requiring a minimum of adaptation in even unrelated languages ( e.g. Chinese ( Olsen et al. , 1998 ) ) .</sentence>
				<definiendum id="0">LCS</definiendum>
				<definiens id="0">an interlingual framework for representing semantic elements that have syntactic reflexes3 LCSs have been ported from English into a variety of languages , including Spanish</definiens>
			</definition>
			<definition id="2">
				<sentence>The representation indicates the argument-taking properties of verbs ( hit requires an object ; smile does not ) , selectional constraints ( the subject of fear and the object of frighten are animate ) , thematic information of arguments ( the subject of frighten is an agent ; the object is a patient ) and classification information of verbs ( motion verbs like go are conceptually distinct from psychological verbs like fear/frighten ; run is a more specific type of motion verb than go ) .</sentence>
				<definiendum id="0">selectional constraints</definiendum>
				<definiens id="0">the subject of fear and the object of frighten are animate ) , thematic information of arguments</definiens>
				<definiens id="1">a patient</definiens>
			</definition>
			<definition id="3">
				<sentence>The MILT architecture allows us both to enumerate errors of these types , and parse data that includes such errors .</sentence>
				<definiendum id="0">MILT architecture</definiendum>
				<definiens id="0">allows us both to enumerate errors of these types , and parse data that includes such errors</definiens>
			</definition>
			<definition id="4">
				<sentence>The Lexical Conceptual Structure ( LCS ) allows principles of robustness , flexibility and modularity to apply to the semantic component of the proposed system .</sentence>
				<definiendum id="0">Lexical Conceptual Structure</definiendum>
				<definiendum id="1">LCS</definiendum>
				<definiens id="0">principles of robustness , flexibility and modularity to apply to the semantic component of the proposed system</definiens>
			</definition>
			<definition id="5">
				<sentence>The LCS is considered a subset of mental representation , that is , the language of mental representation as realized in language ( Dorr et al. , 1995 ) .</sentence>
				<definiendum id="0">LCS</definiendum>
			</definition>
			<definition id="6">
				<sentence>The assessment phase goes beyond the current work in test scoring , combining recognition of acoustic features , such as the Automatic Spoken Language Assessment by Telephone ( ASLAT ) or PhonePass ( Ordinate , 1998 ) 29 with aspects of the syntactic , discourse , and semantic factors , as in e-rater .</sentence>
				<definiendum id="0">assessment phase</definiendum>
				<definiens id="0">goes beyond the current work in test scoring , combining recognition of acoustic features , such as the Automatic Spoken Language Assessment by Telephone ( ASLAT ) or PhonePass ( Ordinate , 1998 ) 29 with aspects of the syntactic , discourse , and semantic factors</definiens>
			</definition>
			<definition id="7">
				<sentence>Decision tree type classifiers have an additional advantage : unlike neural network or nearest neighbor classifiers , they are easily interpretable by humans .</sentence>
				<definiendum id="0">Decision tree type classifiers</definiendum>
				<definiens id="0">unlike neural network or nearest neighbor classifiers</definiens>
			</definition>
			<definition id="8">
				<sentence>Machine Translation : A View from the Lexicon .</sentence>
				<definiendum id="0">Machine Translation</definiendum>
				<definiens id="0">A View from the Lexicon</definiens>
			</definition>
</paper>

		<paper id="0600">
			<definition id="0">
				<sentence>Hong Kong University of Science and Technology , Human Language Technology Center INVITED SPEAKERS : Kenneth W. Church ( AT &amp; T Labs-Research ) Richard Schwartz ( BBN Technologies ) ORGANIZERS : Pascale Fung , Chair Joe Zhou , Co-chair PROGRAM COMMITTEE : Jing-Shin Chang Ken Church Ido Dagan Marti Hearst Huang , Changning Pierre Isabelle Lillian Lee David Lewis Dan Melamed Mehryar Mohri Masaaki Nagata Richard Sproat Andreas Stolcke Ralph Weischedel Dekai Wu David Yarowsky ( Behavior Design Corp. ) ( AT &amp; T Labs-Research ) ( Bar-Ilan University ) ( UC-Berkeley ) ( Microsoft Research China ) ( Xerox Research Europe ) ( Comell University ) ( AT &amp; T Labs-Research ) ( West Group ) ( AT &amp; T Labs-Research ) ( NTT ) ( AT &amp; T Labs-Research ) ( SRI International ) ( BBN ) ( HKUST ) ( Johns Hopkins University ) ADDITIONAL REVIEWERS : Srinivas Bangalore Rebecca Bruce Michael Collins Gregory Grefenstette Vasileios Hatzivassiloglou David Hull Peter Jackson Christian Jacquemin Liu , XiaohuSung Hyon Myaeng Shimei Pan Ted Pederson Roberto Pieraccini Ellen Riloff Hinrich Shtitze Yannis Stylianou Zhao , Jun ( AT &amp; T Labs-Research ) ( Univ. of North Carolina ) ( AT &amp; T Labs Research ) ( Xerox Research Europe ) ( Columbia University ) ( Xerox Research Europe ) ( West Group ) ( LIMSI ) ( HKUST ) ( Chunguam National Univ. ) ( Columbia University ) ( Cal Poly ) ( AT &amp; T Labs-Research ) ( University of Utah ) ( Xerox PARC ) ( AT &amp; T Labs-Research ) ( HKUST ) FURTHER INFORMATION : Pascale Fung Human Language Technology Center Department of Electrical and Electronic Engineering University of Science and Tehnology ( HKUST ) Clear Water Bay , Kowloon Hong Kong Email : pascale @ ee.ust.hk .</sentence>
				<definiendum id="0">Stylianou Zhao</definiendum>
				<definiendum id="1">LIMSI ) ( HKUST )</definiendum>
				<definiens id="0">Hong Kong University of Science and Technology , Human Language Technology Center INVITED SPEAKERS : Kenneth W. Church ( AT &amp; T Labs-Research ) Richard Schwartz ( BBN Technologies ) ORGANIZERS : Pascale Fung , Chair Joe Zhou , Co-chair PROGRAM COMMITTEE : Jing-Shin Chang Ken Church Ido Dagan Marti Hearst Huang , Changning Pierre Isabelle Lillian Lee David Lewis Dan Melamed Mehryar Mohri Masaaki Nagata Richard Sproat Andreas Stolcke Ralph Weischedel Dekai Wu David Yarowsky ( Behavior Design Corp. ) ( AT &amp; T Labs-Research ) ( Bar-Ilan University ) ( UC-Berkeley ) ( Microsoft Research China ) ( Xerox Research Europe ) ( Comell University ) ( AT &amp; T Labs-Research ) ( West Group ) ( AT &amp; T Labs-Research ) ( NTT ) ( AT &amp; T Labs-Research ) ( SRI International ) ( BBN ) ( HKUST ) ( Johns Hopkins University ) ADDITIONAL REVIEWERS : Srinivas Bangalore Rebecca Bruce Michael Collins Gregory Grefenstette Vasileios Hatzivassiloglou David Hull Peter Jackson Christian Jacquemin Liu , XiaohuSung Hyon Myaeng Shimei Pan Ted Pederson Roberto Pieraccini Ellen Riloff Hinrich Shtitze Yannis</definiens>
				<definiens id="1">AT &amp; T Labs Research ) ( Xerox Research Europe ) ( Columbia University ) ( Xerox Research Europe</definiens>
				<definiens id="2">Pascale Fung Human Language Technology Center Department of Electrical and Electronic Engineering University of Science</definiens>
			</definition>
			<definition id="1">
				<sentence>Richard Schwartz ( BBN Technologies ) 9:40-9:50 Short Break 9:50-10:10 POS Tags and Decision Trees for Language Modeling Peter A. Heeman 10:10-10:30 An Information-Theoretic Empirical Analysis of Dependency-Based Feature Types for Word Prediction Models Dekai Wu , Zhao Jun and Sui Zhifang 10:30-10:50 Word Informativeness and Automatic Pitch Accent Modeling Shimei Pan and Kathleen McKeown 10:50-11:10 Learning Discourse Relations with Active Data Selection Tadashi Nomoto and Yuji Matsumoto 11:10-11:30 Break 11:30-11:50 A Learning Approach to Shallow Parsing Marcia Mufioz , Vasin Punyakanok , Dan Roth and Dav Zimak 11:50-12:10 12:10-12:30 Guiding a Well-Founded Parser with Corpus Statistics Amon Seagull and Lenhart Schubert Exploiting Diversity in Natural Language Processing : Combining Parsers John Henderson and Eric Bnll 12:30-14:00 LUNCH 14:00-15:10 Panel Discussion The Future of Language Technologies : Research , Development and Marketing Ken Church ( AT &amp; T ) , Pierre Isabelle ( Xerox Europe ) , Roberto Pieraccini ( AT &amp; T ) , John Rausch ( Lexis-Nexis ) , Keh-Yih Su ( Behavior Design Corp. ) , Raphael Wong ( Intel ) 15:10-15:20 Short Break 15:20-15:40 15:40-16:00 Lexical Ambiguity and Information Retrieval Revisted Julio Gonzalo , Anselmo Pefias and Felisa Verdejo Detecting Text Similarity over Short Passages : Exploring Linguistic Feature Combinations via Machine Learning Vasileios Hatzivassiloglou , Judith L. Klavans and Eleazar Eskin 16:00-16:20 16:20-16:40 Automated Construction of Weighted String Similarity Measures J6rg Tiedernann Taking the Load Off the Conference Chairs : Towards a Digital Paper Routing Assistant David Yarowsky and Radu Flonan TABLE OF CONTENTS What 's Happened Since the First SIGDAT Meeting ?</sentence>
				<definiendum id="0">Isabelle ( Xerox Europe</definiendum>
				<definiendum id="1">Keh-Yih Su</definiendum>
				<definiens id="0">Lexical Ambiguity and Information Retrieval Revisted Julio Gonzalo , Anselmo Pefias and Felisa Verdejo Detecting Text Similarity over Short Passages : Exploring Linguistic Feature Combinations via Machine Learning Vasileios Hatzivassiloglou</definiens>
			</definition>
</paper>

		<paper id="0106">
			<definition id="0">
				<sentence>The PREFERENCE module imposes preferences on potential antecedents on the basis of their grammatical roles , parallelism , frequency , proximity , etc .</sentence>
				<definiendum id="0">PREFERENCE module</definiendum>
			</definition>
			<definition id="1">
				<sentence>Hence , the fundamental intuition underlying VT is that the RST-specific distinction between nuclei and satellites constrains the range of referents to which anaphors can be resolved ; in other words , the nucleus-satellite distinction induces for each anaphor ( and each referential expression ) a Domain of Referential Accessibility ( DRA ) .</sentence>
				<definiendum id="0">VT</definiendum>
			</definition>
			<definition id="2">
				<sentence>Based on this information , we evaluated the potential of each of the two classes of models discussed in section 2 ( Linear-k and Discourse-VT-k ) to correctly estab• lish co-referential links as follows : For each model , each k , and each marked referential expression a , we determined whether or not the corresponding LPA ( defined over k elementary units ) contained a referee from the same equivalence class .</sentence>
				<definiendum id="0">LPA</definiendum>
				<definiens id="0">defined over k elementary units ) contained a referee from the same equivalence class</definiens>
			</definition>
			<definition id="3">
				<sentence>In order to assess the statistical significance of the difference between the potentials of the two models to establish correct co-referential links , we carried out a Paired-Samples T Test for each k. In general , a Paired-Samples T Test checks whether the mean of casewise differences between two variables differs from 0 .</sentence>
				<definiendum id="0">Paired-Samples T Test</definiendum>
				<definiens id="0">for each k. In general , a Paired-Samples T Test checks whether the mean of casewise differences between two variables differs from 0</definiens>
			</definition>
			<definition id="4">
				<sentence>We consider that the effort e ( M , a , EDRAt ) of a model M to determine correct c0-referential links with respect to one referential a in unit u , given a correspondingEDRA of size k ( EDRAt ( u ) ) is given by the number of units between u and the first unit in EDRAt ( u ) that contains a co-referential expression ofa .</sentence>
				<definiendum id="0">EDRAt )</definiendum>
			</definition>
</paper>

		<paper id="0604">
			<definition id="0">
				<sentence>Pr ( f/le~ ) } • ( 1 ) The argmax operation denotes the search problem , i.e. the generation of the output sentence in the target language .</sentence>
				<definiendum id="0">Pr</definiendum>
				<definiendum id="1">argmax operation</definiendum>
				<definiens id="0">the search problem , i.e. the generation of the output sentence in the target language</definiens>
			</definition>
			<definition id="1">
				<sentence>p ( e'\ [ e '' , e ' '' ) • Qe , , , ( J 1 , e '' ) } } p ( 5 ) is the alignment probability for the three cases above , p ( .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the alignment probability for the three cases above , p (</definiens>
			</definition>
			<definition id="2">
				<sentence>The complexity of the algorithm for full search is J-E 4 , where E is the size of the target language vocabulary .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">the size of the target language vocabulary</definiens>
			</definition>
			<definition id="3">
				<sentence>• PER ( position-independent word error rate ) : A shortcoming of the WER is the fact that it requires a perfect word order .</sentence>
				<definiendum id="0">PER</definiendum>
				<definiendum id="1">WER</definiendum>
				<definiens id="0">the fact that it requires a perfect word order</definiens>
			</definition>
</paper>

		<paper id="0620">
			<definition id="0">
				<sentence>The paper presents a new approach to identifying discourse relations , which makes use of a particular sampling method called committeebased sampling ( CBS ) .</sentence>
				<definiendum id="0">CBS</definiendum>
				<definiens id="0">makes use of a particular sampling method called committeebased sampling (</definiens>
			</definition>
			<definition id="1">
				<sentence>CBS tries to identify such an example by randomly generating multiple models ( committee members ) based on posterior dis159 tributions of model parameters and measuring how much the member models disagree in classifying the example .</sentence>
				<definiendum id="0">CBS</definiendum>
				<definiens id="0">tries to identify such an example by randomly generating multiple models ( committee members ) based on posterior dis159 tributions of model parameters and measuring how much the member models disagree in classifying the example</definiens>
			</definition>
			<definition id="2">
				<sentence>Probabilities P ( wi I ti ) and P ( ti+l I ti ) are called model parameters of an HMM tagger .</sentence>
				<definiendum id="0">Probabilities P</definiendum>
				<definiens id="0">I ti ) are called model parameters of an HMM tagger</definiens>
			</definition>
			<definition id="3">
				<sentence>In Dagan and Engelson ( 1995 ) , P ( M I S ) is given as the posterior multinomial distribution P ( al = al , ... , an = an J S ) , where ai is a model parameter and ai represents one of the possible values .</sentence>
				<definiendum id="0">ai</definiendum>
				<definiens id="0">a model parameter and ai represents one of the possible values</definiens>
			</definition>
			<definition id="4">
				<sentence>S is a small Set of samples drawn from the tagged corpus .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">a small Set of samples drawn from the tagged corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>LocSen takes a continuous value between 0 and 1 .</sentence>
				<definiendum id="0">LocSen</definiendum>
				<definiens id="0">takes a continuous value between 0 and 1</definiens>
			</definition>
			<definition id="6">
				<sentence>LocW : i.thinPar takes continuous values ranging from 0 to 1 .</sentence>
				<definiendum id="0">LocW</definiendum>
				<definiens id="0">i.thinPar takes continuous values ranging from 0 to 1</definiens>
			</definition>
			<definition id="7">
				<sentence>The fea2For a word j in a sentence Si ( j E Si ) , its weight wij is defined by : N w # = tf~j • log ~df~ is the number of sentences in the text which have an occurrence of a word j. N is the total number of sentences in the text .</sentence>
				<definiendum id="0">fea2For</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">a word j in a sentence Si ( j E Si</definiens>
				<definiens id="1">the number of sentences in the text which have an occurrence of a word j.</definiens>
			</definition>
			<definition id="8">
				<sentence>X , Y ) = t i=x t E E i=1 i=1 where w ( xi ) represents a t~idf weight assigned to the term xi .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">a t~idf weight assigned to the term xi</definiens>
			</definition>
			<definition id="9">
				<sentence>The measure is known as the Dice coefficient ( Salton and McGill , 1983 ) ture takes 'y ' if a sentence contains one or more cues relevant to distinguishing between the two relation types .</sentence>
				<definiendum id="0">Dice coefficient</definiendum>
				<definiendum id="1">ture</definiendum>
				<definiens id="0">takes 'y ' if a sentence contains one or more cues relevant to distinguishing between the two relation types</definiens>
			</definition>
			<definition id="10">
				<sentence>In the Japanese linguistics literature , there is a popular theory that sentence endings are relevant for identifying semantic relations among 3INFOx ( T ) measures the entropy of the distribution of classes in a set T with respect to a feature X. We define INFOx just as given in Quinlan ( 1993 ) : xNFOx ( T ) = x xNFo ( T , ) i=1 Ti represents a partition of T corresponding to one of the values for X. INFO ( T ) is defined as follows : k INFO ( T ) = ~ freq ( Cj , T ) freq ( Cj , T ) ~ i.~\ ] x log s \ ] T I j=l fi'eq ( C , T ) is the number of cases from class C in a set T of cases .</sentence>
				<definiendum id="0">freq ( Cj , T ) freq ( Cj , T ) ~ i.~\ ] x log s \ ] T I j=l fi'eq ( C , T )</definiendum>
				<definiens id="0">a popular theory that sentence endings are relevant for identifying semantic relations among 3INFOx ( T ) measures the entropy of the distribution of classes in a set T with respect to a feature X. We define INFOx just as given in Quinlan ( 1993 ) : xNFOx ( T ) = x xNFo ( T , ) i=1 Ti represents a partition of T corresponding to one of the values for X. INFO ( T ) is defined as follows : k INFO ( T ) = ~</definiens>
				<definiens id="1">the number of cases from class C in a set T of cases</definiens>
			</definition>
			<definition id="11">
				<sentence>The x-axis represents the amount of training data , and the y-axis the error rate .</sentence>
				<definiendum id="0">x-axis</definiendum>
				<definiens id="0">the amount of training data</definiens>
			</definition>
			<definition id="12">
				<sentence>The error rate is the proportion of the misclassified instances to the total number of instances .</sentence>
				<definiendum id="0">error rate</definiendum>
				<definiens id="0">the proportion of the misclassified instances to the total number of instances</definiens>
			</definition>
</paper>

		<paper id="0618">
			<definition id="0">
				<sentence>By the laws of conditional probabilities , a language model can be represented in left-to-right fashion as P ( S ) = P ( wo ) P ( w I \ [ hl ) ... P ( w i I hi ) ... P ( wn \ [ h , ) where S denotes a sequence of words w0 , w~ ... .. w , , and ha denotes the history of w~ ( 0 &lt; i _ &lt; n ) .</sentence>
				<definiendum id="0">language model</definiendum>
				<definiendum id="1">S</definiendum>
			</definition>
			<definition id="1">
				<sentence>IR ( F1 , Fz ; O ) denotes the redundant information between Fi and F2 in predicting O , which is defined as the difference between IQ ( F2 ; O ) and IG ( Fz ; OIF1 ) , or the difference between IQ ( F~ ; O ) and IG ( F~ ; OIF2 ) .</sentence>
				<definiendum id="0">IR</definiendum>
				<definiendum id="1">IQ</definiendum>
				<definiendum id="2">IG</definiendum>
				<definiendum id="3">IG</definiendum>
				<definiens id="0">the redundant information between Fi and F2 in predicting O</definiens>
			</definition>
			<definition id="2">
				<sentence>When R is not in the history preceding O , it can not be used to predict O. Similarly , a possible factor in the fact that M ( IQ ( M ; O ) =2.237 ) is less predictive than B is that M sometimes lies to the right of O. Another factor in the cas'e of M is that none of the leaf nodes in a dependency tree have an M. predicted word ) is less effective than M ( the word modifying the predicted word ) when they are used individually for word prediction , R is more effective than M if they are used On top of a standard bigram model ( the feature B ) .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the word modifying the predicted word ) when they are used individually for word prediction</definiens>
			</definition>
			<definition id="3">
				<sentence>/zuo2tian l/yesterday -ff ~/xia4wu3/aftemoon '' xue2 sheng3 men2 zheng4 zaii4 jiao4 shi4 student ( plural marker ) ( -ing ) in classroom RT ... j-vp -- ... ~ xie3 lun4 wen2 write paper R , B 0 f e vt • Figure 8 : The dependency structure o th phrase ~/xle3/write -~3~/lun4wen2/paper '' We measured the information gain of MT over M to be only IG ( MT ; OIM ) =0.110 bits , while the information redundancy of MT and M is a much larger IR ( MT , M ; O ) =0.861 bits .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">a much larger IR ( MT ,</definiens>
			</definition>
			<definition id="4">
				<sentence>The lexical identities of the words ( R , O ) involved in a dependency relation determine to a large extent the type of modification relation RT that holds between O and the word it modifies , R. Consider the sentence in Figure 8 , the identity of the words `` ~/xie3/write '' and `` J , ~3~ : /lun4wen2/paper '' determine with near certainty that their relationship is verb phrase ( vp ) : MP , MT , R , RP , RT } , the preference order for selecting feature types is B , R , M , RT , MT , BP , RP , MP .</sentence>
				<definiendum id="0">verb phrase</definiendum>
			</definition>
</paper>

		<paper id="0311">
			<definition id="0">
				<sentence>The annotation scheme consists of seven non-hierarchical labels which model prototypical academic argumentation and expected intentional 'moves ' .</sentence>
				<definiendum id="0">annotation scheme</definiendum>
				<definiens id="0">consists of seven non-hierarchical labels which model prototypical academic argumentation and expected intentional 'moves '</definiens>
			</definition>
			<definition id="1">
				<sentence>Basic categories are defined by attribution of intellectual ownership ; they distinguish between : • statements which are presented as generally accepted ( BACKGROUND ) ; • statements which are attributed to other , specific pieces of research outside the given paper , including the authors ' own previous work ( OTHER ) ; • statements which describe the authors ' own new contributions ( OWN ) .</sentence>
				<definiendum id="0">Basic categories</definiendum>
			</definition>
			<definition id="2">
				<sentence>In particular , the basic annotation scheme is stable ( K=.82 , .81 , .76 ; N=1220 ; k=2 for all three annotators ) and reproducible ( K=.71 , N=4261 , k=3 ) , where k denotes the number of annotators , N the number of sentences annotated , and K gives the Kappa value .</sentence>
				<definiendum id="0">k</definiendum>
				<definiendum id="1">K</definiendum>
				<definiens id="0">the number of annotators</definiens>
			</definition>
			<definition id="3">
				<sentence>Our training material is a collection of 80 conference papers and their summaries , taken from the Computation and Language E-Print Archive ( http : //xxx .</sentence>
				<definiendum id="0">E-Print Archive ( http</definiendum>
				<definiens id="0">a collection of 80 conference papers and their summaries , taken from the Computation and Language</definiens>
			</definition>
			<definition id="4">
				<sentence>P ( seRIF ' '' ' '' Fk ) ~ 1-i~= p¢Fj ) where P ( s e RIF1 , .</sentence>
				<definiendum id="0">P (</definiendum>
			</definition>
			<definition id="5">
				<sentence>Tense ( associated with first finite verb in sentence ) Modal Auxiliaries Negation Action type of first verb in sentence Type of Agent Type of formulaic expression occurring in sentence Does the sentence contain keywords as determined by the tf/idf measure ?</sentence>
				<definiendum id="0">Tense</definiendum>
			</definition>
			<definition id="6">
				<sentence>Heuristic rules determine that the agent is the subject in an active sentence , or the head of the by-phrase ( if present ) in a passive sentence .</sentence>
				<definiendum id="0">Heuristic rules</definiendum>
				<definiens id="0">the subject in an active sentence , or the head of the by-phrase ( if present ) in a passive sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>However , the Kappa statistic , which controls for expected random agreement , reveals just how bad that baseline really is : Kappa is K=-.12 ( machine vs. one annotator ) .</sentence>
				<definiendum id="0">Kappa statistic</definiendum>
				<definiens id="0">controls for expected random agreement , reveals just how bad that baseline really is : Kappa is K=-.12 ( machine vs. one annotator )</definiens>
			</definition>
			<definition id="8">
				<sentence>The automatic generation of literary abstracts : an approach based on the identification of self-indicating phrases .</sentence>
				<definiendum id="0">literary abstracts</definiendum>
				<definiens id="0">an approach based on the identification of self-indicating phrases</definiens>
			</definition>
</paper>

		<paper id="0301">
			<definition id="0">
				<sentence>Annotation graphs ( AGs ) are now defined as follows : Definition 1 An annotation graph G over R , N is a set of triples having the form ( nl , r , n~ ) , r e R , nl , n2 6 N , which satisfies the following conditions : acyclic digraph .</sentence>
				<definiendum id="0">Annotation graphs ( AGs</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">follows : Definition 1 An annotation graph G over R ,</definiens>
				<definiens id="1">a set of triples having the form ( nl , r , n~ ) , r e R , nl , n2 6 N , which satisfies the following conditions : acyclic digraph</definiens>
			</definition>
			<definition id="1">
				<sentence>L = { oh , okay , IOS : Commit } C = 0 N = { 1,2,3 } r = { &lt; 1,52.46 } , ( 3,53.14 } } ( l , Wlohl,2 &gt; , A = ( 2 , W/okay/,3 ) , ( 1 , DnOS : Comm~/ , 3 &gt; } XML is a natural 'surface representation ' for annotation graphs and could provide the primary exchange format .</sentence>
				<definiendum id="0">DnOS</definiendum>
				<definiendum id="1">XML</definiendum>
				<definiens id="0">a natural 'surface representation ' for annotation graphs and could provide the primary exchange format</definiens>
			</definition>
			<definition id="2">
				<sentence>First , there are many types of entities and 6 &lt; Dialog Id=d92a-~.2 J~anoCation-date= '' 08-14-97 '' Anuotator= '' Re¢onciled Version '' Speech= '' /d92a-2.2/dialog.fea '' Statue=Verified &gt; &lt; Turn Id=T9 Speakez~ '' s '' Speech= '' -s 44.853889 -e 52.175728 '' &gt; &lt; U¢¢ Id=uttl7 A~eenent=None Influence-on-listener=Action-directive Influence-on-speaker=Commit Info-level=Task Response-to= '' '' Speech= '' -s 45.87 -e 52.175728 '' Statement=Assert &gt; [ sil ] tun eell [ ail ] ge also need ¢0 make the orange juice [ sil ] so ve need to get + oranges [ sil ] to Elmira + &lt; Turn Id=T10 Speaker= '' u '' Speech= '' -s 51.106658 -e 53.14 '' &gt; &lt; Uct Id=uct18 AEreenent=Accept Influence-on-listener=Action-directive Influence-on-speaker=Commit Info-level=Task Response-to- '' ut¢17 '' Speech= '' -s 51.106658 -e 52.67 '' Statement=Assert Understanding=SU-Acknogledge &gt; + oh ge need to pick up + oranges &lt; Utt Id -- uCt19 Agreement=Accept Influence-on-speaker=Commit Info-level=Task Response-¢o= '' utt17 '' Speech= '' -s 52.466781 -e 53.14 '' Understandin~None &gt; oh + okay ÷ &lt; Turn Id=Tli Speaker~ '' s '' Speech= '' -s 52.047996 -e 53.247996 '' &gt; &lt; Utt Id -- utt20 Agreement=Accept Info-level=Task Response-to= '' uttl8 '' Speech= '' -s 52.047996-e 53.247996 '' Understanding=SU-Ackno~ledge &gt; + yeah+ &lt; /Dialog &gt; Figure 8 : DAMSL Annotation of a TRAINS Dialogue D/ Utt/ W/ W/ Utt/ D~ : i : : `` 13 `` 26 `` 33 :48 `` 54 `` 65 i `` 36 -47 `` 54 i~7 I : so , i04 • '.47 `` 66 : .94 Figure 9 : Graph Structure for TRAINS Example relations , on many scales , from acoustic features spanning a hundredth of a second to narrative structures spanning tens of minutes .</sentence>
				<definiendum id="0">Understanding=SU-Ackno~ledge &gt;</definiendum>
				<definiens id="0">Dialog Id=d92a-~.2 J~anoCation-date= '' 08-14-97 '' Anuotator= '' Re¢onciled Version '' Speech= '' /d92a-2.2/dialog.fea '' Statue=Verified &gt; &lt; Turn Id=T9 Speakez~ '' s '' Speech=</definiens>
			</definition>
			<definition id="3">
				<sentence>The AG representation offers a way to deal productively with both kinds of multivocality .</sentence>
				<definiendum id="0">AG representation</definiendum>
				<definiens id="0">offers a way to deal productively with both kinds of multivocality</definiens>
			</definition>
			<definition id="4">
				<sentence>ToBI is an acronym for `` Tones and Break Indices '' , and correspondingly provides two types of information : Tones , which are taken from a fixed vocabulary of categories of ( stress-linked ) `` pitch accents '' and ( juncture-linked ) `` boundary tones '' ; and Break Indices , which are integers characterizing the strength and nature of interword disjunctures .</sentence>
				<definiendum id="0">ToBI</definiendum>
				<definiendum id="1">Break Indices</definiendum>
				<definiens id="0">an acronym for `` Tones and Break Indices '' , and correspondingly provides two types of information : Tones , which are taken from a fixed vocabulary of categories of ( stress-linked )</definiens>
			</definition>
</paper>

		<paper id="0307">
			<definition id="0">
				<sentence>The kappa coefficient measures palrwise agreement among a set of coders who make category judgements , correcting for chance expected agreement ( see equation ( 3 ) helow , where P ( A ) is the proportion of times a set of coders agree and P ( E ) is the proportion of times a set of coders are expected to agree by chance ) .</sentence>
				<definiendum id="0">kappa coefficient</definiendum>
			</definition>
</paper>

		<paper id="0621">
			<definition id="0">
				<sentence>The SNoW learning architecture is a sparse network of linear ftmctions over a predefined or incrementally learned feature space .</sentence>
				<definiendum id="0">SNoW learning architecture</definiendum>
				<definiens id="0">a sparse network of linear ftmctions over a predefined or incrementally learned feature space</definiens>
			</definition>
			<definition id="1">
				<sentence>The SNoW ( Sparse Network of Winnows 1 ) learning architecture is a sparse network of linear units over : a common pre-defined or incrementally learned feature space .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiendum id="1">learning architecture</definiendum>
				<definiens id="0">a sparse network of linear units over : a common pre-defined or incrementally learned feature space</definiens>
			</definition>
			<definition id="2">
				<sentence>The SNoW predictor in this case consists of three targets O , I and B. Figure 1 depicts the feature extraction module which extracts the local features and generates an example for each word in the sentence .</sentence>
				<definiendum id="0">SNoW predictor</definiendum>
				<definiens id="0">extracts the local features and generates an example for each word in the sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>We call p = ( o , c ) a pair , where o is an open bracket and c is any close bracket that was predicted with respect to o. The position of a bracket at the : ith word is defined to be i if it is an open bracket and i + 1 if it is a close bracket .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">a close bracket</definiens>
			</definition>
			<definition id="4">
				<sentence>A pairing is a set of pair s P = { pl , p2 , ... pn } such that Pl is compatible with pj for all i and j where i ~ j. The value of the pairing is the sum of all of the values of the pairs within the pairing .</sentence>
				<definiendum id="0">pairing</definiendum>
				<definiens id="0">the sum of all of the values of the pairs within the pairing</definiens>
			</definition>
			<definition id="5">
				<sentence>In the accuracy column , O indicates the accuracy of the Open predictor and C indicates the accuracy of the Close predictor .</sentence>
				<definiendum id="0">O</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">indicates the accuracy of the Open predictor and</definiens>
			</definition>
</paper>

		<paper id="0634">
			<definition id="0">
				<sentence>Specifically , a coreference relation denotes an identity of reference and holds between two textual elements known as markables , which are nouns , noun phrases , or pronouns .</sentence>
				<definiendum id="0">coreference relation</definiendum>
			</definition>
			<definition id="1">
				<sentence>Most of the unmatched noun phrases are of the following types : ( 1 ) Our system generated a head noun which is a subset of the noun phrase in the annotated corpus .</sentence>
				<definiendum id="0">unmatched noun phrases</definiendum>
				<definiens id="0">a subset of the noun phrase in the annotated corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>A feature vector consists of 10 features described below , and is derived based on two extracted markables , i and j , where i is the antecedent and j is the anaphor .</sentence>
				<definiendum id="0">feature vector</definiendum>
				<definiens id="0">consists of 10 features described below , and is derived based on two extracted markables</definiens>
			</definition>
			<definition id="3">
				<sentence>If the selected semantic class of a markable is a subclass of one of our defined semantic class C , then the semantic class of the markable is C , else its semantic class is `` unknown '' .</sentence>
				<definiendum id="0">semantic class of a markable</definiendum>
				<definiens id="0">a subclass of one of our defined semantic class C , then the semantic class of the markable is C , else its semantic class is `` unknown ''</definiens>
			</definition>
</paper>

		<paper id="0613">
			<definition id="0">
				<sentence>A spelling rule might be a simple look-up for the string ( e.g. , a rule that Honduras is a location ) or a rule that looks at words within a string ( e.g. , a rule that any string containing Mr. is a person ) .</sentence>
				<definiendum id="0">spelling rule</definiendum>
				<definiens id="0">a location ) or a rule that looks at words within a string ( e.g. , a rule that any string containing Mr. is a person )</definiens>
			</definition>
			<definition id="1">
				<sentence>AdaBoost finds a weighted combination of simple ( weak ) classifiers , where the w'eights are chosen to minimize a function that bounds the classification error on a set of training examples .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">finds a weighted combination of simple ( weak ) classifiers , where the w'eights are chosen to minimize a function that bounds the classification error on a set of training examples</definiens>
			</definition>
			<definition id="2">
				<sentence>It is a sequence of proper nouns within an NP ; its last word Cooper is the head of the NP ; and the NP has an appositive modifier ( a vice president at S. &amp; P ) whose head is a singular noun ( president ) .</sentence>
				<definiendum id="0">Cooper</definiendum>
				<definiens id="0">a sequence of proper nouns within an NP ; its last word</definiens>
				<definiens id="1">the head of the NP ; and the NP has an appositive modifier ( a vice president at S. &amp; P ) whose head is a singular noun</definiens>
			</definition>
			<definition id="3">
				<sentence>Each xij is a member of A ' , where X is a set of possible features .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a set of possible features</definiens>
			</definition>
			<definition id="4">
				<sentence>Output of the learning algorithm : a function h : &amp; ' × y ~ \ [ 0 , 1\ ] where h ( x , y ) is an estimate of the conditional probability p ( ylx ) of seeing label y given that feature x is present .</sentence>
				<definiendum id="0">h</definiendum>
				<definiens id="0">an estimate of the conditional probability p</definiens>
			</definition>
			<definition id="5">
				<sentence>The label for a test example with features x is then defined as y ( x ) =arg max h ( x , y ) ( 1 ) xEx , yrY In this paper we define h ( x , y ) as the following function of counts seen in training data : Count ( x , y ) + ol h ( x , y ) = Count ( x ) +ks ( 2 ) Count ( x , y ) is the number of times feature x is seen with label y in training data , Count ( x ) = ~ueyC°unt ( x'Y ) '' a is a smoothing parameter , and k is the number of possible labels .</sentence>
				<definiendum id="0">y )</definiendum>
				<definiendum id="1">Count ( x ) = ~ueyC°unt ( x'Y ) '' a</definiendum>
				<definiendum id="2">k</definiendum>
				<definiens id="0">y ( x ) =arg max h ( x , y ) ( 1 ) xEx , yrY In this paper we define h ( x , y ) as the following function of counts seen in training data : Count ( x , y ) + ol h ( x , y ) = Count ( x ) +ks ( 2 ) Count ( x ,</definiens>
				<definiens id="1">the number of times feature x is seen with label y in training data</definiens>
				<definiens id="2">a smoothing parameter , and</definiens>
			</definition>
			<definition id="6">
				<sentence>Consider the case where IXll = \ ] Xa\ ] = N and N is a `` medium '' sized number so that it is feasible to collect O ( N ) unlabeled examples .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">a `` medium '' sized number so that it is feasible to collect O ( N ) unlabeled examples</definiens>
			</definition>
			<definition id="7">
				<sentence>The input to AdaBoost is a set of training examples ( ( Xl , Yl ) , .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">a set of training examples</definiens>
			</definition>
			<definition id="8">
				<sentence>We first define `` pseudo-labels '' , yi , as follows : Yi l &lt; i &lt; m Yi = sign ( g~-l ( x2 , i ) ) m &lt; i &lt; _ n Thus the first m labels are simply copied from the labeled examples , while the remaining ( n m ) examples are taken as the current output of the second classifier. We can now add a new weak hypothesis ht 1 based on a feature in P ( 1 with a confidence value oct 1 . ht 1 and tit 1 are chosen to minimize the function n Zclo = Z exp ( -- , Yi ( g~ -l ( xi ) + c~tlh~ ( xl , i ) ) ) '' ( 8 ) i=1 We now define , for 1 &lt; i &lt; n , the following virtual distribution , As before , Zt 1 is a normalization constant. Equ. ( 8 ) can now be rewritten 5 as n Z Dtl ( i ) exp ( - , Yi~h~ ( xl , i ) ) ' i=l which is of the same form as the function Zt used in AdaBoost. Using the virtual distribution Dtl ( i ) and pseudo-labels ~ ) i , values for W0 , W+ and W_ can be calculated for each possible weak hypothesis ( i.e. , for each feature x E ,121 ) ; the weak hypothesis with minimal value for W0 + 2~+W_ can be chosen as before ; and the weight for this weak hypothesis c~t = ½ In \ w_ +~ ) can be calculated. This procedure is repeated for T rounds while alternating between the two classifiers. The pseudo-code describing the algorithm is given in Fig. 2. The CoBoost algorithm described above divides the function Zco into two parts : Zco = Zclo + Zc2o • • On each step CoBoost searches for a feature and a weight so as to minimize either Zclo or Zc2o . In 5up to a constant factor Zt ~ which does not affect the minimization of Equ. ( 8 ) w.r.t , ht and at. 107 n m Input : { ( xl , i , x2 , i ) } i=l , { Yi } i=l Initialize : Vi , j : g° ( x/ ) = 0. Fort = 1 , ... . T and forj = 1,2 : • Set pseudo-labels : Yi l &lt; i &lt; m Yi = sign ( 9~- } ( x3_j , { ) ) m &lt; i _ &lt; n • Set virtual distribution : D { ( i ) = 1 -~exp ( -gig\ ] -I ( xj , i ) ) Zt where Zt 3 = E~=I exp ( -Yi9\ ] -1 ( xj , i ) ) . • Get a weak hypothesis ht 3 : 2A : J -- + IR. by training weak learner j using distribution D~. • Choose at 6 ~. • Update : t X -~\ ] -- l : x Vi : gj ( j , i ) g ~ j , i ) + c~th~ ( xj , i ) . Output final hypothesis : f ( x ) = sign ( E~=i gT ( Xj ) ) Figure 2 : The CoBoost algorithm. practice , this greedy approach almost always results in an overall decrease in the value of Zco. Note , however , that there might be situations in which Zco in fact increases. One implementation issue deserves some elaboration. Note that in our formalism a weakhypothesis can abstain. In fact , during the first rounds many of the predictions of gl , 92 are zero. Thus corresponding pseudo-labels for instances on which 9j abstainare set to zero and these instances do not contribute to the objective function. Each learner is free to pick the labels for these instances. This allow the learners to `` bootstrap '' each other by filling the labels of the instances on which the other side has abstained so far. The CoBoost algorithm just described is for the case where there are two labels : for the named entity task there are three labels , and in general it will be useful to generalize the CoBoost algorithm to the multiclass case. Several extensions of AdaBoost for multiclass problems have been suggested ( Freund and Schapire 97 ; Schapire and Singer 98 ) . In this work we extended the AdaBoost.MH ( Schapire and Singer 98 ) algorithm to the cotraining case. AdaBoost.MH maintains a distribution over instances and labels ; in addition , each weak-hypothesis outputs a confidence vector with one confidence value for each possible label. We again adopt an approach where we alternate between two classifiers : one classifier is modified while the other remains fixed. Pseudo-labels are formed by taking seed labels on the labeled examples , and the output of the fixed classifier on the unlabeled examples. AdaBoost.MH can be applied to the problem using these pseudolabels in place of supervised examples. For the experiments in this paper we made a couple of additional modifications to the CoBoost algorithm. The algorithm in Fig. ( 2 ) was extended to have an additional , innermost loop over the ( 3 ) possible labels. The weak hypothesis chosen was then restricted to be a predictor in favor of this label. Thus at each iteration the algorithm is forced to pick features for the location , person and organization in turn for the classifier being trained. This modification brings the method closer to the DL-CoTrain algorithm described earlier , and is motivated by the intuition that all three labels should be kept healthily populated in the unlabeled examples , preventing one label from dominating -this deserves more theoretical investigation. We also removed the context-type feature type when using the CoBoost approach. This `` default '' feature type has 100 % coverage ( it is seen on every example ) but a low , baseline precision. When this feature type was included , CoBoost chose this default feature at an early iteration , thereby giving non-abstaining pseudo-labels for all examples , with eventual convergence to the two classifiers agreeing by assigning the same label to almost all examples. Again , this deserves further investigation. Finally , we would like to note that it is possible to devise similar algorithms based with other objective functions than the one given in Equ. ( 7 ) , such as the likelihood function used in maximum-entropy problems and other generalized additive models ( Lafferty 99 ) . We are currently exploring such algorithms. The Expectation Maximization ( EM ) algorithm ( Dempster , Laird and Rubin 77 ) is a common approach for unsupervised training ; in this section we describe its application to the named entity problem. A generative model was applied ( similar to naive Bayes ) with the three labels as hidden vari108 ! ables on unlabeled examples , and observed variables on ( seed ) labeled examples. The model was parameterized such that the joint probability of a ( label , feature-sei ) pair P ( Yi , xi ) is written as P ( Yi , xi ) = P ( Yi , Xil '' . Ximi ) mi = P ( yi ) P ( mi ) N P ( xij\ ] Yi ) j=l ( 9 ) The model assumes that ( y , x ) pairs are generated by an underlying process where the label is first chosen with some prior probability P ( Yi ) ; the number of features mi is then chosen with some probability P ( mi ) ; finally th~ features are independently generated with probabilities P ( xij \ [ Yi ) . We again assume a training set of n examples { xl ... Xn } where the first m examples have labels { Yl ... ym } , and the last ( n m ) examples are unlabeled. For the purposes of EM , the `` observed '' data is { ( xx , ya ) i ... ( Xm , Ym ) , Xm+l ... Xn } , and the hidden data is { ym+l ... Yn } . The likelihood of the observed data under the model is m n k l~ P ( yi , xl ) × II ~ P ( y , xi ) i=1 i=m+l y=l ( 10 ) where P ( Yi , xi ) is defined as in ( 9 ) . Training under this model involves estimation of parameter values for P ( y ) , P ( m ) and P ( xly ) . The maximum likelihood estimates ( i.e. , parameter values which maximize 10 ) can not be found analytically , but the EM algorithm can be used to hill-climb to a local maximum of the likelihood function from some initial parameter settings. In our experiments we set the parameter values randomly , and then ran EM to convergence. Given parameter estimates , the label for a test example x is defined as f ( x ) = argum { ~xk } P ( x , y ) ( 11 ) We should note that the model in equation 9 is deficient , in that it assigns greater than zero probability to some feature combinations that are impossible. For example , the independence assumptions mean that the model fails to capture the dependence between specific and more general features ( for example the fact that the feature full'-string=New_York is always seen with the features contains ( New ) and Learning Algorithm Accuracy Accuracy ( Clean ) ( Noise ) Baseline EM ( Yarowsky 95 ) Yarowsky-cautious DL-CoTrain CoBoost 45.8 % 83.1 % 81.3 % 91.2 % 91.3 % 91.1 % 41.8 % 75.8 % 74.1 % 83.2 % 83.3 % 83.1 % Table 2 : Accuracy for different learning methods. The baseline method tags all entities as the most frequent class type ( organization ) . contains ( York ) and is never seen with a feature such as contains ( Group ) ) . Unfortunately , modifying the model to account for these kind of dependencies is not at all straightforward. 88,962 ( spelling , context ) pairs were extracted as training data. 1,000 of these were picked at random , and labeled by hand to produce a test set. We chose one of four labels for each example : location , person , organization , or noise where the noise category was used for items that were outside the three categories. The numbers falling into the location , person , organi z at i on categories were 186 , 289 and 402 respectively. 123 examples fell into the noise category. Of these cases , 38 were temporal expressions ( either a day of the week or month of the year ) . We excluded these from the evaluation as they can be easily identified with a list of days/months. This left 962 examples , of which 85 were noise. Taking Arc to be the number of examples an algorithm classified correctly ( where all gold standard items labeled no i s e were counted as being incorrect ) , we calculated two measures of accuracy : Nc Accuracy : Noise - ( 12 ) 962 Nc Accuracy : Clean ( 13 ) 962 85 See Tab. 2 for the accuracy ofthe different methods. Note that on some examples ( around 2 % of the test set ) CoBoost abstained altogether ; in these cases we labeled the test example with the baseline , organization , label. Fig. ( 3 ) shows learning curves for CoBoost. 109 1 `` . , .¢¢ '' ... ... ... ... ... ... ... ' ... ... ... ... . , ,. , , , ~.- '' Coverage : train -- -- * ... . .~ : Agreements : train ... .. • ... . 10 1 O0 1000 10000 Number of rounds Figure 3 : Learning curves for CoBoost. The graph gives the accuracy on the test set , the coverage ( proportion of examples on which both classifiers give a label rather than abstaining ) , and the proportion of these examples on which the two classifiers agree. With each iteration more examples are assigned labels by both classifiers , while a high level of agreement ( &gt; 94 % ) is maintained between them .</sentence>
				<definiendum id="0">E~=i gT</definiendum>
				<definiendum id="1">Again</definiendum>
				<definiendum id="2">P</definiendum>
				<definiendum id="3">maximum likelihood estimates</definiendum>
				<definiens id="0">the current output of the second classifier. We can now add a new weak hypothesis ht 1 based on a feature in P ( 1 with a confidence value oct 1 . ht 1 and tit 1 are chosen to minimize the function n Zclo = Z exp ( -- , Yi ( g~ -l ( xi ) + c~tlh~ ( xl , i ) ) ) '' ( 8 ) i=1 We now define , for 1 &lt; i &lt; n , the following virtual distribution</definiens>
				<definiens id="1">a normalization constant. Equ. ( 8 ) can now be rewritten 5 as n Z Dtl ( i ) exp ( - , Yi~h~ ( xl , i ) ) ' i=l which is of the same form as the function Zt used in AdaBoost. Using the virtual distribution Dtl ( i ) and pseudo-labels ~ ) i , values for W0 , W+ and W_ can be calculated for each possible weak hypothesis ( i.e. , for each feature x E ,121 ) ; the weak hypothesis with minimal value</definiens>
				<definiens id="2">CoBoost algorithm described above divides the function Zco into two parts : Zco = Zclo + Zc2o • • On each step CoBoost searches for a feature and a weight so as to minimize either Zclo or Zc2o . In 5up to a constant factor Zt ~ which does not affect the minimization of Equ. ( 8 ) w.r.t , ht and at. 107 n m Input : { ( xl , i , x2 , i ) } i=l , { Yi } i=l Initialize : Vi , j : g° ( x/ ) = 0. Fort = 1 , ... . T and forj = 1,2 : • Set pseudo-labels : Yi l &lt; i &lt; m Yi = sign ( 9~- } ( x3_j , { ) ) m &lt; i _ &lt; n • Set virtual distribution : D {</definiens>
				<definiens id="3">2A : J -- + IR. by training weak learner j using distribution D~. • Choose at 6 ~. • Update : t X -~\ ] -- l : x Vi</definiens>
				<definiens id="4">of the predictions of gl , 92 are zero. Thus corresponding pseudo-labels for instances on which 9j abstainare set to zero and these instances do not contribute to the objective function. Each learner is free to pick the labels for these instances. This allow the learners to `` bootstrap '' each other by filling the labels of the instances on which the other side has abstained so far. The CoBoost algorithm just described is for the case where there are two labels : for the named entity task there are three labels , and in general it will be useful to generalize the CoBoost algorithm to the multiclass case. Several extensions of AdaBoost for multiclass problems have been suggested ( Freund and Schapire 97 ; Schapire and Singer 98 ) . In this work we extended the AdaBoost.MH ( Schapire and Singer 98 ) algorithm to the cotraining case. AdaBoost.MH maintains a distribution over instances and labels ; in addition , each weak-hypothesis outputs a confidence vector with one confidence value for each possible label. We again adopt an approach where we alternate between two classifiers : one classifier is modified while the other remains fixed. Pseudo-labels are formed by taking seed labels on the labeled examples , and the output of the fixed classifier on the unlabeled examples. AdaBoost.MH can be applied to the problem using these pseudolabels in place of supervised examples. For the experiments in this paper we made a couple of additional modifications to the CoBoost algorithm. The algorithm in Fig. ( 2 ) was extended to have an additional , innermost loop over the ( 3 ) possible labels. The weak hypothesis chosen was then restricted to be a predictor in favor of this label. Thus at each iteration the algorithm is forced to pick features for the location , person and organization in turn for the classifier being trained. This modification brings the method closer to the DL-CoTrain algorithm described earlier , and is motivated by the intuition that all three labels should be kept healthily populated in the unlabeled examples , preventing one label from dominating -this deserves more theoretical investigation. We also removed the context-type feature type when using the CoBoost approach. This `` default '' feature type has 100 % coverage ( it is seen on every example ) but a low , baseline precision. When this feature type was included , CoBoost chose this default feature at an early iteration , thereby giving non-abstaining pseudo-labels for all examples , with eventual convergence to the two classifiers agreeing by assigning the same label to almost all examples.</definiens>
				<definiens id="5">possible to devise similar algorithms based with other objective functions than the one given in Equ. ( 7 ) , such as the likelihood function used in maximum-entropy problems and other generalized additive models ( Lafferty 99 ) . We are currently exploring such algorithms. The Expectation Maximization ( EM ) algorithm ( Dempster , Laird and Rubin 77 ) is a common approach for unsupervised training ; in this section we describe its application to the named entity problem. A generative model was applied ( similar to naive Bayes ) with the three labels as hidden vari108 ! ables on unlabeled examples , and observed variables on ( seed ) labeled examples. The model was parameterized such that the joint probability of a ( label , feature-sei ) pair P ( Yi , xi ) is written as P ( Yi , xi ) = P ( Yi , Xil '' . Ximi ) mi = P ( yi ) P ( mi ) N P ( xij\ ] Yi ) j=l ( 9 ) The model assumes that ( y , x ) pairs are generated by an underlying process where the label is first chosen with some prior probability P ( Yi ) ; the number of features mi is then chosen with some probability P ( mi ) ; finally th~ features are independently generated with probabilities P ( xij \ [ Yi ) . We again assume a training set of n examples { xl ... Xn } where the first m examples have labels { Yl ... ym } , and the last ( n m ) examples are unlabeled. For the purposes of EM , the `` observed '' data is { ( xx , ya ) i ... ( Xm , Ym ) , Xm+l ... Xn } , and the hidden data is { ym+l ... Yn } . The likelihood of the observed data under the model is m n k l~ P ( yi , xl ) × II ~ P ( y , xi ) i=1 i=m+l y=l ( 10 ) where P ( Yi , xi ) is defined as in ( 9 ) . Training under this model involves estimation of parameter values for P ( y )</definiens>
				<definiens id="6">i.e. , parameter values which maximize 10 ) can not be found analytically , but the EM algorithm can be used to hill-climb to a local maximum of the likelihood function from some initial parameter settings. In our experiments we set the parameter values randomly , and then ran EM to convergence. Given parameter estimates , the label for a test example x is defined as f ( x ) = argum { ~xk } P ( x , y ) ( 11 ) We should note that the model in equation 9 is deficient , in that it assigns greater than zero probability to some feature combinations that are impossible. For example , the independence assumptions mean that the model fails to capture the dependence between specific and more general features ( for example the fact that the feature full'-string=New_York is always seen with the features contains ( New ) and Learning Algorithm Accuracy Accuracy ( Clean ) ( Noise ) Baseline EM</definiens>
				<definiens id="7">the most frequent class type ( organization ) . contains ( York ) and is never seen with a feature such as contains ( Group ) ) . Unfortunately , modifying the model to account for these kind of dependencies is not at all straightforward. 88,962 ( spelling , context ) pairs were extracted as training data. 1,000 of these were picked at random , and labeled by hand to produce a test set. We chose one of four labels for each example : location , person , organization , or noise where the noise category was used for items that were outside the three categories. The numbers falling into the location</definiens>
				<definiens id="8">either a day of the week or month of the year ) . We excluded these from the evaluation as they can be easily identified with a list of days/months. This left 962 examples , of which 85 were noise. Taking Arc to be the number of examples an algorithm classified correctly ( where all gold standard items labeled no i s e were counted as being incorrect ) , we calculated two measures of accuracy : Nc Accuracy : Noise - ( 12 ) 962 Nc Accuracy : Clean ( 13 ) 962 85 See Tab. 2 for the accuracy ofthe different methods. Note that on some examples ( around 2 % of the test set ) CoBoost abstained altogether</definiens>
				<definiens id="9">Learning curves for CoBoost. The graph gives the accuracy on the test set , the coverage ( proportion of examples on which both classifiers give a label rather than abstaining ) , and the proportion of these examples on which the two classifiers agree. With each iteration more examples</definiens>
			</definition>
</paper>

		<paper id="0605">
			<definition id="0">
				<sentence>Cross-language information retrieval ( CLIR ) , where the user presents queries in one language to retrieve documents in another language , has recently been one of the major topics within the information retrieval community .</sentence>
				<definiendum id="0">Cross-language information retrieval</definiendum>
				<definiendum id="1">CLIR</definiendum>
				<definiens id="0">the user presents queries in one language to retrieve documents in another language , has recently been one of the major topics within the information retrieval community</definiens>
			</definition>
			<definition id="1">
				<sentence>Each document consists of the document ID , title , name ( s ) of author ( s ) , name/date of conference , hosting organization , abstract and keywords , from which titles , abstracts and keywords were used for our evaluation .</sentence>
				<definiendum id="0">document</definiendum>
				<definiens id="0">consists of the document ID , title , name ( s ) of author ( s ) , name/date of conference , hosting organization , abstract and keywords , from which titles , abstracts and keywords were used for our evaluation</definiens>
			</definition>
			<definition id="2">
				<sentence>Each query consists of the title of the topic , description , narrative and list of synonyms , from which we used only the description .</sentence>
				<definiendum id="0">query</definiendum>
				<definiens id="0">consists of the title of the topic , description , narrative and list of synonyms , from which we used only the description</definiens>
			</definition>
			<definition id="3">
				<sentence>The SYSTRAN NLP browser : An application of machine translation technology in multilingual information retrieval .</sentence>
				<definiendum id="0">SYSTRAN NLP browser</definiendum>
				<definiens id="0">An application of machine translation technology in multilingual information retrieval</definiens>
			</definition>
</paper>

		<paper id="0800">
</paper>

		<paper id="0703">
			<definition id="0">
				<sentence>The BOAS Project Boas \ [ Nirenburg , 1998 , Nirenburg and Raskin , 1998\ ] is a semi-automatic knowledge elicitation system that guides a team of two people through tile process of de~ veloping the static knowledge sources for a moderatequality , broad-coverage MT system from any `` lowdensity '' language into English .</sentence>
				<definiendum id="0">BOAS Project Boas</definiendum>
				<definiens id="0">a semi-automatic knowledge elicitation system that guides a team of two people through tile process of de~ veloping the static knowledge sources for a moderatequality , broad-coverage MT system from any `` lowdensity '' language into English</definiens>
			</definition>
			<definition id="1">
				<sentence>The box in Figure 2 labeled Morphological Analyzer Generation is the main component which takes in the information elicited and generates a series of regular expressions for describing the morphological lexicon and morphographemic rules .</sentence>
				<definiendum id="0">Morphological Analyzer Generation</definiendum>
				<definiens id="0">the main component which takes in the information elicited and generates a series of regular expressions for describing the morphological lexicon and morphographemic rules</definiens>
			</definition>
			<definition id="2">
				<sentence>20 u - &gt; 1 \ [ \ ] LeftContext _ RightContext ; where u ( pper ) is a symbol in the segmented form , l ( ower ) is a symbol in the surface form .</sentence>
				<definiendum id="0">u</definiendum>
				<definiens id="0">a symbol in the surface form</definiens>
			</definition>
			<definition id="3">
				<sentence>Two-level morphology : A general computational model for word form recognition and production .</sentence>
				<definiendum id="0">Two-level morphology</definiendum>
				<definiens id="0">A general computational model for word form recognition and production</definiens>
			</definition>
</paper>

		<paper id="0622">
			<definition id="0">
				<sentence>The Linguistic Data Consortium provides a preliminary version ( 1.075 ) of the Treebank 's bracketing of the Brown Corpus ( Ku~era and Francis , 1967 ) .</sentence>
				<definiendum id="0">Linguistic Data Consortium</definiendum>
			</definition>
			<definition id="1">
				<sentence>To this end , we propose a generative model which is a direct extension of a Probabilistic Context Free Grammar ( PCFG ) .</sentence>
				<definiendum id="0">generative model</definiendum>
			</definition>
			<definition id="2">
				<sentence>Labeled precision and recall ( Table 1 ) are the same as in other reports on statistical parsing : they measure how often a particular syntactic category was correctly calculated to span a particular portion of the input .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">they measure how often a particular syntactic category was correctly calculated to span a particular portion of the input</definiens>
			</definition>
			<definition id="3">
				<sentence>Link grammars allow for a probabilistic model with ternary head-headhead relations ( Lafferty et al. , 1992 ) .</sentence>
				<definiendum id="0">Link grammars</definiendum>
			</definition>
			<definition id="4">
				<sentence>The link grammar website reports that , on a test of their parser on 100 sentences ( average length 25 words ) of Wall Street Journal text , over 82 % of the labeled constituents were correctly calculated/ Some limited work has been done using u-ary lexical statistics .</sentence>
				<definiendum id="0">link grammar website</definiendum>
				<definiens id="0">reports that , on a test of their parser on 100 sentences ( average length 25 words ) of Wall</definiens>
			</definition>
			<definition id="5">
				<sentence>More interestingly , results from our small corpus indicate that WordNet ( or some ontology ) is necessary for n-ary statistics to be useful .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="6">
				<sentence>GPSM : A generalized probabilistic semantic model for ambiguity resolution .</sentence>
				<definiendum id="0">GPSM</definiendum>
				<definiens id="0">A generalized probabilistic semantic model for ambiguity resolution</definiens>
			</definition>
			<definition id="7">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="8">
				<sentence>X Syntax : A Study of Phrase Structure .</sentence>
				<definiendum id="0">X Syntax</definiendum>
				<definiens id="0">A Study of Phrase Structure</definiens>
			</definition>
			<definition id="9">
				<sentence>In Christiane Fellbaum , editor , WordNet : An Electronic Lexical Database , chapter 8 , pages 199-216 .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An Electronic Lexical Database , chapter 8</definiens>
			</definition>
			<definition id="10">
				<sentence>Selection and Information : A Class-Based Approach to Lexical Relationships .</sentence>
				<definiendum id="0">Selection</definiendum>
				<definiendum id="1">Information</definiendum>
			</definition>
</paper>

		<paper id="0208">
			<definition id="0">
				<sentence>The third section presents the antecedentlikelihood ( henceforth , AL ) theory , which is the way information collected by means of the annotation was organised so as to be used to resolve new cases of coreference in other dialogues .</sentence>
				<definiendum id="0">AL ) theory</definiendum>
				<definiens id="0">the way information collected by means of the annotation was organised so as to be used to resolve new cases of coreference in other dialogues</definiens>
			</definition>
			<definition id="1">
				<sentence>( 4 ) B : A '' B : A : and uh you know my own personal finances are well sure it 's just out but you have applied er for monies ( FNP ; im_12 ; st ; LS ; ) I keep hearing wherever I go Finally , a category named as discourse knowledge was used to classify cases in which the resolution required full processing of combined bits of discourse information .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">A ''</definiens>
			</definition>
</paper>

		<paper id="0619">
			<definition id="0">
				<sentence>First , we adopt an information-based framework ( Shannon , 1948 ) , quantifying the `` Information Content ' , ( IC ) '' of a word as the negative log likelihood of a word in a corpus .</sentence>
				<definiendum id="0">Information Content</definiendum>
				<definiendum id="1">IC )</definiendum>
				<definiens id="0">'' of a word as the negative log likelihood of a word in a corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>TF*IDF Following the standard definition in information theory ( Shannon , 1948 ; Fano , 1961 ; Cover and Thomas , 1991 ) the IC of a word is IC ( w ) = -log ( P ( w ) ) where P ( w ) is the probability of the word w appearing in a corpus and P ( w ) is estimatted as : _~2 where F ( w ) is the frequency of w in the corpus and N is the accumulative occurrence of all the words in the corpus .</sentence>
				<definiendum id="0">P ( w )</definiendum>
				<definiendum id="1">w )</definiendum>
				<definiendum id="2">N</definiendum>
				<definiens id="0">the probability of the word w appearing in a corpus</definiens>
				<definiens id="1">the frequency of w in the corpus</definiens>
				<definiens id="2">the accumulative occurrence of all the words in the corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>TF ( Term Frequency ) is the word frequency within a document ; IDF ( Inverse Document Frequency ) is the logarithm of the ratio of the total number of documents to the number of documents containing the word .</sentence>
				<definiendum id="0">TF</definiendum>
				<definiendum id="1">IDF</definiendum>
				<definiens id="0">the word frequency within a document ;</definiens>
				<definiens id="1">the logarithm of the ratio of the total number of documents to the number of documents containing the word</definiens>
			</definition>
			<definition id="3">
				<sentence>dj is the the frequency of word wi in document dj , N is the total number of 149 documents , Nw~ is the number of documents containing word w~ and M is the number of distinct stemmed words in document dj .</sentence>
				<definiendum id="0">dj</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">Nw~</definiendum>
				<definiendum id="3">M</definiendum>
				<definiens id="0">the the frequency of word wi in document dj ,</definiens>
				<definiens id="1">the total number of 149 documents ,</definiens>
				<definiens id="2">the number of documents containing word w~ and</definiens>
			</definition>
			<definition id="4">
				<sentence>IC is a matrix global in the domain of a corpus and each word in a corpus has a unique IC score .</sentence>
				<definiendum id="0">IC</definiendum>
				<definiens id="0">a matrix global in the domain of a corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>150 Rank 1 2 3 4 5 6 7 8 9 10 ICMost Informative IC Least Informative Words IC Words IC zophrin namel xyphoid wytensin pyonephritis orobuccal tzanck synthetic Rx quote 14.02725 14.02725 14.02725 14.02725 14.02725 14.02725 14.02725 14.02725 14.02725 14.02725 with on patient in she he for no day had Rank 1 2 3 4 5 6 7 8 9 10 Table I : IC Most and Least informative words TF*IDF Most Informative Words TF*IDF your vol tank sonometer papillary pancuronium name2 name3 incomplete yes TF*IDF Least Informative Words TF*IDF and 0.00008 a 0.00009 the 0.00009 to 0.00016 was 0.00020 of 0.00024 with 0.00034 in 0.00041 old 0.00068 year 0.00088 Table 2 : TF*IDF Most and Least informative words Informativeness and Accent Prediction In order to verify whether word informativeness is correlated with pitch accent , we employ Spearman 's rank correlation coefficient p and associated test ( Conover , 1980 ) to estimate the correlations between IC and pitch prominence as well as TF*IDF and pitch prominence .</sentence>
				<definiendum id="0">ICMost Informative IC Least Informative Words IC Words IC zophrin namel</definiendum>
				<definiens id="0">TF*IDF Most and Least informative words Informativeness and Accent Prediction In order to verify whether word informativeness is correlated with pitch accent , we employ Spearman 's rank correlation coefficient p and associated test ( Conover , 1980 ) to estimate the correlations between IC and pitch prominence as well as TF*IDF and pitch prominence</definiens>
			</definition>
			<definition id="6">
				<sentence>RIPPER is a system that learns sets of classification rules from training data .</sentence>
				<definiendum id="0">RIPPER</definiendum>
				<definiens id="0">a system that learns sets of classification rules from training data</definiens>
			</definition>
			<definition id="7">
				<sentence>HMM is a probability model which has been successfully used in many applications , such as speech recognition ( Rabiner , 1989 ) and part-of-speech tagging ( Kupiec , 1992 ) .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">a probability model which has been successfully used in many applications , such as speech recognition</definiens>
			</definition>
			<definition id="8">
				<sentence>A HMM is defined as a triple : ) ~= ( A , B , H ) where A is a state transition probability matrix , B is a observation probability distribution matrix , and H is an initial state distribution vector .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiendum id="1">H</definiendum>
				<definiens id="0">a triple : ) ~= ( A , B , H ) where A is a state transition probability matrix , B is a observation probability distribution matrix</definiens>
				<definiens id="1">an initial state distribution vector</definiens>
			</definition>
			<definition id="9">
				<sentence>Because of the limitation of the size of the speech corpus , we use a firstorder HMM where the following condition is assumed : P ( Qt+I -~i\ [ Qt = j , Qt-1 = k , . . . Q1 =n ) = P ( Qt+i =ilQt=j ) where Qt is the state at time t. Because we employ a supervised training process , no sophisticated parameter estimation procedure , such as the Baum-Welch algorithm ( Rabiner , 1989 ) is necessary .</sentence>
				<definiendum id="0">Qt</definiendum>
				<definiens id="0">a supervised training process , no sophisticated parameter estimation procedure</definiens>
			</definition>
			<definition id="10">
				<sentence>, N } F ( Qi =i ) ~'i= F ( Qi ) where N is the number of hidden states and M is the number of observations .</sentence>
				<definiendum id="0">N } F ( Qi =i ) ~'i= F ( Qi</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">M</definiendum>
				<definiens id="0">the number of hidden states and</definiens>
				<definiens id="1">the number of observations</definiens>
			</definition>
			<definition id="11">
				<sentence>For example , CABG is a common operation in this domain .</sentence>
				<definiendum id="0">CABG</definiendum>
				<definiens id="0">a common operation in this domain</definiens>
			</definition>
			<definition id="12">
				<sentence>We also show that IC is a more powerful measure of informativeness than TF*IDF for pitch accent prediction .</sentence>
				<definiendum id="0">IC</definiendum>
				<definiens id="0">a more powerful measure of informativeness than TF*IDF for pitch accent prediction</definiens>
			</definition>
			<definition id="13">
				<sentence>Transmission of Information : A Statistical Theory of Communications .</sentence>
				<definiendum id="0">Transmission of Information</definiendum>
				<definiens id="0">A Statistical Theory of Communications</definiens>
			</definition>
			<definition id="14">
				<sentence>In Christiane Fellbaum , editor , WordNet : An electronic lexical database , chapter 11 .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An electronic lexical database , chapter 11</definiens>
			</definition>
</paper>

		<paper id="0403">
			<definition id="0">
				<sentence>The Rosetta Stone TM is a successful CDROM based interactive program for teaching foreign languages , that uses speech comparison to help students improve their pronunciation .</sentence>
				<definiendum id="0">Rosetta Stone TM</definiendum>
			</definition>
			<definition id="1">
				<sentence>A zipper object implements a mapping from description A to description B in patches .</sentence>
				<definiendum id="0">zipper object</definiendum>
				<definiens id="0">implements a mapping from description A to description B in patches</definiens>
			</definition>
			<definition id="2">
				<sentence>A patch is a segment ( time-contiguous series of feature vectors ) of A that is mapped to a segment of identical length ( duration ) in B. A zipper is a series of compatible patches -- no overlaps , and the nth patch , timewise , in A is mapped to the nth patch in B. In the gaps between patches , A is mapped to B by interpolation .</sentence>
				<definiendum id="0">patch</definiendum>
				<definiens id="0">a segment ( time-contiguous series of feature vectors ) of A that is mapped to a segment of identical length ( duration ) in B. A zipper is a series of compatible patches -- no overlaps</definiens>
			</definition>
			<definition id="3">
				<sentence>A track ( A , B ) maps each feature vector of description A onto a feature vector of description B in a time non-decreasing fashion .</sentence>
				<definiendum id="0">track ( A , B )</definiendum>
				<definiens id="0">maps each feature vector of description A onto a feature vector of description B in a time non-decreasing fashion</definiens>
			</definition>
			<definition id="4">
				<sentence>The trackCost penalizes tracks where the timing of A relative to B is not uniform .</sentence>
				<definiendum id="0">trackCost</definiendum>
			</definition>
			<definition id="5">
				<sentence>Since a track maps each feature vector of A onto one of B , the trackValue is the sum of the vectorMatches of those pairs of vectors , divided by the null hypothesis value of the match of A. The vectorMatch ( Fa , Fb ) of a pair of feature vectors Fa , Fb is vectorMatch ( Fa , Fb ) = Fa .</sentence>
				<definiendum id="0">trackValue</definiendum>
				<definiens id="0">the sum of the vectorMatches of those pairs of vectors , divided by the null hypothesis value of the match</definiens>
			</definition>
			<definition id="6">
				<sentence>SUM ( i=I to m ) { min ( Fa\ [ i\ ] , Fb\ [ i\ ] ) } MAMI ( Fa , Fb ) ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... * l/m SUM ( i=I to m ) { max ( Fa\ [ i\ ] , Fb\ [ i\ ] ) } Thus if the features are random uniformly distributed random variables in the range 0 to 1 , the expected ( null hypothesis ) value of MAMI is V2 .</sentence>
				<definiendum id="0">SUM</definiendum>
			</definition>
</paper>

		<paper id="0617">
			<definition id="0">
				<sentence>Perplexity is an estimate of how well the language model is able to predict the next word of a test corpus in terms of the number of alternatives that need to be considered at each point .</sentence>
				<definiendum id="0">Perplexity</definiendum>
				<definiens id="0">an estimate of how well the language</definiens>
			</definition>
			<definition id="1">
				<sentence>The perplexity of a test set Wi , N is calculated as 2 H , where H is the entropy , defined as follows .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">H</definiendum>
				<definiens id="0">the entropy , defined as follows</definiens>
			</definition>
			<definition id="2">
				<sentence>The second term Pr ( WP ) is the POS-based language model and accounts for both the sequence of words and their POS assignment .</sentence>
				<definiendum id="0">WP )</definiendum>
				<definiens id="0">the POS-based language model and accounts for both the sequence of words and their POS assignment</definiens>
			</definition>
			<definition id="3">
				<sentence>One reason for the good performance of our POS-based model is that we use all of the information in the context in estimating the word and POS probabilities .</sentence>
				<definiendum id="0">POS-based model</definiendum>
				<definiens id="0">the information in the context in estimating the word</definiens>
			</definition>
			<definition id="4">
				<sentence>The n-best algorithm : An efficient procedure for finding top n sentence hypotheses .</sentence>
				<definiendum id="0">n-best algorithm</definiendum>
			</definition>
</paper>

		<paper id="0608">
			<definition id="0">
				<sentence>Decision trees have been successfully applied to a number of different NLP problems and , in particular , in POS tagging they have proven to be an efficient and compact way of capturing the relevant information for disambiguating .</sentence>
				<definiendum id="0">Decision trees</definiendum>
				<definiens id="0">an efficient and compact way of capturing the relevant information for disambiguating</definiens>
			</definition>
			<definition id="1">
				<sentence>Tagger RTT is a reductionistic tagger in the sense of Constraint Grammars ( Karlsson et al. , 1995 ) .</sentence>
				<definiendum id="0">Tagger RTT</definiendum>
			</definition>
			<definition id="2">
				<sentence>• Dictionary-related information : Does the target word contains any known word as a prefix ( or a suffix ) ?</sentence>
				<definiendum id="0">Dictionary-related information :</definiendum>
				<definiens id="0">Does the target word contains any known word as a prefix ( or a suffix</definiens>
			</definition>
			<definition id="3">
				<sentence>302 w/s 0.90 Mb Table 3 : Tagging accuracy , speed , and storage requirement of RTT and STT taggers The general methods for constructing ensembles of classifiers are based on four techniques : 1 ) Resampling the training data , e.g. Boosting ( Freund and Schapire , 1995 ) , Bagging ( Breiman , 1996 ) , and Cross-validated Committees ( Parmanto et al. , 1996 ) ; 2 ) Combining different input features ( Cherkauer , 1996 ; Tumer and Ghosh , 1996 ) ; 3 ) Changing output representation , e.g. ECOC ( Dietterich and Bakiri , 1995 ) and PWC-CC ( Moreira and Mayoraz , 1998 ) ; and 4 ) Injecting randomness ( Dietterich , 1998 ) .</sentence>
				<definiendum id="0">e.g. Boosting</definiendum>
				<definiendum id="1">4 ) Injecting randomness</definiendum>
				<definiens id="0">Tagging accuracy , speed , and storage requirement of RTT and STT taggers The general methods for constructing ensembles of classifiers are based on four techniques : 1 ) Resampling the training data</definiens>
			</definition>
			<definition id="4">
				<sentence>In particular , we have selected a set of seven functions that achieve a similar accuracy , namely : Gini Impurity Index , Information Gain and Gain Ratio , Chi-square statistic ( X2 ) , Symmetrical Tau criterion , RLM ( a distance-based method ) , and a version of RELIEF-F which uses the Information Gain function to assign weights to the features .</sentence>
				<definiendum id="0">RLM (</definiendum>
			</definition>
			<definition id="5">
				<sentence>oo % 12.44 % 12.75 % 18.23 % 19.60 % 17.21 % BestER 12.89 % 20.30 % 12.68 % 12.35 % 15.56 % 29.37 % 11.20 % 14.71 % 15.22 % 10.24 % 22.73 % 11.43 % 10.52 % 13.40 % 19.26 % Table 4 : classes Comparative results ( error rates ) of different ensembles on the most significant ambiguity Tagger RTT RTT ( cPD ) RTT ( ENS ) RTT ( cPD+ENS ) STT STT ( cPD ) STT ( ENs ) STT ( cPD+ENS ) STT + STT+ ( cPD ) STT+ ( ENS ) 5TT+ ( CPD+ENS ) Overall Known Ambig .</sentence>
				<definiendum id="0">cPD ) STT+</definiendum>
				<definiens id="0">classes Comparative results ( error rates ) of different ensembles on the most significant ambiguity Tagger RTT RTT ( cPD ) RTT ( ENS ) RTT ( cPD+ENS ) STT STT</definiens>
			</definition>
			<definition id="6">
				<sentence>In that table , TBL stands for Brill 's transformation-based error-driven tagget ( Brill , 1995 ) , ME stands for a tagger based on the ma×imum entropy modelling ( Ratnaparkhi , 1996 ) , SPATTER stands for a statistical parser based on decision trees ( Magerman , 1996 ) , IGTREE stands for the memory-based tagger by Daelemans et al. ( 1996 ) , and , finally , TComb stands for a tagger that works by combination of a statistical trigram-based tagger , 59 Tagger TBL ME SPATTER IGTREE TComb STT+ ( CPD+ENS ) Train Test 950 Kw 150 Kw 963 Kw 193 Kw ~975 Kw 47 Kw 2,000 kw 200 Kw 1 , i00 Kw 265 Kw Overall Known Unknown 96.6 % -82.2 % 96.5 % -86.2 % 96.5 % -- 96.4 % 96.7 % 90.6 % 97.2 % -- Ambig 998 Kw 175 Kw 97.2 % 97.5 % 84.5 % 92.8 % Table 6 : Comparison of different tuggers on the WSJ corpus TBL and ME ( Brill and Wu , 1998 ) .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiendum id="1">ME</definiendum>
				<definiendum id="2">SPATTER</definiendum>
				<definiendum id="3">IGTREE</definiendum>
				<definiendum id="4">TComb</definiendum>
				<definiens id="0">stands for Brill 's transformation-based error-driven tagget</definiens>
			</definition>
			<definition id="7">
				<sentence>Acknowledgments This research has been partially funded by the Spanish Research Department ( CICYT 's ITEM project TIC96-1243-C03-02 ) , by the EU Corn60 mission ( EuroWordNet LE4003 ) and by the Catalan Research Department ( CIRIT 's consolidated research group 1997SGR 00051 , and CREL project ) .</sentence>
				<definiendum id="0">EU Corn60 mission</definiendum>
				<definiens id="0">EuroWordNet LE4003 ) and by the Catalan Research Department ( CIRIT 's consolidated research group 1997SGR 00051</definiens>
			</definition>
			<definition id="8">
				<sentence>Part-of-Speech Tagging : A Machine Learning Approach based on Decision Trees .</sentence>
				<definiendum id="0">Part-of-Speech Tagging</definiendum>
				<definiens id="0">A Machine Learning Approach based on Decision Trees</definiens>
			</definition>
			<definition id="9">
				<sentence>BoosTexter : A system for multiclass multi-label text categorization .</sentence>
				<definiendum id="0">BoosTexter</definiendum>
				<definiens id="0">A system for multiclass multi-label text categorization</definiens>
			</definition>
</paper>

		<paper id="0906">
			<definition id="0">
				<sentence>Decipherment is driven by knowledge about the spoken language .</sentence>
				<definiendum id="0">Decipherment</definiendum>
				<definiens id="0">driven by knowledge about the spoken language</definiens>
			</definition>
			<definition id="1">
				<sentence>Given a particular character sequence ( `` ancient document '' ) , the EM algorithm searches for adjustments to the spelling model that will increase the probability of that character sequence .</sentence>
				<definiendum id="0">EM algorithm</definiendum>
				<definiens id="0">searches for adjustments to the spelling model that will increase the probability of that character sequence</definiens>
			</definition>
			<definition id="2">
				<sentence>Visible Speech : The Diverse Oneness of Writing Systems .</sentence>
				<definiendum id="0">Visible Speech</definiendum>
			</definition>
</paper>

		<paper id="0700">
</paper>

		<paper id="0616">
</paper>

		<paper id="0631">
			<definition id="0">
				<sentence>The data consists of a multiset of 'co-occurrence triples ' , each triple consisting of a noun lemma , verb lemma , and argument position .</sentence>
				<definiendum id="0">data</definiendum>
			</definition>
			<definition id="1">
				<sentence>7 For C C C , v E Vandr E 7~ , the association norm is defined as follows : A ( C , v , r ) p ( CIv ' r ) p ( CI ) For example , the association between the object position of eat and the set of concepts denoting kinds of food is expressed as follows : A ( &lt; food &gt; , eat , object ) .</sentence>
				<definiendum id="0">association norm</definiendum>
				<definiens id="0">follows : A ( C , v , r ) p ( CIv ' r ) p ( CI ) For example , the association between the object position of eat and the set of concepts denoting kinds of food is expressed as follows : A ( &lt; food &gt; , eat , object )</definiens>
			</definition>
			<definition id="2">
				<sentence>C c C , p ( C\ ] v , r ) is just the probability of the disjunction of the concepts in C ; that is , = Zp ( clv , r ) cEC In order to see how p ( clv , r ) relates to the input data , note that given a concept c , verb v and argument position r , a noun can be generated according to the distribution p ( n\ [ c , v , r ) , where p ( nlc , v , r ) = 1 nEsyn ( c ) Now we have a model for the input data : p ( n , v , r ) = p ( v , r ) p ( niv , r ) = p ( v , r ) p ( clv , rlp ( ntc , v , r ) cecn ( n ) Note that for c ¢ cn ( n ) , p ( nlc , v , r ) = O. The association norm ( and similar measures such as the mutual information score ) have been criticised ( Dunning , 1993 ) because these scores can be greatly over-estimated when frequency counts are low .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">the probability of the disjunction of the concepts in C</definiens>
			</definition>
			<definition id="3">
				<sentence>£ ( c , v , r ) _ P ( cI v , r ) ( Clr ) Let freq ( c , v , r ) , for a particular c , v and r , be the number of ( n , v , r ) triples in the data in which n is being used to denote c , and let freq ( v , r ) be the number of times verb v appears with something in position r in the data ; then the relevant maximum likelihood estimates , for c E C , v E 12 , r E 7~ , are as 260 follows .</sentence>
				<definiendum id="0">freq</definiendum>
				<definiens id="0">the number of ( n , v , r ) triples in the data in which n is being used to denote c , and let freq ( v , r ) be the number of times verb v appears with something in position r in the data ; then the relevant maximum likelihood estimates</definiens>
			</definition>
			<definition id="4">
				<sentence>The standard approach is to estimate freq ( c , v , r ) by distributing the count for each noun n in syn ( c ) evenly among all senses of the noun as follows : freq ( n , v , r ) freq ( c , v , r ) = ~ I cn ( n ) l nEsyn ( c ) where freq ( n , v , r ) is the number times the triple ( n , v , r ) appears in the data , and \ [ cn ( n ) \ ] is the cardinality of an ( n ) .</sentence>
				<definiendum id="0">freq</definiendum>
				<definiens id="0">to estimate freq ( c , v , r ) by distributing the count for each noun n in syn ( c ) evenly among all senses of the noun as follows : freq ( n , v</definiens>
				<definiens id="1">the number times the triple ( n , v , r ) appears in the data , and \ [ cn ( n ) \ ] is the cardinality of an ( n )</definiens>
			</definition>
			<definition id="5">
				<sentence>fr rn+l. eq ( c , v , r ) = freq ( n , v , r ) Am ( \ [ c'~ % r\ ] 'v'r ) m ( F , v , rl , v , r ) decn ( n ) Note that only nouns n in syn ( c ) contribute to the count for c. The count freq ( n , v , r ) is split among all concepts in 261 &lt; milk &gt; &lt; meal &gt; &lt; course &gt; &lt; dish &gt; &lt; delicacy &gt; ^ 0 freq ( ~ , eat , obj ) 15.4 ^ 0 freq ( ~ , obj ) ^ 0 freq ( ~ , eat , obj ) 78.0 ( 80.9 ) 24.7 ( 24.3 ) 82.3 ( 81.9 ) 27.4 ( 25.9 ) 221.4 ^ 0 freq ( ~ , obj ) = ^ Ev~v freq° ( ~ , v , obj ) 86.5 26.0 87.6 27.7 236.8 Table 1 : Contingency table for children of &lt; nutriment &gt; cn ( n ) according to the ratio £m ( \ [ c , v , r\ ] , v , r ) 5L~¢ .</sentence>
				<definiendum id="0">count freq</definiendum>
				<definiens id="0">split among all concepts in 261 &lt; milk &gt;</definiens>
			</definition>
			<definition id="6">
				<sentence>Hiding a Semantic Class Hierarchy in a Markov Model .</sentence>
				<definiendum id="0">Semantic Class Hierarchy</definiendum>
				<definiens id="0">in a Markov Model</definiens>
			</definition>
			<definition id="7">
				<sentence>Selection and Information : A Class-Based Approach to Lexical Relationships .</sentence>
				<definiendum id="0">Selection</definiendum>
				<definiendum id="1">Information</definiendum>
			</definition>
</paper>

		<paper id="0200">
</paper>

		<paper id="0313">
			<definition id="0">
				<sentence>A Common Ground Unit ( CGU ) contains all and only the utterance tokens needed to ground ( that is , make part of the common ground ) some bit of content .</sentence>
				<definiendum id="0">Common Ground Unit ( CGU )</definiendum>
				<definiens id="0">contains all and only the utterance tokens needed to ground ( that is , make part of the common ground ) some bit of content</definiens>
			</definition>
			<definition id="1">
				<sentence>Grounding ( which is what CGUs capture ) is mainly concerned with the understanding level ( and also the perception of messages ) , while there is a large part of the notion of response that is concerned with attitudinal reaction and not strictly mutual understanding .</sentence>
				<definiendum id="0">Grounding</definiendum>
				<definiens id="0">what CGUs capture ) is mainly concerned with the understanding level ( and also the perception of messages</definiens>
			</definition>
			<definition id="2">
				<sentence>The refinement indicates understanding of the original , and is thus part of the prior CGU , which presents the original , but it also'introduces new material ( the refinement itself ) , and thus also initiates a new CGU , which requires further signals of understanding to he added to the common ground .</sentence>
				<definiendum id="0">CGU</definiendum>
				<definiens id="0">presents the original , but it also'introduces new material ( the refinement itself</definiens>
			</definition>
			<definition id="3">
				<sentence>TRAINS dialogs consist of two human speakers , the system and the user .</sentence>
				<definiendum id="0">TRAINS dialogs</definiendum>
				<definiens id="0">consist of two human speakers , the system and the user</definiens>
			</definition>
</paper>

		<paper id="0509">
			<definition id="0">
				<sentence>In this paper , we report on our experience in buildmg computational semantic lexicons for use in NLP applications In a machine-graded approach , the computer reduces part of the semantic knowledge to be acquired by an acqulrer An overt semantics can help predict the syntactic behavior of words By overt semantics we mean applying the hnkmg or lexlcal rules at the semantic level and not on lexlcal base forms More specffically~ we address the different strategies of acqms~tlon arguing for an applicationdriven , training-intensive effort We also report on how to develop lexicons using off the shelf resources , and address multlhngual issues We will try to provide an assessment of the difficulties we encountered and some directions to bypass them Our experience in building computational semantic lexlcons which are used by Natural Language Processmg ( NLP ) systems comes from Mlkrokosmos , a knowledge-based machine translation system , 1 where texts from Spanish and Chinese are translated into Enghsh Mlkr0k~n~os adopts an xnterhnguabased approach ( Nlrenfurg et al , 1992 ) and all lexicons can be used for multdmgual analysis and generatmn each word is mapped to an mterhngua structure The lexicons built for Mlkrokosmos are multipurpose multlhngual to support translation or multflmgual generatmn tasks , reusable , that is , apphcable to several NLP tasks~ ( e g , generation , analysis , information extraction ) , and maintainable , that Is , supporting semi-automatic acquisition and restructuring of the lexicons The content of the Lexlcal Knowledge Base ( LKB ) ~s essentially the same ~rrespective of a particular application The types of information important for analysis and generation might differ , as suggested by Dale and Melhsh ( 1998 ) For instance , recording all the senses of a lexeme is more important for analysis than generation , conversely , knowing styhstlc mformation on words such as hzghfalutm or formal m 1For a descnptmn of Mlkrokosmos , see http//crl nmsu edu/Research/Projects/nukro/mdex html important for generation ( Hovy , 1988 ) The content of a multl-purpose LKB is apphcatlon Independent ( modulo its indexing m analysis the LKB Is Indexed on lexemes whereas for generation the LKB is indexed on concepts ) We argue , m section 2 that the acquisition process ~s apphcatmn-dependent Moleover we argue that defining the meamng of a word for NLP systems requires a training-intensive effolt In other words , the fact that we , as humans , understand texts does not entail that we can determine the `` computational '' meaning of a word Chomsklan trees are linguists ' constructs , not Innate structures A hngmst must be trained to be able to build syntactic patterns ( e g , trees ) In computational semantics , the same rule applies one must be trained to build the corresponding semantics ( e g frames , predicates , ) for a word In order to approach the `` computational '' meaning of a word , training Is the most important means we have to date to ensure consistency among acquuers Other means are to adopt an overt semantics with a machine-guided approach which directs as much as possible the acqulrer ( Section 3 ) This machine guided approach could also act behind the ' back '' of an acquner `` correcting ~ ' some mc0nslstencms m lexmal descnptlons between acqmrers , as will be shown m Sectmn 6 In Section 4 , we &amp; scuss our use of off the shelf lesources , such as WordNet ( Miller , 1990 ) , to accelerate the machine-graded acqmsltlon of the Enghsh lexicon by taking advantage of the existing database of synsets 2 whmh provide synonym lists for a lexeme We also show how a semantic-based approach , can help predict the syntactic behavior of words Note that the reverse ( predicting semantms from syntax ) is not true , as some experiments on Levm 's work ( 1993 ) have shown ( Sectmn 4 ) In Sectmn 5 , we address mulUlmgual issues in lexicon development The semantics of an entry is an underspecffied Text Meaning Representation ( TMR ) fragment ( e g , De2Synsets represent WordNet 's building blocks whmh are words , synonyms or Rear-synonyms , that can be used to refer to a given concept ( Miller , 1990 ) 62 \ [ \ ] fnse and Nlrenburg , 1991 ) Th , s TMR fragment can be a concept from the ontology or some lnterhngua structures such as att , tudes , modahtms , aspects , sets and TMR relatmns ( addltion , enumeratlon , compamson ) Concepts and lnterhngua structures can appear together or independently The ontology , to which lexemes are mapped , conmsts of concepts ( named sets of property-value pairs ) organized hlerarchmally along subsumptlon hnks , w~th an average of 14 relational hnks ( such as ISA , SUBCLASS , AGENT , THEME-OF , HEADED-BY , HAS-MEMBER ) per concept ( Mahesh , 1996 ) In a multflmgual enwronment , the main practical advantage of connectmg the lexlcon to an ontology is cost-effect , veness , as only the `` language-dependent '' propertms have tO be acquired when adding new natural laffh~iages to the system The mapping between a word and the ontology is the most difficult task of lexicon acquisition , and requires to develop the most cost-effective approach in terms of trmmng and strategms 2 1 Importance of Training The expemment reported below shows that training is essential to determine the `` computational '' meanmg of a word A native spea\ ] ~er of Spanish , who had not taken part m the lexacon traanmg process , was asked to add some senses to entries m the Spanish lexicon Thls was mainly done for testing the analyzer , as there were only 23 out of 167 words which were ambiguous m one text we were analyzing But we also d~scovered thls was a very useful exercise for testing the quahty of a semantic lexicon The list of added senses was reviewed by two computational hngmsts , one in charge of supervising the training and the other with proficiency m our framework who had seen entries as they were used by the analyzer but had not taken part to the training process either The untrained acqmrer , hereafter UNACQ , added a total of 111 to 55 open class words or so Among these 55 words where ambiguity had been added , 33 were already ambiguous in the Spanzsh lexicon After a closer look at the Spanish lexicon , and at the senses retrieved by the semantic analyzer , and after doing an on-hne corpora search , the computational hngulsts accepted less than 20 new senses among the 111 suggested This `` overge , aeratlor~ '' of senses by UNACQ had different origins 1 ) the analyzer did not present all the senses from the Spanlsh lexicon to UNACQ , it only presented the ones that were accepted after syntactic binding , u ) the senses added by UNACQ were `` equivalent '' to the senses already in the Spanish lexicon , but not recogmzed by UNACQ , as they were acquired as `` unspecffied '' in the Spanish lexicon , m ) UNACQ hardcoded non-hteral meanings of the words , iv ) the addition of senses was MRD-dnven UNACQ acquired the list of meanings provzded by the Spanlsh-Enghsh Larousse and Colhns , adopt , ng an enumeration approach Such a task Is not superficial , it ensures that the quahty of the core lexicon , s good enough so that it can serve as a basis for lexicon expansion techtuques , some of which we develop below ( see Vmgas ( 1999 ) for the choices an acqu , rer faces when workmg out the semantic mapping Of a word ) There are mainly two approaches to word sense assignment corpus-dr , yen and mental-driven The former is better adapted to braiding lexicons used m analysis , whereas the latter better suits lexicons to be used in generation We refer to Kllganff ( 1997 ) for the corpus-driven approach , and discuss m this paper the mental-driven .</sentence>
				<definiendum id="0">TMR fragment</definiendum>
				<definiendum id="1">ontology</definiendum>
				<definiens id="0">computational semantic lexicons for use in NLP applications In a machine-graded approach , the computer reduces part of the semantic knowledge to be acquired by an acqulrer An overt semantics can help predict the syntactic behavior of words By overt semantics we mean applying the hnkmg or lexlcal rules at the semantic level</definiens>
				<definiens id="1">training-intensive effort We also report on how to develop lexicons using off the shelf resources , and address multlhngual issues We will try to provide an assessment of the difficulties we encountered and some directions to bypass them Our experience in building computational semantic lexlcons</definiens>
				<definiens id="2">supporting semi-automatic acquisition and restructuring of the lexicons The content of the Lexlcal Knowledge Base ( LKB ) ~s essentially the same ~rrespective of a particular application The types of information important for analysis</definiens>
				<definiens id="3">e g frames , predicates , ) for a word In order to approach the `` computational '' meaning of a word</definiens>
				<definiens id="4">an underspecffied Text Meaning Representation ( TMR ) fragment ( e g</definiens>
				<definiens id="5">ontology , to which lexemes are mapped , conmsts of concepts ( named sets of property-value pairs ) organized hlerarchmally along subsumptlon hnks</definiens>
				<definiens id="6">they were used by the analyzer but had not taken part to the training process either The untrained acqmrer</definiens>
				<definiens id="7">at the senses retrieved by the semantic analyzer , and after doing an on-hne corpora search , the computational hngulsts accepted less than 20 new senses among the 111 suggested This `` overge , aeratlor~ '' of senses by UNACQ had different origins</definiens>
			</definition>
			<definition id="1">
				<sentence>in mm 63 the part of speech and the polysemy count Bihngum dictionaries , filtered by a native speaker of the foreign language , are used for the translations into English ( for the acquisition of languages other than English ) In order to increase speed at acqulsitmn time , each acqmrer works on one type of Mapping-Tag at a time For instance , some acqmrers work on type OBJECT Type OBJECT call only be lexlcahzed into nouns , e g DEVICE -+ devzce instrument tool apphance Others work on the type EVENT ~VENTS can be lexlcahzed into nouns , e g EXPLODE -- ~ bombzn9 , bombardment , or into verbs bomb , bombard , drop_bombs_on , throw_bombs_at In order to increase consistency , acquIrers go through specially designed trammg sessions Syntax : A Machine-guided Approach Mappings between semantic roles and syntacUc complements axe defined via a mapping ( a rule ) These mappings can be defined for large sub-classes of lexical entries For example , the rule Atl ; -Pred-Adj creates an entry which accepts in the semantic feature a concept from the subtree of ATTRIBUTE or an ATTITUDE and accepts attributive ( e g safe car ) and predlcat , ve uses ( e g the car zs sa\ ] e ) In the case of an adjecUve mapped to a RELATION ( e g MENTAL-OBJECT-RELATION ) the preferred rule would be Att-Adj generating an attributive reading ( e g , dental practzce ) , and not ( ~the practice ~s dental ) By selecting the appropriate mapping for classes of entries , it is possible to hide the mapping from the acqulrer since these mappings are defined in a lexlcal class , not m an instance As defined by an acqulrer , an entry looks as follows \ [ key `` safe '' , syn Att-Pred-Adj , sem \ [ name Safety-Attrlbute , range Safe\ ] \ ] , During compilation of the dictionary , the Att-Pred-Ad 3 label is replaced with its definition and makes explicit the co-reference between the subcategorization and the semantics So far we have developed for the English lexicon about twenty syntactic patterns whmh apply to a large number of semantic frames In the case of adjectives , we have 3 rules , one for attributive adjectives , another one for predicative adjectives , and a third one for attributive adjective used predicatively In the case of nouns , we have developed four patterns as Illustrated below Subcat pattern Example ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... . weapon NObllOpt father ( of two ) NObll-0bl20pt bomblng of Iraq ( by the US ) NObllOpt-Obl2Opt computatlon ( of the bank reserve ) ( by its clerks ) We presented above the labels of subcategorlzation patterns as they appear at acqms~tlon time At processing time , there is no difference between Obll and Ob12 , which are both of type Oblique Our machine-graded approach helps the acqmrer to select a rule as it only presents the relevant ones for a specffic semantic type For instance , in the case of a lexeme mapped to an OBJECT no rules having obliques will be presented to the acqmrer as described below example semantzcs subeat lexlcal class ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. weapon 0hi N 0bin father .</sentence>
				<definiendum id="0">entry</definiendum>
				<definiens id="0">the part of speech and the polysemy count Bihngum dictionaries , filtered by a native speaker of the foreign language</definiens>
				<definiens id="1">OBJECT call only be lexlcahzed into nouns , e g DEVICE -+ devzce instrument tool apphance Others work on the type EVENT ~VENTS can be lexlcahzed into nouns , e g EXPLODE -- ~ bombzn9 , bombardment , or into verbs bomb , bombard , drop_bombs_on , throw_bombs_at In order to increase consistency , acquIrers go through specially designed trammg sessions Syntax : A Machine-guided Approach Mappings between semantic roles and syntacUc complements axe defined via a mapping ( a rule ) These mappings can be defined for large sub-classes of lexical entries For example , the rule Atl ; -Pred-Adj creates an entry which accepts in the semantic feature a concept from the subtree of ATTRIBUTE or an ATTITUDE and accepts attributive ( e g safe car ) and predlcat , ve uses ( e g the car zs sa\ ] e ) In the case of an adjecUve mapped to a RELATION ( e g MENTAL-OBJECT-RELATION ) the preferred rule would be Att-Adj generating an attributive reading ( e g , dental practzce )</definiens>
				<definiens id="2">looks as follows \ [ key `` safe '' , syn Att-Pred-Adj , sem \ [ name Safety-Attrlbute , range Safe\ ] \ ] , During compilation of the dictionary , the Att-Pred-Ad 3 label is replaced with its definition and makes explicit the co-reference between the subcategorization and the semantics So far we have developed for the English lexicon about twenty syntactic patterns whmh apply to a large number of semantic frames In the case of adjectives</definiens>
				<definiens id="3">by the US ) NObllOpt-Obl2Opt computatlon ( of the bank reserve ) ( by its clerks ) We presented above the labels of subcategorlzation patterns as they appear at acqms~tlon time At processing time</definiens>
			</definition>
			<definition id="2">
				<sentence>type 'Event ' and therefore subcategorlze for two obhques ( Obl ) the former must be Obj whereas the latter can be either Obj or Event These Obl can be optional ( Opt ) Acqmrers may specify the preposition ( head of the oblique or preposlUonal phrase ) For Instance , in the case of lather , once an acqulrer has mapped the word to the concept ' Father '' which is a Prop ( Property ) the acquisition tool presents the subcategorizatmn NObllOpt This allows the acquirer to select wluch prepositlon ( s ) can go with the range of Father ( in this case `` of '' will be selected ) This Information is important in generation For generation , one must specify , at acquisition tlme , whether or not one can say the bombing o/Iraq , the bombing of Iraq by the US ~ the bombing by the US It also helps in word sense dxsamblguation In the case of verbs , one can also define lexicosyntactic classes for different semantic classes For instance , in the case of ASSERTIVEACT the lexemes mapped to it will accept a comp clause ( e g he A 64 sazd ( that , ) he would come ) One class of aspectuals subcategonzes for nps ( e g I started a new book ) , xcomps ( e g I started reading/Tinting a new book ) , and accepts the intransitive alternation when the grammatical object is of type Event ( e g the surgery started very late ) 3 In this section , we briefly discuss how to extend a lexmon using denvatlonal morphology , and off the shelf resources such as WordNet ( Miller , 1990 ) to propagate the English lexicon with synonyms , and Levm 's database of subcategonzatlons and alternations for Enghsh verbs ( Levm , 1993 ) to encode syntactic information m the verb entries 4 Morphology We refer the reader to Vmgas et al ( 1996 ) for the details on this type of acquisition and theoretical background of Lexlcal Rules ( LRs ) To sketch this operation briefly , applying morpho semantic LRs to the entry for the Spanish verb comprar ( buy ) , our acquisition system produced automatically 26 new entries ( comprador-N1 ( buyer ) , comprable-Ad\ ] ( buyable ) , etc ) This includes creating new syntax , semantics and syntax-semantm mappings with correct subcategomzations and also the right semantics For instance , the lexmal entry for comprable will have the subcategonzatlon for predicative and attributive adjectives and the semantics adds the attribute FEASIBILITYATTRIBUTE to the basic meaning BuY of comprar ( Vmgas et al , 1996 ) describes about 100 morpho-semantlc LRs , which were applied to 1056 verb citation forms with 1,263 senses among them The rules helped acquire an average of 26 candidate new ~ntrms per verb sense This produced a total of 31,680 candidate entries , with an average of over 90 % and 85 % correctness in the assignment of syntax and semantics respectively LRs constitute a powerful tool to extend a core lexicon from a monohngual viewpoint We present other ways of extending lexicons , from monohngual ( next paragraph ) and multlhngual ( Section 5 ) perspectives 4 2 Using WordNet WordNet has been used as follows We extracted the synsets assooated with a lexeme using fuzzy string matches between , on the one hand , the value of the ontological concept ( e g , DESIRE ) , its defimtlon ( e g , for DESIRE `` to want something '' ) and the concept and definition of ~ts corresponding ISA concept ( e g , INTEND ) and , on the other hand , the direct hypernyms and hyponyms for the lexeme m 3See Vmgas et al ( 1999 ) for the details on the web raterfaces used for the acqulsltmn 4See Vlegas et al ( 1998 ) for more details WordNet synsets For instance , for the English verb expect , mapped to the ontological concept DESIRE our algorithm only kept one synset hope , expect , trust , deswe for expect and the following synsets for Its hypernyms wzsh , des : re , want The output of our automatlc procedure and manual filtering Is illustrated below for the ontological concept DESIRE , along with the synonyms from WordNet belonging to the same ontological class DESIRE want expect trust wish All these lexemes will be mapped to the concept DESIRE and minimally accept the same subcategomzatlons ( e g np-v-np-xcomp as in I want you to /eel comfortable ) We should mention that this step also Involved some manual filtering by acqulrers We used a machine-guided mode to help the acqulrer in this task This type of filtering was done very quickly , mainly due to the fact that WordNet is orgamzed on a semantic basis One of the major problems m using Levm 's database was filtering out homonyms , as classes in Levm 's database are defined on the basis of the same subcategonzatlon pattern ( as seen in alternations ) and not on a semantic basis , as shown by many researchers s The advantage of our approach is that ~t is semantic-based , this allows us to organize verbs into true ( frame-based ) semantic classes , with their associated sets of subcategonzatlons Therefore , we can pledlct that all velbs belonging to a particular semantra class Will have the Same syntactic behavior For instance , if one considers the serhantm class of aspectual verbs which selects a theme of type Event , e g begin , continue , finzsh , then one can minimally associate to any verb belonging to this semantic class the following subcategonzatlons ( a ) NP-V-NP m John began h : s homework , ( b ) NP-V-XCOMP John began to work//workzng Note that the reverse is not necessarily true verbs which accept ( a ) and ( b ) are not necessarily aspectuals , e g forget in I forgot the key or I forgot to brzng the key In thls sectlon , -we briefly address what can be generahzed to multiple languages The methodologms described here are part of what is needed to build 5Many experiments have resulted m a sumlar finding , as described In ( Dorr et al , 1997 ) , ( Dang et al , 1997 ) SamtD~z~er ( 1996 ) also showed that these classes do not apply easfly to French 65 a multi-purpose LKB while keeping the costs of acqmsltmn as low as possible By mapping lexemes to concepts , it is possible to create lexicons for dufferent languages , at a mmlmum cost , once a core lexicon has been acquired Th~s task can be further accelerated if one has access to blhngual d~ctmnames to semi-automate the translatmn task Finally , if one has access to a rlch structured ontology ( as is the case in Mlkrokosmos ) then dynamic procedures ( e g , generalization , speciahzatmn ) can help the acqulrer in `` filling '' the gap m the case of lexlco-semantm mismatches ( e g , cook , bake ~ cuwe ) Multflinguahty : Morpho : semantics All the LRs ( e g , LR2agent-o\ ] ) developed for Spanlsh can be used to extend other languages , even unrelated ones , in other words , these rules are language mdependent The morpho-semant , c aspect of the LRs is , however , specific to particular languages But , in order to benefit from the work done on morpho-semantlc LRs , we separated the assignmeat of affixes from the assignment of LRs In other words , if m Spanish LR~agent-of m ass~ghed to say the suffix -dot , by translating suffixes between languages , ( -dot -+ -cur in French ) , the French lexlcon can be extended m the same way ( comprador -- + acheteur ) Again , this work will necesmtate some manual checking , because of some overgeneration , which can not be accepted for generation But overall , one can use the same methodology , the same LRs and engine to produce new entries MultihnguahtY The subcategonzatlons attached to a lexeme have an even more idiosyncratic behavmr than lexlcal LRs But here agam , the rules we developed can be applied at least to family-related languages , and then filtered out by a human For mstance , the Spanish word comer has the pattern np-v-np associated to it ( e g Juan come una pera ) , so this same pattern will be attached to the translatmn of comer ( eat ) as m ( Juan eats a pear ) However , gomg from Spanish to English , one misses all the alternatmns ( Lewn , 1993 ) not common in Spanish such as John gave Mary a book The MIkrokosmos lexicon acqulmtlon group has acquired the following data Spanish lexicon 7,000 word sense entrms ( 35,000 word sense entries after applying the morpho-semantm lexlcal rules ) , Chinese lexicon about 3,000 word sense entries , and Enghsh , about 15,000 word sense entrms so far For instance , the acquisition of 15,000 word sense entries took one year and involved 50 % of the time of a computational hngmst ( to develop the methodology , train the acqulrers and design the GUIs ) , 50 acqmrer hours per week , 10 hours per week of a programmer to tmplement the GUIs , mamtam the tools and test the entries Our approach to the development of lex , cons differs from others m that our rules apply directly to semantlc frames and not to the basic forms of verbs Our methodology allows us to alleviate the burden of manual checking by applying linking rules directly on the semantics of the lexemes Some rules add discourse related features , such as focus m some alternations , e g , they zmproved the s~tuatwn -- + the s~tuatzon zmproved What is Important to evaluate is how much do we gam by using rules and other resources Today , ~t ~s still d~fficult to say exactly how much Adequately predicting the subcategonzatlons for a semantic class depends on its gram size the finergrained , the better the pred2ctwn wall be However , m NLP apphcatlons , where one Is constramed by tlme , only the semantics necessary for a particular application is acquired , which means that m many cases the semantms is left at a coarser grain s~ze than the one required to predict the subcategomzatlons In practice , we overgenerate some subcategortzatlons and need therefore to have them checked by humans This ~s why we have concentrated on a small set of rules Results on that trade-off issue have been reported in Vmgas et al ( 1998 ) Our experience in large-scale acqulsltmn of lexicons shows that Idiosyncrasies overrule many of our general rules This is mainly due to the fact that we need a more fine-gramed semantms than the one which is available now This , s not just a criticism of our framework , , t is a genelal fact that we all encounter when mvestlgatmg lexlcal semantics This might be due to the fact that we work m a synchronic perspective ( a highly recommended approachl ) , whereas language evolves constantly , thus creatmg `` artificial '' ldmsyncrasms In any case one can not avold them when butldmg a computatmnal semantic lexicon We have also learnt dunng the acquisition of the Mtkrokosmos lexmons that different acqulrers , who have been through the same Intensive tralmng , will arrive at the same numbel of meanings for a word , in more than 90 % of the cases The meaning of a word might differ , for different trained acqulrers , along ISA links Corpora also Influence the decision of the acqmrers , and here too we have seen some human `` mconsltencms '' which we thmk could be `` corrected '' automatically , as discussed in the followmg section 66 We are investigating the msue of taking into account mconmstent lex~cal descnptmns between the lexicon acqmrers by taking advantage of the semantm tarotmatron encoded in the ontology If we look at the following data and their subcategonzatlons ( 1 ) I fixed the meal \ [ NP1 , NP2\ ] ( 2 ) I fixed a sandwlch for you \ [ NP1 , NP2 , PP1\ ] ( 3 ) I fixed you a sandwich \ [ NP1 , NP3 , NP2\ ] where fix means PREPAREFOOD , then one must subcategonzatmns m between square brackets are assocmted to the lexmal ~tems mapped to A , B and C ACREATEINGEST \ [ NP1 , NP2 , PP1 , PP2 , \ ] allow the analysm and generation of any of sentences ( 1 ) , ( 2 ) and ( 3 ) , whether there is a mapping of fix s CREATEINGESTBENEF C CREATEINGESTTHEME onto the concepts A or B or C 6 \ [ NPI , NP3 , NP2\ ] \ [ NPI , NP2\ ] \ [ NPI , NP2 , PPI\ ] ACREATEINGEST \ [ ARGI , ARO2 , ARQ3 , ARC4 , \ ] B CREATEINGESTBENEF CCREATEINGESTTHEME \ [ ARGI , ARG2 , ARG3\ ] \ [ ARGI , haG2\ ] Looking at example ( 1 ) , and m absence of examples ( 2 ) and ( 3 ) in the corpus , fix could easily be mapped into A or C , whereas with examples ( 2 ) and ( 3 ) , and m absence of example ( 1 ) m the corpus , ~t could be easily mapped into A or B by the acqmrers We clmm that thin is of no importance as far as there are mechamsms to go from one to the other This requires to have access to semantic reformation The dmgram above is a computational hngumt construct and has no `` reality '' per se B and C are constructs which provide for every semantic class the different semantic patterns that a particular semantic class accepts , such as the pattern CREATEINGESTBENEF requires 3 semantm arguments ( AGENT , BENEFICIARY and THEME ) , whereas CREATEINGESTTHEME only reqmres 2 semantic arguments In this case , thin means that the BENEFICIARY IS optional , a fact the acqmrer `` failed '' to recogmze This diagram can be further specified for a particular natural language , where the required arguments are mapped to syntactic arguments and where lexlcal rules for a particular language provide the link between the different semantic patterns for a semantic class The dmgram below is for English where 6We g*ve the general diagram for CREATEINGEST events , as PREPAREFOOD is a subtype and will inherit all the properties of the semantic class CREATEINGEST The corpus can indeed Influence the way a lexicon acqmrer will do the mapping So if a lexicon acqmrer creates an unspecffied entry ( mapping fix on ( A ) , as opposed to ( B ) or ( C ) ) , dynamic mechamsms such as speclahzatlon or generahzatmn would enable the system to get to ( B ) and ( C ) from ( A ) and vice versa ( to ( A ) from ( B ) or ( C ) ) Moreover , ff a lexicon acqmrer decides to map to ( B ) instead of ( C ) or vine versa , then a lexmal rule ( LR ) between ( B ) and ( C ) will enable the system to go from ( B ) to ( C ) and wce versa In other words , although there are three potentrolly different ways of writing the lexlcon entry for fix for example sentences ( 1 ) , ( 2 ) and ( 3 ) , these different ways of encoding fix should remain a virtual difference at processing t~me the system must encode mechanisms and rules to `` interpret '' and reconcile the different points of wew of different acqmrels This enables the system to process sentences ( 1 ) , ( 2 ) and ( 3 ) from any of the three p0tentml lexicon entries We beheve that an unportant msue m computational semantics m to study how lexicon entries could be dynamically changed to fit different hngmstic contexts and different acqmrers ' analysis of the data This is what we plan to investigate m our future research Acknowledgments .</sentence>
				<definiendum id="0">PREPAREFOOD</definiendum>
				<definiens id="0">specify the preposition ( head of the oblique or preposlUonal phrase</definiens>
				<definiens id="1">the acquirer to select wluch prepositlon ( s ) can go with the range of Father</definiens>
				<definiens id="2">describes about 100 morpho-semantlc LRs , which were applied to 1056 verb citation forms with 1,263 senses among them The rules helped acquire an average of 26 candidate new ~ntrms per verb sense This produced a total of 31,680 candidate entries</definiens>
				<definiens id="3">selects a theme of type Event , e g begin , continue , finzsh , then one can minimally associate to any verb belonging to this semantic class the following subcategonzatlons ( a ) NP-V-NP m John began h : s homework , ( b ) NP-V-XCOMP John began to work//workzng Note that the reverse is not necessarily true verbs which accept ( a ) and ( b ) are not necessarily aspectuals</definiens>
				<definiens id="4">50 acqmrer hours per week , 10 hours per week of a programmer to tmplement the GUIs , mamtam the tools and test the entries Our approach to the development of lex</definiens>
				<definiens id="5">a computational hngumt construct and has no `` reality '' per se B and C are constructs which provide for every semantic class the different semantic patterns that a particular semantic class accepts</definiens>
				<definiens id="6">a particular natural language , where the required arguments are mapped to syntactic arguments and where lexlcal rules for a particular language provide the link between the different semantic patterns for a semantic class The dmgram below is for English where 6We g*ve the general diagram for CREATEINGEST events</definiens>
				<definiens id="7">a subtype and will inherit all the properties of the semantic class</definiens>
				<definiens id="8">opposed to ( B ) or ( C ) ) , dynamic mechamsms such as speclahzatlon or generahzatmn would enable the system to get to ( B ) and ( C ) from ( A ) and vice versa ( to ( A ) from ( B ) or ( C ) ) Moreover , ff a lexicon acqmrer decides to map to ( B ) instead of ( C ) or vine versa</definiens>
			</definition>
</paper>

		<paper id="0105">
			<definition id="0">
				<sentence>\ ] thepatient ( i.e. the house ) is essential for the interpretation of the sentence .</sentence>
				<definiendum id="0">] thepatient</definiendum>
				<definiens id="0">essential for the interpretation of the sentence</definiens>
			</definition>
</paper>

		<paper id="0503">
			<definition id="0">
				<sentence>tinguish the verb classes ~ In exploring these quesUons , we focus on verb classlficaUon for several reasons Verbs are very important sources of knowledge in many language engineering tasks , and the relationships among verbs appear to play a major role m the orgamzatmn and use of this knowledge Knowledge about verb classes is crucml for lex , cal acqmsltton m support of language generation and machine translatmn ( Dolt , 1997 ) and document cl~sfficatmn ( Klavans and Kan , 1998 ) , yet manual classfficauon of large numbers of verbs is a difficult and resource intensive task ( Levm , 1993 Miller et al , 1990 , Dang et al , 1998 ) To address these issues , we suggest that one can tram an automatic classffier for verbs on the basts of staUstmal approxlmaUons to verb dlatheses We use dlatheses -- alternatmns m the expression of the arguments of the verb -- following Levm and Dorr , for two reasons Fnst , verb dlatheses are syntacuc cues one strong assumptmn regarding the nature of the representatmns under study semantic notmns and syntacuc notmns are correlated , at least m part This assurapuon is under debate ( Bnscoe and Copestake , 1995 , Levm , 1993 , Dorr and Jones , 1996 , Dorr , 1997 ) , but we adopt ~t here without further dlscussmn 15 ' • to semantic classes , hence they can be more easily captured by corpus-based techniques Second , using verb d~atheses reduces no , se There ~s a certain consensus ( Bnscoe and Copestake , 1995 , Pustejovsky , 1995 , Palmer , 1999 ) that verb dmtheses are regular sense extensmns Hence focussing on thin type of classfficatmn allows one to abstract from the problem of word sense dmamb , guatmn and treat remdual d~fferences m word senses as no~se m the classfficatmn task We present an m-depth case study , m which we apply machine learning techmques to automaUcally classify a set of verbs based on d~stnbutmns of grammaucal indicators of dmtheses , extracted from a very large corpus We look at three very mterestmg classes of verbs unergaUves , unaccusauves , and obJect-drop verbs ( Levm , 1993 ) These are Interestmg classes because they all parUcapate m the trans~uvlty alternatmn , and they are minimal parrs that as , a small number of well-defined dmtmctmns d~fferentmte their trans , tlve/mtranmUve behavmr Thus , we expect the differences m their dmtnbuttons to be small , entailing a fine-grained dlscr , mmaUon task that prowdes a challenging testbed for automatic classfficatmn The specffic theoretical questmn we mvesUgate ~s whether the factors underlying the verb class dmtmctmns are reflected m the statmttcal dmtnbutmns of lex~cal features related to dmtheses presented by the md , v~dual verbs m the corpus In doing th~s , we address the questmns above by determining what are the lexmal features that could d~stmgmsh the behavtor of the classes of verbs w~th respect to the relevant dmtheses , ~hmh of those features can be gleaned from the corpus , and which of those , once the staUstmal dmtnbutmns are available , can be used successfully by an automatic classifier In m~ttal work ( Stevenson and Merlo , 1999 ) , ~e found that hngmstlcally motivated features that d~stmgmsh the verb classes can be extracted from an annotated , and m one case parsed , corpus These features are sufficient to almost halve the error rate compared to chance ( 45 % reductmn ) m automaUc verb classtficaUon , suggesting that d~stnbuUonal data prowdes knowledge useful to the class~ficaUon of verbs The focus of our original stud~ was tho demonstration m prmctple of l~a.nmg verb classes from frequency d~stnbutmns ofsyntactm features , and an analysm of the relaUve contrtbutmn of the various features to learmng Th~s paper turns to the nnportant next steps of rephcatmg our findrags using other training methods and learning algorithms , and analyzing the performance on each of tbe three classes of verbs This more detailed analys~s of accuracy within each class m turn leads to the development of a new dlstrtbutmnal feature mtended to improve dlscnmmabthty among t~o of the classes The addltmn of the ne~ feature successfully reduces the error rate of out mltml results m classlficatmn by 19 % , for a 56 % overall reductmn m error rate compared to chance In this sectmn , we present mouvatmn for the mttml features that we mvesUgated m terms of their role m learmng the verb classes We first present the hngmstlcally den~ed features then turn to e~tdence from experimental psychohngutstlcs to e\tend the set of potentially relevant features The three verb classes under mvesugatmn unergaUves , unaccusaUves , and object-drop -differ m the properties of their translttve/mtranslhve a\ [ ternaUons , which are exemphfied below UnergaUve ( la ) The horse raced past the barn ( lb ) The jockey raced the horse past the barn Wnaccusatave ( 2a ) The butter melted m the pan ( 2b ) The cook melted the butter m the pan ObJect-drop ( 3a ) The boy washed the hall ( 3b ) The boy washed The sentences m ( 1 ) use an unergatwe velb .</sentence>
				<definiendum id="0">obJect-drop verbs</definiendum>
				<definiens id="0">very important sources of knowledge in many language engineering tasks</definiens>
				<definiens id="1">use dlatheses -- alternatmns m the expression of the arguments of the verb -- following Levm and Dorr , for two reasons Fnst , verb dlatheses are syntacuc cues one strong assumptmn regarding the nature of the representatmns under study semantic notmns and syntacuc notmns</definiens>
			</definition>
			<definition id="1">
				<sentence>gent Ithe doer of the e~ent ) , and m an Intransitive unaccusaUve , the subject ts a Theme ( ~omething affected by the e~ent ) The role assignments to the corresponding semanuc arguments of the ttans~u~e forms -- I e , the dnect objects -- a~e the ~ame 16 with the addition of a Causal Agent ( the causer of the event ) as subject in both cases Object-drop verbs simply assign Agent to the subject and Theme to the optional object We expect the differing semantic role assignments of the verb classes to be reflected m their syntactic behavior , and consequently in the distributional data we collect from a corpus The three classes can be characterized by their occurrence in two alternations the transittve/mtrans~tive alternation and the causative alternation Unergatives are distinguished from the other classes m being rare in the transitive form ( see ( Stevenson and Merlo , 1997 ) for an explanation of this fact ) Both unergatives and unaccusatives are dlstmgmshed from obJect-drop m being causative in their transitive form , and sundarly we expect this to be reflected in amount of detectable causative use Furthermore , since the caus &amp; tlve is a transitive use , and the transitive use of unergatlves is expected to be rare , causativity should primarily distinguish unaccusatlves from objectdrops In conclusion , we expect the defining features of the verb classes -- the intransitive/transitive and causative ~lternatlons -- to lead to distributional differences m the observed usages of the verbs in these alternations 2 2 Psychollngmst~cally Relevant Features The verbs under study not only differ in their thematic properties , they also differ in their processmg properties Because these verbs can occur both in a trans~tive and an intransitive form , they have been particularly studied in the context of the mare verb/reduced relative ( MV/I : tR ) ambiguity illustrated below ( Bever , 1970 ) The horse raced past the barn fell The verb ~aced can be interpreted as either a past tense main verb , or as a past participle w~thm a reduced relative clause ( l e , the horse \ [ that was\ ] raced past the barn ) Because fell is the main verb , the leduced relative lnterpretatmn of raced is required for a coherent analysis of the complete sentence But the main verb interpretation of raced is so strongly preferred that people experience great difficulty at the verb fell , unable to integrate it with the interpretation that has been developed to that point However , the reduced relative interpretation is not difficult for all verbs , as in the follo~mg example The boy washed in the tub was angry The difference in ease of interpreting the lesolutions of this ambiguity has been shown to be sensitive to both frequency differentials ( MacDonald 1994 , Trueswell , 1996 ) and to verb class d~stmctmns ( Stevenson and Merlo , 1997 , Flhp et al , 1999 ) Consider the features that d~stmguish the t~o resolutions of the M\ , /RR ambiguity MV The horse raced past the barn quickly RR The horse raced past the barn fell In the main verb resolution , the ambiguous ~erb raced is used in its intransitive form , while in the reduced relative , it is used in its transitive , causative form These features correspond directly to the defining alternations of the three verb classes under study ( intransitive/transitive , causative ) ~ , ddltionally , we see that other related features to these usages serve to distinguish the two resolutions of the ambiguity The mare verb form Is active and a mare verb part-of-speech ( labeled as VBD by automatic POS taggers ) , by contrast , the reduced relative foim is passive and a past partic~ple ( tagged as \ BN ) Since these features ( active/passive and VBD/VBN ) are related to the intransitive/transitive alteination , we expect them to also exhibit d~stributloaal differences among the verb classes Specifically , ~e expect the unergatives to yield a higher proportion of act~ e and `` vBD usage , since , as noted above , the transitive use of unergatwes is rare Features We assume that currently available large cotpoLa are a reasonable approximation to language ( Pullum , 1996 ) Using a combined corpus of 65-mllhon words , we measured the relative frequenc ) distributions of the four linguistic features ( VBD/~ BN active/passive , Intransitive/transitive , causative/noncausative ) over a sample of verbs from the three lextcal semantic classes 3 1 Materials ~e chose a set of 20 verbs from each class based pllmaidy on the classfficatlon of verbs m ( Le~ m 1993 ) ( see Appendl~ ~ ) The uneigatlves ale maanei oI motion verbs The unaccusatl~es ale ~erbs of~haage of state The object-drop verbs are unspecified object alternation verbs The ~e~bs ~ere sele~Led flora Lenin 's classes based on their absolute fiequenc } Ful thermore , they do not generally sho~ ma~l~ e depaitures from the intended verb sense m the cotpu~ ( Though note that there are only 19 unaccu~atlxes because , zpped , ~hlch ~as initially counted m the unaccusatives , was then excluded from the aaal~sis as It occurred mostly in a different usage m the corpus , as a velb plus paltlcle ) Most of the vetb~ can occur m the transitive and in the passive Each ~erb presents the ~ame folm m the simple pa~t and m the past palticlple In order to smlphf~ the ~ouat17 mg procedure , we made the assumptron that counts on this single verb form would approximate the distribution of the features across all forms of the verb Most counts were performed on the tagged versron of the Brown Corpus and on the portion of the Wall Street Journal distmbuted by the ACL/DCI ( years 1987 , 1988 , 1989 ) , a combined corpus m excess of 65 mdhon words , with the exceptmn of causatrvlty which was counted only for the 1988 year of the WSJ , a corpus of 29 million words 3 2 Method We counted the occurrences of each verb token in a transrtlve or mt~ansltr~e use ( INTR ) , m an active or passive use ( ACT ) , rn a past pamcrple or smaple past use ( VBD ) , and in a causative or non-causative use ( CAUS ) More precrsely , features were counted as follows INTR a verb occurrence was counted as transrtlve if rmmediately followed by a nominal group , else rt was counted as mtransitrve ACT mare verbs ( tagged VBD ) were counted as actrve , participles ( tagged V BN ) counted as actrve ff the closest preceding auxiliary was have , as passive ff the closest preceding auxiliary was be VBD occurrences tagged VBD were simple past , VBN were past participle ( Each of the above three counts was normalized over all occurrences of the verb , yielding a single relative frequency measure for each verb for that feature ) CAUS The causative feature was approximated by the followmg steps Frrst , for each verb , all cooccurrmg subjects and objects were extracted from a parsed corpus ( Colhns , 1997 ) Then the proportmn of overlap between the two multrsets of nouns was calculated , meant to capture the causative alternation , ~here the subject of the mtransrtrve can occur as the object of the trans~trve Vve define overlap as the largest multiset of elements belongmg to both the subjects and the object multisets , eg { a , a , a , b } ( 3 { a } = { a , a , a } The proportron is the ratio between the o~erlap and the sum of the subject and object multrsets ( For example , for the rumple sets above , the ratio would be 3/5 or 60 ) All ra~ and normahzed corpus data ale a~adable from the authors , and more detarl concerning data collectron can be found m ( Stevenson and Merto , 1999 ) The frequency drstnbutrons of the verb alternatmn features yield a vector for each verb that represents the relative frequency values for the verb on each drmensron , the set of 59 vectors constrtute the data for our machine learmng experiments Template \ [ verb , VBD , ACT , INTR , CADS , class\ ] Example \ [ opened , 79 , 91 , 31 , 16 , unacc\ ] Our goal was to determine whether automatm classfficatlon techniques could determine the class of a verb from the distributional propertms represented m this vector In related work ( Stevenson and Merlo , 1999 ) ~e describe initial unsupervised and supervised lealnmg experiments on this data , and discuss the contllbutlon of the four different features ( the frequenc .</sentence>
				<definiendum id="0">Intransitive unaccusaUve</definiendum>
				<definiendum id="1">Theme</definiendum>
				<definiens id="0">a corpus of 29 million words 3 2 Method We counted the occurrences of each verb token in a transrtlve or mt~ansltr~e use ( INTR ) , m an active or passive use ( ACT ) , rn a past pamcrple or smaple past use ( VBD ) , and in a causative or non-causative use ( CAUS ) More precrsely , features were counted as follows INTR a verb occurrence was counted as transrtlve if rmmediately followed by a nominal group , else rt was counted as mtransitrve ACT mare verbs ( tagged VBD ) were counted as actrve , participles ( tagged V BN ) counted as actrve ff the closest preceding auxiliary was have , as passive ff the closest preceding auxiliary was be VBD occurrences tagged VBD were simple past , VBN were past participle</definiens>
				<definiens id="1">the ratio between the o~erlap and the sum of the subject and object multrsets</definiens>
			</definition>
</paper>

		<paper id="0407">
			<definition id="0">
				<sentence>The paper describes FAME , a functional annotation meta-scheme for comparison and evaluation of existing syntactic annotation schemes , intended to be used as a flexible yardstick in multi-lingual and multi-modal parser evaluation campaigns .</sentence>
				<definiendum id="0">FAME</definiendum>
				<definiens id="0">a functional annotation meta-scheme for comparison and evaluation of existing syntactic annotation schemes</definiens>
			</definition>
			<definition id="1">
				<sentence>More concretely , SPARKLE xcomp ( want , leave ) , for the sentence She wants to leave , appears to convey two sorts of information : ( a ) that leave is a complement of want , ( b ) that leave is an open predicate .</sentence>
				<definiendum id="0">SPARKLE xcomp</definiendum>
				<definiens id="0">for the sentence She wants to leave , appears to convey two sorts of information : ( a ) that leave is a complement of want</definiens>
				<definiens id="1">an open predicate</definiens>
			</definition>
			<definition id="2">
				<sentence>Moreover , it can also be used to mark subject control relations and , possibly , raising to object/subject Phenomena , as exemplified below : sabj ( leave , John ) John promised Mary to leave subj ( leave , Mary ) John ordered Mary to leave subj ( be , her ) John believes her to be intelligent subj ( be , John ) John seems to be intelligent Also clausal subjects are marked as sub j : subj ( mean , leave ) that Mary left meant she was sick subj ( require , win ) to win the America 's Cup requires 42 heaps of cash comp ( bead , dependent ) is the most generic relation between a head and a complement , whether a modifier or a subcategorized argument .</sentence>
				<definiendum id="0">bead , dependent )</definiendum>
				<definiens id="0">leave , John ) John promised Mary to leave subj ( leave , Mary ) John ordered Mary to leave subj ( be , her ) John believes her to be intelligent subj</definiens>
			</definition>
			<definition id="3">
				<sentence>dobj ( head , dependent ) is the relation between a predicate and its direct object ( always non-clausal ) , e.g. : dobj ( read , book ) John read many books iobj ( head , dependent ) is the relation between a predicate and the indirect object , i.e. the complement expressing the recipient or beneficiary of the action expressed by the verb , e.g. iobj ( speak , Mary ) John speaks to Mary iobj ( give , Mary ) John gave Mary the contract iobj ( give , Mary ) John gave the contract to Mary oblobj ( bead , dependent ) is the relation between a predicate and a non-direct non clausal complement , e.g. oblobj ( live , Rome ) John lives in Rome oblobj ( inforra , ruu ) John informed me of his run In order to represent conjunctions and disjunctions , FAME avails itself of the two symmetric relations conj and dis j , lying outside the dependency hierarchy .</sentence>
				<definiendum id="0">FAME</definiendum>
				<definiens id="0">the relation between a predicate and its direct object ( always non-clausal )</definiens>
				<definiens id="1">the relation between a predicate and the indirect object</definiens>
				<definiens id="2">the relation between a predicate and a non-direct non clausal complement</definiens>
			</definition>
</paper>

		<paper id="0213">
</paper>

		<paper id="0207">
			<definition id="0">
				<sentence>Let ~\ ] t denote the total number of tagged 4In order to keep the formula simple the frequency types are omitted ( cf. Table 1 ) 49 anaphor-antecedent pairs contained in the test data , El the number of these pairs passing the decision tree filter , and ~ the number of correctly selected antecedents .</sentence>
				<definiendum id="0">El</definiendum>
				<definiens id="0">the formula simple the frequency types are omitted ( cf. Table 1 ) 49 anaphor-antecedent pairs contained in the test data</definiens>
			</definition>
</paper>

		<paper id="0611">
			<definition id="0">
				<sentence>Pronouns are marked as one of NOMinative , ACCusative , POSSessive , or AMBigUOUS ( you and it ) .</sentence>
				<definiendum id="0">AMBigUOUS</definiendum>
				<definiens id="0">one of NOMinative , ACCusative , POSSessive , or</definiens>
			</definition>
			<definition id="1">
				<sentence>Next , we define the following distance metric between two noun phrases : dist ( NPi , NPj ) -- -~ f e F W f * incompatibility f ( N P i , N P y ) where F corresponds to the NP feature set described above ; incompatibilityf is a function that returns a value between 0 and l inclusive and indicates the degree of incompatibility of f for NPi and NPj ; and wf denotes the relative importance of compatibility w.r.t , feature f. The incompatibility functions and corresponding weights are listed in Table 2 .</sentence>
				<definiendum id="0">incompatibilityf</definiendum>
				<definiendum id="1">wf</definiendum>
				<definiens id="0">the following distance metric between two noun phrases : dist ( NPi , NPj ) -- -~ f e F W f * incompatibility f</definiens>
				<definiens id="1">a function that returns a value between 0 and l inclusive and indicates the degree of incompatibility of f for NPi and NPj</definiens>
				<definiens id="2">the relative importance of compatibility w.r.t , feature f. The incompatibility functions and corresponding weights are listed in Table 2</definiens>
			</definition>
			<definition id="2">
				<sentence>84 Feature f Words Head Noun Position Pronoun Article Words-Substring Appositive Number Proper Name Semantic Class Gender Animacy Weight Incompatibility function 10.0 ( ~ of mismatching words a ) / ( ~of words in longer NP ) r 1 if NP~ is a pronoun and NPj is not ; else 0 r 1 if NPj is indefinite and not appositive ; else 0 -~ 1 if NPi subsumes ( entirely includes as a substring ) NPj ; -~ 1 if NPj is appositive and NPi is its immediate predecessor ; else 0 o¢ 1 if they do not match in number ; else 0 co 1 if both are proper names , but mismatch on every word ; else 0 1 if they do not match in class ; else 0 c~ 1 if they do not match in gender ( allows EITHER to match MASC or FEM ) ; else 0 c~ 1 if they do not match in animacy ; else 0 aPronouns are handled as gender-specific `` wild cards '' .</sentence>
				<definiendum id="0">NP~</definiendum>
				<definiendum id="1">NPj</definiendum>
				<definiendum id="2">NPi</definiendum>
				<definiens id="0">a pronoun and</definiens>
				<definiens id="1">if they do not match in class ; else 0 c~ 1 if they do not match in gender ( allows EITHER to match MASC or FEM</definiens>
			</definition>
			<definition id="3">
				<sentence>them a distance of -c &lt; ) via the word substring term ; however , NPi 's semantic class is COMPANY , and NP2 's class is OBJECT , generating a distance of cx ) via the semantic class feature .</sentence>
				<definiendum id="0">NPi</definiendum>
				<definiens id="0">'s semantic class is COMPANY , and NP2 's class is OBJECT , generating a distance of cx ) via the semantic class feature</definiens>
			</definition>
			<definition id="4">
				<sentence>WordNet : An Electronical Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0623">
			<definition id="0">
				<sentence>C is the union of the sets of constituents suggested by the parsers .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the union of the sets of constituents suggested by the parsers</definiens>
			</definition>
			<definition id="1">
				<sentence>Mi ( c ) is a binary function returning t when parser i ( from among the k parsers ) suggests constituent c should be in the parse .</sentence>
				<definiendum id="0">Mi ( c )</definiendum>
			</definition>
			<definition id="2">
				<sentence>Precision is the portion of hypothesized constituents that are correct and recall is the portion of the Treebank constituents that are hypothesized .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">the portion of the Treebank constituents that are hypothesized</definiens>
			</definition>
			<definition id="3">
				<sentence>F-measure is the harmonic mean of precision and recall , 2PR/ ( P + R ) .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiens id="0">the harmonic mean of precision and recall , 2PR/ ( P + R )</definiens>
			</definition>
</paper>

		<paper id="0205">
			<definition id="0">
				<sentence>In this work , a topic is defined as a theme which is described , and a focus is defined as a word which is stressed by the speaker ( or the writer ) .</sentence>
				<definiendum id="0">topic</definiendum>
				<definiens id="0">a theme which is described</definiens>
				<definiens id="1">a word which is stressed by the speaker ( or the writer )</definiens>
			</definition>
			<definition id="1">
				<sentence>Training sentences { example sentences ( Walker et al. , 1994 ) ( 43 sentences ) , a folk tale Kobutori jiisan ( Nakao , 1985 ) ( 93 sentences ) , an essay in Tenseijingo ( 26 sentences ) , an editorial ( 26 sentences ) } Test sentences { a folk tale Tsuru no ongaeshi ( Nakao , 1985 ) ( 91 sentences ) , two essays in Tenseijingo ( 50 sentences ) , an editorial ( 30 sentences ) } Precision is the fraction of the noun phrases which were judged to have the indirect anaphora as antecedents .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">Training sentences { example sentences ( Walker et al. , 1994 ) ( 43 sentences ) , a folk tale Kobutori jiisan ( Nakao , 1985 ) ( 93 sentences ) , an essay in Tenseijingo ( 26 sentences ) , an editorial ( 26 sentences ) } Test sentences { a folk tale Tsuru no ongaeshi ( Nakao , 1985 ) ( 91 sentences ) , two essays in Tenseijingo ( 50 sentences ) , an editorial ( 30 sentences ) }</definiens>
				<definiens id="1">the fraction of the noun phrases which were judged to have the indirect anaphora as antecedents</definiens>
			</definition>
			<definition id="2">
				<sentence>Recall is the fraction of the noun phrases which have the antecedents of indirect anaphora .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the fraction of the noun phrases which have the antecedents of indirect anaphora</definiens>
			</definition>
</paper>

		<paper id="0211">
			<definition id="0">
				<sentence>The approach has been implemented within an existing MUC coreference system , which constructs a full discourse model of texts , including information about changes of focus , which can be used in the selection of chains .</sentence>
				<definiendum id="0">focus</definiendum>
				<definiens id="0">constructs a full discourse model of texts</definiens>
			</definition>
			<definition id="1">
				<sentence>Our summary representation is a 'best chain ' , selected from the set of coreference chains by the application of one or more heuristics .</sentence>
				<definiendum id="0">summary representation</definiendum>
				<definiens id="0">a 'best chain ' , selected from the set of coreference chains by the application of one or more heuristics</definiens>
			</definition>
			<definition id="2">
				<sentence>The LaSIE system ( Gaizauskas et al. , 1995 ) has been designed as a general purpose IE system which can conform to the MUC task specifications for named entity identification , coreference resolution , IE template element and relation identification , and the construction of scenario-specific IE templates .</sentence>
				<definiendum id="0">LaSIE system</definiendum>
			</definition>
			<definition id="3">
				<sentence>The overall contributions of these stages may be briefly described as follows ( see ( Gaizauskas et al. , 1995 ) for further details ) : lexical preprocessing reads and tokenises the raw input text , performs phrasal matching against lists of proper names , identifies sentence boundaries , tags the tokens with parts-of-speech , performs morphological analysis ; parsing and semantic interpretation builds lexical and phrasal chart edges in a feature-based formalism then does two pass chart parsing , pass one with a special named entity grammar , pass two with a general grammar , and , after selecting a 'best parse ' , which may have only partial coverage , constructs a predicate-argument representation of each sentence ; discourse interpretation adds the information from the predicate-argument representation to a hierarchically structured semantic net which encodes the system 's world and domain model , adds additional information presupposed by the input , performs coreference resolution between new and existing instances in the world model , and adds any information consequent upon the new input .</sentence>
				<definiendum id="0">discourse interpretation</definiendum>
				<definiens id="0">adds the information from the predicate-argument representation to a hierarchically structured semantic net which encodes the system 's world and domain model , adds additional information presupposed by the input</definiens>
			</definition>
			<definition id="4">
				<sentence>The discourse interpreter maintains an explicit representation of coreference chains created as a result of instances being merged in the discourse model .</sentence>
				<definiendum id="0">discourse interpreter</definiendum>
				<definiens id="0">maintains an explicit representation of coreference chains created as a result of instances being merged in the discourse model</definiens>
			</definition>
			<definition id="5">
				<sentence>A focus chain is the subset of a coreference chain which contains only those mentions of an instance that occur as the focus of a clause .</sentence>
				<definiendum id="0">focus chain</definiendum>
				<definiens id="0">the subset of a coreference chain which contains only those mentions of an instance that occur as the focus of a clause</definiens>
			</definition>
</paper>

		<paper id="0807">
			<definition id="0">
				<sentence>Linguistic Instruments : Grammar Laboratories for the Macintosh .</sentence>
				<definiendum id="0">Linguistic Instruments</definiendum>
				<definiens id="0">Grammar Laboratories for the Macintosh</definiens>
			</definition>
</paper>

		<paper id="0706">
			<definition id="0">
				<sentence>Many systems ( e.g. , the KERNEL system \ [ Palmer et al. , 1993\ ] ) use these relationships as an intermediate , form when determining the semantics of syntactically parsed text .</sentence>
				<definiendum id="0">Many systems</definiendum>
			</definition>
			<definition id="1">
				<sentence>Our example sentence , `` I saw the cat that ran '' thus translates directly to the following : 45 Proposition saw ( xl x2 ) I ( xl ) cat ( x2 ) ran ( x2 ) =e3 rood ( e3 x2 ) Comment SUBJ and OBJ ' relations SUBJ relation ( e3 is the event variable ) MOD relation We do not have an explicit level for clauses between our core phrase and grammatical relations levels .</sentence>
				<definiendum id="0">e3</definiendum>
			</definition>
			<definition id="2">
				<sentence>I I I I I I I I I I I I I I I I I I I RELATION `` EXAMPLE ( s ) in the format Name I Description , \ [ source\ ] -- ~ \ [ target\ ] in `` text '' subj \ [ I\ ] -- + obj loc-obj subject subject of a verb -link a copula subject and object -link a state with the item in that state -link a place with the item moving to or from that place object -object of a verb object of an adjective -surface subject in passives -object of a preposition , not for partitives or subsets -object of an adverbial clause complementizer location object -link a movement verb with a place where entities are moving to or from indobj i indirect object empty use instead of `` subj '' relation when subject is an expletive ( existential ) `` it '' or `` there '' pp-subj genitive functional `` of '' 's use instead of `` subj '' relation when the subject is linked via a preposition , links preposition to its head pp-obj nongenitive functional `` of '' 's use in place of `` obj '' relation when the object is linked via a preposition , links preposition to its head i pp-io use in place of `` indobj '' relation when the indirect object is linked via a preposition .</sentence>
				<definiendum id="0">EXAMPLE</definiendum>
				<definiens id="0">-object of an adverbial clause complementizer location object -link a movement verb with a place where entities are moving to or from indobj i indirect object empty</definiens>
			</definition>
			<definition id="3">
				<sentence>This/-score is a type of harmonic mean of the precision ( p ) and recall ( r ) and is given by 2pr/ ( p + r ) .</sentence>
				<definiendum id="0">This/-score</definiendum>
				<definiens id="0">a type of harmonic mean of the precision ( p ) and recall ( r ) and is given by 2pr/ ( p + r )</definiens>
			</definition>
			<definition id="4">
				<sentence>Wordnet : an on-line lexical database .</sentence>
				<definiendum id="0">Wordnet</definiendum>
				<definiens id="0">an on-line lexical database</definiens>
			</definition>
</paper>

		<paper id="0601">
</paper>

		<paper id="0627">
			<definition id="0">
				<sentence>where N is the total number of documents and docfj is the document frequency of the jth word ( the number of documents the word appears in ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">docfj</definiendum>
				<definiens id="0">the total number of documents and</definiens>
			</definition>
			<definition id="1">
				<sentence>wj ( 1 ) PE~i where Pl is the pool of papers for ith reviewer , r ( P ) is the weight/relevance of paper P and cj ( P ) is the word count of jth word in paper P ( a given word might weight differently in different regions see region weighting below ) .</sentence>
				<definiendum id="0">Pl</definiendum>
				<definiens id="0">the pool of papers for ith reviewer</definiens>
			</definition>
			<definition id="2">
				<sentence>sum of the composing reviewers ' centroids : = Z ( 2 ) Ri EC~ where Ck is the pool of reviewers for committee k. on the cosine similarity between the paper 's vector and the committee centroids the one that ranks highest is chosen as the classification of the paper : classification ( Pt ) = argmax ( cosine_similarity ( Pl , Ck ) ) k=l..</sentence>
				<definiendum id="0">Ck</definiendum>
				<definiens id="0">the pool of reviewers for committee k. on the cosine similarity between the paper 's vector and the committee centroids the one that ranks highest is chosen as the classification of the paper : classification ( Pt ) = argmax</definiens>
			</definition>
			<definition id="3">
				<sentence>( ° '' ° ' ) E E E No o , ,o ) /¢=1 pET ~ /*=1 where Np ( ai , aj ) is the number of times a~ was cited in the paper p if ai is an author of p , 0 otherwise , and Nc ( ai , aj ) is the number of papers in which ai and a 3 were coauthors identified either from the head of Distance d 1 2 3 4 Accuracy 30.3 % 30.4 % 32.6 % 34.5 % Average Position 2.28 2.22 2.17 2.17 One-of-best-2 65.2 % I 71.7 % 73.9 % 71.7 % Table 9 : Performance comparison at different levels of parameter d , A = 0.8 and fl = 1 , evaluated on devtest data a paper p 6 ~ , or a bibliographic citation extracted from p. The relation Cited_by can be captured by the transposition of the citation matrix Cites T. A symmetric similarity matrix combining these base relations is defined as : Sire I = ( Cites + Cites T ) + ( 1 A ) ½ ( Coauthor + Coauthor T ) ( 4 ) where A is a weighting factor between the contributing sources of similarity .</sentence>
				<definiendum id="0">Np</definiendum>
				<definiendum id="1">aj )</definiendum>
				<definiendum id="2">ai</definiendum>
				<definiendum id="3">Nc</definiendum>
				<definiendum id="4">aj )</definiendum>
				<definiens id="0">'' ° ' ) E E E No o</definiens>
				<definiens id="1">the number of times a~ was cited in the paper p if</definiens>
				<definiens id="2">the number of papers in which ai</definiens>
				<definiens id="3">Performance comparison at different levels of parameter d , A = 0.8 and fl = 1 , evaluated on devtest data a paper p 6 ~ , or a bibliographic citation extracted from p. The relation Cited_by can be captured by the transposition of the citation matrix Cites T. A symmetric similarity matrix combining these base relations is defined as : Sire I = ( Cites + Cites T ) + ( 1 A ) ½ ( Coauthor + Coauthor T ) ( 4 ) where A is a weighting factor between the contributing sources of similarity</definiens>
			</definition>
			<definition id="4">
				<sentence>Inference and Disputed Authorship : The Federalist .</sentence>
				<definiendum id="0">Inference</definiendum>
				<definiendum id="1">Disputed Authorship</definiendum>
				<definiens id="0">The Federalist</definiens>
			</definition>
</paper>

		<paper id="0402">
			<definition id="0">
				<sentence>Participants spoke over the telephone with other non-native speakers , forcing them to communicate using speech .</sentence>
				<definiendum id="0">Participants</definiendum>
				<definiens id="0">spoke over the telephone with other non-native speakers , forcing them to communicate using speech</definiens>
			</definition>
			<definition id="1">
				<sentence>Briggs ( Briggs , 1986 ) emphasizes the importance of understanding the meaning of the speech event for the speaker .</sentence>
				<definiendum id="0">Briggs</definiendum>
				<definiens id="0">emphasizes the importance of understanding the meaning of the speech event for the speaker</definiens>
			</definition>
</paper>

		<paper id="0806">
			<definition id="0">
				<sentence>'Top level ' : General Information : Tutoriah Search Engine : http : //clwww.essex.ac.uk/w3c/ http : //clwww.essex.ac.uk/w3c/corpusling/content/introduction.html http : //clwww.essex.ac.uk/w3c/help/intro/start~age.html http : //clwww.essex.ac.uk/w3c/corpusling/content/search~ngine.html Table 1 : Web Addresses for W3Corpora Resources Apart from the Search Engine , the implementation is rather straightforward : text marked up as html , there is extensive use of frames so that users are able to maintain an overview of documents as well pursuing detail .</sentence>
				<definiendum id="0">'Top level</definiendum>
				<definiens id="0">General Information : Tutoriah Search Engine : http : //clwww.essex.ac.uk/w3c/ http : //clwww.essex.ac.uk/w3c/corpusling/content/introduction.html http : //clwww.essex.ac.uk/w3c/help/intro/start~age.html http : //clwww.essex.ac.uk/w3c/corpusling/content/search~ngine.html Table 1 : Web Addresses for W3Corpora Resources Apart from the Search Engine</definiens>
			</definition>
			<definition id="1">
				<sentence>CobuUd This site gives limited access to the Cobuild Corpora : the `` Bank of English '' ( over 50million words ) , giving an idea of the kinds of search possible with the full system .</sentence>
				<definiendum id="0">Cobuild Corpora</definiendum>
			</definition>
			<definition id="2">
				<sentence>It , is possible to search for regular expressions ( including a special character which matches inflectional endings ) , combinations of words , and part of speech tags .</sentence>
				<definiendum id="0">regular expressions</definiendum>
				<definiens id="0">including a special character which matches inflectional endings ) , combinations of words , and part of speech tags</definiens>
			</definition>
			<definition id="3">
				<sentence>LDC/Brown Corpus Text Corpora , and Speech Corpora , are accessible via the Linguistic Data Consortium .</sentence>
				<definiendum id="0">LDC/Brown Corpus Text Corpora</definiendum>
			</definition>
			<definition id="4">
				<sentence>The BNC Handbook : Exploring the British National Corpus with SARA .</sentence>
				<definiendum id="0">BNC Handbook</definiendum>
			</definition>
			<definition id="5">
				<sentence>Language and Computers : a practical introduction to the computer analysis of language .</sentence>
				<definiendum id="0">Language</definiendum>
				<definiendum id="1">Computers</definiendum>
				<definiens id="0">a practical introduction to the computer analysis of language</definiens>
			</definition>
</paper>

		<paper id="0808">
			<definition id="0">
				<sentence>The Internet itself is the biggest IR testbed , and the web search engines are the most powerful applications of IR techniques .</sentence>
				<definiendum id="0">Internet itself</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Virtual Campus : Trends for Higher Education and Training .</sentence>
				<definiendum id="0">Virtual Campus</definiendum>
			</definition>
</paper>

		<paper id="0100">
</paper>

		<paper id="0904">
			<definition id="0">
				<sentence>We adopt here the layers used in ( Fradin , 1994 ) , as exemplified on the French noun table : ( G ) table ( F ) ( teibl ) ( M ) fem-sg ( SX ) N ( S ) table where ( G ) corresponds to the graphemic form of the word , ( F ) to the phonological form , and ( M ) , ( SX ) and ( S ) respectively contain morphological , syntactic and semantic information .</sentence>
				<definiendum id="0">SX</definiendum>
				<definiens id="0">S ) respectively contain morphological , syntactic and semantic information</definiens>
			</definition>
			<definition id="1">
				<sentence>s. ( w~ ( S ) ) ) where Op is a derivation process , Opt is the component of Op which operates on the graphemic layer , and w ( G ) is the graphemic layer associated to word W. The different layers can be divided up into three main dimensions , used in linguistic studies to identify and classify suffixes of a language : the formal dimension ( corresponding to G and F ) , the morphosyntactic dimension ( M and SX ) , and the semantic dimension ( S ) .</sentence>
				<definiendum id="0">Op</definiendum>
				<definiendum id="1">Opt</definiendum>
				<definiens id="0">a derivation process ,</definiens>
				<definiens id="1">the component of Op which operates on the graphemic layer</definiens>
				<definiens id="2">dimensions , used in linguistic studies to identify and classify suffixes of a language : the formal dimension ( corresponding to G and F ) , the morphosyntactic dimension</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , for Indo-European languages , for the formal dimension , a suffixation operation consists in the concatenation of a suffix to the original form .</sentence>
				<definiendum id="0">suffixation operation</definiendum>
				<definiens id="0">consists in the concatenation of a suffix to the original form</definiens>
			</definition>
			<definition id="3">
				<sentence>The notion of validity only requires that two words of a same derivational family can be related by the suffix pair , which is the case for the previous pair in so far as it relates `` friser frison '' ( curl ( +V ) curl ( +N ) ) families The problem we have to face now is the one of grouping words which belong to the same derivational family , and to avoid grouping words which do not belong to the same derivational family .</sentence>
				<definiendum id="0">suffix pair</definiendum>
				<definiens id="0">the one of grouping words which belong to the same derivational family , and to avoid grouping words which do not belong to the same derivational family</definiens>
			</definition>
			<definition id="4">
				<sentence>We then ran the evaluation above and obtained the following results : SMART stemmer : 0.82 Porter 's stemmer : 0.65 Not surprisingly , the SMART stemmer , which is the result of twenty years of ( levelopment , is a better approximation of derivational processes than Porter 's stemmer .</sentence>
				<definiendum id="0">SMART</definiendum>
				<definiendum id="1">SMART stemmer</definiendum>
				<definiens id="0">a better approximation of derivational processes than Porter 's stemmer</definiens>
			</definition>
			<definition id="5">
				<sentence>Furthermore , since we restrict ourselves to concatenative languages , we adopt the following form for a suffixation operation S : S= ( ad=c°ncat ( G° 's ) ) MSo~MSd where G4 ( MSa ) stands for the graphemic ( morphosyntactic ) form of the derived word produced by the suffixation operation , Go ( MSo ) for the graphemic ( morpho-syntactic ) form of the original word on which the suffixation operation operates , conea* is the concatenation operation , and s is the suffÉx associated to the suffixation operation S. We can then write the probability that a word w2 derives , through a suffixation process , from a. word wl as follows : P ( Wl -- +w2 ) = = ~s p ( S ) p ( Ga -+ G2 , MS1 -+ MS ' , IS ) = ~s p ( S ) p ( G1 -+ G2\ ] S ) p ( MS1 ~ MSu\ ] G1 -+ G~ , S ) ~~s p ( 5 ' ) p ( Gi ~ G21S ) p ( M &amp; ~ M &amp; IS ) the last equation being based on an independence assumption between the graphetnic form and the morpho-syutactic information attached to words .</sentence>
				<definiendum id="0">s</definiendum>
				<definiens id="0">the graphemic ( morphosyntactic ) form of the derived word produced by the suffixation operation , Go ( MSo ) for the graphemic ( morpho-syntactic ) form of the original word on which the suffixation operation operates , conea* is the concatenation operation , and</definiens>
				<definiens id="1">the probability that a word w2 derives , through a suffixation process</definiens>
			</definition>
			<definition id="6">
				<sentence>The t.erm involving morpho-syntactic information , i.e. the probability to produce MS2 from MS1 knowing the suffixation operation S , can be directly rewritten as : p ( MS~ -- + MS2\ ] S ) = ~ ( MS1 , MSo ) 5 ( MS2 , MSd ) where 5 is the Kronecker symbol ( 6 ( x , y ) equals 1 if the two arguments are equal and 0 otherwise ) .</sentence>
				<definiendum id="0">morpho-syntactic information</definiendum>
				<definiens id="0">the probability to produce MS2 from MS1 knowing the suffixation operation S</definiens>
			</definition>
			<definition id="7">
				<sentence>Since : allomorphy , truncation and morphographemic phenomena do not depend on the words themselves but on some subparts of the words ; direct concatenation gives a better access to the suffix used ; and suffixation usually adds element to the original form 3 , we use the following forln for p ( G , ~ G21S ) : p ( G1 ~ G2\ ] S ) = 0 if l ( G1 ) &gt; l ( G2 ) else p ( G1 ~ G.~IS ) = co if diff ( G1 , G2 , s ) = 0 el if diff ( Gx , G2 , s ) = 1 e : , if diff ( G1 , G ; , s ) = 2 ca if diff ( G1 , G~ , s ) = 3 0 otherwise where I ( G ) is the length of G , diff ( strl , str2 , suff ) represents the number of characters differing between strl and str2suff ( i.e. the string obtained via removal of surf from str2 , proceeding backward from the end of str2 ) , and ei , 0 &lt; i &lt; 3 are arbitrary constants , the stun of which equals 1 , which control the confidence we have on a suffix with respect to the edit distance between G1 and G2 .</sentence>
				<definiendum id="0">suffixation</definiendum>
				<definiens id="0">allomorphy , truncation and morphographemic phenomena do not depend on the words themselves but on some subparts of the words</definiens>
				<definiens id="1">l ( G1 ) &gt; l ( G2 ) else p ( G1 ~ G.~IS ) = co if diff ( G1 , G2 , s ) = 0 el if diff ( Gx , G2 , s ) = 1 e : , if diff ( G1 , G ; , s ) = 2 ca if diff ( G1 , G~ , s ) = 3 0 otherwise where I ( G ) is the length of G , diff ( strl , str2 , suff ) represents the number of characters differing between strl</definiens>
			</definition>
</paper>

		<paper id="0805">
</paper>

		<paper id="0900">
			<definition id="0">
				<sentence>We would also like to thank those members of the program committee and others who contributed to the reviewing process : Steve Abney ( AT &amp; T Laboratories ) , Eric Brill ( Johns Hopkins University ) , Rebecca Bruce ( University of North Carolina at Asheville ) , Eugene Charniak ( Brown University ) , Michael Collins ( AT &amp; T Laboratories ) , Marie desJardins ( SRI International ) , Moises Goldszmidt ( SRI International ) , John Lafferty ( Carnegie-Mellon University ) , Lillian Lee ( Cornell University ) , Chris Manning ( University of Sydney ) , Ray Mooney ( University of Texas , Austin ) , Srini Narayanan ( ICSI , Berkeley ) , Fernando Pereira ( AT &amp; T Laboratories ) , David Powers ( Flinders University of South Australia ) , Adwait Ratnaparkhi ( IBM Research ) , Dan Roth ( University of Illinois at Urbana-Champaign ) , Richard Sproat ( AT &amp; T Laboratories ) , Janyce Wiebe ( New Mexico State University ) , and David Yarowsky ( Johns Hopkins University ) .</sentence>
				<definiendum id="0">Ray Mooney</definiendum>
			</definition>
</paper>

		<paper id="0705">
			<definition id="0">
				<sentence>Here is how this rule is represented in the # -TBL system 's compositional rule/template formalism : tag : vb &gt; nn &lt; tag : dr @ \ [ -1\ ] . This is of course the exact counterpart of the transformation rule in Brill 's original framework. Addition rules specify when a feature value should be added to a word. An example would be `` add tag nn to a word if the word immediately to the left has a tag tit '' : tag:0 &gt; nn &lt; tag : dr @ \ [ -1\ ] . Note that a feature value is actually added to a word only if it not already there. Deletion rules dictate when a feature value should be removed from a word. An example would be `` remove tag vb from a word if the word immediately to the left has a tag dt '' : tag : vb &gt; 0 &lt; tag : dt @ \ [ -1\ ] . Reduction rules reduce the set of feature values for a word with a certain value. An example would be `` reduce a word 's tag values with tag vb if the word immediately to the left has a tag dr '' : tag : vb &gt; l &lt; tag : dr @ I-I\ ] . An important difference between deletion rules and reduction rules is that the latter will only remove a feature value from a word if it is not the last value for that feature. If vb is the last value the above rule is not applicable and the reduction will not take place. This should remind us of the kind of constraints that are central to the so called reductionistic approach to disambiguation. as represented by for example Constraint Gram34 mar \ [ Karlsson et al. , 1995\ ] ) . Constraint grammars may indeed be possible to learn in the IL-TBL system , as I will show towards the end of this paper. In the p-TBL system 's rule formalism , conditions may refer to different symbol features , and complex conditions may be composed from simpler ones. For example , here is a rule saying `` replace the tag for adverb with the tag for adjective , if the current word is `` only '' , and if the previous tag , or the tag before that , is a determiner tag. '' : tag : ab &gt; jj &lt; wd : only @ \ [ O\ ] k tag : dt @ \ [ -1 , -2\ ] . Ill this paper , I will break with the tradition to think about transformation rules in exclusively procedural terms , and instead try to think about them in declarative and logical terms. Transformation rules ( partially ) describe an ordered sequence of pairs of symbols , which I will refer to as a relation. Such a relation form training data for a TBL system. Here is a simple ( and unrealistically small ) example : dt vb nn dt vb kn dt vb ab dt vb dt nn vb dt nn kn dt jj kn dt nn The sequence formed by the upper elements of the pairs will be referred to as Sl , and the sequence formed by the lower elements as Sn. Such sequences can be. modelled by means of two sets of clauses , which relate positions in the sequences to symbol feature values : $ 1 ( 1 , dr ) Sl ( 2 , vb ) $ 1 ( 3 , nn ) ... S1 ( 11 , vb ) S. ( I , dr ) S~ ( 2 , nn ) S. ( 3 , vb ) ... S. ( 11 , nn ) A central point in this paper is the suggestion that the declarative semantics of transformation rules can be captured by rule formulas in the form of universally quantified implications , and that , for example , the meanings of the four very simple rules shown previously are captured by the following formulas : Replacement Vpo , p , \ [ S , ( po , vb ) A ( Pl = 1 ) o 1 ) A St ( p , .dr ) -- r S , ( po , nn ) \ ] Addition Vpo , p , \ [ - , St ( po , nn ) A ( p , = Po 1 ) A St ( p , , at ) -- -r S , ( po , nn ) \ ] Deletion Vpo.p , \ [ St ( po , vb ) A ( p , = po 1 ) A St ( p , , dr ) -- ~ -~S. ( po , vb ) \ ] Reduction Vpo , p , \ [ Sl ( po , vb ) A Bxo\ [ S , ( po , xo ) A ( x0 # vb ) \ ] A ( P , = P0 -1 ) A S , ( pl , dt ) -- ~ -.S. ( po , vb ) \ ] Rule formulas as such will not be put to any direct computational use , but the notion of a rule formula provides a starting point , from which computational tools can be derived. A rule instance is a rule formula in which every variable has been replaced with a constant. Now , we may define the notions of positive and negative instances of rule formulas ( and thus indirectly of transformation rules ) . A positive rule instance is a rule instance where the mltecedent and the consequent are both true. Thus , the following formula is a positive instance of the formula corresponding to the simple replacement rule above : Sl ( 2 , vb ) A ( 1 = 2 1 ) A S , ( I , dt ) -- + S , ( 2 , nn ) A negative instance of a rule is a rule instance where the antecedent is true but where the consequent is false , for example : Sl ( 8 , vb ) A ( 7 = 8 1 ) A S~ ( 7 , dt ) -~ S , , ( 8 , nn ) Note that Brilrs notion of a neutral instance of a rule , i.e. an instance of a rule that replaces an incorrect tag with another incorrect tag , is a negative instance in my terminology. ( In practice , this does not seem to matter much , as I will show later. ) We now define two important rule evaluation measures. The score of a rule is the number of its positive instances minus the number of its negative instances : sco~e ( R ) =1 pos ( R ) 1 I neg ( R ) I The accuracy of a rule is its number of positive instances divided by the total number of instances of the rule : accuracy ( R ) = I pos ( R ) I I P°S ( R ) I + I neg ( R ) I The notion of rule accuracy is well-known in rule induction and inductive logic programming , and towards the end of this paper we will see that it may have a role to play in the context of transformation-based learning too. An Overview of the # -TBL System Through the use of unification and a particular search strategy ( backtracking ) , a logic programming environment such as Prolog implements a constructive kind of inference which allows us to define predicates that are able to recognize , generate and search for positive and negative instances of transformation rules. Furthermore , a layer of recta-logical predicates provides a way to collect and count such instances , and thus a way to calculate the score and accuracy for any rule. Therefore , in a logic programming framework , transformation-based learning can be implemented in a very clear and simple way. However , for such an implementation to become useful. we have to think about efficiency. Among other things , we need to think about how we index our training data. Assuming the part-of-speech tagging task. corpus data can be represented by '' means of three `` kinds of clauses : 35 wd ( P , N ) is true iff the word W is at position P in the corpus tag ( P , A ) is true iff the word at position P in the corpus is tagged A tag ( A , B , P ) is true iff the word at , P is tagged A and the correct tag for the word at P is B Although this representation may seem a bit redundant , it provides exactly the kind of indexing into the data that is needed. 3 A decent Prolog system can deal with millions of such clauses. Rules that can be learned in TBL are instances of templates , such as `` replace tag A with B if tho symbol ( e.g. the word ) immediately to the left has tag C , where A , B and C are variables. Here is how we write this template in the p-TBL system : t3 ( A , B , C ) # tag : A &gt; B &lt; tag : C @ \ [ -l\ ] . The term to the left of # is a unique identifier for the template. A template instance is a template in which every variable in the identifier has been replaced by a constant. If we strip the identifier we end up with a transformation rule again. The instantiated identifier uniquely identifies that rule. Positive instances of rules that are instancbs of the above template can be efficiently recognized , generated and searched for , by means of the following clause : positive ( t3 ( A , B , C ) ) : tag ( A , B , PO ) , Pl is PO-I , tag ( Pl , C ) . Negative instances are handled as follows : negative ( t3 ( A , B , C ) ) : tag ( A , X , PO ) , dif ( X , B ) , P1 is PO-I , taE ( PI , C ) . It should be clear how these clauses use the representation described above , and that they respect the semantics exemplified in the previous section. Clauses corresponding to other templates and other types of rules can be defined accordingly. Tied to each template is also an update proce.dure that will apply rules that are instances of this template , and thus update sequences , by replacing feature values with other feature values , adding to the feature values , or removing from them. For example : apply ( t3 ( A , B , C ) ) : ( tag ( A , X , P ) , P1 is P-l , tag ( PI , C ) , retract ( tag ( A , X , P ) ) , retract ( tag ( P , l ) ) , assert ( tag ( B , X , P ) ) , asser~ ( tag ( P , B ) ) , fail ; true ) . 3Assuming a Prolog with first argument indexing. I I I I I I I I I I I I I I I I I I I To write clauses such as these by hand for large sets of templates would be tedious and prone to errors and omissions. Fortunately , since the formalism is compositional , it is easy to write a template compiler that generates them automatically. The # u-TBL system uses wellknown Prolog compiler writing techniques to expand templates written in the compositional high-level notation into clauses that can be run as programs. Thus , the convenience and flexibility of a high-level notation for templates and rules does not compromise performance. A template grammar defines the exact relation between a template and a set of clauses. As an illustration , the following grammar rules are used to expand a template into a Prolog clause defining positive/l , negative/1 and apply/l , for that template : term_expansion ( ( ID # A &lt; -Cs ) , \ [ ( positive ( ID ) : G1 ) , ( negative ( ID ) : G2 ) , ( apply ( ID ) : - ( G3.fail ; true ) ) \ ] ) : pos ( ( A &lt; -Cs ) , LI , \ [ \ ] ) , list2goal ( L1 .G1 ) , ne E ( ( A &lt; -Cs ) , L2 , \ [ \ ] ) . list2goal ( Li , G2 ) , app ( ( A &lt; -Cs ) , L3 , \ [ \ ] ) , list2goal ( L3 , G3 ) . pos ( ( F : A &gt; B &lt; -Cs ) ) -- &gt; { G = .</sentence>
				<definiendum id="0">template instance</definiendum>
				<definiendum id="1">P1</definiendum>
				<definiendum id="2">P1</definiendum>
				<definiendum id="3">template grammar</definiendum>
				<definiens id="0">the tradition to think about transformation rules in exclusively procedural terms , and instead try to think about them in declarative and logical terms. Transformation rules ( partially ) describe an ordered sequence of pairs of symbols</definiens>
				<definiens id="1">a relation. Such a relation form training data for a TBL system. Here is a simple ( and unrealistically small ) example : dt vb nn dt vb kn dt vb ab dt vb dt nn vb dt nn kn dt jj kn dt nn The sequence formed by the upper elements of the pairs will be referred to as Sl , and the sequence formed by the lower elements as Sn. Such sequences can be. modelled by means of two sets of clauses</definiens>
				<definiens id="2">the suggestion that the declarative semantics of transformation rules can be captured by rule formulas in the form of universally quantified implications , and that , for example , the meanings of the four very simple rules shown previously are captured by the following formulas : Replacement Vpo , p , \ [</definiens>
				<definiens id="3">a positive instance of the formula corresponding to the simple replacement rule above</definiens>
				<definiens id="4">sco~e ( R ) =1 pos ( R ) 1 I neg ( R ) I The accuracy of a rule is its number of positive instances divided by the total number of instances of the rule : accuracy ( R ) = I pos ( R</definiens>
				<definiens id="5">implements a constructive kind of inference which allows us to define predicates that are able to recognize , generate and search for positive and negative instances of transformation rules. Furthermore , a layer of recta-logical predicates provides a way to collect and count such instances , and thus a way to calculate the score</definiens>
				<definiens id="6">true iff the word W is at position P in the corpus tag</definiens>
				<definiens id="7">true iff the word at position P in the corpus is tagged A tag ( A , B , P ) is true iff the word at</definiens>
				<definiens id="8">the word ) immediately to the left has tag C , where A , B and C are variables. Here is how we write this template in the p-TBL system : t3 ( A , B , C ) # tag : A &gt; B &lt; tag : C @ \</definiens>
				<definiens id="9">easy to write a template compiler that generates them automatically. The # u-TBL system uses wellknown Prolog compiler writing techniques to expand templates written in the compositional high-level notation into clauses</definiens>
				<definiens id="10">A &gt; B &lt; -Cs ) ) -- &gt; { G =</definiens>
			</definition>
			<definition id="1">
				<sentence>By backtracking through the solutions to a call to positive/1 we may for example verify that there are ten ways to instantiate our example template in our example data ( for space reasons , I show only the first three solutions ) : \ [ 7positive ( RuleID ) , RuleID # Rule• Rule = tag : vb &gt; nn &lt; tag : dt @ \ [ -l\ ] 7 ; Rule = tag : nn &gt; vb &lt; tag : vb @ \ [ -1\ ] ? ; Rule = tag : dr &gt; dr &lt; tag : nn @ \ [ -l\ ] ? ; • . . Alternatively , we might be interested only in instances where the aligned feature values ( h and B ) are different , and there are six of those : a Sdif/2 is a built-in predicate in SICStus Prolog. A call to dif ( X , Y ) constrains X and Y to represent different terms. Calls to dif/2 either succeed~ fail. or are blocked depending oil whether X and Y are sufficiently instantiated. 36 l 7dif ( A , B ) , positive ( ID , A , B ) , ID # Rule. Or , we might be interested only in template instances where the aligned symbols have feature values nn and vb , respectively. There is only one such rule : i ? positive ( RulelD , nn , vb ) , RuleID # Rule. Rule = tag : nn &gt; vb &lt; tag : vb @ \ [ -l\ ] ? ; Sometimes , a random sample of a positive rule might be more useful : 7sample ( RuleID , nn , vb ) , RuleID # Rule. Rule = tag : nn &gt; vb &lt; tag : vb @ \ [ -1\ ] As for negative instances , we may want to know if the rule tag : vb &gt; nn &lt; tag : dr @ \ [ -1\ ] has any negative instances in the training data , and indeed there is one at position 8 , where vb is aligned with jj rather than nn : ? RuleID # ( tag : vb &gt; nn &lt; tag : dt0\ [ -l\ ] ) , negative ( RuleID , A , B , P ) . h = vb , B = jj , P = 8 ? Library ranking Library ranking is a package for scoring and ranking rules. It was written for the specific purpose of scoring transformation rules in the context of TBL , but is likely to be more generally useful , hence deserving its status as a libra~'y. The basic notions are defined as follows : A score is an integer &gt; 0 A ranking entry is a pair S-R such that S is a score and R is a rule A ranking is an ordered sequence of ranking entries where each rule occurs only once .</sentence>
				<definiendum id="0">RuleID</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">we might be interested only in instances where the aligned feature values ( h and B ) are different</definiens>
				<definiens id="1">a Sdif/2 is a built-in predicate in SICStus Prolog. A call to dif ( X , Y ) constrains X and Y to represent different terms. Calls to dif/2 either succeed~ fail. or are blocked depending oil whether X and Y are sufficiently instantiated. 36 l 7dif ( A , B ) , positive ( ID , A , B ) , ID # Rule. Or , we might be interested only in template instances where the aligned symbols have feature values nn and vb , respectively. There is only one such rule : i ? positive ( RulelD , nn , vb ) , RuleID # Rule. Rule = tag : nn &gt; vb &lt; tag : vb @ \ [ -l\ ] ? ; Sometimes , a random sample of a positive rule might be more useful : 7sample ( RuleID , nn , vb ) , RuleID # Rule. Rule = tag : nn &gt; vb &lt; tag : vb @ \ [ -1\ ] As for negative instances , we may want to know if the rule tag : vb &gt; nn &lt; tag : dr @ \ [ -1\ ] has any negative instances in the training data , and indeed there is one at position 8 , where vb is aligned with jj rather than nn : ? RuleID # ( tag : vb &gt; nn &lt; tag : dt0\ [ -l\ ] ) , negative ( RuleID , A , B , P ) . h = vb , B = jj , P = 8 ? Library ranking Library ranking is a package for scoring and ranking rules. It was written for the specific purpose of scoring transformation rules in the context of TBL , but is likely to be more generally useful , hence deserving its status as a libra~'y. The basic notions are defined as follows : A score is an integer &gt; 0 A ranking entry is a pair S-R such that S is a score and</definiens>
				<definiens id="2">a rule A ranking is an ordered sequence of ranking entries where each rule occurs only once</definiens>
			</definition>
			<definition id="2">
				<sentence>WRS ) Among the different instances of R , NR is the rule with the highest score ( i.e. the 'winning rule ' ) , and NRS is its score , defined as the number of solutions to the goal PGoal minus the number of solutions to NGoal .</sentence>
				<definiendum id="0">WRS</definiendum>
				<definiendum id="1">NR</definiendum>
				<definiendum id="2">NRS</definiendum>
				<definiens id="0">) Among the different instances of R ,</definiens>
				<definiens id="1">the rule with the highest score ( i.e. the 'winning rule '</definiens>
			</definition>
			<definition id="3">
				<sentence>Works a~ if defined by : highscore ( R , PGoal , NGoal , ST , AT , WR , ~IRS ) -rank ( R , PGoal , ST , Rnkng ) , penalize ( R , NGoal , Rnkng , ST , AT , NewRnkng ) , at _pos it ion ( 1 , NewRnkng , WR , WRS ) .</sentence>
				<definiendum id="0">NewRnkng )</definiendum>
				<definiens id="0">highscore ( R , PGoal , NGoal , ST , AT , WR , ~IRS ) -rank ( R , PGoal , ST , Rnkng ) , penalize ( R , NGoal , Rnkng , ST , AT ,</definiens>
			</definition>
			<definition id="4">
				<sentence>rank ( R , A-B ' ( dif ( A , B ) , positive ( R , A , B ) ) , l , L ) , print_ranking ( L ) .</sentence>
				<definiendum id="0">B</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">A , B ) ) , l</definiens>
			</definition>
			<definition id="5">
				<sentence>3 tag : vb &gt; nn &lt; tag : dt @ \ [ -1\ ] 1 tag : vb &gt; jj &lt; tag : dtO\ [ -l\ ] I I I I I I I I I I I i I I I I I I I And here is how we find the highest scoring rule : I 7highscore ( R , A'B ' ( dif ( A , B ) , positive ( R , A , B ) ) , negat ire ( R ) , 1 , WR , WRS ) . WR = tag : vb &gt; nn &lt; tag : tit @ \ [ -1\ ] , WRS = 3 ? ; This concludes the demonstration of how the template compiler and the ranking library allows a particular combination of templates and training data to be interactively explored from the Prolog prompt. Simple TBL Full transformation-based learning is just a small snippet of code away. Given corpus data , templates and values for the thresholds ( ST and AT ) , the predicate tbl/3 implements learning of a sequence of rules : Program 1 tbl ( ST , AT , WRs ) : ( highscore ( Rule , A'B '' ( dif ( A , B ) , positive ( Rule , A , B ) ) , negative ( Rule ) , ST , AT , WR , WRS ) - &gt; apply ( ~ ) , tbl ( ST , AT , WRsl ) , was = \ [ ~n~lWas13 ; WRs = \ [ \ ] ) .</sentence>
				<definiendum id="0">B )</definiendum>
				<definiens id="0">a particular combination of templates and training data to be interactively explored from the Prolog prompt. Simple TBL Full transformation-based learning is just a small snippet of code away. Given corpus data , templates and values for the thresholds</definiens>
			</definition>
			<definition id="6">
				<sentence>learn_one ( RnkngO , LR , LRS , AT , NR , NRS ) : ( RnkngO -\ [ N-CA , B ) lEnkng\ ] , N &gt; LRS - &gt; ( highscore ( R , positive ( R , A , B ) , negative ( R , A , A ) , LRS , AT , LR1 , LRSI ) - &gt; learn_one ( Rnkng , LR1 , LRS1 , AT , NR , NRS ) ; learn_one ( Rnkng , LR , LRS , AT , NR , WRS ) ) ; NR = LR , NRS = LI~ ) .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">RnkngO , LR , LRS , AT , NR , NRS ) : ( RnkngO -\ [ N-CA ,</definiens>
			</definition>
			<definition id="7">
				<sentence>An implementation of this algorithm can be assembled by replacing the definition of learn_one/6 in Program 2 with the following definition : Program 3 learn_one ( Rnkng0 , LR , LRS , AT , NR , NRS ) : ( Rnkng0 = \ [ N- ( A , B ) IRnkng\ ] , N &gt; LRS - &gt; samp1e_R ( 16 , A , B , Rs ) , ( highscore ( R , ( member ( R , Rs ) , positive ( R , A , B ) ) , negative ( R , A , A ) , LRS , AT , LRI , LRS1 ) learn_one ( Rnlmg , LRI , LRSl , AT , NR , NRS ) Iearn_one ( Rnkng , LR , LRS , AT , NR , NRS ) - &gt; ) ) .</sentence>
				<definiendum id="0">B</definiendum>
				<definiendum id="1">B ) )</definiendum>
				<definiendum id="2">LRI , LRSl , AT , NR , NRS ) Iearn_one ( Rnkng , LR , LRS , AT , NR</definiendum>
				<definiens id="0">Rnkng0 , LR , LRS , AT , NR , NRS ) : ( Rnkng0 = \ [ N- ( A ,</definiens>
			</definition>
			<definition id="8">
				<sentence>Instead of loading a set of templates into the system , the user may load a couple of template declarations , which , in terms of 'window ' sizes and ranges of relative positions over which windows 'slide ' , constrain the relation between templates and clauses , defined by the template grammar .</sentence>
				<definiendum id="0">template declarations</definiendum>
				<definiens id="0">'window ' sizes and ranges of relative positions over which windows 'slide ' , constrain the relation between templates and clauses</definiens>
			</definition>
			<definition id="9">
				<sentence>Interactive Prolog is all interactive language and this is something that the # -TBL system inherits .</sentence>
				<definiendum id="0">Interactive Prolog</definiendum>
				<definiens id="0">all interactive language</definiens>
			</definition>
			<definition id="10">
				<sentence>Grammatical bfference : Learning Syntax : fi'om Sentences , Springer Verlag .</sentence>
				<definiendum id="0">Grammatical bfference</definiendum>
				<definiens id="0">Learning Syntax : fi'om Sentences</definiens>
			</definition>
</paper>

		<paper id="0612">
			<definition id="0">
				<sentence>Precision ( P ) represents the percentage of the entities that the system recognized 95 which are actually correct .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">P )</definiendum>
				<definiens id="0">the percentage of the entities that the system recognized 95 which are actually correct</definiens>
			</definition>
			<definition id="1">
				<sentence>Recall ( R ) represents the percentage of the correct named entities in the text that the system identified .</sentence>
				<definiendum id="0">Recall</definiendum>
			</definition>
			<definition id="2">
				<sentence>Configuration ( e ) shows contrastive performance when using standard continuous EM smoothing on the same data and data structures .</sentence>
				<definiendum id="0">Configuration ( e )</definiendum>
				<definiens id="0">shows contrastive performance when using standard continuous EM smoothing on the same data and data structures</definiens>
			</definition>
</paper>

		<paper id="0203">
			<definition id="0">
				<sentence>1 ( x _ &lt; n ) fa ( n , x ) = 0 ( x &gt; n ) ( 5 ) where x is the order of certainty of candidates .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">the order of certainty of candidates</definiens>
			</definition>
			<definition id="1">
				<sentence>The system combines these results into one result funion ( n , m , z ) , where the person corresponding to z is expected to be a common person , funion ( n , m , z ) is the final output of the whole system .</sentence>
				<definiendum id="0">z )</definiendum>
				<definiens id="0">the final output of the whole system</definiens>
			</definition>
</paper>

		<paper id="0308">
			<definition id="0">
				<sentence>These characteristics of the Metamodel mean that the therapist can challenge the client 's assumptions that their linguistic model is reality , which is a major part of the therapeutic process .</sentence>
				<definiendum id="0">reality</definiendum>
				<definiens id="0">a major part of the therapeutic process</definiens>
			</definition>
</paper>

		<paper id="0633">
			<definition id="0">
				<sentence>In this study Brill 's rule-based part of speech ( PoS ) tagger is tested on Hungarian , a dissimilar language , concerning both morphology and syntax , to English .</sentence>
				<definiendum id="0">PoS</definiendum>
				<definiens id="0">a dissimilar language , concerning both morphology and syntax , to English</definiens>
			</definition>
			<definition id="1">
				<sentence>A rule consists of two parts : a condition ( the trigger and possibly a current tag ) , and a resulting tag .</sentence>
				<definiendum id="0">rule</definiendum>
				<definiens id="0">consists of two parts : a condition ( the trigger and possibly a current tag )</definiens>
			</definition>
			<definition id="2">
				<sentence>The tag set of the training corpus consists of 452 PoS tags including inflectional properties of 31 different parts of speech .</sentence>
				<definiendum id="0">tag</definiendum>
				<definiens id="0">set of the training corpus consists of 452 PoS tags including inflectional properties of 31 different parts of speech</definiens>
			</definition>
			<definition id="3">
				<sentence>Precision ( correct_found/retrieved_total ) and recall ( correct_found~intended_total ) for PoS categories of both test texts PoS tags DET ( Determiner ) NM ( Pronoun ) FN ( Noun ) MN ( Adjective ) i IGE ( Verb ) INF ( Infinitive ) IK ( Verbal Particle ) HA ( Adverb ) SZN ( Numeral ) NU ( Postposition ) KOT ( Conjunction ) ISZ ( Interjection ) Precision Recall To sum up the results , the tagger has greatest difficulties with categories belonging to the open classes because of 279 their morphological structure and homonymy , while grammatical categories are easier to detect and correctly annotate .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">Verbal Particle ) HA ( Adverb ) SZN ( Numeral ) NU ( Postposition ) KOT ( Conjunction ) ISZ ( Interjection ) Precision Recall To sum up the results , the tagger has greatest difficulties with categories belonging to the open classes because of 279 their morphological structure</definiens>
			</definition>
			<definition id="4">
				<sentence>Also , Hungarian is a pro-drop language , i.e. , the subject position of the verb can be left empty , which implies a larger number of contextual rules for Hungarian than for English because of the paradigmatic and/or syntagmatic difference between personal pronouns and nouns .</sentence>
				<definiendum id="0">Hungarian</definiendum>
				<definiens id="0">a pro-drop language</definiens>
			</definition>
			<definition id="5">
				<sentence>Transformation-Based ErrorDriven Learning and Natural Language Processing : A Case Study in Part of speech Tagging .</sentence>
				<definiendum id="0">Transformation-Based ErrorDriven Learning</definiendum>
				<definiens id="0">Natural Language Processing : A Case Study in Part of speech Tagging</definiens>
			</definition>
</paper>

		<paper id="0103">
			<definition id="0">
				<sentence>Introduction Human face &lt; o-face communication is an ideal model for humm-computainterface. One of the major features of face-to-face communication is its multiplicity of communication channels that acts on multiple modalities. By providing a number of channels through which information may pass between a user and a computer , a multi-modal dialogue system gives the user a • more convenient and natural interface than a language-only dialogue system. In the system , a user often uses a variety of anaphodc expressions like this , the red item , it , etc. User 's intention is passed to the system through multiple channels , e.g. , the auditory channel ( carrying speech ) and the visual channel ( c~nrying gestures and/or facial expressions ) . For example , a user can say utterance ( 4 ) in Figure ! ! while touching an item on the screen. The user may also say utterance ( 8 ) without touching the screen when there is only one red item displayed on the screen. Moreover , the user can use anaphoric expression to refer to an entity in previous utterances as in utterance ( 10 ) . ( 1 ) S : May I help you7 ( 2 ) U : I want to see some desks. ( 3 ) S : ( displaying mode/200 and mode/250 ) We have these modeb. ( 4 ) U : ( pointing to the model200 ) How much is thLv ? ( 5 ) S : It is 150,000 Won. ( 6 ) U : I 'd like to see some chairs , too. ( 7 ) S : ( displaying model 100 and model 150 ) We have t/w~re medeb. ( 8 ) U : How much is the red item ? ( 9 ) S : It is 80,000 Won. ( 10 ) U : ( pointing to the model 100 ) l 'd like to buy thb and tke prev/ous se/ect/on. Figure 1 : Motivational example I Previous rescaw , h on a multi-modal dialogue system was focused on finding the relationship between a pointing gesture and a deictic expression ( Bolt ( 1980 ) , Neal et al. ( 1988 ) , Salisbury et al. ( 1990. ) , Shimazu et al. ( 1994 ) , Shimazu and Takmhima ( 1996 ) ) and on mapping a predefined symbol to a simple t S means a multi-modal dialogue system and U means a user. Our goal is developing a multi-modal dialogue system ( Kim and Son ( 1997 ) ) . of which domain is home shopping and in which a user purchases furniture using Korean utC~ ' , mccs with pointing gestures on a touch screw. 21 command ( Johnston et al. ( 1997 ) ) . None of them , however , suggest methods of resolving deictic expressions with which pointing gestures are omitted : e.g.. the red item in utterance ( 8 ) . These approaches do not consider resolving an anaphoric expression that refers an object mentioned in previous utterances or displayed on previous screens. It , however , is important also for a multi-modal dialogue system to resolve all of these anaphora so that the system should correctly catch his/her intention. In this paper , we propose general methods to resolve a variety of anaphoric expressions that are found in a multi-modal dialogue. We classify anaphora into two types : deictic expression with/without a pointing gesture and referring expression , and propose methods to resolve them. To resolve deictic expression like this in utterance ( 4 ) which c~rs with a pointing gesture and the red item in utterance ( 8 ) which is uttered with no pointing gestures , the system counts the `` number of pointing gestures and the number of anaphoric noun phrases included in a user 's utterance , and compares them. Then , the system maps the noun phrases to pointed items. To resolve referring expression , one of the well known methods is centering theory developed by Grosz , Jo~hi , and Weinstein ( Grosz et al. ( 1983 ) ) . The centering algorithm was further developed by Brennan , Friedman and Pollard for pronoun resolution ( Brennan et al. ( 1987 ) ) and was improved by Walker ( Walker ( 1998 ) ) . However , ' those centering algorithms are not applicable to resolve anaphora in a multi-medal dialogue because the algurithm excludes the gestures and facial • expression of a dialogue partner , which are important clues to mgierstand his/her uttexances. And. the algorithm can not resolve complex anaphora like the previous selection in ( 10 ) beeanse it does not keep the time When the previous screen is switched to the current screen. To resolve inch anaphom , we extend Walker 's centedng algorithm to the one with a dual cache model , which keeps the information displayed on a ~ With screen switching-time. The rest of this paper begins with describing our approach in section ! . After showing two methods to resolve anaphora in a rrmlti-modal dialogue system in section 2 , we report experimental results on these methods in section 22 In this paper , we define two types of anaphora : screen anaphora and referring anaphora. Screen anaphora is an anaphoric noun phrase that refers to an entity on the present screen by a pointing gesture or through a visual channel. For example , th/s in uuerance ( 4 ) in Figure ! is the screen anaphora referred by a pointing gesture , and the red item in utterance ( 8 ) is the one referred through a visual channel. Referring anaphora is an anaphoric noun phrase that refers to an entity in previous utterances or on pre~ , ions screens , For example , we call it in utterance ( 9 ) referring anaphora because the referred entity is the red item in the previous utterance ( 8 ) . We also call the previous selection in utterance ( 10 ) referring anaphora because the refe~nt is the model 200 shown on the previous screen. The screen anaphora resolution algorithm counts the number of pointing gestures and the number of anaphoric noun phrases included in the user 's utterance and compares them. If the numbers are equal , the system maps the gestures to the phrases. Otherwise. the system uses some heuristics to map the gestures according to the priority of the phrases. The referring anaphora resolution algorithm is based on the Walker 's centering algorithm with a cache model. Centering is formulated as a theory that relates focus of attention , choice of referring expressions and perceived coherence of utterances ; within a discourse segment. The centering algorithm ( Ccnsz et al. ( 1983 ) , Brennan et al. ( 1987 ) , Walker et aL ( 1990 ) ) consists of three main structures. Forwardlooking Centers are entities which form a set of entities associated with each. utterance. Forward-looking Centers are ranked according to their relative salience. The highest ranged entity is called the Preferred Center. Backwardlooking Center is a special member of this set. It is the highest ranked member of Forwardlooking Centers of the previous utterance , which is also realized in the current utterance. The algorithm defines a set of constraints , rules , and transition states between a pair of utterances by the use of these structures. It incorlgntes these rules and the other linguistic constraints to resolve anaphoric expressions. In the past , it was integrated with a stack model because most researchers believed that the centers should exist within a discourse segment ( Grosz and Sidner 0 0 0 0 O 0 0 0 0 O 0 0 0 0 0 0 0 0 O 0 0 0 0 0 0 0 O 0 0 0 0 O O ( 9 } NtS 80.000 WOn. { 8 } HOw much nt ff~ ' *~ steoO ( ~ ' ) We have s. , ~se moOel $ citer* , ttm feuee¢ .. &gt; S'wffchit~l-fime Cache Memory Figure 2 : Walker 's cache model • ~ m~ra~ sk~ ~maml slol lwmbll~ m~ m~t r , e~ m m~ JG~m~ Id~ ~a~ ~iw um~q W mb t~ .</sentence>
				<definiendum id="0">o-face communication</definiendum>
				<definiendum id="1">U</definiendum>
				<definiens id="0">an ideal model for humm-computainterface. One of the major features of face-to-face communication is its multiplicity of communication channels that acts on multiple modalities. By providing a number of channels through which information may pass between a user</definiens>
				<definiens id="1">the auditory channel ( carrying speech ) and the visual channel ( c~nrying gestures and/or facial expressions ) . For example</definiens>
				<definiens id="2">a predefined symbol to a simple t S means a multi-modal dialogue system and</definiens>
				<definiens id="3">general methods to resolve a variety of anaphoric expressions that are found in a multi-modal dialogue. We classify anaphora into two types : deictic expression with/without a pointing gesture and referring expression</definiens>
				<definiens id="4">the red item in the previous utterance ( 8 )</definiens>
				<definiens id="5">the model 200 shown on the previous screen. The screen anaphora resolution algorithm counts the number of pointing gestures and the number of anaphoric noun phrases included in the user 's utterance and compares them. If the numbers are equal , the system maps the gestures to the phrases. Otherwise. the system uses some heuristics to map the gestures according to the priority of the phrases. The referring anaphora resolution algorithm is based on the Walker 's centering algorithm with a cache model. Centering is formulated as a theory that relates focus of attention</definiens>
				<definiens id="6">consists of three main structures. Forwardlooking Centers are entities which form a set of entities associated with each. utterance. Forward-looking Centers are ranked according to their relative salience. The highest ranged entity is called the Preferred Center. Backwardlooking Center is a special member of this set. It is the highest ranked member of Forwardlooking Centers of the previous utterance , which is also realized in the current utterance. The algorithm defines a set of constraints , rules , and transition states between a pair of utterances by the use of these structures. It incorlgntes these rules</definiens>
			</definition>
			<definition id="1">
				<sentence>occurs when a user omits a pointing gesture because heJshe can uniquely select an item on the screen with the anaphoric expression or when the~ are referring anaphom as well as screen amphora as in utterance ( I0 ) in Figure I. In the former case , the algorithm can easily resolve the anaphora because it can uniquely decide the referred entity on the screen by visual information of the item .</sentence>
				<definiendum id="0">I0</definiendum>
			</definition>
			<definition id="2">
				<sentence>The omission consists of two types : partial omission and total omission .</sentence>
				<definiendum id="0">omission</definiendum>
				<definiens id="0">consists of two types : partial omission and total omission</definiens>
			</definition>
			<definition id="3">
				<sentence>The dual cache model consists of two slots and time points : visual slot , utterance slot , and screen switching-times as shown in Figure 4 .</sentence>
				<definiendum id="0">dual cache model</definiendum>
				<definiens id="0">consists of two slots and time points : visual slot , utterance slot , and screen switching-times as shown in Figure 4</definiens>
			</definition>
			<definition id="4">
				<sentence>In Figure 4 , Vt is the kth visual slot , which includes visual information of the kth screen .</sentence>
				<definiendum id="0">Vt</definiendum>
				<definiens id="0">includes visual information of the kth screen</definiens>
			</definition>
</paper>

		<paper id="0201">
			<definition id="0">
				<sentence>Therefore , for doc.36 ( Figure 2 ) , since at least one of the three noun phrases ( `` John Perry , '' `` he , '' and `` Perry '' ) in the coreference chain of interest appears in each of the three sentences in the extract , the summary produced by SentenceExtractor is the extract itself .</sentence>
				<definiendum id="0">SentenceExtractor</definiendum>
				<definiens id="0">the extract itself</definiens>
			</definition>
			<definition id="1">
				<sentence>The final precision and recall numbers are computed by the following two formulae : N Final Precision = ~ wi * Precisioni i=l N = ~ wi * Recalli Final Recall i -- -- 1 where N is the number of entities in the document , and wi is the weight assigned to entity i in the document .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">wi</definiendum>
				<definiens id="0">the number of entities in the document , and</definiens>
			</definition>
			<definition id="2">
				<sentence>~ MUC AIg : Recall -+ -- '' -- GI ( . ''</sentence>
				<definiendum id="0">-- GI</definiendum>
				<definiens id="0">Recall -+ -- ''</definiens>
			</definition>
			<definition id="3">
				<sentence>The `` election '' data set often mentioned election events which consisted of more than one actual election .</sentence>
				<definiendum id="0">election</definiendum>
				<definiens id="0">'' data set often mentioned election events which consisted of more than one actual election</definiens>
			</definition>
</paper>

		<paper id="0901">
			<definition id="0">
				<sentence>It estimates p ( clv , r ) as f ( v , r , c ) /~c ' f ( v , r , c ' ) , where f ( v , r , c ) is in turn approximated by allocating the frequency of the cooccurrence tuple ( v , r , n ) among the classes C ( n ) to which the senses of n belong .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">in turn approximated by allocating the frequency of the cooccurrence tuple ( v , r , n ) among the classes C ( n ) to which the senses of n belong</definiens>
			</definition>
			<definition id="1">
				<sentence>Suppose further that BREAD is a hyponym of BAKED-GOODS , FOOD , ARTIFACT , and TOP , and MONEY is a hyponym solely of TOP .</sentence>
				<definiendum id="0">MONEY</definiendum>
				<definiens id="0">a hyponym of BAKED-GOODS , FOOD , ARTIFACT , and TOP , and</definiens>
				<definiens id="1">a hyponym solely of TOP</definiens>
			</definition>
			<definition id="2">
				<sentence>The HMM consists of a set of states { ql , ... , qn } , which we identify with the nodes of the concept graph ; a set of possible emissions which we identify with W U { e } ( that is , we permit non-emitting states ) ; and three parameter matrices : A = { aij } The transition probabilities .</sentence>
				<definiendum id="0">HMM</definiendum>
			</definition>
			<definition id="3">
				<sentence>The value aij represents the probability of making a transition from state qi to state qj .</sentence>
				<definiendum id="0">transition</definiendum>
				<definiens id="0">the probability of making a</definiens>
			</definition>
			<definition id="4">
				<sentence>Each HMM has the same structure , determined by the semantic hierarchy .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">the same structure , determined by the semantic hierarchy</definiens>
			</definition>
			<definition id="5">
				<sentence>The training sample consists of the nouns filling the associated `` slot '' ( v , r ) -- that is , a token of the noun n is included in the training sample for each token of the tuple ( v , r , n ) that occurs in the corpus .</sentence>
				<definiendum id="0">training sample</definiendum>
				<definiens id="0">consists of the nouns filling the associated `` slot '' ( v , r ) -- that is , a token of the noun n is included in the training sample for each token of the tuple ( v , r , n ) that occurs in the corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>Words apple , bagel , and cheese , along with half of meat , provide evidence for the state FOOD , giving it a total count of 31/2 ; but the only evidence for state COGNITION is the other half of meat , giving it a total count of 1/2 .</sentence>
				<definiendum id="0">COGNITION</definiendum>
				<definiens id="0">the other half of meat , giving it a total count of 1/2</definiens>
			</definition>
			<definition id="7">
				<sentence>j ) w ) where Ew ( ) is the expectation based on the model and corpus and D ( j , w ) is the number of unique paths starting at j and ending in a state that can generate w. One then sums over all tokens of the corpus to get the expectation for the corpus .</sentence>
				<definiendum id="0">Ew ( )</definiendum>
				<definiendum id="1">w )</definiendum>
				<definiens id="0">the expectation based on the model and corpus</definiens>
				<definiens id="1">the number of unique paths starting at j and ending in a state that can generate w. One then sums over all tokens of the corpus to get the expectation for the corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>WordNet : An On-Line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0306">
			<definition id="0">
				<sentence>However , it is highly questionable that p ( WilGi ) can adequately be modeled using standard n-gram models , because : • it appears that a much smaller portion of ngrams have discriminative distributions for dialogue games in comparison with the speech act case • the interaction between the speakers is lost using word level bigram or trigram statistics Detection from the speech act level : For these reasons , we have been pursuing a second possible modeling approach , which estimates p ( WilGi ) with a probability model that uses speech-acts as an intermediate discourse level : p ( W lG , ) = p ( W , lS , , G , ) p ( S , IG , ) s 44 Using similar independence assumptions as above we can rewrite this as p ( w , IG , ) = p ( S , IG , ) S j=l , ... , rni In this setup potential speech act constraints of dialogue games are enforced explicitly .</sentence>
				<definiendum id="0">WilGi</definiendum>
				<definiens id="0">p ( W , lS , , G , ) p ( S , IG , ) s 44 Using similar independence assumptions as above we can rewrite this as p ( w , IG , ) = p ( S , IG , ) S j=l , ...</definiens>
			</definition>
</paper>

		<paper id="0303">
			<definition id="0">
				<sentence>The Text Encoding Initiative ( TEI ) will soon be broadening its scope , so far mostly concerned with text structure , but has not circulated concrete proposals yet on discourse .</sentence>
				<definiendum id="0">Text Encoding Initiative ( TEI</definiendum>
				<definiens id="0">circulated concrete proposals yet on discourse</definiens>
			</definition>
			<definition id="1">
				<sentence>REASONING AND RHETORIC Reasoning and &lt; ASSN &gt; assertion argumentation &lt; JUSTIF &gt; type= { fact , goal , analogy , justification declaration } &lt; EVID &gt; evidence &lt; BACKGROUND &gt; background &lt; CONCESSION &gt; concession &lt; CONTRAST &gt; contrast &lt; EX &gt; reality : { present , past , virtual , example 19 m m m TYPE TAG ELEMENTS DESCRIPTION projected } &lt; C-EX &gt; &lt; HYP &gt; &lt; REL &gt; &lt; CONS &gt; &lt; CONDITION &gt; &lt; ATT-CONS &gt; &lt; CONTRA JUST &gt; &lt; PRO &gt; &lt; CONTRA &gt; &lt; ANN-ASSN &gt; &lt; WHATIF &gt; &lt; METAPHOR &gt; &lt; INTERP &gt; Rhetorical &lt; REAS_TECHNIQUE &gt; &lt; TROPE &gt; &lt; RHETQUES &gt; &lt; FOCUS &gt; Tone &lt; POL &gt; Description of a &lt; FRAME OF REF &gt; state of affairs &lt; SITUATION &gt; &lt; BACKGROUND &gt; &lt; SCENARIO &gt; Actors and assertions ; polemical stance &lt; ALTERNATIVE &gt; &lt; RECOM &gt; &lt; ACTOR &gt; &lt; OPP &gt; Text function &lt; INTRO &gt; &lt; DEVT &gt; &lt; REPHRASE &gt; &lt; CONCL &gt; &lt; SUMMARY &gt; &lt; QUOTE &gt; &lt; REF &gt; &lt; LINK &gt; &lt; COMMENT &gt; Narrative &lt; EVENT &gt; structure Speech acts , actor interaction &lt; LATEREVENT &gt; &lt; QUES &gt; &lt; ANSW &gt; &lt; REQUEST &gt; type = { modusPonens , modusTollens , induction ... } type : { stresslmportance , stressUrgency } tone = { ironic , derisive , afflicted , aggressive } ref= { nature , etc. } mod= { certain , likely , unlikely , imposs ible } mod= { certain , likely , unlikely , imposs ible } name , title expose = { lie , inconsequence } strategy = { counter-facts , badconsequences , bad-outweighs-good , untenable-principles , badPrecedents } BY ( element allowed in any tag ) adeq = { adequate , beside the point } counter-example hypothesis related to enounce consequences ( of state of affairs ) premiss or condition attitude as a natural consequence justification for opposition position-pro , position-contra contradict-without-justification announce assertion thought experiment metaphor interpretation of a state of affairs , a stance , or a declaration reasoning technique tropes as commonplaces ( mere ) rhetorical question use of focus ( e.g. importance of an element in the reasoning ) varieties of polemic tone model ( description of one 's view of a state of affairs ) ; its frame of reference description of the current situation background on the situation hypothesis on the future alternative recommendation an actor : a person or institution saying or doing something opposition introduction development rephrasing conclusion summary point quoting an actor reference ( hyper ) link author 's comment event with actor , time , type etc. later or subsequent event author of an utterance , believer of an opinion question anSWfff requesting information m m m m m m m m m m u m m m mm 20 TYPE TAG ELEMENTS DESCRIPTION Logical evaluation , &lt; GOOD ARG &gt; including fallacies &lt; FALLACY &gt; Reader 's position and comments &lt; CONTRAD &gt; &lt; CONTRAD EXT &gt; &lt; COMMONPLACE &gt; &lt; AGREE &gt; &lt; DISAG &gt; &lt; SEARCH FOR EVID &gt; &lt; KW &gt; &lt; REM &gt; to = 113 of referent to = ID of referent supplying information rebuttal of an actor 's point by another actor apology flattery type = { beggingTheQuestion , redHerring , ignoratioElenehi , simplisticModel , strawMan , AdMajoritatem , adHominem , overGeneralization , etc. } ref .</sentence>
				<definiendum id="0">REASONING AND RHETORIC Reasoning</definiendum>
				<definiens id="0">past , virtual , example 19 m m m TYPE TAG ELEMENTS DESCRIPTION projected } &lt; C-EX &gt; &lt; HYP &gt; &lt; REL &gt; &lt; CONS &gt; &lt; CONDITION &gt; &lt; ATT-CONS &gt; &lt; CONTRA JUST &gt; &lt; PRO &gt; &lt; CONTRA &gt; &lt; ANN-ASSN &gt; &lt; WHATIF &gt; &lt; METAPHOR &gt; &lt; INTERP &gt; Rhetorical &lt; REAS_TECHNIQUE &gt; &lt; TROPE &gt; &lt; RHETQUES &gt; &lt; FOCUS &gt; Tone &lt; POL &gt; Description of a &lt; FRAME OF REF &gt; state of affairs &lt; SITUATION &gt; &lt; BACKGROUND &gt; &lt; SCENARIO &gt; Actors and assertions ; polemical stance &lt; ALTERNATIVE &gt; &lt; RECOM &gt; &lt; ACTOR &gt; &lt; OPP &gt; Text function &lt; INTRO &gt; &lt; DEVT &gt; &lt; REPHRASE &gt; &lt; CONCL &gt; &lt; SUMMARY &gt; &lt; QUOTE &gt; &lt; REF &gt; &lt; LINK &gt; &lt;</definiens>
			</definition>
			<definition id="2">
				<sentence>As intended , the selection of the output type is done by an HTML interface lauching a CGI which parses the XML and translates it to HTML , selectively to reflect the choice of viewing made by the user .</sentence>
				<definiendum id="0">CGI</definiendum>
				<definiens id="0">parses the XML and translates it to HTML , selectively to reflect the choice of viewing made by the user</definiens>
			</definition>
</paper>

		<paper id="0507">
			<definition id="0">
				<sentence>SIMPLE is a large-scale Emopean lexicon project funded by the European Commlssmn with the partlctpat~on ot 12 European countries The mm of the project is to add harmomzed semantm mtormatlon to the LE-PAROLE lexicons 1 , which contain motphological and syntactic information In this paper we present some examples of concrete nouns trom the Danish SIMPLE lexicon which illustrate two central aspects of the SIMPLE model 1 ) the expressive power of the Quaha Structure exemphhed with a phenomenon relevant to a Scandinavian language like Damsh namely the iepresentatlon of the mternal structure of Danish nondevet bal nominal compounds , and 2 ) the leptesentatmn ol legular polysemy in the Damsh SIMPLE lexmon The SIMPLE model is primarily based on three lexlcal flameworks ( Lencl et al , 1998 ) The Geneiatlve Lexicon ( cf Pustejovsky , 1995 ) , WoldNet ( cf Miller and Fellbaum , 1991 ) , and EuroWordNet ( ct Vossen et al , 1998 ) The basic underlying assumption m the model is that word senses diffei in tel ms of their internal complexity Hence the SIMPLE model consists of three different semantic types ( t ) simple types , which can be characterized In terms of z The LE-PAROLE lexlcons contain 20,000 entries with corresponding morphological and syntactic mlormation tot each ot the 12 languages that parttclpated m this project , whlch was also tunded by the European Commtssmn ( ct Rmmy et al , 1998 ) monodimensional relations , ( n ) unified types , which involve multidimensional information , and ( ill ) complex types , which identify regular polysemous classes One of the basic tasks during the SIMPLE lexicon encoding phase is the assignment of semantic typing to the word senses to be encoded ( called the semantic units or SemU 's ) A set of schematic structures called 'templates ' constituting the SIMPLE Ontology ( consisting of approx 140 semantic types in all ) guides thls encoding process A template ~s a cohort of various different Information types which is primarily used by the lexicon encoder to express the semantic type of a word sense , but also to express its domain , defmlnon , predicative representation , argument structure , polysemous classes , etc The multiple dimensions of meaning are represented In SIMPLE by the use of the Quaha Structure from the Generative Lexicon ( Pustejovsky 1995 ) to represent lexlcal meaning expressed by means oforthogonat inheritance The Quaha Structure involves tour different roles 0 ) the formal role , which ptovldes reformation that distinguishes an entity wtthm a lalger set , 01 ) the agennve role , which concelns the orlgm of an entity , ( m ) the tehc role , which concerns the typical function of an entity , and 0v ) the constitutive role , which expresses a variety of relations concerning the internal constitution of an entity As an illustration , consider m Figure 1 the meaning components involved m the noun pudding 46 Figure 1 : The meaning components ofpuddmg ( Lento et al 1998 pp 17 ) constitutive ~ agenttve I\ [ \ [ \ [ 1 substance ingredients eat make puddmg The central meaning aspects are m~rrored in the llngmstlc contexts surrounding the word , so for pudding we could have John refused the pudding refemng to the eat event , that 's an easy pudding referring to the make event , there zs pudding on tile floor referring to the substance dimension , and that was a nice bread puddmg referrmg to the ingredients of whlch it Is made As an example of the semantic types explessed m the SIMPLE Ontology and of how the different dlmensmns of meaning are involved for each semantic type , consider F~gure 2 which shows a subset of the SIMPLE ontology referring to human beings Figure 2 : Subset of the SIMPLE Core Ontology representing human beings Some examples of word senses encoded as simple types are russer ( a Russian ) under the template type 'people ' , 'jcde ( Jew ) .</sentence>
				<definiendum id="0">SIMPLE</definiendum>
			</definition>
			<definition id="1">
				<sentence>of expresswe power m the lex~cal entries The Quaha Structure as It ~s expressed m the SIMPLE model provides a good basls for a lexlcahsed encoding of Damsh non-deverbal nominal compounds , as for example nominal compounds denoting containers The template type 'Container ' belongs to the set of templates conmtutmg the SIMPLE Core Ontology It is a unified type that has the umficat~on path 'Concrete entity + Artffact/Agenttve + Tehc ' Thts indicates that the template denotes a kind of concrete ennty , and that ~t has been augmented w~th two kinds of addltmnal type-defining mformatmn ( 1 ) agentlve mformatmn ( namely that these concrete entrees are man-made artifacts ) , and ( n ) tehc mformatmn ( namely that these concrete entrees are used for a spemfic purpose to contain things ) All Damsh contamers encoded under th~s template type have been encoded w~th Damsh mformatmn about the formal role vm an tsahlermchy As a default , beholder ( container ) is chosen as hypernym for the Damsh containers m the re_a-hierarchy Since containers are ( manmade ) artifacts , the process of their creanon ~s spectfied wa the agentlve role For Damsh containers thls is the process fremsttlle ( to create ) As Is apparent from the umficatmn path for th~s template , containers are also encoded w~th the type-defining tehc mformatmn that their funcnon ts to contam things For Damsh containers th~s ~s specified w~th the verb mdeholde ( to contam ) m the encoding of the tehc role the tehc role for such compounds as mdlebteger ( measuring cup ) , raflebceger ( ht cup for casting dice = dice cup ) , or drtkkebmger ( dnnkmg cup ) In the SIMPLE model , the encoding of the meaning of bmger can also be further specified by mcludmg mformatmn about the constltutwe .</sentence>
				<definiendum id="0">Quaha Structure</definiendum>
				<definiendum id="1">tehc mformatmn</definiendum>
				<definiens id="0">the set of templates conmtutmg the SIMPLE Core Ontology It is a unified type that has the umficat~on path 'Concrete entity + Artffact/Agenttve + Tehc ' Thts indicates that the template denotes a kind of concrete ennty , and that ~t has been augmented w~th two kinds of addltmnal type-defining mformatmn ( 1 ) agentlve mformatmn ( namely that these concrete entrees are man-made artifacts</definiens>
				<definiens id="1">a spemfic purpose to contain things ) All Damsh contamers encoded under th~s template type have been encoded w~th Damsh mformatmn about the formal role vm an tsahlermchy As a default</definiens>
				<definiens id="2">the process fremsttlle ( to create ) As Is apparent from the umficatmn path for th~s template , containers are also encoded w~th the type-defining tehc mformatmn that their funcnon ts to contam things For Damsh containers th~s ~s specified w~th the verb mdeholde ( to contam ) m the encoding of the tehc role the tehc role for such compounds as mdlebteger ( measuring cup ) , raflebceger ( ht cup for casting dice = dice cup ) , or drtkkebmger ( dnnkmg cup</definiens>
			</definition>
			<definition id="2">
				<sentence>~se '' /tm cald example= '' en urtepotteunderskal , hvon man omvendt har sat en tom bhkdase fyldes reed vand ' /a flo~et put ~autet m ~htch one har placed an empt~ tm can up~tde dtmn t~ then fdled utth ~atet/ freedefimnon= '' d~se lavet af bhk '' Aan made of trial welghtvalsemfeaturel= '' WVS FTemplateContamerPROT WVSFUmficattonPathConcreteentlty-ArtttactAgenttve-TehcPROT ' &gt; &lt; RWelghtValSemU target= '' USEM~N_dhse_CON_ 1 '' Atod semr= 'SRIsa '' &gt; &lt; RWezghtValSemU target= 'USEM_V_fremstdle_ 1'/to imMuc e~ semr= 'SRCreatedby '' &gt; &lt; RWmghtValSemU target= '' USEM_V_mdeholde_l '' /to contain/ senu'= '' SRUsedfor '' &gt; &lt; R WetghtValSemU target= '' USEM_N bhk ARS_ 1 '' /tm/ semr=- '' SRMadeof '' &gt; &lt; /SemU &gt; Addmonal const~tutlve mformatmn ( 'Madeof ' ) 49 m 1 m \ [ \ ] m m m mm m m mm mm m m U m m \ [ \ ] m m m n m m m 1 lexicon Regular polysemy when groups of related words display the same amblgmty is handled m a uniform way In the SIMPLE model vm the identification of a set of well-estabhshed regular semantic classes , which are adjusted for each of the languages involved Whde unsystematic ambiguous readings of a word are represented as totally unrelated semantic units , regular polysemous senses can be encoded as mterhnked semantic units In the SIMPLE model this is represented by an reformation slot called complex , whose value is the polysemous class to which the semantic unlt belongs This strategy relates to Pustejovsky ( 1995 ) , where regular polysemous classes correspond to complex types , which allows for an underspectfied semantic typing of word senses The solution adopted in SIMPLE intends to be a first step towards the future development of underspeclfled semantic types ( Lencl et al , 1998 ) Empmcally-based studies of regular polysemous semantic classes of Damsh are at present very scarce ( see however Boje &amp; Sch0sler ( ed ) ( 1992 ) pp 11-12 and Braasch &amp; Pedersen ( forthcoming ) for some minor cons~derauons of regular polysemy m Danish nouns as well as Malmgren ( 1988 ) for an extensive study of iegular polysemy in Swedish , a language which displays polysemous behavlour very slmdar to Damsh ) Th~s fact underpins the need for corpus-oriented encoding procedures which have therefore been given a centlal focus m the the Danish SIMPLE d~ctlonary in the sense that each semantic encoding is supported by corpus exammauons 3 In the Damsh lexicon the most productive cases of regular polysemy mvolwng concrete nouns prove to be the following • animal/food ot 44 mill runmng words ( consisting ot `` Bedmgske Korpus ' , 'Bergenholtz Korpus ' and 'Parole Korpus ' ) • geographical location / human gloup • fruit / plant • human group / restitution • semiotic artifact / reformation Other well-known polysemous palrs are not productive m Damsh , as for example 'people / language ' and 'flower / colour ' , where only a few examples of each can be found Thls difference relates to the d~stmct~on made by Apresjan ( apud Malmgren , 1988 ) between productive and iegular polysemy Here productwe polysemy refers to cases where more or less the whole group of nouns within a semantlc class display the same polysemy relations , whereas regular polysemy refers to cases where at least two words but not the whole class follow the same polysemy pattern Below xs shown an example of the semantic encoding of a proper noun denoting a Damsh c~ty , which belongs to the productwe 'geographlcal location / human group ' polysemy This example shows the encoding of the human group ' sense of the word This can be seen m the corpus example ( 'example ' ) , the defimtlon ( 'freedeflnmon ' ) , and the kinds of quaha roles encoded We beheve that the corpus-orlented approach used dunng the encoding of the Damsh SIMPLE lexicon facdltates the Ident~ficat~on of new polysemous classes ; since the differences m d~stnbutlonal patterns of the encoded wo~ds senses are a good indication of whether a regular polysemy relation could be revolved 50 &lt; SemU ~d= '' USEM_N_Dragor HUG_ 1 '' nammg= '' DragCr '' /DlagOrDam~h otto~ example= '' DragC , r m.-i i ar af reed godt 31 mill kr ul den kommunale udhgnmg '' /Tht~ ~ear DragCr muct pa ) approt 31 mdl clo~n~ to the 6ommumty equahzatton / freedefimaon= '' de mennesker der bor t Dragcr '' /The people hying in DragCr/ wetghtvalsemfeaturel= '' WVSFTemplateHumanGroup WVSFTemplateS uperTypeGroupPROT &lt; RWe~ghtValSemU target= '' USEM N_befolknmg_HUG_l '' /pol~Uk : tum / senu'= '' S Rlsa '' &gt; &lt; RWelghtValSemU target= '' USEM_NIndb } gger_HUM_l '' / cttt-ett / semr= '' S RHasasrnember '' &gt; &lt; RWe~ghtValSemU I target= '' USEM_N_Dragcr_GEO_I '' semr= '' S RPolysemyHu manGroup-GeopohttcalLocatlon '' : ~ &lt; /SemU &gt; Damsh ts a typical Scandmawan language wtth respect to nominal compounding and patterns of regular polysemy In this paper we have demonstrated how a large-scale , plunhngual , and multffunctlonal lexicon project hke SIMPLE facdltates a flexible semanttc encoding that can capture untversal semantic principles as well as these language-spectflc charactensttcs Considering the current status of language technology for a 'small ' European language such as Dantsh , the scope of the SIMPLE project makes it a truly ptoneermg project The development of thts harmontzed large-scale semantic lexicon for 12 European languages will enable system developers to ~mplement sophisticated language technology that will also encompass small European languages in the future Pohttkens Store Nudansk Ordbog p~ cd-rom , Version 2 1 1997 Polmkens Forlag , K~benhavn Boje , F &amp; L Sch~sler ( ed ) ( 1992 ) 'DISEM A Semantic MT-Component ' m CST Wotktng Papers no 1 , Center fol Sprogteknologt , Copenhagen Braasch , A &amp; B Pedersen ( torthcommg ) 'En stor sprogteknologlsk ordbog tot dansk med s2erhgt Iokus p3 , hhndtermg at flertydxghed ten mveaudelt ordbo~ ' , m Umverstty Lenct , A , F Busa , N Rulmy , E Gola , M Monachml , N Calzolan , A Zampolh , El Gutmter , G Recourc6 L Humphreys , U Von Rekovsky , A Ogonowskl , C McCauley , W Peters , I Peters , M Vtllegas ( 1998 ) 'Speclficatlons ' , SIMPLE Work , Ltngut~tt6 DehveJable D2 1 , Ptsa Malmgren , S ( 1988 ) 'On Regular Polysemy m Swedtsh ' , m Studtes m Computer-Aided Lextcographv , Almqutst &amp; Wtksell , Stockholm Rulmy , N O Corazzart , E Gola , A Spanu , N Calzolan , A Zampolh ( 1998 ) 'The European LE-PAROLE ProJect The ltahan Syntactic Lextcon ' , m Fost b~ternat , onal Conference on Language Re~ou : ces &amp; Evaluatton , Granada , Spare Pagglo , P &amp; B Orsnes ( 1993 ) Automatic translation ol nominal compounds A case study ot Damsh and ltahan ' m Revtzta d , LuzgutJt , ca 5 I pp 129-156 , Rosenbelg &amp; Selher , Tormo Pustejovsky , J ( 1995 ) The Genetattve Lexicon , Cambridge , MA , The MIT Press Vossen , P , L Bloksma , H Rodngues , S Chment , A Roventm~ , F Bretagna , A ALonge , W Peters ( 1998 ) 'The EuroWordNet Base Concepts and Top Ontology ' , Dehverable D017 , DO34 , D036 , WP5 , LE2-4003 Orsnes , B ( 1995 ) The Dettvatton and Compounding oJ Comple~ Event Nominals tn Modern Damsh PhD D~ssertatlon , Umverslty ot Copenhagen</sentence>
				<definiendum id="0">Zampolh</definiendum>
				<definiens id="0">a uniform way In the SIMPLE model vm the identification of a set of well-estabhshed regular semantic classes , which are adjusted for each of the languages involved Whde unsystematic ambiguous readings of a word are represented as totally unrelated semantic units</definiens>
				<definiens id="1">a language which displays polysemous behavlour very slmdar to Damsh ) Th~s fact underpins the need for corpus-oriented encoding procedures which have therefore been given a centlal focus m the the Danish SIMPLE d~ctlonary in the sense that each semantic encoding</definiens>
			</definition>
</paper>

		<paper id="0606">
			<definition id="0">
				<sentence>Boosting is a machine learning algorithm that is not well known in computational linguistics .</sentence>
				<definiendum id="0">Boosting</definiendum>
				<definiens id="0">a machine learning algorithm that is not well known in computational linguistics</definiens>
			</definition>
			<definition id="1">
				<sentence>Boosting is a machine learning algorithm that has been applied successfully to a variety of problems , but is almost unknown in computational linguistics .</sentence>
				<definiendum id="0">Boosting</definiendum>
				<definiens id="0">a machine learning algorithm that has been applied successfully to a variety of problems , but is almost unknown in computational linguistics</definiens>
			</definition>
			<definition id="2">
				<sentence>AdaBoost calls the weak learner repeatedly in a series of rounds .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">calls the weak learner repeatedly in a series of rounds</definiens>
			</definition>
			<definition id="3">
				<sentence>On round t , AdaBoost provides the weak learner with a set of importance weights over the training set .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">provides the weak learner with a set of importance weights over the training set</definiens>
			</definition>
			<definition id="4">
				<sentence>Having obtained a hypothesis ht from the weak learner , AdaBoost updates the weights by multiplying the weight of each example i by I e -ylht ( xi ) .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">updates the weights by multiplying the weight of each example i by I e -ylht ( xi )</definiens>
			</definition>
			<definition id="5">
				<sentence>AdaBoost outputs a final hypothesis which makes predictions using a simple vote of the weak hypotheses ' predictions , taking into account the varying confidences of the different predictions .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">outputs a final hypothesis which makes predictions using a simple vote of the weak hypotheses ' predictions , taking into account the varying confidences of the different predictions</definiens>
			</definition>
			<definition id="6">
				<sentence>MH , an alternative we have pursued is to use binary AdaBoost to train separate discriminators ( binary classifiers ) for each class , and combine their output by choosing the class c that maximizes re ( x ) , where fc ( x ) is the final confidenceweighted prediction of the discriminator for class c. Let us call this algorithm AdaBoost .</sentence>
				<definiendum id="0">MH</definiendum>
				<definiendum id="1">combine</definiendum>
				<definiendum id="2">fc ( x )</definiendum>
				<definiens id="0">their output by choosing the class c that maximizes re ( x )</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , the sentence Congress accused the president of peccadillos is classified according to the attachment site of the prepositional phrase : attachment to N : accused \ [ the president of peccadillos\ ] attachment to V : ( 4 ) accused \ [ the president\ ] \ [ of peccadillos\ ] The UPenn Treebank-II Parsed Wall Street Journal corpus includes PP-attachment information , and PP-attachment classifiers based on this data have been previously described in Ratnaparkhi , Reynar , Roukos ( 1994 ) , Brill and Resnik ( 1994 ) , and Collins and Brooks ( 1995 ) .</sentence>
				<definiendum id="0">UPenn Treebank-II Parsed Wall Street Journal corpus</definiendum>
				<definiens id="0">includes PP-attachment information</definiens>
			</definition>
			<definition id="8">
				<sentence>The instances of PP-attachment considered are those involving a verb immediately followed by a simple noun phrase ( the direct object ) and a prepositional phrase ( whose attachment is at issue ) .</sentence>
				<definiendum id="0">simple noun phrase</definiendum>
				<definiens id="0">the direct object ) and a prepositional phrase ( whose attachment is at issue )</definiens>
			</definition>
			<definition id="9">
				<sentence>N2 NUMBER N NUMBER N NUMBER N NUMBER N NUMBER N NUMBER N million V million V NUMBER N NUMBER N NUMBER N revenue N NUMBER V earnings V earnings V profit V assumption N quarter V cash V bureau '' V NUMBER N NUMBER N market V earnings V scale N maturity V August V quarter V Inc .</sentence>
				<definiendum id="0">N2 NUMBER N NUMBER N NUMBER N NUMBER N NUMBER N NUMBER N million V million V NUMBER N NUMBER N NUMBER N revenue N NUMBER V</definiendum>
			</definition>
</paper>

		<paper id="0603">
			<definition id="0">
				<sentence>Labeling to NLP Relaxation labeling ( RL ) is a generic name for a family of iterative algorithms which perform function optimization , based on local information .</sentence>
				<definiendum id="0">Relaxation labeling ( RL )</definiendum>
				<definiens id="0">a generic name for a family of iterative algorithms which perform function optimization , based on local information</definiens>
			</definition>
			<definition id="1">
				<sentence>The Relaxation Labeling algorithm deals with a set of variables ( which may represent words , synsets , etc. ) , each of which may take one among several different labels ( POS tags , senses , MaD entries , etc. ) .</sentence>
				<definiendum id="0">Relaxation Labeling algorithm</definiendum>
			</definition>
			<definition id="2">
				<sentence>Support is computed according to the constraint set and to the current weights for labels belonging to context variables. . . Increase the weights of the labels more compatible with the context ( larger support ) and decrease those of the less compatible labels ( smaller support ) .</sentence>
				<definiendum id="0">Support</definiendum>
				<definiens id="0">the labels more compatible with the context ( larger support ) and decrease those of the less compatible labels ( smaller support )</definiens>
			</definition>
			<definition id="3">
				<sentence>• We have a conceptual taxonomy ( e.g. WordNet ( Miller et al. , 1991 ) ) , in which the nodes represent concepts , organized as synsets .</sentence>
				<definiendum id="0">conceptual taxonomy</definiendum>
			</definition>
			<definition id="4">
				<sentence>• The possible labels for that variable , are all the WN synsets which contain a word that is a possible translation of the Spanish sense .</sentence>
				<definiendum id="0">WN</definiendum>
				<definiens id="0">synsets which contain a word that is a possible translation of the Spanish sense</definiens>
			</definition>
			<definition id="5">
				<sentence>Relaxation and Neural Learnins : Points of Convergence and Divergence .</sentence>
				<definiendum id="0">Relaxation</definiendum>
			</definition>
</paper>

		<paper id="0902">
			<definition id="0">
				<sentence>Grapheme-phoneme ( `` G-B '' ) alignment is defined as the task of maximally segmenting a grapheme compound into morpho-phonic units , and aligning each unit to the corresponding substring in the phoneme compound ( Bilac et al. , 1999 ) .</sentence>
				<definiendum id="0">Grapheme-phoneme ( `` G-B '' ) alignment</definiendum>
			</definition>
			<definition id="1">
				<sentence>alignment process Grapheme-phoneme alignment is performed as a four-stage process : ( a ) detection of lexical alternations and removal of lexical alternates from the input , ( b ) determination of all possible G-P alignment schemas , ( c ) pruning of alignments through phonological constraints , and ( d ) scoring of all final candidate alignments , and determination of the final solution accordingly .</sentence>
				<definiendum id="0">alignment process Grapheme-phoneme alignment</definiendum>
				<definiens id="0">phonological constraints , and ( d ) scoring of all final candidate alignments</definiens>
			</definition>
			<definition id="2">
				<sentence>Lexical alternation is defined as the condition of there being multiple lexical spell-outs for a given phonetic content , M1 sharing the same basic semantics and kanji component .</sentence>
				<definiendum id="0">Lexical alternation</definiendum>
				<definiens id="0">the condition of there being multiple lexical spell-outs for a given phonetic content , M1 sharing the same basic semantics and kanji component</definiens>
			</definition>
			<definition id="3">
				<sentence>G-P alignment can be subdivided into the three subtasks of ( i ) segmenting the grapheme string into morpho-phonic units , ( ii ) aligning each grapheme segmentation to compatible segmentation ( s ) of the phoneme string , and ( iii ) pruning off illegal alignments through the application of a series of phonological constraints .</sentence>
				<definiendum id="0">G-P alignment</definiendum>
				<definiens id="0">ii ) aligning each grapheme segmentation to compatible segmentation ( s ) of the phoneme string , and ( iii ) pruning off illegal alignments through the application of a series of phonological constraints</definiens>
			</definition>
			<definition id="4">
				<sentence>pruning The final step in alignment is to disallow all alignments ( PSseg ) - ( GSseg ) which contravene any of the following phonological constraints , applicable to grapheme segmentation ( `` G '' ) , phoneme segmentation ( `` e '' ) , and/or grapheme-phoneme alignment ( `` G-P '' ) , respectively : ( Pl ) A demarkation in script form indicates a segment boundary , except for the case of kanjihiragana boundaries .</sentence>
				<definiendum id="0">phoneme segmentation</definiendum>
				<definiens id="0">to disallow all alignments ( PSseg ) - ( GSseg ) which contravene any of the following phonological constraints , applicable to grapheme segmentation ( `` G '' )</definiens>
			</definition>
			<definition id="5">
				<sentence>We integrate the segmentation and alignment processes by taking the frequency of occurrence of a given segment as the number of G-P tuples for which 11 freq ( ( g , p ) ) = \ [ { ( GS , PS ) : 3pvar E phon_var ( p ) ~ ( ... QgQ ... ) - ( ... QpvarQ ... ) E { ( GSs~g ) - ( PSseg ) } } } 1 `` i i+l i i+l t f-id\ ] ( ( g , p , ctxt ) ) = freq ( ( g , p ) ) 1 + a log ( ~eq ( ( g , p ) ) ) freq ( ( g ) ) kfreq ( ( g , p , ctxt ) 1 + a O¢ ( ( ; , p ) ) idff ( ( g , ; , ctxt ) ) ( 1 ) ( 2 ) that segment is contained in the alignment paradigm in an identical lexical context .</sentence>
				<definiendum id="0">p ) ) ) freq</definiendum>
				<definiens id="0">3pvar E phon_var ( p ) ~ ( ... QgQ ... ) - ( ... QpvarQ ... ) E { ( GSs~g ) -</definiens>
				<definiens id="1">g , p , ctxt ) ) = freq ( ( g , p</definiens>
				<definiens id="2">g , p , ctxt ) 1 + a O¢ ( ( ; , p ) ) idff ( ( g , ; , ctxt</definiens>
			</definition>
			<definition id="6">
				<sentence>This can be represented as in equation ( 1 ) , in the case offreq ( ( g , p ) ) , where p is the phoneme string aligning with grapheme string 9 and phon_var ( p ) describes the set of phonological alternates of p. Phonological alternates are predictable instances of phonological alternation from a base form p , with the most widespread types of phonological alternation being `` sequential voicing '' ( Tsujimura , 1996 , 54-63 ) and gemination ; if no method were provided to cluster frequencies for phonological alternates together , data sparseness and skewing of the statistical model would inevitably result .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the phoneme string aligning with grapheme string 9 and phon_var ( p ) describes the set of phonological alternates of p. Phonological alternates are predictable instances of phonological alternation from a base form p</definiens>
			</definition>
			<definition id="7">
				<sentence>current alignment , and c~ is an additive smoothing constant , where 0 &lt; c~ &lt; 1 .</sentence>
				<definiendum id="0">c~</definiendum>
				<definiens id="0">an additive smoothing constant</definiens>
			</definition>
			<definition id="8">
				<sentence>In the case that ( g , Pl is a prefix of the overall G-P string pair , we disregard left lexical context and simply score according to t\ ] , that is the ratio of occurrence of g with reading p , for the two left context scores .</sentence>
				<definiendum id="0">Pl</definiendum>
				<definiens id="0">a prefix of the overall G-P string pair</definiens>
				<definiens id="1">the ratio of occurrence of g with reading p , for the two left context scores</definiens>
			</definition>
			<definition id="9">
				<sentence>For example , for the aligned segment ( ~ &lt; ) - ( to-ku I ( which constitutes the non-past form of the verb tok ( -u ) `` to undo '' ) , conjugational analysis would reveal the possibility , of the segment being comprised of the verb stem of ~ and inflectional suffix of kw .</sentence>
				<definiendum id="0">to-ku I</definiendum>
				<definiendum id="1">tok</definiendum>
				<definiens id="0">constitutes the non-past form of the verb</definiens>
			</definition>
			<definition id="10">
				<sentence>The second discriminative metric ( dm2 ) is a slight variation on this whereby we take the log of the ratio of the highest ranking score to the second ranking score ( `` the log odds ratio '' ) , and multiply it by the highest ranking score , i.e. sl log ~ .</sentence>
				<definiendum id="0">discriminative metric</definiendum>
				<definiens id="0">the log odds ratio '' ) , and multiply it by the highest ranking score</definiens>
			</definition>
</paper>

		<paper id="0701">
			<definition id="0">
				<sentence>Wolff attempts to infer word boundaries from artificially-generated natural language sentences , heavily relying on the co-occurrence frequency of adjacent characters \ [ Wolff1975 , Wolff 1977\ ] .</sentence>
				<definiendum id="0">Wolff</definiendum>
				<definiens id="0">attempts to infer word boundaries from artificially-generated natural language sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>The calculation can be based on the token count change involved in the substitution operatious to derive the new corpus X\ [ r -+ s\ ] ( 9 s , as follows : lowing classic information theory \ [ Shannon 1948 , DL ( X\ [ r -+ s\ ] ( 9 s ) = ~ a ; ' ( x ) log d ( x ) ( 4 ) i Cover and Thomas 1991\ ] , it can be formulated in n ' xEVu { r } terms of token counts in the corpus as below for empirical calculation : where d ( x ) is the new count ofx in the new corpus and n ' is the new corpus length .</sentence>
				<definiendum id="0">d ( x )</definiendum>
				<definiens id="0">the new count ofx in the new corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>I = -~-~c ( x ) log c ( x~ ) ( I ) • IXl n ' = n c ( s ) lsl + c ( s ) + Isl + 1 ( 5 ) I where V is the set of distinct tokens ( i.e. , the vowhere c ( x ) and cs ( x ) are the counts of in the x cabulary ) in X and c ( x ) is the count of x in X. original corpus X and in the string s , respectively .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">c ( x )</definiendum>
				<definiens id="0">-~-~c ( x ) log c ( x~ ) ( I ) • IXl n ' = n c ( s ) lsl + c ( s ) + Isl + 1 ( 5 ) I where</definiens>
			</definition>
			<definition id="3">
				<sentence>Accordingly , the description length gain ( DLG ) A key problem in this straightforward calculat from identifying a ( sub ) sequence s = sis2 .</sentence>
				<definiendum id="0">DLG</definiendum>
				<definiens id="0">A key problem in this straightforward calculat from identifying a ( sub ) sequence s = sis2</definiens>
			</definition>
			<definition id="4">
				<sentence>sk in tion is that we need to derive the count c ( s ) for the corpus X as a segment or chunk , which is exall possible string s 's in the original corpus X , be_ pected to have a nice correspondence to a linguiscause during the lexical learning process it is neci tically significant unit ( e.g. , a lexical item such as to consider all fragments ( i.e. , all n-grams ) essary a word , or a syntactic phrase ) , is formulated as in the corpus in order to select a set of good cam i DLG ( seX ) = DL ( X ) DL ( X\ [ r -- + s\ ] ( 9 s ) ( 2 ) didates for lexical items .</sentence>
				<definiendum id="0">DLG</definiendum>
				<definiens id="0">a segment or chunk , which is exall possible string s 's in the original corpus X , be_ pected to have a nice correspondence to a linguiscause during the lexical learning process it is neci tically significant unit</definiens>
				<definiens id="1">a word , or a syntactic phrase ) , is formulated</definiens>
			</definition>
			<definition id="5">
				<sentence>tn as a string I of some linguistic tokens ( e.g. , characters , words , DLG ( s ) aDLG ( s ) c ( s ) ( 3 ) POS tags ) , the unsupervised lexical acquisition algorithm seeks for an optimal segmentation OS ( U ) This average DLG is an estimation of the compresover the string U such that the sum of the compression effect of extracting an individual instance of sion effect over the segments is maximal .</sentence>
				<definiendum id="0">DLG</definiendum>
				<definiendum id="1">DLG</definiendum>
				<definiens id="0">an estimation of the compresover the string U such that the sum of the compression effect of extracting an individual instance of sion effect over the segments is maximal</definiens>
			</definition>
			<definition id="6">
				<sentence>( B ) The Viterbi segmentation algorithm Figure 1 : The Viterbi algorithm for optimal segmentation , with an illustration put , it looks for os ( u ) = k arg max ~_ , aDLG ( s , ) ( 6 ) sl ... sk s.t. U=sl+ .</sentence>
				<definiendum id="0">aDLG</definiendum>
				<definiens id="0">s , ) ( 6 ) sl ... sk s.t. U=sl+</definiens>
			</definition>
			<definition id="7">
				<sentence>A segmentation is an ordered set ( or list ) of adjacent segments .</sentence>
				<definiendum id="0">segmentation</definiendum>
			</definition>
			<definition id="8">
				<sentence>The difference between the denotations \ [ tk\ ] and tk is that the former indicates that the string tk is extracted from the corpus as the right-hand side of a rule ( a deterministic CFG rule ) , which results in a negative DLG ; whereas the latter treats tk as an individual token instead of a segment , which has a zero DLG .</sentence>
				<definiendum id="0">segment</definiendum>
				<definiens id="0">a deterministic CFG rule</definiens>
			</definition>
			<definition id="9">
				<sentence>With it , the complexity is bounded by O ( mn ) , where m is the maximal common prefix length of sub-strings ( i.e. , n-grams ) in the corpus .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">the maximal common prefix length of sub-strings ( i.e. , n-grams ) in the corpus</definiens>
			</definition>
			<definition id="10">
				<sentence>Accordingly , the average time complexity of the algorithm is O ( an ) : where a is the average common prefix length in the corpus , which is much smaller than m. We have conducted a series of lexical acquisition experiments with the above algorithm on largescale English corpora , e.g. , the Brown corpus \ [ Francis and Kucera 1982\ ] and the PTB WSJ corpus \ [ Marcus et al. 1993\ ] .</sentence>
				<definiendum id="0">O</definiendum>
				<definiens id="0">the average common prefix length in the corpus</definiens>
			</definition>
</paper>

		<paper id="0209">
			<definition id="0">
				<sentence>1 `` Query '' is the translation of the user 's information need into a format appropriate for the system .</sentence>
				<definiendum id="0">Query ''</definiendum>
				<definiens id="0">the translation of the user 's information need into a format appropriate for the system</definiens>
			</definition>
			<definition id="1">
				<sentence>Among them , we can quote : Dragomir Radev , in ( Radev and McKeown , 1997 ) , includes , between the forthcoming extensions of PROFILE system , an algorithm `` ... that will match different instances of the same entity appearing in different syntactic forms -e.g. to establish that 'PLO ' is an alias for de 'Palestine Liberation Organization ' ... '' The second antecedent is ( Bikel et al. , 1998 ) , where Bikel and his collaborators say about the future improvements of their own system : `` ... We would like to incorporate the following into the current model : ... an aliasing algorithm , which dynamically updates the model ( where e.g. IBM is an alias of International Business Machines ) ... '' We call replicancia to the relation which links proper nouns which presumably refer to the same entity if we attend exclusively to the nouns themselves , without paying attention to their respective contexts nor to which their actual referents may be .</sentence>
				<definiendum id="0">e.g. IBM</definiendum>
				<definiens id="0">an alias of International Business Machines ) ... '' We call replicancia to the relation which links proper nouns which presumably refer to the same entity if we attend exclusively to the nouns themselves , without paying attention to their respective contexts nor to which their actual referents may be</definiens>
			</definition>
			<definition id="2">
				<sentence>Replicancia is a diadic , reflexive , simetric , but not necessarily transitive relation .</sentence>
				<definiendum id="0">Replicancia</definiendum>
				<definiens id="0">a diadic , reflexive , simetric , but not necessarily transitive relation</definiens>
			</definition>
			<definition id="3">
				<sentence>A word P2 is a version of another word P1 when their canonic forms are identical , when P2 is the initial of P1 or when the initials of both coincide 4 .</sentence>
				<definiendum id="0">word P2</definiendum>
				<definiens id="0">a version of another word P1 when their canonic forms are identical , when P2 is the initial of P1 or when the initials of both coincide 4</definiens>
			</definition>
			<definition id="4">
				<sentence>/ where Nx-Ny represents the lexemes sequency of noun Nx not present in noun Ny and D12 is NIN2 ; predicate sin_prep ( Nx ) is true for the nouns Nx which do not include prepositions ; suprimenexos is the result of eliminating the noun of the lexemes in N1 which do not begin with a capital letter ; finally , predicate version ( Nx , Ny ) is satisfied if every lexeme of Ny is a version_palabra of any of the lexemes of Nx without any alteration in the relative order of occurrence of each homologous lexeme , as we have already indicated in section 2 .</sentence>
				<definiendum id="0">Nx-Ny</definiendum>
				<definiendum id="1">D12</definiendum>
				<definiendum id="2">predicate sin_prep</definiendum>
				<definiendum id="3">suprimenexos</definiendum>
				<definiens id="0">true for the nouns Nx which do not include prepositions</definiens>
				<definiens id="1">the result of eliminating the noun of the lexemes in N1 which do not begin with a capital letter ; finally , predicate version ( Nx , Ny ) is satisfied if every lexeme of Ny is a version_palabra of any of the lexemes of Nx without any alteration in the relative order of occurrence of each homologous lexeme</definiens>
			</definition>
			<definition id="5">
				<sentence>We have defined the replicancia relation as an instrument for the resolution of co-reference between proper nouns , although we are perfectly aware of its limitations to identify as coreferentials nouns which are not linked by an orthographic relation , as occurs with nicknames and familiar names ( Josd and Pepe , for example ) .</sentence>
				<definiendum id="0">replicancia relation</definiendum>
				<definiens id="0">an instrument for the resolution of co-reference between proper nouns , although we are perfectly aware of its limitations to identify as coreferentials nouns which are not linked by an orthographic relation</definiens>
			</definition>
			<definition id="6">
				<sentence>The result of co-reference resolution is the grouping of the document 's selected objects -the proper nounsin classes .</sentence>
				<definiendum id="0">co-reference resolution</definiendum>
				<definiens id="0">the grouping of the document 's selected objects -the proper nounsin classes</definiens>
			</definition>
			<definition id="7">
				<sentence>The human analyst designs a template which includes the different instances of the same entity present in the document , and then compares it with the system 's response , being this another grouping of objects in classes of co-reference .</sentence>
				<definiendum id="0">human analyst</definiendum>
				<definiens id="0">designs a template which includes the different instances of the same entity present in the document , and then compares it with the system 's response</definiens>
			</definition>
</paper>

		<paper id="0614">
			<definition id="0">
				<sentence>ty is one of the most famous problems in natural language processing ( NLP ) .</sentence>
				<definiendum id="0">ty</definiendum>
				<definiens id="0">one of the most famous problems in natural language processing ( NLP )</definiens>
			</definition>
			<definition id="1">
				<sentence>loc ( which consists of the preposition 's orthographic form followed by an abbreviation derived from the semantic interpretation in the conclusion ) , a short explanation , and a set of example sentences that can be interpreted using this rule .</sentence>
				<definiendum id="0">loc</definiendum>
				<definiens id="0">consists of the preposition 's orthographic form followed by an abbreviation derived from the semantic interpretation in the conclusion</definiens>
			</definition>
			<definition id="2">
				<sentence>• 3.1 Basic ideas PP attachment is one of the most famous problems in NLP .</sentence>
				<definiendum id="0">attachment</definiendum>
				<definiens id="0">one of the most famous problems in NLP</definiens>
			</definition>
			<definition id="3">
				<sentence>This rule component reduces the degree of ambiguity ( i. e. , marks elements in matrix ( aii , j ) as possible or impossible ) and delivers high-level semantic information ( the possible semantic interpretations of the PP for a given candidate mother ) for statistical disambiguation .</sentence>
				<definiendum id="0">rule component</definiendum>
				<definiens id="0">reduces the degree of ambiguity ( i. e. , marks elements in matrix ( aii , j ) as possible or impossible ) and delivers high-level semantic information ( the possible semantic interpretations of the PP for a given candidate mother ) for statistical disambiguation</definiens>
			</definition>
			<definition id="4">
				<sentence>As Table 4 shows , most of the time the correct rule fires ( given the correct mother ; see recall column ) , but false rules fire too ( see precision column ) because interpretation rules refer only to a limited depth 116 preposition readings recall % precision % auf aus bei fiber vor wegen 9 100.0 100.0 6 97.4 39.8 4 93.7 69.8 7 100.0 65.4 6 98.3 54.7 1 100.0 100.0 Table 4 : Results of PP interpretation rules for ( correct ) mothers rf ( aus .</sentence>
				<definiendum id="0">interpretation rules</definiendum>
				<definiens id="0">Results of PP</definiens>
			</definition>
			<definition id="5">
				<sentence>c c , Ic , I where Ci is the set of all subsets of I with ni~t elements that contain ri .</sentence>
				<definiendum id="0">Ci</definiendum>
				<definiens id="0">the set of all subsets of I with ni~t elements that contain ri</definiens>
			</definition>
			<definition id="6">
				<sentence>The relative frequency of ( ri , cat ( cmi ) ) belonging to the correct attachment among A = { ( rl , cat ( cml ) ) , ... , ( rn , cat ( cmn ) ) } is estimated for n &gt; natt as in equation ( 6 ) : Erf ( ( ri , cat ( cmi ) ) , c ) ( 6 ) rf ( ( r , ,cat ( cm , ) ) , A ) : = tee , where Ci is the set of all subsets of A with natt elements that contain ( ri , cat ( cmi ) ) .</sentence>
				<definiendum id="0">relative frequency of ( ri</definiendum>
				<definiendum id="1">Ci</definiendum>
				<definiens id="0">the correct attachment among A = { ( rl , cat ( cml ) ) , ... , ( rn , cat ( cmn ) ) } is estimated for n &gt; natt as in equation ( 6 ) : Erf ( ( ri , cat ( cmi ) ) , c ) ( 6 ) rf ( ( r , ,cat ( cm , ) ) , A ) : = tee , where</definiens>
				<definiens id="1">the set of all subsets of A with natt elements that contain ( ri , cat ( cmi ) )</definiens>
			</definition>
			<definition id="7">
				<sentence>md is an upper limit for distances .</sentence>
				<definiendum id="0">md</definiendum>
				<definiens id="0">an upper limit for distances</definiens>
			</definition>
			<definition id="8">
				<sentence>CoreLex : Systematic Polysemy and Underspecification .</sentence>
				<definiendum id="0">CoreLex</definiendum>
			</definition>
</paper>

		<paper id="0624">
			<definition id="0">
				<sentence>The best-known publicly available corpus handtagged with WordNet senses is SEMCOR ( Miller et al. , 1993 ) , a subset of the Brown Corpus of about 100 documents that occupies about 2.4 Mb .</sentence>
				<definiendum id="0">SEMCOR</definiendum>
			</definition>
			<definition id="1">
				<sentence>Each summary is a human explanation of the text contents , not a mere bag of related keywords .</sentence>
				<definiendum id="0">summary</definiendum>
				<definiens id="0">a human explanation of the text contents , not a mere bag of related keywords</definiens>
			</definition>
</paper>

		<paper id="0302">
			<definition id="0">
				<sentence>XML can be used to describe any sort of coding , and the coding structure can be described in a Document Type Definition ( DTD ) which describes what tags are possible , and where they can occur .</sentence>
				<definiendum id="0">DTD )</definiendum>
				<definiens id="0">which describes what tags are possible , and where they can occur</definiens>
			</definition>
			<definition id="1">
				<sentence>XSL is an XML language , and current developments in XML suggest that DTDs will soon be written in XML itself using `` XML schemata '' \ [ 13 , 14\ ] , so that DTD and stylesheet editors could be written quickly using the workbench .</sentence>
				<definiendum id="0">XSL</definiendum>
				<definiens id="0">an XML language , and current developments in XML suggest</definiens>
			</definition>
</paper>

		<paper id="0630">
			<definition id="0">
				<sentence>A POS tag p is called an antitag a of a lemma m if p can never be a tag of m. The anti-lexicon consists of a set of pieces of this negative information , each called an anti-lexeme ~l : dej where -~p is the anti-tag of lemma m , and p is a POS used in the lexicon .</sentence>
				<definiendum id="0">POS tag p</definiendum>
				<definiendum id="1">-~p</definiendum>
				<definiendum id="2">p</definiendum>
				<definiens id="0">a POS used in the lexicon</definiens>
			</definition>
			<definition id="1">
				<sentence>Some examples of anti-lexemes are : ( happy , -~IN ) ( run , -~JJ } ( in , -- ~VB ) where `` IN '' , '' JJ '' and `` VB '' are the preposition , adjective and verb tags in Brill lexicon respectively .</sentence>
				<definiendum id="0">-~IN )</definiendum>
				<definiens id="0">in , -- ~VB ) where `` IN '' , '' JJ '' and `` VB '' are the preposition , adjective and verb tags in Brill lexicon respectively</definiens>
			</definition>
			<definition id="2">
				<sentence>The `` cohesion '' of a lemma I and a POS tag p measures the likelihood of a POS tag p being a possible tag of a lemma l , and is defined as : 250 SimScore ( /Y , q~ input : Two POS feature vectors of integers with values { 0 , 1 , 2 } ( representing POS tags that may come from different tagsets ) P= { Pl , P2 , .</sentence>
				<definiendum id="0">cohesion</definiendum>
				<definiens id="0">POS feature vectors of integers with values { 0 , 1 , 2 } ( representing POS tags that may come from different tagsets</definiens>
			</definition>
</paper>

		<paper id="0508">
			<definition id="0">
				<sentence>This article reports the results of a prehmlnary analysis of translation equivalents in four languages from different language famdles , extracted from an on-hne parallel corpus of George Orwell 's Nmeteen Eighty-Four The goal of the study is to determine the degree to which translatmn equivalents for different meamngs of a polysemous word In Enghsh are lexlcahzed differently across a variety of languages , and to detelmme whether this information can be used to structure or create a set of sense distinctions useful in natural language processing apphcatmns A coherence Index is computed that measures the tendency for different senses o1 the same English word to be lexlcahzed differently , and flora this data a clustering algorithm is used to create sense hierat chles Introduction It ~s well known that the most nagging issue for word sense disamblguanon ( WSD ) Is the definmon of just what a word sense is At its base , the problem Is a philosophical and linguistic one that is far from being resolved However , work in automated language processing has led to effotts to flnd practical means to dlstmgmsh word senses , at least to the degree that they are useful for natural language processing tasks such as summarization , document retrieval , and machine translataon Several criteria have been suggested and exploited to automatically determine the sense of a word m context ( see Ide and V6roms , 1998 ) , including syntactic behavior , semantic and pragmatic knowledge , and especially in more recent empirical studies , word co-occurrence within syntactic relations ( e g , Hearst , 1991 , Yarowsky , 1993 ) , words co-occurring m global context ( e g , Gale et al , 1993 , Yarowsky , 1992 Schutze , 1992 , 1993 ) , etc No clear criteria have emerged , however , and the problem continues to loom large for WSD work The notion that cross-hngual comparison can be useful fol sense dlsamblguauon has served as a basis for some recent work on WSD Foi example , Brown et al ( 1991 ) and Gale et al ( 1992a , 1993 ) used the parallel , aligned Hansard Corpus of Canadian Parhamentary debates foi WSD , and Dagan et al ( 1991 ) and Dagan and Ital ( 1994 ) used monohngual corpora of Hebrew and German and a bilingual dictionary These studies rely on the assumption that the mapping between words and word senses vanes significantly among languages For example , the word duty in English t~anslates into French as devoir m ~ts obhgatlon sense , and tmpOt m ~ts tax sense By determining the translation 52 , .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">to determine the degree to which translatmn equivalents for different meamngs of a polysemous word In Enghsh are lexlcahzed differently across a variety of languages</definiens>
				<definiens id="1">measures the tendency for different senses o1 the same English word to be lexlcahzed differently , and flora this data a clustering algorithm is used to create sense hierat chles Introduction It ~s well known that the most nagging issue for word sense disamblguanon (</definiens>
			</definition>
			<definition id="1">
				<sentence>corpus ( ENPC , Oslo Umverslty ) to define semantic propemes such as synonymy , ambtgmty , vagueness , and semantic helds and suggested a derivation otsemantic representations for signs ( eg , lexemes ) , captunng semantm relatmnshlps such as hyponymy etc , fiom such translatmnal relatmns Recently , Resnlk and Yarowsky ( 1997 ) suggested that fol the purposes ot WSD , the different senses of a wo~d could be detelmlned by considering only sense d~stmctmns that are lextcahzed cross-hngmstlcally In particular , they propose that some set of target languages be ~dent~fied , and that the sense d~stmctmns to be considered for language processing appllcatmns and evaluatmn be restricted to those that are reahzed lexlcally in some minimum subset of those languages This idea would seem to p~ovtde an answer , at least m part , to the problem of determining different senses of a word mtumvely , one assumes that ff another language lexlcahzes a word m two or more ways , there must be a conceptual monvatmn If we look at enough languages , we would be likely to fred the s~gmficant lexlcal differences that dehmtt different senses of a word However , th~s suggestmn raises several questions Fo~ instance , ~t ~s well known that many amb~gumes are preserved across languages ( for example , the French tntdrYt and the Enghsh interest ) , especmlly languages that are relatively closely related Assuming this problem can be overcome , should differences found m closely related languages be given lesser ( or greater ) weight than those found m more distantly related languages 9 More generally , which languages should be considered for this exermse 9 All languages 9 Closely related languages9 Languages from different language famlhes '~ A mixture of the two 9 How many languages , and of which types , would be `` enough '' to provide adequate lnfotmanon tot this purpose~ There ts also the questmn ot the crlterm that would be used to estabhsh that a sense distinction is `` lexlcahzed cross-hngu~stmally '' How consistent must the d~stlnCtlOn be 9 Does it mean that two concepts are expressed by mutually non-lntetchangeable lexmal items in some slgmficant number ot other languages , or need tt only be the case that the option ot a different lexlcahzatlon exists m a certain percentage of cases 9 Another conslderatmn ts where the cross-hngual mformatlon to answer these questmns would come from Using bdmgual dictionaries would be extremely tedmus and error-prone , g~ven the substantial d~vergence among d~ctlonanes in terms of the kinds and degree of sense dlstmctmns they make Resmk and Yalowsky ( 1997 ) suggest EutoWordNet ( Vossen , 1998 ) as a possible somce of mformatmn , but , given that EuroWordNet ts pttmatdy a lexmon and not a corpus , ~t is subject to many of the same objections as for bl-hngual dictionaries An alternative would be to gather the reformation from parallel , ahgned corpma Unlike bilingual and muttt-hngual dictionaries , translatmn eqmvalents xn parallel texts a~e determined by experienced translatols , who evaluate each instance ot a word 's use m context rather than as a part of the meta-hngmst~c actlvlty of classifying senses for mclusmn in a dictionary However , at present very few parallel ahgned corpora exist The vast majority ot these are bl-texts , mvolwng only two languages , one of which is very often English Ideally , a serious 53 evaluation of Resnik and Yarowsky 's proposal would include parallel texts m languages from several different language families , and , to maximally ensure that the word m question is used in the exact same sense across languages , ~t would be preferable that the same text were used over all languages in the study The only currently avadable parallel corpora for more than two languages are Olwell 's Nmeteen Eighty-Four ( Erjavec and Ide , 1998 ) , Plato 's Repubhc ( Erjavec , et al , 1998 ) , the MULTEXT Journal .</sentence>
				<definiendum id="0">eg</definiendum>
				<definiendum id="1">WSD</definiendum>
				<definiens id="0">to fred the s~gmficant lexlcal differences that dehmtt different senses of a word However</definiens>
			</definition>
			<definition id="2">
				<sentence>~ston corpus ( Ide and V6roms , 1994 ) , and the Bible ( Resnlk , et al , m press ) It is likely that these corpora do not provide enough appropriate data to reliably determine sense distinctions Also , ~t Is not clear how the lexlcahzatlon of sense distractions across languages Is affected by genre , domain , style , etc Thls paper attempts to provide some prehmlnary answers to the questions outhned above , In order to eventually determine the degree to which the use of parallel data ts vmble to determine sense distinctions , and , ff so , the ways in which th~s reformation might be used Given the lack of lalge parallel texts across multiple languages , the study is necessarily hmlted , however , close exammanon of a small sample of parallel data can , as a first step , provide the basis and dlrectmn for more extensive studies I have conducted a small study using parallel , aligned versmns ot George Orwell 's Nineteen Etghtv-Fo , lr ( Euavec and Ide , 1998 ) m five languages Enghsh , Slovene , Estonian , Romanlan , and Czech I The study therefole Involves languages from four language families The O~well parallel corpus also includes vers|ons o ) Ntneteen-E~gho Four m Hungarian , Bulgarmn , Latwan , Llthuaman , Se~bmn , and Russmn ( Germanic , Slavic , Fmno-Ugrec , and Romance ) , two languages from the same family ( Czech and Slovene ) , as well as one non-Indo-European language ( Estoman ) Nmeteen Eighty-Four Is a text of about 100,000 words , translated directly from the original English m each of the other languages The parallel versions of the text are sentence-aligned to the English and tagged for part of speech Although Nineteen Eighty-Four is a work of fiction , Orwell 's prose IS not highly stylized and , as such , it provides a reasonable sample ot modern , ordinary language that ~s not tied to a given topic or sub-domain ( such as newspapers , technical reports , etc ) Furthermore , the translations of the text seem to be relatively faithful to the original for instance , over 95 % ot the sentence alignments in the full pmallel corpus of seven languages are one-to-one ( Prlest-Dorman , et al , 1997 ) Nine ambiguous English words were considered hard , head , country , hne , promise , shght , seize , scrap , float The first four were chosen because they have been used in other dlsamb~guatlon studies , the latter five were chosen from among the words used m the Senseval dlsamblguatlon exercise ( Kllgamff and Palmer , forthcoming ) In all cases , the study was necessarily hmlted to words that occurred frequently enough in the Orwell text to warrant consideration F~ve hundred forty-two sentences conta|nmg an occurrence or occurrences ( Including morphological variants ) of each of the nine words were extracted from the Enghsh text , together w~th the parallel sentences m which they occur m the texts ot the four comparison languages ( Czech , Estonian , Romantan , Slovene ) As Walks and Stevenson ( 1998 ) have pointed out , pa~t-of-speech tagging accomplishes a good portion of the work ot semantic dlsamb~guatmn , therefore occmrences of wolds that appemed in the data in more than 54 one part of speech were grouped separately 2 The Enghsh occurrences were then grouped usmg the sense distinctions m WordNet , ( version 1 6 ) \ [ Miller et al , 1990 , Fellbaum , 1998\ ] ) The sense categonzatmn was performed by the author and two student assistants , results from the three were compared and a final , mutually agreeable set of sense assignments was estabhshed For each of the four comparison languages , the corpus of sense-grouped parallel sentences were sent to a llngmst and natl , ve speaker of the comparison language The hngmsts were asked to provide the lexlcal item m each parallel sentence that corresponds to the ambiguous Enghsh word If inflected , they were asked to provide both the inflected form and the root form In addttmn , the lmgmsts were asked to indicate the type of translatmn , according to the dtstmctmns given m Table 1 For over 85 % of the Enghsh word occurrences ( corresponding to types 1 and 2 m Table 1 ) , a specific lexlcal item or items could be identified as the translation equivalent for the corresponding Enghsh word For comparison purposes , each translanon equivalent was represented by ~ts lemma ( or the lemma of the toot form in the case of derivatives ) and associated w~th the WordNet sense to which it corresponds In order to determine the degree to which the assigned sense dlstlncttons correspond to translation eqmvalents , a coherence index ( Cl ) was computed that measures how often each pmr of senses is translated usmg the same word as well as the consistency with which a g~ven se , ls , z ~s translated with the same word ~ Note that the z The adJective and adverb senses of hard are consadeied together because the distinction is not consistent across the translations used m the study Note that the CI ~s similar to semanuc entropy ( Melamed , 1997 ) However , Melamed computes CIs do not determine whether or not a sense dtstmctton can be lextcahzed in the target language , but only the degree to whmh they are lexicahzed differently m the translated text However , tt can be assumed that the CIs provide a measure of the tendency to lex~cahze different WordNet senses differently , which can m turn be seen as an mdtcatmn of the degree to which the distraction ts vahd For each ambiguous word , the CI Is computed for each pair of senses , as follows S &lt; q t &gt; Cl ( sqS , ) = '=1 m rnrt where @ n ~s the number of comparison languages under consideration , nl~q and m , , are the nt~mber of occurrences olsense sqand sense s~ m the Enghsh corpus , respectively , including occurrences that have no idenufiable translation , s &lt; ~ ~ &gt; m ts the number of times that senses q and r are translated by the same lex~cal Item m language t , i e , x=y t ~tJan ~ ( q ) , r~oan~ ( r ) The CI ts a value between 0 and 1 , computed by examining clusters of occurrences translated by the same word In the othel languages If sense and sense ) are consistently translated w~th the same wo~d in each comparison language , then Cl ( s , s~ ) = 1 , if they are translated with a different word m every occurrence , Cl ( s , ~ ) = 0 In general , the CI for pans of different senses provides an index of thmr relatedness , t e , the greater the value of Cl ( s , sj ) , the more frequently occurrences of-sense t and sense j are translated with the same lextcal item When t = j , we entropy tOl wold types , lather than word senses 55 obtain a measure of the coherence of a ~lven sense Type Meaning meaning as the slngle English word An English phrase contalnmng the ambiguous word Is translated by a single language which has a broader or more specific meanlng , or by a phrase in whl corresponding to the English word Is not explicltl~ lexlcallzed Table 1 Translation types and their trequencles % dizen whl % h h 6 % 6 % 6 % of s p same Word # Description hard 1 1 difficult 2 head i i i 1 Table 2 1 2 _meta~horlcally hard _\ ] 3 not yielding to pressure , 1 4 very strong or ~lgorous , ar 3 earnestly , intently ( adv ) i_ ~art of the body ... .. 3 intellect 4 _r~le_ !</sentence>
				<definiendum id="0">~ston corpus</definiendum>
				<definiendum id="1">Bible</definiendum>
				<definiendum id="2">CI</definiendum>
				<definiens id="0">the study Note that the CI ~s similar to semanuc entropy ( Melamed , 1997 ) However , Melamed computes CIs do not determine whether or not a sense dtstmctton can be lextcahzed in the target language , but only the degree to whmh they are lexicahzed differently m the translated text However , tt can be assumed that the CIs provide a measure of the tendency to lex~cahze different WordNet senses differently , which can m turn be seen as an mdtcatmn of the degree to which the distraction ts vahd For each ambiguous word , the CI Is computed for each pair of senses</definiens>
				<definiens id="1">ts a value between 0 and 1 , computed by examining clusters of occurrences translated by the same word In the othel languages If sense and sense ) are consistently translated w~th the same wo~d in each comparison language</definiens>
				<definiens id="2">the slngle English word An English phrase contalnmng the ambiguous word Is translated by a single language which has a broader or more specific meanlng</definiens>
			</definition>
			<definition id="3">
				<sentence>r , ch , % ef 7 front , front part WoldNet senses ot hard and head CIs were also computed for each language individually as well as for different language groupings Romaman , Czech , and Estonian ( three different language families ) Czech and Slovene ( same family ) , Romaman , Czech , Slovene ( Indo-European , and Estonian ( nonIndo-European ) To better visualize the relationship between senses , a hierarchical clustering algorithm was applied to the CI data to generate trees reflecting sense proximity 4 Finally , in order to determine the degree to which the linguistic relaUon between languages may affect coherence , a correlation was run among CIs for all pairs of the four target languages Fol example , Table 2 gives the senses of hard and head that occurred in the data s The CI data .</sentence>
				<definiendum id="0">Estonian</definiendum>
				<definiendum id="1">Estonian</definiendum>
				<definiens id="0">different language families ) Czech and Slovene ( same family</definiens>
			</definition>
</paper>

		<paper id="0406">
</paper>

		<paper id="0628">
			<definition id="0">
				<sentence>Structural ambiguity is one of the most serious problems that Natural Language Processing ( NLP ) systems face .</sentence>
				<definiendum id="0">Structural ambiguity</definiendum>
				<definiens id="0">one of the most serious problems that Natural Language Processing ( NLP ) systems face</definiens>
			</definition>
			<definition id="1">
				<sentence>The low level disambiguation for the PP is one task that has been somewhat successfully treated using statistical methods .</sentence>
				<definiendum id="0">low level disambiguation</definiendum>
				<definiens id="0">one task that has been somewhat successfully treated using statistical methods</definiens>
			</definition>
			<definition id="2">
				<sentence>Recently \ [ Barton , 1993\ ] has shown that feedforward networks with one layer of sigmoidal nonlinearities achieve an integrated squared error of order O ( ¼ ) for input spaces of dimension d , where n is the number of units of the network .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of units of the network</definiens>
			</definition>
			<definition id="3">
				<sentence>Suppose we have a set of N trained network models yi ( x ) where i = 1 , ... , N. We can then write the mapping function of each network as the desired function t ( x ) plus an error function \ [ Bishop C. , 1995\ ] : = t ( x ) + e ( x ) The average sum-of-squares error for model y~ ( x ) can be written as Ei = E\ [ ( yi ( x ) t ( x ) ) 2\ ] = E\ [ e~\ ] The output of the committee is the average of the outputs of the N networks that integrates the committee , in the form YCOM ( X ) = N yi ( x ) .</sentence>
				<definiendum id="0">yi</definiendum>
				<definiendum id="1">YCOM</definiendum>
				<definiens id="0">the average of the outputs of the N networks that integrates the committee , in the form</definiens>
			</definition>
			<definition id="4">
				<sentence>If we make the assumption that the errors ei ( x ) have zero mean and are uncorrelated , we have where ECOM is the average error made by the committee and EAV is the average error made by the networks acting individually .</sentence>
				<definiendum id="0">ECOM</definiendum>
				<definiendum id="1">EAV</definiendum>
				<definiens id="0">the average error made by the committee and</definiens>
				<definiens id="1">the average error made by the networks acting individually</definiens>
			</definition>
			<definition id="5">
				<sentence>( OWA ) Operators If w is a weighting vector of dimension n , then a mapping OWAw : R '' ~ R is an Ordered Weighted Averaging ( OWA ) operator of dimension n \ [ Yager , 1993\ ] : n OWA ( yl , ... , yn ) = i -- -- 1 where { a ( 1 ) , - .</sentence>
				<definiendum id="0">OWA ) Operators If w</definiendum>
				<definiens id="0">an Ordered Weighted Averaging ( OWA ) operator of dimension n \ [</definiens>
			</definition>
</paper>

		<paper id="0511">
			<definition id="0">
				<sentence>The French DELA system was conceived and developed at LADL ( Laboratoire d'Automatlque Documentaire et LmgmstIque ) It includes monohngual hngulstlc resources ( mainly for French and English ) specifically elaborated to be integrated into NLP systems Standard methods and formats-have been defined and are now used by other national teams working on their own languages German , Greek , Italian , Portuguese and Spanish Within that common framework , important fragments of the descnptmn of the languages involved have been worked out the syntactic and semantic properties of free and frozen sentences are descnbed and formalized e~s for the lexicon , a major component of NLP , large coverage electromc dlctionanes have been built Simple and compound words have been descnbed , and their hnguIstlc characteristics have been hand-coded by computational lexicographers using a common method Most of these lex~cal resources can now be imported into the Intex NLP system ~ , and then automatically applied to large texts Within the scope of this article , we describe the set of lexical resources built so far for Portuguese , and we gwe different examples of automatic Portuguese text parsing By electromc dictionary , we mean a computerized lexicon specifically elaborated to be used tn automatic text parsing operations ( indexing , recognition of complex words , technical and common , etc ) Thus , large coverage electronic dlctlonanes were built for Portuguese for that purpose The set of lexIcal data is organized according to the formal complexity of the lexlcal units The Portuguese DELAS IS the central element of the d~ctionary system Itcontains more than 110,000 simple words , whose grammatical attributes are systemaucally described and encoded The set of compound words Is structured m the Portuguese DELAC At the moment , it Is constituted by a lexicon of 22,000 compound nouns and 3,000 frozen adverbs , so it is stdl far from adequate completion 2 As said before , DELAS is the dIctmnary of simple words We understand by simple words the lexlcal units that correspond to a continuous string of i See http//www ladl lUSSleu fr/IN'I~X/mdex htm ll about 130,000 entries 74 letters The lexlcal entnes of DELAS have the followmg general structure &lt; word &gt; , &lt; formal description &gt; where word represents the canomcal form ( the lemma ) of a simple lexlcal umt ( m general the masculine smgular for the nouns and adjecuves , the mfinmve for the verbs ) , and formal description corresponds to an alphanumenc code contzanmg mformat~on on the grammatical attributes of the entries their grammatical class ( eventually , sub-class ) , and their morphological behavior The mflected forms are automaucally generated from the association of a lemma to an mflecuonal code the hst of all reflected words constitutes the Portuguese DELAF ( 1,250,000 word forms ) In Portuguese , the major grammatical classes nouns , adjectives and verbs have mflected forms -nouns and adjectives can appear m the femmme and/or m the plural , they can recewe dtmmuUve and augmentaave suffixes , the superlative degree of the adjectives can be expressed by morphological means ( suffixes ) , -verbs are conjugated ( mood , tense , person , number ) , furthermore , some verbal forms can undergo formal mo &amp; ficattons reduced by the presence of a clmc pronoun Thus , the DELAS entries gato , NOID1 gordo , AOIDIS1 ( where N and A mdtcate that gato ( cat ) ts a noun and gordo ( fat ) Is an adjective , 01 corresponds to the mflectlon rule for mascuhne , feminine , smgular and plural , DI and $ 1 exphclt the type of dtmmuttve and superlative suffixes that can be accepted by these entries ) produce the following infected forms ( DELAF entnes ) gato , gato N ms ( cat ) gata , gato N fs gatos , gato N mp gatas , gato N fp gatmho , gato N Dms ( httle cat ) gatmha , gato N Dfs gattnhos , gato N Dmp gatmhas , gato N Dfp gordo , gordo A ms ( fat ) gorda , gordo A fs gordos , gordo Amp gordas , gordo A fp 75 gordmho , gordo A Dins ( rather fat ) gordmha , gordo A Dfs gordmhos , gordo A Dmp gordmhas , gordo A Dfp gordlsslmo , gordo A Sms ( very fat ) gordfsstma , gordo A Sfs gord£sstmos , gordo A Stop gord\ [ sstmas , gordo A Sfp As for the verbs , for mstance , dar ( to gwe ) dar , VO2t gives rise to a hst of 73 reflected forms that correspond to the normal conjugation of a nondefective verb , in addmon , dar can be constructed with clmc pronouns ( t ) , m the posmon of accusative and dative complements So , m ( 1 ) Nds demos o hvro ~ Maria ( Lit We gave the book to Maria ) the verb form demos expresses mdlcatlve mood , past tense , and first person plural From a syntactic point of view , dar Is constructed with three arguments , subject Nds ( we ) and two complements o hvro ( the book ) , fi Maria ( to Maria ) The complement syntacuc posmons can be fulfilled by clmc pronouns , respecavely , o ( it ) , accusative , and lhe ( her ) , dauve , as m ( 2 ) N6s demo-lo ~ Maria ( Lit We gave tt to Maria ) ( 3 ) N6s demos-lhe o hvro ( Lit We gave her the book ) ( 4 ) Nds demos-lho ( Lit We gave her_t0 In ( 2 ) , the direct object has been chttclzed , and , due to historical phonetic reasons , both the accusative pronoun and the verb have undergone formal modifications o &gt; lo , demos &gt; demo In ( 4 ) , both pronouns ( dative and accusative ) are obhgatonly agglutinated , forming the contraction lho ( &lt; lhe + o ) So , even though the analysts of the combinations verb-chttc Is a syntactic matter , given the morphological changes reduced by such combinations m Portuguese , a first descnptlon had to be made at the morphcqegtcal level On the other hand , the example m ( 4 ) dlustrates a case where the formal notion of simple word does not correspond to an adequate hngutstlc analys~s Indeed , the form lho results from the contraction of two Independent oronouns lhe + o In Portuguese , contracted forms Issued from the agglutmatton of two different words ( and two different grammaucal categones ) are commonly observed We give some simple examples of contracuons resulting from the merging of preposmons with determiners , pronouns and adverbs pel ( o , a , os , as ) &lt; por + ( o , a , os , as ) ( by the ) del ( e , a , es , as ) &lt; de + ( ele , ela , eles , elas ) ( of ( him , her , them ) ) daqut &lt; de + aqut ( from here ) The relationship between contractions and their base constituent categories are estabhshed by finite-state transducers ( see below ) Compound words , l e , lexical units that are constituted by a fixed combination of s~mple words , represent a large amount of the lexicon of any language One has only to underline m a text the sequences of words that are frozen together to some extent to realize that compounds constitute an important percentage of the text 3 It is therefore illusory to envisage any sort of automatic processing before a slgmficant lexlcal coverage is achieved. The Issue is even more acute if one considers the description of sclenttfic or technical texts or any speciahzed lexicon , where the number of compounds can rise up to appalhng figures As said in 2 compounds are structured m the Portuguese DELAC Priority was given tO the hstlng and formahzatlon of compound nouns , that can mflect lua de mel luas de mel ( honeymoon ) , and to compound adverbs , that are invariable de repente ( suddenly ) From the point of view of the lexicon , the mare focus , especially as far as compound nouns are concerned , has been the every-day , not too techmcal , lexicon In order to ~dentlfy compound words , and dlstmgulsh them from formally Identical word free combinations , a set of morpho-syntactlc criteria was adopted ( Ranchhod ( 1991 ) , Bapttsta ( 1995 ) ) In short , compounds are the sequences of words that present restncUons to the See 5 ~Parsmg Texts Using INTEX Toolscombinatorial properttes that they were supposed to have The formallzauon of compound dtcuonary entries is slmdar to that of simple words Since compound adverbs , preposluons and conjunctions do not reflect , their formats are rather s~mple de repente , ADV+PC ( suddenly ) para corn , PREP ( towards ) afire de , CONJ ( m order to ) Compound nouns , however , have generally reflected forms The rules for the mflect~on of compound nouns presented by grammarians do apply to some cases , but most compound nouns exhibit mflecuonal restrictions on gender or number that can not be accounted by the morphological properties of their constituents In the DELA format , the inflectional properties of compound nouns are specified according to the same criteria as m the dictionary of simple words Thus , g~ven the following nominal entries of the DELAC ser ( 21 ) humano ( Ol ) , N + NA ms + ( human being ) guerra frta , N + NA fs ( cold war ) vtstta ( 30 ) de estudo , N + NDN fs + ( field trip ) The first two compound nouns , ser humano and guerra frta have an internal structure Noun Adjective ( NA ) , the most productwe class m Portuguese , vtstta de estudo ~s a compound of structure Noun de Noun , also a very productwe one Each entry is characterized by the posslbdlty ( + ) or lmposstbtllty ( - ) of gender and number reflection , respecttvely , the elements of the compound that can be inflected receive the mflecuonal code that they have m the DELAS both constltuents of ser humano inflect ( in number ) according to , respectively , the rules 21 and 01 ser humano seres humanos , guerra frta is invariable , and the noun vlstta de estudo only allows the inflection of vtstta vtstta de estudo vtsttas de estudo As well as for other languages ( e g French ) , addluonal mformat~on Is being added , namely semantic 76 Most of the local hngutstgc phenomena , as well as many complex sentences , are represented m a natural way by the formalism of finite-state automata ( FSA ) For instance , frozen or semtfrozen structures are very naturally described by graphs , that represent FSAs ( Sllberztem ( 1997 ) ) We illustrate the use of graphs with an elementary example , selected from the hbrarles of Portuguese local grammars This grammar descnbes a family of adverbial expressions ( dates ) , which refer to a period of ttme around the middle of the months ( or , by extensmn , of some years ) as m the underlined expression lsso aconteceu nos tdos de Marfo ( That happened on the ides of March ) \ / ? a l M~ , ' ~o , . / ~ , ok , ' , l , a. t , , ~ ) , ' , , , , , , , , , , @ N~ -- ' '' ~ ... . , : t~ , , , , , , , IO , ,z. , ,t ( , The following examples show how transducers are used to analyze contracuons , ambtgumes and compound numerical determiners As stated above ( 2 1 ) , contracted forms resulting from the agglutination of two independent words are commonly observed nn Portuguese To properly analyze these entrees we built flmte state transducers ( FST ) that , given a contracted form , produce an output corresponding to the decomposition of the contractxon into ~ts base constituents For xnstance , the FST ( de , ~ t~q~ , ,Al~ F~g 2 Analysis of the contracted form daqut decomposes daqut ( a contraction of the preposmon de ( from ) and the adverb aqut ( here ) ) m ~ts base constituents and , s~multaneously , associate to them the grammatical reformation of the dtcuonary ~__ / ~ ... ... ... .. \ [ : ~j '' \ [ Dtsambtguanon can be done at different moments • ~ { i-~.'rld ... ... ... . ~ , ) , v , m , ! , of parsing '~ I..~. , .I ~ m ~ ' -- '~. , I'~ ' , '' ! / `` -~ , I '' '' '' I t a ) Dtsambtguatmn durmg normahzatwn - , ~lallll *J i : ~ ' ( I The normahzation of texts for hnguistlc analysis I~ \ [ uses FST to identify sentences and unambiguous • It : | compounds , to solve contractions and ehsxons As i~ , ~ an example of dxsamblguatlon at this level , we • I p.I , .i.. '' ~ , still use the case of contracuons .. l , ' , 'j ' The form dele results from the contrachon of de \ [ \ ] Fig 1-Advldos grf ( of ) with the ambiguous personal pronoun ele ( he , Th~s set of adverbial phrases corresponds to a h~m ) , which can be either a subjective ( coded N ) \ [ \ ] linguistic object of clearly flmte-state nature , but or a genitive form ( coded O ) hngmst~c phenomena of a more complex nature ele , eu PRO+Pes N3ms 03ms However , only • can be efficmntly described by such formahsms genitive forms can occur m the contraction dele ( Gross ( 1997 , 1995 ) ) ( de + ele ) So , the FST \ [ \ ] I~ PI/FI'I le-r* ~ Pilt'1 , - ) ~prl O , m~l . , , . , ,.AI. '' . \ [ &amp; .l~i't.~r.l~l \ [ eCe- , ,e~ H , lO+l'-e. , ~.~ ) \ [ , Ik '' Pl~..ll~N r-N~ , eu , PPd'l '' rPe , m , ONp ) Fig 3 Analysis of the contracted forms dele , dela , deles , delas From the graphs of the local grammars , parsers ( FSTs ) can be automatically constructed , that applied to texts m combination with the dictionaries , allow the detection of a large variety of hngmstlc patterns ( see below ) Finite-state automata and transducers can be efficiently apphed at various levels of hngutstm analysis 77 ts used not only to decompose the contracted form dele m its base consmuents but to dlsamb~guate the pronouns ele , ela , eles , elas Identical FSTs can be used to analyze more complex situations where both constituents of a contraction can mflect mdependently 4 b ) Dtsambiguatwn for tagging In Portuguese , a word such as compra can be either a noun or a verb , the form o can be a determiner , a demonstranve pronoun and a personal pronoun So , the linear combination of these elements allows six different analyses However , m sentences hke Ela compra-o hoje ( She buys it today ) compra Is only a verb , and o is only a personal pronoun , bound to the verb by an hyphen The following FST Fig 4 FST for the dlsamblguanon of verbs and clmcs was built to solve these amb~gmttes the five erroneous analyses are not taken mto account , compra and o receive the correct tags The Portuguese numerical determiners from dots ( 2 ) to novecentos e noventa e nove md novecentos e noventa e nove ( 999,999 ) are plural forms However , some of them can reflect m gender dol_.~s &lt; hvro__s &gt; ( two &lt; books &gt; ) du_a~s &lt; cadeira_.ss &gt; ( two &lt; chmrs &gt; ) trezentos e vmte e dots &lt; hvro__~s &gt; ( three hundred and twenty-two &lt; books &gt; ) trezenta___~s e vmte e duas &lt; cadetra_._s_s &gt; ( three hundred and twenty-two &lt; chmrs &gt; ) ~ That ~s the case of aqueloutra which Is the contraction of the demonstrative pronouns aquela + outra ( that ( fs ) + otherOes ) ) In Portuguese , even though contracted words are numerous , the hst of contractions ~s stdl a closed set So its descnpuon with FSTs is possible However , this solution would not be adequate to describe productive phenomena revolving agglutination , as it is probably the case of most compound nouns In German , for instance Others are mvanant an respect to gender vinte &lt; hvros &gt; ( twenty &lt; books &gt; ) vtnte &lt; cadeiras &gt; ( twenty &lt; chairs &gt; ) rail e sete &lt; hvros &gt; ( one hundred and seven &lt; books &gt; ) mde sete &lt; cadeiras &gt; ( one hundred and seven &lt; chmrs &gt; ) Numerical deternuners such as dots , duas and vmte are simple words and therefore they are formahzed tn the DELAF dicnonary , numerical deterrnmers such as trezentos e vmte e dots , trezentas e vinte e duas and mtle sete can be seen as specml compound words that are more adequately described by FST The first FST m figure -In `` d i I / ) ) ~ .</sentence>
				<definiendum id="0">Portuguese DELAS IS</definiendum>
				<definiendum id="1">DELAS</definiendum>
				<definiendum id="2">word</definiendum>
				<definiendum id="3">Dins</definiendum>
				<definiendum id="4">Dfs</definiendum>
				<definiendum id="5">FSA</definiendum>
				<definiendum id="6">FST</definiendum>
				<definiendum id="7">FST</definiendum>
				<definiendum id="8">( FSTs</definiendum>
				<definiens id="0">includes monohngual hngulstlc resources ( mainly for French and English ) specifically elaborated to be integrated into NLP systems Standard methods and formats-have been defined and are now used by other national teams working on their own languages German , Greek , Italian , Portuguese and Spanish Within that common framework , important fragments of the descnptmn of the languages involved have been worked out the syntactic and semantic properties of free and frozen sentences are descnbed and formalized e~s for the lexicon , a major component of NLP , large coverage electromc dlctionanes have been built Simple and compound words</definiens>
				<definiens id="1">the central element of the d~ctionary system Itcontains more than 110,000 simple words , whose grammatical attributes are systemaucally described and encoded The set of compound words Is structured m the Portuguese DELAC At the moment , it Is constituted by a lexicon of 22,000 compound nouns and 3,000 frozen adverbs</definiens>
				<definiens id="2">the dIctmnary of simple words We understand by simple words the lexlcal units that correspond to a continuous string of</definiens>
				<definiens id="3">an alphanumenc code contzanmg mformat~on on the grammatical attributes of the entries their grammatical class ( eventually , sub-class ) , and their morphological behavior The mflected forms are automaucally generated from the association of a lemma to an mflecuonal code the hst of all reflected words constitutes the Portuguese DELAF ( 1,250,000 word forms</definiens>
				<definiens id="4">conjugated ( mood , tense , person , number ) , furthermore , some verbal forms can undergo formal mo &amp; ficattons reduced by the presence of a clmc pronoun Thus , the DELAS entries gato</definiens>
				<definiens id="5">gordmhos , gordo A Dmp gordmhas , gordo A Dfp gordlsslmo , gordo A Sms ( very fat ) gordfsstma , gordo A Sfs gord£sstmos , gordo A Stop gord\ [ sstmas , gordo A Sfp As for the verbs</definiens>
				<definiens id="6">the contracted forms dele , dela , deles , delas From the graphs of the local grammars , parsers</definiens>
			</definition>
</paper>

		<paper id="0907">
			<definition id="0">
				<sentence>Term clustering methods are typically based on the statistics of term co-occurrence within a word window , or within syntactic constructs ( e.g. Pereira et al. , 1993 ) .</sentence>
				<definiendum id="0">Term clustering methods</definiendum>
			</definition>
			<definition id="1">
				<sentence>Denote by Cx the part containing x~X. Recall that if Cx contains additional elements , some of them must be elements of Y. Hence , Cx represents coupling of the subsets XACx and YnCx .</sentence>
				<definiendum id="0">Cx</definiendum>
				<definiens id="0">coupling of the subsets XACx and YnCx</definiens>
			</definition>
			<definition id="2">
				<sentence>Note that E ( M ) pretends to reflect balance of constrains , as described above , only for a particular pair of documents at a time .</sentence>
				<definiendum id="0">M )</definiendum>
				<definiens id="0">pretends to reflect balance of constrains</definiens>
			</definition>
</paper>

		<paper id="0625">
			<definition id="0">
				<sentence>WordNet \ [ Miller et al. 1990\ ] provides sense information , placing words in sets of synonyms ( synsets ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">provides sense information , placing words in sets of synonyms ( synsets )</definiens>
			</definition>
			<definition id="1">
				<sentence>The TDT corpus , developed by NIST and DARPA , is a collection of 16,000 news articles from Reuters and CNN where many of the articles and transcripts have been manually grouped into 25 categories each of which corresponds to a single event ( see http : //morph.ldc .</sentence>
				<definiendum id="0">TDT corpus</definiendum>
				<definiens id="0">a collection of 16,000 news articles from Reuters and CNN where many of the articles</definiens>
			</definition>
			<definition id="2">
				<sentence>As comparisons are made between all pairs of paragraphs from the same topic , the total number of comparisons is equal to E i=1 where Ni is the number of paragraphs in all selected articles from topical category i. Training of our machine learning component was done by three-fold cross-validation , randomly splitting the 10,345 pairs of paragraphs into three ( almost ) equally-sized subsets .</sentence>
				<definiendum id="0">Ni</definiendum>
				<definiens id="0">the number of paragraphs in all selected articles</definiens>
			</definition>
			<definition id="3">
				<sentence>The kappa statistic is defined as PA -Po g-~-l-P0 where PA is the probability that two reviewers agree in practice , and P0 is the probability that they would agree solely by chance .</sentence>
				<definiendum id="0">kappa statistic</definiendum>
				<definiendum id="1">PA</definiendum>
				<definiendum id="2">P0</definiendum>
				<definiens id="0">the probability that two reviewers agree in practice</definiens>
			</definition>
			<definition id="4">
				<sentence>4 SMART utilizes a modified TF*IDF measure ( ATC ) plus stemming and a fairly sizable stopword list .</sentence>
				<definiendum id="0">SMART</definiendum>
				<definiens id="0">utilizes a modified TF*IDF measure</definiens>
			</definition>
			<definition id="5">
				<sentence>Text Retrieval and Filtering : Analytic Models of Performance .</sentence>
				<definiendum id="0">Filtering</definiendum>
				<definiens id="0">Analytic Models of Performance</definiens>
			</definition>
			<definition id="6">
				<sentence>Introduction to WordNet : An On-Line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="7">
				<sentence>BoosTexter : A BoostingBased System for Text Categorization .</sentence>
				<definiendum id="0">BoosTexter</definiendum>
				<definiens id="0">A BoostingBased System for Text Categorization</definiens>
			</definition>
</paper>

		<paper id="0803">
			<definition id="0">
				<sentence>JavaScript is a pure client-side application , and has a number of practical advantages which outweigh many of its limitations : JavaScript is interpreted , not compiled , and the code is immediately available for inspection by the user ; despite its sireplicity , it permits arbitrarily complex textual and numerical manipulation and basic window management ; like other scripting languages , Javascript is not designed for modular programme development or library deployment , but is best restricted to small applications of the kind used in introductory work .</sentence>
				<definiendum id="0">JavaScript</definiendum>
				<definiendum id="1">JavaScript</definiendum>
				<definiens id="0">not designed for modular programme development or library deployment , but is best restricted to small applications of the kind used in introductory work</definiens>
			</definition>
			<definition id="1">
				<sentence>generator Database methodology is an essential part of computational linguistic training ; traditionally , UNIX ASCII databases have been at the core of many NLP lexical databases , though large scale applications require a professional DBMS .</sentence>
				<definiendum id="0">UNIX ASCII</definiendum>
				<definiens id="0">an essential part of computational linguistic training</definiens>
			</definition>
			<definition id="2">
				<sentence>Tasks range from testing and evaluating to parsing phonological ( or orthographic ) FSA descriptions .</sentence>
				<definiendum id="0">Tasks</definiendum>
			</definition>
			<definition id="3">
				<sentence>DATR is a well-known theoretically wellfounded and practically oriented lexicon representation language .</sentence>
				<definiendum id="0">DATR</definiendum>
				<definiens id="0">a well-known theoretically wellfounded and practically oriented lexicon representation language</definiens>
			</definition>
</paper>

		<paper id="0626">
			<definition id="0">
				<sentence>A commonly used technique for measuring string similarity is to look for the longest common subsequence ( LCS ) of characters in two strings ; the characters in this sequence do not necessarily need to be contiguous in the original strings ( Wagner and Fischer , 1974 ; Stephen , 1992 ) .</sentence>
				<definiendum id="0">commonly used technique for measuring string similarity</definiendum>
				<definiens id="0">to look for the longest common subsequence ( LCS ) of characters in two strings</definiens>
			</definition>
			<definition id="1">
				<sentence>Dynamic Programming A common technique for computing the length of the longest common subsequence for two given 2LCSR scores were calculated for tokens containing at least one alphabetic character and a threshold of 0.7 was used to filter the resulting list .</sentence>
				<definiendum id="0">Dynamic Programming</definiendum>
				<definiens id="0">A common technique for computing the length of the longest common subsequence for two given 2LCSR scores were calculated for tokens containing at least one alphabetic character</definiens>
			</definition>
			<definition id="2">
				<sentence>If n is the length of string x and m is the length of string y an ( 0 .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">the length of string x and</definiens>
			</definition>
			<definition id="3">
				<sentence>Now , the function m has to be modified to ra ( x , y ) = w ( x ) in all cases of x = y where w ( x ) is a weight for the character x z. Another possibility is to define a complete character matching function for all elements from the alphabet .</sentence>
				<definiendum id="0">w ( x )</definiendum>
				<definiens id="0">a weight for the character x z. Another possibility is to define a complete character matching function for all elements from the alphabet</definiens>
			</definition>
			<definition id="4">
				<sentence>String Segmentation There is a common segmentation problem with units larger than one element .</sentence>
				<definiendum id="0">String Segmentation There</definiendum>
				<definiens id="0">a common segmentation problem with units larger than one element</definiens>
			</definition>
			<definition id="5">
				<sentence>The following formulas describe approximations of two commonly used metrics , Mutual Information ( I ) and the Dice coefficient ( Dice ) ( Smadja et al. , 1996 ; Church et al. , 1991 ) : I ( x , y ) Dice ( x , y ) Estimated Position • f ( x , y ) .</sentence>
				<definiendum id="0">Mutual Information</definiendum>
				<definiendum id="1">Dice coefficient</definiendum>
				<definiens id="0">( Dice ) ( Smadja et al. , 1996 ; Church et al. , 1991 ) : I ( x , y ) Dice ( x , y ) Estimated Position • f ( x , y )</definiens>
			</definition>
			<definition id="6">
				<sentence>Char_align : A Program for Aligning Parallel Texts at the Character Level .</sentence>
				<definiendum id="0">Char_align</definiendum>
				<definiens id="0">A Program for Aligning Parallel Texts at the Character Level</definiens>
			</definition>
			<definition id="7">
				<sentence>Translation Collocations for Bilingual Lexicons : A Statistical Approach .</sentence>
				<definiendum id="0">Translation Collocations for Bilingual Lexicons</definiendum>
			</definition>
</paper>

		<paper id="0501">
			<definition id="0">
				<sentence>Th~s paper presents an on-going project mtended to enhance WordNet molpholog~cally and semanttcally The mottvatmn for th~s work steams from the current hm~tat~ons of WordNet when used as a hngmst~c knowledge base We enwmon a software tool that automatically parses the conceptual defining glosses , attributing part-ofspeech tags and phrasal brackets The nouns , verbs , adjectives and adverbs from every defimtmn are then d~samb~guated and hnked to the corresponding synsets Th~s increases the connectlv~ty between synsets allowing the ~etneval of topically ~elated concepts Furthermore , the tool t~ansforms the glosses , first into logical forms and then into semantm fo~ms Usmg der~vatmnal morphology new hnks are added between the synsets WordNet has already been ~ecogmzed as a valuable ~esource m the human language technolog &gt; and know , ledge processing commumtms Its apphcabfl~ty has been c~ted m mo~e than 200 papers and s~stems have been m~plemented usmg WordNet A Wo~dNet bkbhog~aph~ ~s mamtamed at the Umve~mt ) of Penns : ~l~ama ( http //www c~s upenn edu/~oseph~ /wnbtblw html ) In Europe , WordNet ~s being u~ed to develop a multflmgual database w~th basic semantic relatmns between words for several European languages ( the EuroWordNet project ) Capabihties WordNet was conceived as a machine-readable dmtlonary , followmg psychohngmstm principles Unhke standard alphabetmal dmt~onaHes ~hmh o~gamze vocabula~ms using mo~phologmal mmllm ltms , WordNet structures lex~cal reformation m terms of word meanings WordNet maps word forms m ~ord senses usmg the s ) ntact~c category as a parametel Although it covers onl~ fouI paits of speech nouns verbs , adjectives and adverbs , it encompasses a large majont ) of Enghsh words ( http //www cogscz pmnceton edu/~ .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">the EuroWordNet project ) Capabihties WordNet was conceived as a machine-readable dmtlonary</definiens>
			</definition>
			<definition id="1">
				<sentence>wn ) Wolds of the same syntactm catego~ ) that can be used to express the same meamng are grouped into a smgle synonym set , called synset Words wlth multiple meanings ( polysemous ) belong to multiple synsets An ~mportant part of the 99 643 synsets encoded m WordNet 1 6 contain word collocatmns , thus representing complex nominals ( e g the synset { manufacturer , maker , manufacturing business } , ( omplex velbals ( eg the synset { leave office , quit , step down } , complex adjectlvals ( e g the ~ynset { true , dead on target } or complex adverbmls ( e g the synset { out of hand , beyond control } The iep~esentatmn of collocatmns as synset entries p~ov~des for their semantm mterp~etatmn Wolds and concepts are furthei connected through a small set of lexmo-semantm relatmns The dominant semantm relatmn is the hypernymy , xvh~ch structures the noun concepts m 11 hmraichms and the verb concepts into 512 ) he , atchins Thlee melonym Ielatlons are encoded between noun concepts the ha~_member , the ha~_~tu\ ] f and the has_part ~elatlons Loglcal opelatlon~ betx~een events or entltms ale modeled through entazlment and cause_to ~elatmns between verb concepts or antonymy relatmns among nouns , veibs ad ) ect~ves or adverb words The~e are only a few mo~phologmally motivated connectmns between x~ords known as perta~mym relatmns Llmltatmns The mare ~eaknesses of \Vo~dNet c~ted m the hte~ature ale hmrarctnes cally related words restnctmns mmsmg `` the2e m a lack of umform~ty and consmtency 2n the defimtmns The key idea m our project is to put to wo , k the rich sourse of mformauon contained m glosses that now can be used only by humans to Iead the deflmtmn of synsets For example , Wo , dNet 1 6 hsts the concept { cat , true cat ) with the gloss ( fellne mammal usually havlng thlck soft fur and belng unable to roar , domestxc cats , wxldcats ) Currently , from a concept like thin , only a few other concepts could be reached In Extended Wo2dNet , the concept { cat , true cat } will be , elated to 215othel concepts ( I0 from its own gloss , 38 flom the glosses of its hypern &gt; ms , 25 concepts that use ~t m the*r glosses as a defining concept plus other 142 concepts with which the concept mteracts in these 25 glosses ) Thin level of mformatmn , s rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning Machine Readable DmUonanes ( MRDs ) have long been , ecogmzed as ~aluable resources m computauonal hngmstlcs In their paper , Ide and Vetoms ( Ide and Veloms , 1993 ) plojected a rather pes~lmmuc outlook for the uuhty of MRDs as knowledge sources , a view that has impeded the enthus2asm of some researchers ( Wfiks et al 1996 ) make a strong argument m favor of using MRDs and shine thel , posluve experience w~th using some dlcuonarms The MmdNet project at Mmrosoft alms at fully automatmg the development of a vel } large lexlcal knowledge base using t~o MRDs the Longman DicUonary of ContemporaD Enghsh ( LDOCE ) and the American Heritage Third EdlUon ( AHD3 ) Man : y techmcal aspects of thin project are rooted m the works of Vanderwende ( Vanderwende 1996 ) and Richardson ( R2chardson 1997 ) gloss concepts There are se~e , al dlffe~ences bet~een gloss dlsamblguauon and text dlsamb~guatmn A n-la\ ] oi difference is that m our project we know the meaning of each gloss , namely the synset to whmh a gloss apphes Second , the glosses contain a defimUon , comments , and one or more examples We address the word sense dmamblguaUon problem by using three complementary methods ( a ) heunstms , ( b ) conceptual dens , ty , and ( c ) staustins on large corpora The first two methods rely enurely on the mfolmaUon contained m WordNet , while the th , rd one uses other corpora Specffically , the sources of knowledge available to us me ( 1 ) lexlcal mformauon that includes part of speech , posluon of ~ords ( 1 e head word ) , and lexmal lelauons ( 2 ) collocauons and s ) ntacuc patterns , ( 3 ) s } nset to which a gloss belongs , ( 4 ) hypernyms of s ) nset and their glosses ( 5 ) synsets of pobsemouns x~o2ds and their glosses , ( 6 ) hypernyms of synsets of polysemous words , and their glosses , and so on Method 1 Classes of heur , st , cs for word sense dmarnblguatmn A statable techmque for dmamblguatmg dmuonarms is to rely on heu !</sentence>
				<definiendum id="0">MRDs</definiendum>
				<definiens id="0">a smgle synonym set , called synset Words wlth multiple meanings ( polysemous ) belong to multiple synsets An ~mportant part of the 99 643 synsets encoded m WordNet 1 6 contain word collocatmns , thus representing complex nominals ( e g the synset { manufacturer , maker , manufacturing business } , ( omplex velbals ( eg the synset { leave office , quit</definiens>
				<definiens id="1">the hypernymy , xvh~ch structures the noun concepts m 11 hmraichms and the verb concepts into 512 ) he , atchins Thlee melonym Ielatlons are encoded between noun concepts the ha~_member , the ha~_~tu\ ] f and the has_part ~elatlons Loglcal opelatlon~ betx~een events or entltms ale modeled through entazlment and cause_to ~elatmns between verb concepts or antonymy relatmns among nouns , veibs ad</definiens>
				<definiens id="2">includes part of speech , posluon of ~ords ( 1 e head word ) , and lexmal lelauons ( 2 ) collocauons and s ) ntacuc patterns , ( 3 ) s } nset to which a gloss belongs , ( 4 ) hypernyms of s ) nset and their glosses ( 5 ) synsets of pobsemouns x~o2ds and their glosses , ( 6 ) hypernyms of synsets of polysemous words , and their glosses , and so on Method 1 Classes of heur , st</definiens>
			</definition>
			<definition id="2">
				<sentence>\ ] are ~ound m txvo glosses of % % bldNet , and the~e are senses of w~ and w~ that have a common hypernym , it is hkely that the correlatmn between w , and the common hypeInym is projected m both collocatlons Example The gloss of the synset { Underground Rallroad } Is ( abolltlonlsts secret ald to escaping slaves ) • We have \ [ wlrw2\ ] \ [ ald to slave\ ] • The gloss of { ald # 4 } is ( ald to someone ) • The pronoun someone can tefel to { slave # l } thus sense 4 of noun ald IS picked Method 2 Conceptual dens , ty method We have , mplemented a WSD system for free text that disamb , guates multiple wolds mmultaneousl3 ( Mlhalcea and Moldovan , 1999 ) The method is based on measuring the number of common nouns shared by the verb and noun hmrarchms , and thus gets around the lack of connections problem As an example , consider a verb noun pair of uotds Denote w~th &lt; vl , v2 , , Vh &gt; and &lt; nl , n2 , , nt &gt; the senses of the verb and the noun m WoidNet Fo~ each possible pelt v , n j , the conceptual density m computed as follows of v , and determine the nouns from these glosses This constitutes the noun-context of verb v , Each such noun is stored together with a weight w that indicates the level m the sub-hmrarchy of the velb concept m whose gloss the noun was found of nj and determine the nouns m them mon concepts between the nouns obtained at ( 1 ) and the nouns obtained at ( 2 ) using the metllc Icd , j I &amp; C~3 = lo9 ( descendentsj ) ( 1 ) where • \ [ ~d , ~l is the number of common concepts between the tnelarch , es of v~ attd nj • w~ are the levels of the nouus m the lueiaich~ of verb v , • descendentsj *s the total number of uotd~ w , thm the hmra , chy of noun nj ants of th , s method work for other parts of speech pairs such as noun-noun , noun-verb , verb-verb , verb-noun , adje.cUve-noun and verb-adverb Th , s , s a powerful method that v , orks surprisingly x~ell even for free text We ha~e tested the method on SemCor , the pint of the Brown coipus tagged x~ltlt WotdNet seltses \V , th tlns technique it is possible to , ank the senses and \ [ o keep not only the h~st lanked sense , but the second ol th , td ~anked senses 3 especmlly when the tankmg is sufficiently close and there ~s another wa~ to check the vahd , ty of the d~samb~guaUon Method 3 Statistics on large corpora As a last resort , we can use a staustmal approach to d , samblguate those words that can not be done with any of the methods described so fal Consider a collocating word-word pmr wl w2 m whmh we conslde , that Wl has been dtsambtguated already The dlsambtguatmn of w2 proceeds as follows ( 1 ) Foi each sense w~ , form a slmdanty hst with w ) and all other words that may be m that synset { w.~ , w ' , ( 1 ) `` , ( 2 ) ~ ' _ , w 2 ) } ( 2 ) Form pans of wz and all the % xords m each ~Izmlarzty hst foI all z ( 3 ) Search a lalge empus for the occurrences o\ [ any of the pans m the hst above , .</sentence>
				<definiendum id="0">~l</definiendum>
				<definiens id="0">mplemented a WSD system for free text that disamb</definiens>
				<definiens id="1">the conceptual density m computed as follows of v , and determine the nouns from these glosses This constitutes the noun-context of verb v</definiens>
			</definition>
			<definition id="3">
				<sentence>K2 ) ~ , , { wtw~ '' OR ~1~ OR wzw 2 ) } We have searched the Internet using the AltaV~sta search engine The number of hits for each similarity hst measmes the , elatedness of w~ wtth each sense w~ and thus provtdes a ranking of the senses Overall Procedure and Results The followmg procedure was used to dlsamb~guate 12,762 words from 1000 randomly selected glosses Step 1 Identify and separate the monosemous words that have only one sense m WordNet ( m out experiment 6468 words were found ) Step 2 Apply Method 1 HeurlsUcs to the reroaming 6294 polysemous words Method 1 provides correct d~samblguatmn for 5475 words , thus an accmac~ of 87 % Out of the remammg 13 % of the words , 3 % were dlsamb~guated erroneously and 10 % could not be done with the heuristics used The correct sense for each word was determined manually by a team of three students We ha~e found a fe~ s ) n~ets such as { commemorate , remember } that have no hnks to an~ other synsets , m no h3 pern3 ms and no hypom } ms Step 3 Apply Method 2 Conceptual Denszty to the 6294 polysemous words , staitmg hesh Step 4 Apply Method 3 StaUstlcs to the 6294 words using Alta¥~sta on the Internet Step 5 The results obtained wtth Method 1 and Method 2 are combined , that is , take all the wo , ds that were d~sambzguated , and m the case of conflict g~ve prmnty to Method 1 Step 6 The results from Step 5 are combmed wtth the results g~ven by Method 3 and m the case of conflmt gtve priority to results obtained m Step 5 Table 1 indicates the accuracy obtamed at each step An overall accmacy of 94 % x~as achmved Out goal , s to improve the techmque to be able to dlsamb~guate all words automatmally These results must be seen agamst the background average rate of 59 39 % correct sense asstgnment achmved when the first WordNet sense is assigned to each polysemous word This is considered the basehne performance level for word-sense dlsamblguat , on programs ( Gale et al 1992 ) and is consistent ~uth out own measurements Our extenszon of WordNet Intends to serve as a lexlco-semantic Iesource for a variety of NLP apphcations , many of them requiring pragmauc and common-sense knowledge ( Harabagm and Moldovan 1998 ) It is beneficial to transform the conceptual glosses m logical foimulae Approach to implement Logical Form Transformat , ons ( LFTs ) ( 1 ) Traditional lexmographm principles deteIImne the d , scnmmatlon of any conceptual defimtlons into a genus and the dzfferentza Our LFTs Implement the same dlstlncUon by always plaong the genus predicate on the first position of the LFT , and the rest of the LFT viewed as the definition differentia ( 2 ) A predmate is generated for every noun , verb , adjective or adverb encountered In any gloss The name of the predicate is a concatenatmn of the morpheme 's base form , the pat t-of-speech and the WordNet semanuc sense , thus capturing the full lemcal and semantm disamblguaUon For example , the LFT of the gloss of { student , pupzl , educatee } contains the predmates learner n # l , enroll v # l and educabonaIJnstJtutlon n # l ( 3 ) In the sprat of the Davidsoman tzeatment oi the acUon predicates , all verb predmates ( as ~ell as the nommahzaUons zeptesentmg acuons , e~ents or states ) haxe thlee arguments actlon/state/eventpredlcate ( e , ,~\ [ , x~ ) , where • e , zeptesents the eventuahty of the acUon state ot exent ~ stated b &gt; the xetb to take place , • 3 .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a ranking of the senses Overall Procedure and Results The followmg procedure was used to dlsamb~guate 12,762 words from 1000 randomly selected glosses Step 1 Identify and separate the monosemous words</definiens>
			</definition>
</paper>

		<paper id="0909">
			<definition id="0">
				<sentence>Kupiec ( Kupiec , 1992 ) uses an unsupervised version of the Baum-Welch algorithm , which is a way of using examples to iteratively estimate the probabilities of a Hidden Markov Model for part of speech tagging .</sentence>
				<definiendum id="0">Kupiec</definiendum>
				<definiens id="0">uses an unsupervised version of the Baum-Welch algorithm , which is a way of using examples to iteratively estimate the probabilities of a Hidden Markov Model for part of speech tagging</definiens>
			</definition>
			<definition id="1">
				<sentence>Kanazawa ( Kanazawa , 1994 ) and Buszkowski ( Buszkowski , 1987 ) use a unification based approach with a corpus annotated with semantic structure , which in CG is a strong indicator of the syntactic structure .</sentence>
				<definiendum id="0">Kanazawa</definiendum>
				<definiens id="0">a strong indicator of the syntactic structure</definiens>
			</definition>
			<definition id="2">
				<sentence>Secondly , the syntactic structure in CG parallels the semantic structure , which allows an elegant interaction between the two .</sentence>
				<definiendum id="0">semantic structure</definiendum>
				<definiens id="0">allows an elegant interaction between the two</definiens>
			</definition>
			<definition id="3">
				<sentence>Where Word is a word , Category is a Prolog representation of the CG category assigned to that word and Frequency is the number of times this category has been assigned to this word up to the current point in the learning process .</sentence>
				<definiendum id="0">Word</definiendum>
				<definiendum id="1">Category</definiendum>
				<definiendum id="2">Frequency</definiendum>
				<definiens id="0">a word ,</definiens>
			</definition>
			<definition id="4">
				<sentence>The Parser The system employs a probabilistic chart parser , which calculates the N most probable parses , where N is the beam set by the user .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the beam set by the user</definiens>
			</definition>
			<definition id="5">
				<sentence>The most probable annotation of the corpus is the set of top-most parses after the final parse selection .</sentence>
				<definiendum id="0">most probable annotation of the corpus</definiendum>
				<definiens id="0">the set of top-most parses after the final parse selection</definiens>
			</definition>
			<definition id="6">
				<sentence>The CFG ( shown in Figure 4 ) covers a range of simple declarative sentences with intransitive , transitive and ditransitive verbs and with adjectives .</sentence>
				<definiendum id="0">CFG</definiendum>
				<definiens id="0">shown in Figure 4 ) covers a range of simple declarative sentences with intransitive , transitive and ditransitive verbs and with adjectives</definiens>
			</definition>
			<definition id="7">
				<sentence>The lexicon accuracy column is a measure , calculated by manual analysis , of the percentage of lexical entries i.e. entries that have word-category pairs that can plausibly be accepted as existing in English .</sentence>
				<definiendum id="0">lexicon accuracy column</definiendum>
				<definiens id="0">a measure , calculated by manual analysis , of the percentage of lexical entries i.e. entries that have word-category pairs that can plausibly be accepted as existing in English</definiens>
			</definition>
</paper>

		<paper id="0502">
</paper>

		<paper id="0110">
			<definition id="0">
				<sentence>The pattern of '' coreference that is observed with these three types of measures ( intuitive judgments , reading time , and frequency in a corpus ) is accounted for by a model ( Gordon &amp; Hendricl~ 1998 ) that incorporates aspects of Centering Theory ( Grosz , Joshi , &amp; Weinstein , 1995 ) into Discourse Representation Theory ( Kamp &amp; Reyle , 1993 ) .</sentence>
				<definiendum id="0">pattern of '' coreference</definiendum>
				<definiens id="0">intuitive judgments , reading time , and frequency in a corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>PRO ( Const~ction Rule for Pronouns ) I I Trigguring Condition : ~ b._J\ ] Inslructions • Chose an antecedent vj , after considering every vi i &lt; j such that vl and vj exist in the ordered set of discourse referents in the DRS and are suitable antecedents , and substitute vj for \ [ co ~ \ ] in the triggering condition .</sentence>
				<definiendum id="0">PRO</definiendum>
				<definiens id="0">vl and vj exist in the ordered set of discourse referents in the DRS and are suitable antecedents</definiens>
			</definition>
			<definition id="2">
				<sentence>PN ) which posits a new entity ( here shown as x ) in the universe of the discourse and which introduces a condition in the universe consisting of the name predicated on this new entity .</sentence>
				<definiendum id="0">PN</definiendum>
				<definiens id="0">posits a new entity ( here shown as x ) in the universe of the discourse and which introduces a condition in the universe consisting of the name predicated on this new entity</definiens>
			</definition>
			<definition id="3">
				<sentence>Pro ) which searches the discourse universe for a *'suitable antecedent '' ( one that matches on grammatically encoded features ) .</sentence>
				<definiendum id="0">Pro</definiendum>
				<definiens id="0">searches the discourse universe for a *'suitable antecedent '' ( one that matches on grammatically encoded features</definiens>
			</definition>
			<definition id="4">
				<sentence>EQ : Adjunct ... . Triggering Condition - : the condition set _ ( u ) within -- Ki where _ is a pronoun Instructions : • Equate u with a discourse referent v that is within the universe K~ .</sentence>
				<definiendum id="0">EQ</definiendum>
				<definiens id="0">the condition set _ ( u ) within -- Ki where _ is a pronoun Instructions : • Equate u with a discourse referent v that is within the universe K~</definiens>
			</definition>
			<definition id="5">
				<sentence>Finally , DRT describes semantic interpretation as an incremental process in which the interpretation of an utterance involves a dynamic interaction of the characteristics of the utterance with the discourse universe that represents the meanings created from the earlier utterances in the discourse .</sentence>
				<definiendum id="0">DRT</definiendum>
				<definiens id="0">describes semantic interpretation as an incremental process in which the interpretation of an utterance involves a dynamic interaction of the characteristics of the utterance with the discourse universe that represents the meanings created from the earlier utterances in the discourse</definiens>
			</definition>
			<definition id="6">
				<sentence>Pro ) interprets a pronoun as referring to an entity in the current discourse representation and therefore forces integration of the utterance into the current discourse representation .</sentence>
				<definiendum id="0">Pro )</definiendum>
				<definiens id="0">interprets a pronoun as referring to an entity in the current discourse representation</definiens>
			</definition>
</paper>

		<paper id="0411">
			<definition id="0">
				<sentence>The e-rater system uses an ETS-enhanced version of the CASS syntactic chunker ( Abney ( 1996 ) ) , referred to here as the parser .</sentence>
				<definiendum id="0">e-rater system</definiendum>
				<definiens id="0">uses an ETS-enhanced version of the CASS syntactic chunker</definiens>
			</definition>
			<definition id="1">
				<sentence>E-rater 's formula for the weight of word w in essay j is : weightwj= ( freqw/maxfreqj ) * log ( nessays/essaysw ) where freqwj is the frequency of word w in essay j , maxfreqi is the frequency of the most frequent word in essay j , nessays is the total number of training essays , and essaysw is the number of training essays that contain w. The first part of the formula measures the relative importance of the word in the essay .</sentence>
				<definiendum id="0">freqwj</definiendum>
				<definiendum id="1">maxfreqi</definiendum>
				<definiendum id="2">essaysw</definiendum>
				<definiens id="0">the frequency of the most frequent word in essay j , nessays is the total number of training essays</definiens>
				<definiens id="1">the number of training essays that contain w. The first part of the formula measures the relative importance of the word in the essay</definiens>
			</definition>
			<definition id="2">
				<sentence>70 score is computed using the following formula , rounded to the nearest integer : Score for test essay t = E ( cosinetj * scorej ) /~ cosinetj where j ranges over the 6 closest training essays , scorej is the human rater score for training essay j , and cosineg is the cosine between test essay t and training essayj .</sentence>
				<definiendum id="0">scorej</definiendum>
				<definiendum id="1">cosineg</definiendum>
				<definiens id="0">computed using the following formula , rounded to the nearest integer : Score for test essay t = E ( cosinetj * scorej ) /~ cosinetj where j ranges over the 6 closest training essays</definiens>
				<definiens id="1">the human rater score for training essay j , and</definiens>
				<definiens id="2">the cosine between test essay t and training essayj</definiens>
			</definition>
			<definition id="3">
				<sentence>The overall score for the test essay is an adjusted mean of the argument scores using the following formula , rounded to the nearest integer : Score for test essay t = ( ~argscorej + nargst ) l ( nargst + 1 ) where j ranges over the arguments in test essay t , argscorej is the score of argument j , and nargst is the number of arguments in t. Using this adjusted mean has the overall effect of reducing , slightly , the score for essays with few arguments , and of increasing somewhat the score of essays with many arguments .</sentence>
				<definiendum id="0">argscorej</definiendum>
				<definiendum id="1">nargst</definiendum>
				<definiens id="0">an adjusted mean of the argument scores using the following formula , rounded to the nearest integer : Score for test essay t = ( ~argscorej + nargst ) l ( nargst + 1 ) where j ranges over the arguments in test essay t</definiens>
			</definition>
			<definition id="4">
				<sentence>There-was however an effect of Prompt in the analysis of Agreement for Arabic speakers , where Agreement levels in TWE1 and TWE2 were significantly different ( Z2 ( 1 ) = 6.607 , p &lt; .01 ) ; no other group differences in Agreement were found between the two prompts .</sentence>
				<definiendum id="0">Agreement levels</definiendum>
				<definiens id="0">no other group differences in Agreement were found between the two prompts</definiens>
			</definition>
			<definition id="5">
				<sentence>Computer Analysis of the TOEFL Test of Written English ( TWE ) .</sentence>
				<definiendum id="0">Computer Analysis</definiendum>
			</definition>
</paper>

		<paper id="0109">
			<definition id="0">
				<sentence>Cb ( U. ) is the highest-ranked element of C/ ( U.-I ) that is realised in Un .</sentence>
				<definiendum id="0">Cb</definiendum>
				<definiens id="0">the highest-ranked element of C/ ( U.-I ) that is realised in Un</definiens>
			</definition>
			<definition id="1">
				<sentence>Cf ( Un ) is a partial ordering on the entities mentioned ( or ~lised n ) in Un , ranked by grammatical role , e.g. SUBJ ) DIR-OBJ &gt; INDIR-OBJ ~ &gt; COMP ( S ) ~ &gt; A.DJUNCT ( S ) .</sentence>
				<definiendum id="0">Cf</definiendum>
			</definition>
			<definition id="2">
				<sentence>Recall that the Up is defined as the most salient entity realised in Un , which is predicted to be the Gb of U , +l. However this `` prediction '' is not in fact cashed out in the rul~ for centering transitions , which take no account of whether Cp ( Un ) is actually realised in U , +l. S &amp; H ( op cit. , p. 275 ) propose the principle of cheapness which is satisfied if Cp ( U. ) = Cb ( U.+ l ) .</sentence>
				<definiendum id="0">Cp ( Un</definiendum>
				<definiens id="0">the most salient entity realised in Un , which is predicted to be the Gb of U</definiens>
				<definiens id="1">actually realised in U , +l. S &amp; H ( op cit. , p. 275 ) propose the principle of cheapness which is satisfied if Cp ( U. ) = Cb ( U.+ l )</definiens>
			</definition>
			<definition id="3">
				<sentence>Cb ( U , ) may be pronominalised ifi o Cb ( U. ) = cb ( u._ , ) ( QJw 83 ) o C b ( U. ) = cp ( u._~ ) ( Brenn~ 98 ) Figure 3 : Locating centering tasks in the pipeline theme and theme .</sentence>
				<definiendum id="0">Cb</definiendum>
				<definiendum id="1">cb</definiendum>
				<definiens id="0">u._ , ) ( QJw 83 ) o C b ( U. ) = cp ( u._~ )</definiens>
				<definiens id="1">Locating centering tasks in the pipeline theme and theme</definiens>
			</definition>
			<definition id="4">
				<sentence>In~tential Centering : A Case Study .</sentence>
				<definiendum id="0">In~tential Centering</definiendum>
			</definition>
</paper>

		<paper id="0310">
			<definition id="0">
				<sentence>Many-to-many mapping can thus be viewed as the result of the following situation : i ) for each tag set , tags are defined in relation to their relevance to an intended goal ( be it practical or theoretical ) ; ii ) the definition calls upon a number of relatively independent classificatory dimensions ; iii ) neither all tags in the same tag set nor tags belonging to different schemes consistently share the same dimensions .</sentence>
				<definiendum id="0">iii )</definiendum>
				<definiens id="0">neither all tags in the same tag set nor tags belonging to different schemes consistently share the same dimensions</definiens>
			</definition>
			<definition id="1">
				<sentence>In particular , each dimension in the list below covers a specific level of information taken as criterial for tag-assignment in the tag definitions overviewed in our pilot experiment : • D1 , Grammatical information : tagassignment presupposes availability of morphosyntactic , syntactic , prosodic and lexical information ( limited to grammatical words only ) : see , for example , wh-questions and yes-/noquestions in SWITCHBOARD • D2 , Information about lexical and semantic content : tag-assignment presupposes knowledge about the propositional content of an utterance , e.g. in terms of its logical structure , topic representation , inter-clausal dependencies within the utterance and occurrence of semantically full words ( as opposed to grammatical words ) : see , for example , the category Assert 78 in DAMSL , defined as a truth-conditional claim about the world * D3 , Co-textual information : tagassignment presupposes knowledge of the previous/following utterance ( s ) ( see all `` backwardlooking , or responsive categories ) .</sentence>
				<definiendum id="0">Grammatical information</definiendum>
				<definiens id="0">tagassignment presupposes availability of morphosyntactic , syntactic , prosodic and lexical information ( limited to grammatical words only</definiens>
				<definiens id="1">tag-assignment presupposes knowledge about the propositional content of an utterance , e.g. in terms of its logical structure , topic representation , inter-clausal dependencies within the utterance and occurrence of semantically full words ( as opposed to grammatical words ) : see , for example , the category Assert 78 in DAMSL</definiens>
				<definiens id="2">a truth-conditional claim about the world * D3 , Co-textual information : tagassignment presupposes knowledge of the previous/following utterance ( s ) ( see all `` backwardlooking , or responsive categories )</definiens>
			</definition>
			<definition id="2">
				<sentence>Category &amp; Scheme Assert ( DAMSL ) Statement ( SWBD ) Explain ( MAPTASK ) Inform ( VERBMOBIL ) D1 D2 D3 D4 4-t-t-I-I-Id-t÷ -I-t-F Table 3 : Assert Categories vs Dimensions An Assert in DAMSL is an utterance `` whose primary intention is to make claims about the world , also in the weaker form of hypothesizing or suggesting that something might be true '' ( Allen and Core , 1997 ) .</sentence>
				<definiendum id="0">Assert Categories</definiendum>
				<definiens id="0">vs Dimensions An Assert in DAMSL is an utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>The Explain category in MAP TASK is defined as an utterance `` stating information which has not been elicited by the partner '' ( Carletta et al. , 1996 ) .</sentence>
				<definiendum id="0">Explain category in MAP TASK</definiendum>
			</definition>
			<definition id="4">
				<sentence>• D3.1 : Adjacency Pairs Initiative : the utterance prompts an expectation Reply : the utterance fulfills ~m expectation • D3.2 : Compliance Compliant : the utterance fulfills the expectation set up by a previous utterance in the expected way 80 Non-Compliant : the utterance fulfills the expectation set up by a previous utterance in an unexpected/dlspreferred way • D3.3 : Presupposition -New : the utterance provides information which is new to the hearer -Old : the utterance provides information which is old to the hearer D4 : Pragmatic Information This dimension characterizes an utterance on the basis of pragmatic information , i.e. knowledge of the social relationship between speaker/hearer , the physical setting of the interaction , the topic of the dialogue etc .</sentence>
				<definiendum id="0">Presupposition -New</definiendum>
				<definiendum id="1">Pragmatic Information</definiendum>
				<definiens id="0">the utterance prompts an expectation Reply : the utterance fulfills ~m expectation • D3.2 : Compliance Compliant : the utterance fulfills the expectation set</definiens>
			</definition>
</paper>

		<paper id="0505">
			<definition id="0">
				<sentence>The mapping from WordNet to Hector senses m Senseval provides a `` gold standard '' against wluch to judge our ability to compare lexlcal resources The `` gold standard '' is provided through a word overlap analysis ( with and without a stop list ) for flus mapping , achieving at most a 36 percent correct mapping ( inflated by 9 percent from `` empty '' assignments ) An alternaUve componenttal analysis of the defimtaons , using syntacUc , collocatmnal , and semantac component and relation identification ( through the use ofdefimng patterns integrated seamlessly mto the parsing thclaonary ) , provides an almost 41 percent correct mapping , with an additaonal 4 percent by recogmzmg semantic components not used in the Senseval mapping Defimtion sets of the Senseval words from three pubhshed thclaonanes and Dorr 's lextcal knowledge base were added to WordNet and the Hector database to exanune the nature of the mapping process between defimtton sets of more and less sco\ [ ~e The tecbauques described here consUtute only an maaal implementation of the componenUal analysis approach and suggests that considerable further improvements can be aclueved Introduction The difficulty of companng lemcal resources , long a s~gnfficant challenge in computauonal hnguistlcs ( Atlans , 1991 ) , came to the fore in the recent Senseval competatton ( IOlgarnff , 1998 ) , when some systems that relied heavily on the WordNet ( Miller , et al , 1990 ) sense inventory were faced with the necessity of using another sense inventory ( Hecto0 A hasty solutaon to the problem was the `` development of a map between the two inventories , but some part~cipants expressed concerns that use of flus map may have degraded their performance to an unknown degree Although there were disclaimers about the WordNet-Hector map , it nonetheless stands as a usable gold standard for efforts to compare lexical resources Moreover , we have a usable baseline ( a word overlap method suggested m ( Lesk , 1986 ) ) against which to compare whether we are able to make improvements m the mapping ( since flus method has been shown to perform not as well as expected ( Krovetz , 1992 ) ) We first describe the lextcal resources used m the study ( Hector , WordNet , other dicUonanes , and a lex~cal knowledge base ) , first characterizing them in terms ofpolysemy and the types of leracal mformaUon each contmns ( syntacUc properties and features , semantac components and relaUons , and collocaUonal properties ) We then present results of perfornung the word overlap analysis of the 18 verbs used m Senseval , analyzing the definitions m WordNet and Hector We then expand our analysis to include other dictionaries We describe our methods of analysis , particularly the methods of parsing defimtaons and identff ) qng semantic relations ( semrels ) based on defimng patterns , essentially takang first steps m Implementing the program described by Atkms and focusmg on the use of '' meamng '' full mformataon rather than statistical mformaUon We identify the results that have been achieved thus far and outline further steps that may add more `` meanmg '' to the analysis IAll analyses described m this paper were performed automatically using functlonahty incorporated m DIMAP ( Dictionary Maintenance Programs ) ( available for immediate download at ( CL Research , 1999a ) ) This includes automatac extracuon of WordNet reformation for the selected words ( mtegrated m DIMAP ) Hector defimtlons were uploaded into DIMAP dicUonanes after use of a conversmn program Defimtlons for other 30 The Lexical Resources Tlus analysis focuses on the mmn verb senses used In Senseval ( not ichoms and phrases ) , specifically the followmg AMAZE , BAND , BET , BOTHER , BURY , CALCULATE , CONSUME , DERIVE , FLOAT , HURDLE , INVADE , PROMISE , SACK , SANCTION , SCRAP , SEIZE , SHAKE , SLIGHT The Hector database used In Senseval consists of a tree of senses , each of which contains defimttons , syntactic properties , example usages , and `` clues '' ( collocational information about the syntactic and semantic enwronment in wluch a word appears in the spectfic sense ) The WordNet database contmns synonyms ( synsets ) , perhaps a defimtton or example usages ( gloss ) , some syntactic mformaUon ( verb frames ) , hypernyms , hyponyms , and some other semrels ( ENTAILS , CAUSES ) To extend our analysis In order to look at other issues of lexacal resource comparison , we have included the defirauons or leracal information from the following additional sources • Webster 's 3 ra New International Dictionary ( W3 ) • Oxford Advanced l.earners D~ctlonary ( OALD ) • American Hentage DlcUonary ( AI-ID ) • Dorr 's Lexacal Knowledge Base ( Dorr ) We used only the defimuons from W3 , OALD , and AHD ( which also contmn sample usages and some collocattonal information m the form of usage notes , not used at the present tame ) Dorr 's database contains thematic grids wluch characterize the thematic roles of obligatory and optional semanuc components , frequently identifying accompanying preposmons ( Olsen , et al , 1998 ) The following table identities the number of senses and average overall polysemy for each of these resources dictionaries were entered by hand Word amaze band bet bother bury calculate consume denve float hurdle invade pronuse sack sanction scrap seize shake shght Average Polysemy o o o 1 2 4 2 3 1 II 4 4 2 5 5 7 6 9 7 12 6 14 5 5 5 10 9 6 6 8 8 6 5 15 5 16 4 41 14 2 1 4 3 6 2 10 5 5 4 7 4 4 4 6 3 2 2 5 2 3 1 3 3 11 6 21 13 8 8 37 17 1 1 6 3 O 1 2 2 4 1 3 4 4 8 1 3 1 3 1 3 2 10 5 1 0 3 1 3 2 2 0 1 1 1 0 7 1 7 12 I 0 57 37 120 62 34 22 Word Overlap Analysis We first estabhsh a baseline for automatic replication of the lexicographer 's mappmg from WordNet 1 6 to Hector , using a s~mple word overlap analysis smular to ( Lesk , 1986 ) The lextcographer mapped the 66 WordNet senses ( each synset m which a test occurred ) Into 102 Hector senses A total of 86 assignments were made , 9 WordNet senses were gwen no assignments , 40 recewed exactly one , and 17 senses received 2 or 3 asssgnments The WordNet senses contained 348 words ( about half of wluch were common words appeanng on our stop list , which contained 165 words , mostly preposmons , pronouns , and conjunctions ) The Hector senses selected m the word overlap analysis contained about 960 words ( all Hector senses contained 1878 words ) We performed a strict word overlap analysts ( with and wsthout a stop hst ) between tile definlUons in WordNet and the Hector senses , that is , we did not attempt to ldenttfy root forms of Inflected words We took each word m a WordNet sense and determined whether ~t appeared in a Hector sense , we selected a Hector sense based on the highest percentage of words over all Hector senses An 31 empty selection was made ff all the words in the WordNet sense did not appear in any Hector sense , only content words were considered when the stop hst was used For example , for bet , WordNet sense 2 ( stake ( money ) on the outcome of an issue ) mapped into Hector sense 4 ( ( of a person ) to risk ( a sum of money or property ) m thts way ) In this case , there was an overlap on two words ( money , 039 in the Hector defimtlon ( 0 13 of its 15 words ) without the stop list When the stop list was invoked , there was an overlap of only one word ( money , 0 07 of the Hector defimtion ) In this case , the lexicographer had made three assignments ( Hector senses 2 , 3 , and 4 ) , our scoring method treated flus as only 1 out of 3 correct ( not using the relaxed method employed in Senseval of treating flus as completely correct ) Without the stop hst , our selections matched the lexicographer 's in 28 of 86 cases ( 32 6 % ) , using the stop list , we were successful in 31 of 86 cases ( 36 1 % ) The improvement arising when the stop list was used is deceptive , where 8 cases were due to empty assignments ( so that only 23 cases , 26 7 % , were due to matching content words ) Overall , only 41 content words were involved in these 23 successes when the stop list was used , an average of I 8 content words To summanze the word overlap analysis ( 1 ) despite a ncher set of defimtions in Hector , 9 of 66 WordNet senses ( 13 6 % ) could not be assigned , ( 2 ) despite the greater detail in Hector senses compared to WordNet senses ( 2 8 times as many words ) , only 1 8 content words participated in the assignments , and ( 3 ) therefore , the defimng vocabulary between these two definition sets seems to be somewhat divergent Although it might appear as if the word overlap analysis does not perform well , this is not the case The analysis provides a broad overview of the defimuon companson process between two definmon sets and frames a deeper analysis of the differences Moreover , it appears that the accuracy of a `` gold standard '' mapping is not crucially important The quality of the mapping may help frame the subsequent analysis more precisely , but it seems sufficient that any reasonable mapping will suffice This will be discussed further after presenting the results of the componentlal analysis of the defimtlons 32 Meaning-Full Analysis of Definitions The deeper analysis of the mapping between two defimtion sets relies primarily on two major steps ( 1 ) parsing definitions and using defimng patterns to identify semrels present m the definitions and ( 2 ) relaxing values to these relations by allowing `` synonymic '' substitution ( using WordNet ) Thus , for example , ffwe identify hypernyms or instruments from parsing a defimtion , we would say that the defimtions are `` equal '' not just ffthe hypernym or instrument is the same word , but also Lf the hypernyms or instruments are members of the same synset This approach is based on the finding ( Litkowski , 1978 ) that a dictionary induces a semantic network where nodes represent `` concepts '' that may be lexicahzed and verbalized in more than one way This finding implies , in general , the absence of true synonyms , and instead the kind of `` concept '' embodied in WordNet synsets ( with several lexical items and phraseologles ) A slmdar approach , parsing defimtlons and relaxing semrel values , was followed in ( Dolan , 1994 ) for clnstenng related senses w~thin a single dictionary The ideal toward which this approach strives is a complete identification of the meamng components included in a defimtion The meaning components can include syntactic features and charactenstlcs ( including subcategonzation patterns ) , semantm components ( realized through identification of semrels ) , selectional restrictions , and coUocational specifications The first stage of the analysis parses the definitions ( CL Research , 1999b , Litkowski , to appear ) and uses the parse results to extract ( via defining patterns ) semrels Since definitions have many idiosyncrasies ( that do not follow ordinary text ) , an important first step in this stage is preprocessmg the definition text to put it into a sentence frame that facilitates the extraction of semrels 2 2Note that the stop hst is not applicable to the definition parsing The parser is a full-scale sentence parser , where prepositmns and other words on the stop list are necessary for successful parsing Moreover , inclusion of the prepositions is cmcml to the method , since they are the bearers of much semrel information The extractmn of semrels examines the parse results , a e , a tree whose mtermedaate nodes represent non-ternunals and whose leaves represent the lextcal atems that compnse the defimuons , where any node may also include annotations such as characterizations of number and tense For all noun or verb defimttons , flus includes Identification of the head noun ( with recogmtton of '' empty '' heads ) or verb , for verbs , we signal whether the defimtaon contmned any selecttonal restnctmus ( that as , pamcular parenthesazed expressaons ) for the subject and object We then exanune preposattonal phrases In the defimUon and deterrmne whether we have a `` defining pattern '' for the preposaUon whach we can use as mdacaUve of a partacular semrel We also identify adverbs m the parse tree and look these up in WordNet to adentffy an adjecuve synset from wluch they are derived ( if one is gwen ) The defimng pattems are actually part of the dictionary used by the parser That is , we do not have to develop specafic routines to look for specLfic patterns A defimng pattern ~s a regular expressaon that arlaculates a syntactac pattern to be matched Thus , to recograze a `` manner '' semrel , we have the foUowmg entry for `` m '' m ( dpat ( ( ~ rep0 l ( det ( 0 ) ) adj manner ( 0 ) st ( manner ) ) ) ) This allows us to recognize `` m '' as possibly gwmg rise to a `` manner '' component , where we recogmze `` m '' ( the tdde , which allows us to specify partacular elements before the `` m '' as well ) , vath a noun phrase that consasts of 0 or 1 determiner , an adjectwe , and the lateral `` manner '' The '0 ° after the detenmner and the hteral mdacate that these words are not copied into the value for a `` manner '' role , so that the value to the `` manner '' semrel becomes only the adjectwe that as recogmzed The second stage of the analysis uses the populated lexacal database to compare senses and make the selectaons This process follows the general methodology used m Senseval ( Lltkowska , to appear ) Specifically , m the defimtaon comparison , we first exanune exclusaon cntena to rule out specific mappings These criteria include syntacUc properUes ( e g , a verb sense that Is only transluve can not map into one that Is only mtransRave ) and collocataonal propertaes ( e g , a sense that is used with a parUcle can not map into one that uses a different particle ) At the present tune , these are used only rmmmally 33 We next score each viable sense based on rots semrels We increment the score ff the senses have a common hypernym or If a sense 's hypernyms belong • to the same synset as the other sense 's hypernyms If a parUcular sense con~ns a large number of synonyms ( that as , no differentiae on the hypernym ) and they overlap consaderably m the synsets they evoke , the score can be increased substanUally Currently , we add 5 points for each match 3 We increment the score based on common semrels In tins amtml tmplementaUon , we have defimng patterns ( usually qmte nummal ) for recogmzmg Instrument , means , location , purpose , source , manner , has-constituents , has-members , is-part-of , locale , and goal 4 We Increment the score by 2 points when we have a common semrel and then by another 5 points when the value Is ~dentacal or m the same synset After all possable increments to the scores have been made , we then select the sense ( s ) w~th the lughest score Finally , we compare our selecuon with that of the gold standard to assess our mapping over all senses Another way an wluch our methodology follows the Senseval process as that at proceeds incrementally Thus , ~t ms not necessary to have a `` final '' perfect parse and mapping rouUne We can make conUnual refinements at any stage of the process and exarmne the overall effect As m Senseval , we may make changes to deal wath a particular phenomenon with the result that overall performance dechnes , but w~th a sounder basis for making subsequent amprovements Results of Componential Analysis The `` gold standard '' analysis Involves mapping 66 WordNet senses with 348 words into 102 Hector senses with 1878 words Using the method described above , we obtained 35 out of 86 correct 3At the present tame , we use WordNet to adentffy semreis We envaslon usmg the full semanlac network created by parsing all a dlcUonary 's defimtaons Thas would include a richer set of semrels than currently included m WordNet 4The defimng patterns are developed by hand We have onlyJust begun this effort , so the current set ms somewhat Impoverished mappmgs ( 407 % ) , a shght improvement over the 31 correct assignments usmg the stop-last word overlap techmque However , as mentioned above , the stophst techmque had aclueved 8 of its successes by matclung null assignments Consadered on tlus basins , ~t seems that the componentaal analysis techmque provides substantial ~mprovement In addition , our technique `` erred '' on 4 cases by malang assagnments where none were made by the leracographer We suggest that these cases do con~n some common elements of meaning and may conceivably not be construed as errors The mapping from WordNet to Hector had relatavely few empty mappings , senses for wtuch It was not possable to make an assignment These are the cases where at appears that the chetmnanes do not overlap and thus prowde a tentative mdacataon of where two dictionaries may have different coverage The cases of multiple assignments mchcate the degree ofamblgmty m the mapping The average m both darecUons between Hector and WordNet were donunated by the mabdaty to obtain good dascnnunatton for the word `` semze '' Thus , tlus method identifies individual words where the &amp; scnnunatwe ablhty needs to be further refined • Perhaps more importantly , the componentml analysis method exploits consaderably more WordNet Hector • mformauon than the word overlap methods Whereas the stop-hst word overlap mapping was • based on only 41 content words , the componenual ~ approach ( In the selected mappings ) had 228 hits in ~ .</sentence>
				<definiendum id="0">gold standard</definiendum>
				<definiendum id="1">instrument</definiendum>
				<definiens id="0">a word overlap analysis ( with and without a stop list ) for flus mapping , achieving at most a 36 percent correct mapping ( inflated by 9 percent from `` empty '' assignments ) An alternaUve componenttal analysis of the defimtaons , using syntacUc , collocatmnal , and semantac component and relation identification ( through the use ofdefimng patterns integrated seamlessly mto the parsing thclaonary ) , provides an almost 41 percent correct mapping , with an additaonal 4 percent by recogmzmg semantic components not used in the Senseval mapping Defimtion sets of the Senseval words from three pubhshed thclaonanes and Dorr 's lextcal knowledge base were added to WordNet and the Hector database to exanune the nature of the mapping process between defimtton sets of more and less sco\ [ ~e The tecbauques described here consUtute only an maaal implementation of the componenUal analysis approach and suggests that considerable further improvements can be aclueved Introduction The difficulty of companng lemcal resources , long a s~gnfficant challenge in computauonal hnguistlcs ( Atlans , 1991 ) , came to the fore in the recent Senseval competatton ( IOlgarnff , 1998 ) , when some systems that relied heavily on the WordNet ( Miller , et al , 1990 ) sense inventory were faced with the necessity of using another sense inventory ( Hecto0 A hasty solutaon to the problem was the `` development of a map between the two inventories , but some part~cipants expressed concerns that use of flus map may have degraded their performance to an unknown degree Although there were disclaimers about the WordNet-Hector map , it nonetheless stands as a usable gold standard for efforts to compare lexical resources Moreover , we have a usable baseline ( a word overlap method suggested m ( Lesk , 1986 ) ) against which to compare whether we are able to make improvements m the mapping ( since flus method has been shown to perform not as well as expected ( Krovetz , 1992 ) ) We first describe the lextcal resources used m the study ( Hector , WordNet , other dicUonanes , and a lex~cal knowledge base ) , first characterizing them in terms ofpolysemy and the types of leracal mformaUon each contmns ( syntacUc properties and features , semantac components and relaUons , and collocaUonal properties ) We then present results of perfornung the word overlap analysis of the 18 verbs used m Senseval , analyzing the definitions m WordNet and Hector We then expand our analysis to include other dictionaries We describe our methods of analysis , particularly the methods of parsing defimtaons and identff ) qng semantic relations ( semrels ) based on defimng patterns , essentially takang first steps m Implementing the program described by Atkms and focusmg on the use of '' meamng '' full mformataon rather than statistical mformaUon We identify the results that have been achieved thus far and outline further steps that may add more `` meanmg '' to the analysis IAll analyses described m this paper were performed automatically using functlonahty incorporated m DIMAP ( Dictionary Maintenance Programs ) ( available for immediate download at ( CL Research , 1999a ) ) This includes automatac extracuon of WordNet reformation for the selected words ( mtegrated m DIMAP ) Hector defimtlons were uploaded into DIMAP dicUonanes after use of a conversmn program Defimtlons for other 30 The Lexical Resources Tlus analysis focuses on the mmn verb senses used In Senseval ( not ichoms and phrases ) , specifically the followmg AMAZE , BAND , BET , BOTHER , BURY , CALCULATE , CONSUME , DERIVE , FLOAT , HURDLE , INVADE , PROMISE , SACK , SANCTION , SCRAP , SEIZE , SHAKE , SLIGHT The Hector database used In Senseval consists of a tree of senses , each of which contains defimttons , syntactic properties , example usages , and `` clues '' ( collocational information about the syntactic and semantic enwronment in wluch a word appears in the spectfic sense ) The WordNet database contmns synonyms ( synsets ) , perhaps a defimtton or example usages ( gloss ) , some syntactic mformaUon ( verb frames ) , hypernyms , hyponyms , and some other semrels ( ENTAILS</definiens>
				<definiens id="1">included the defirauons or leracal information from the following additional sources • Webster 's 3 ra New International Dictionary ( W3 ) • Oxford Advanced l.earners D~ctlonary ( OALD ) • American Hentage DlcUonary ( AI-ID ) • Dorr 's Lexacal Knowledge Base ( Dorr ) We used only the defimuons from W3 , OALD , and AHD ( which also contmn sample usages and some collocattonal information m the form of usage notes , not used at the present tame ) Dorr 's database contains thematic grids wluch characterize the thematic roles of obligatory and optional semanuc components , frequently identifying accompanying preposmons ( Olsen , et al , 1998 ) The following table identities the number of senses and average overall polysemy for each of these resources dictionaries were entered by hand Word amaze band bet bother bury calculate consume denve float hurdle invade pronuse sack sanction scrap seize shake shght Average Polysemy o o o 1</definiens>
				<definiens id="2">I 0 57 37 120 62 34 22 Word Overlap Analysis We first estabhsh a baseline for automatic replication of the lexicographer 's mappmg from WordNet 1 6 to Hector , using a s~mple word overlap analysis smular to ( Lesk , 1986 ) The lextcographer mapped the 66 WordNet senses ( each synset m which a test occurred ) Into 102 Hector senses A total of 86 assignments were made , 9 WordNet senses were gwen no assignments , 40 recewed exactly one , and 17 senses received 2 or 3 asssgnments The WordNet senses contained 348 words ( about half of wluch were common words appeanng on our stop list , which contained 165 words , mostly preposmons , pronouns , and conjunctions ) The Hector senses selected m the word overlap analysis contained about 960 words ( all Hector senses contained 1878 words ) We performed a strict word overlap analysts ( with and wsthout a stop hst ) between tile definlUons in WordNet and the Hector senses , that is , we did not attempt to ldenttfy root forms of Inflected words We took each word m a WordNet sense and determined whether ~t appeared in a Hector sense , we selected a Hector sense based on the highest percentage of words over all Hector senses An 31 empty selection was made ff all the words in the WordNet sense did not appear in any Hector sense , only content words were considered when the stop hst was used For example , for bet , WordNet sense 2 ( stake ( money ) on the outcome of an issue ) mapped into Hector sense 4 ( ( of a person ) to risk ( a sum of money or property ) m thts way ) In this case , there was an overlap on two words ( money , 039 in the Hector defimtlon ( 0 13 of its 15 words ) without the stop list When the stop list was invoked , there was an overlap of only one word ( money , 0 07 of the Hector defimtion ) In this case , the lexicographer had made three assignments ( Hector senses 2 , 3 , and 4 ) , our scoring method treated flus as only 1 out of 3 correct ( not using the relaxed method employed in Senseval of treating flus as completely correct ) Without the stop hst , our selections matched the lexicographer 's in 28 of 86 cases ( 32 6 % ) , using the stop list , we were successful in 31 of 86 cases ( 36 1 % ) The improvement arising when the stop list was used is deceptive , where 8 cases were due to empty assignments ( so that only 23 cases , 26 7 % , were due to matching content words ) Overall , only 41 content words were involved in these 23 successes when the stop list was used , an average of I 8 content words To summanze the word overlap analysis ( 1 ) despite a ncher set of defimtions in Hector , 9 of 66 WordNet senses ( 13 6 % ) could not be assigned , ( 2 ) despite the greater detail in Hector senses compared to WordNet senses ( 2 8 times as many words ) , only 1 8 content words participated in the assignments , and ( 3 ) therefore , the defimng vocabulary between these two definition sets seems to be somewhat divergent Although it might appear as if the word overlap analysis does not perform well , this is not the case The analysis provides a broad overview of the defimuon companson process between two definmon sets and frames a deeper analysis of the differences Moreover , it appears that the accuracy of a `` gold standard '' mapping is not crucially important The quality of the mapping may help frame the subsequent analysis more precisely , but it seems sufficient that any reasonable mapping will suffice This will be discussed further after presenting the results of the componentlal analysis of the defimtlons 32 Meaning-Full Analysis of Definitions The deeper analysis of the mapping between two defimtion sets relies primarily on two major steps ( 1 ) parsing definitions and using defimng patterns to identify semrels present m the definitions and ( 2 ) relaxing values to these relations by allowing `` synonymic '' substitution ( using WordNet ) Thus , for example , ffwe identify hypernyms or instruments from parsing a defimtion</definiens>
				<definiens id="3">the same word , but also Lf the hypernyms or instruments are members of the same synset This approach is based on the finding ( Litkowski , 1978 ) that a dictionary induces a semantic network where nodes represent `` concepts '' that may be lexicahzed and verbalized in more than one way This finding implies , in general , the absence of true synonyms , and instead the kind of `` concept '' embodied in WordNet synsets ( with several lexical items and phraseologles ) A slmdar approach , parsing defimtlons and relaxing semrel values , was followed in ( Dolan , 1994 ) for clnstenng related senses w~thin a single dictionary The ideal toward which this approach strives is a complete identification of the meamng components included in a defimtion The meaning components can include syntactic features and charactenstlcs ( including subcategonzation patterns ) , semantm components ( realized through identification of semrels ) , selectional restrictions , and coUocational specifications The first stage of the analysis parses the definitions ( CL Research , 1999b , Litkowski , to appear ) and uses the parse results to extract ( via defining patterns ) semrels Since definitions have many idiosyncrasies ( that do not follow ordinary text ) , an important first step in this stage is preprocessmg the definition text to put it into a sentence frame that facilitates the extraction of semrels 2 2Note that the stop hst is not applicable to the definition parsing The parser is a full-scale sentence parser , where prepositmns and other words on the stop list are necessary for successful parsing Moreover , inclusion of the prepositions is cmcml to the method , since they are the bearers of much semrel information The extractmn of semrels examines the parse results , a e , a tree whose mtermedaate nodes represent non-ternunals and whose leaves represent the lextcal atems that compnse the defimuons , where any node may also include annotations such as characterizations of number and tense For all noun or verb defimttons , flus includes Identification of the head noun ( with recogmtton of '' empty '' heads ) or verb , for verbs , we signal whether the defimtaon contmned any selecttonal restnctmus ( that as , pamcular parenthesazed expressaons ) for the subject and object We then exanune preposattonal phrases In the defimUon and deterrmne whether we have a `` defining pattern '' for the preposaUon whach we can use as mdacaUve of a partacular semrel We also identify adverbs m the parse tree and look these up in WordNet to adentffy an adjecuve synset from wluch they are derived ( if one is gwen ) The defimng pattems are actually part of the dictionary used by the parser That is , we do not have to develop specafic routines to look for specLfic patterns A defimng pattern ~s a regular expressaon that arlaculates a syntactac pattern to be matched Thus , to recograze a `` manner '' semrel</definiens>
				<definiens id="4">dpat ( ( ~ rep0 l ( det ( 0 ) ) adj manner ( 0 ) st ( manner ) ) ) ) This allows us to recognize `` m '' as possibly gwmg rise to a `` manner '' component</definiens>
				<definiens id="5">allows us to specify partacular elements before the `` m '' as well ) , vath a noun phrase that consasts of 0 or 1 determiner , an adjectwe , and the lateral `` manner '' The '0 ° after the detenmner and the hteral mdacate that these words are not copied into the value for a `` manner '' role , so that the value to the `` manner '' semrel becomes only the adjectwe that as recogmzed The second stage of the analysis uses the populated lexacal database to compare senses and make the selectaons This process follows the general methodology used m Senseval ( Lltkowska , to appear ) Specifically , m the defimtaon comparison , we first exanune exclusaon cntena to rule out specific mappings These criteria include syntacUc properUes ( e g , a verb sense that Is only transluve can not map into one that Is only mtransRave ) and collocataonal propertaes ( e g , a sense that is used with a parUcle can not map into one that uses a different particle ) At the present tune , these are used only rmmmally 33 We next score each viable sense based on rots semrels We increment the score ff the senses have a common hypernym or If a sense 's hypernyms belong • to the same synset as the other sense 's hypernyms If a parUcular sense con~ns a large number of synonyms ( that as , no differentiae on the hypernym ) and they overlap consaderably m the synsets they evoke , the score can be increased substanUally Currently , we add 5 points for each match 3 We increment the score based on common semrels In tins amtml tmplementaUon , we have defimng patterns ( usually qmte nummal ) for recogmzmg Instrument , means , location , purpose , source , manner , has-constituents , has-members , is-part-of , locale , and goal 4 We Increment the score by 2 points when we have a common semrel and then by another 5 points when the value Is ~dentacal or m the same synset After all possable increments to the scores have been made</definiens>
				<definiens id="6">over all senses Another way an wluch our methodology follows the Senseval process as that at proceeds incrementally Thus , ~t ms not necessary to have a `` final '' perfect parse and mapping rouUne We can make conUnual refinements at any stage of the process and exarmne the overall effect As m Senseval , we may make changes to deal wath a particular phenomenon with the result that overall performance dechnes , but w~th a sounder basis for making subsequent amprovements Results of Componential Analysis The `` gold standard '' analysis Involves mapping 66 WordNet senses with 348 words into 102 Hector senses with 1878 words Using the method described above</definiens>
				<definiens id="7">the full semanlac network created by parsing all a dlcUonary 's defimtaons Thas would include a richer set of semrels than currently included m WordNet 4The defimng patterns are developed by hand We have onlyJust begun this effort , so the current set ms somewhat Impoverished mappmgs ( 407 % ) , a shght improvement over the 31 correct assignments usmg the stop-last word overlap techmque However , as mentioned above , the stophst techmque had aclueved 8 of its successes by matclung null assignments Consadered on tlus basins , ~t seems that the componentaal analysis techmque provides substantial ~mprovement In addition , our technique `` erred '' on 4 cases by malang assagnments where none were made by the leracographer We suggest that these cases do con~n some common elements of meaning and may conceivably not be construed as errors The mapping from WordNet to Hector had relatavely few empty mappings , senses for wtuch It was not possable to make an assignment These are the cases where at appears that the chetmnanes do not overlap and thus prowde a tentative mdacataon of where two dictionaries may have different coverage The cases of multiple assignments mchcate the degree ofamblgmty m the mapping The average m both darecUons between Hector and WordNet were donunated by the mabdaty to obtain good dascnnunatton for the word `` semze '' Thus , tlus method identifies individual words where the &amp; scnnunatwe ablhty needs to be further refined • Perhaps more importantly , the componentml analysis method exploits consaderably more WordNet Hector • mformauon than the word overlap methods Whereas the stop-hst word overlap mapping was • based on only 41 content words , the componenual ~ approach ( In the selected mappings ) had 228 hits in ~</definiens>
			</definition>
</paper>

		<paper id="0111">
			<definition id="0">
				<sentence>e~ , rsl ( ~E ( ~en~red ( ~ , 5 ) km ( ~ ) ) ) ) ~ ( V , ~ ) ~ ( D , ~ie= , , e1 ( ~ ( =a~ ( F , 5 ) ~ ( F ) ) ) ) This =contains a reference to a centred time before speech time : , 'e l ( AC ( , ~ , -~ , ,~ ( c ) ) ) &gt; B ) ) ~The~z s~re fiuther cases of cataphors which we do n't attempt to deal with here .</sentence>
				<definiendum id="0">~E</definiendum>
				<definiens id="0">a reference to a centred time before speech time : , 'e l ( AC ( , ~ , -~ , ,~ ( c ) ) ) &gt; B )</definiens>
			</definition>
</paper>

		<paper id="0707">
			<definition id="0">
				<sentence>The unique property of memory-based approaches which sets them apart from other learning methods is the fact that they are lazy learners : they keep all training data available for extrapolation .</sentence>
				<definiendum id="0">memory-based approaches</definiendum>
				<definiens id="0">the fact that they are lazy learners : they keep all training data available for extrapolation</definiens>
			</definition>
			<definition id="1">
				<sentence>Memory-Based Shallow Syntactic Analysis Memory-Based Learning ( MBL ) is a classificationbased , supervised learning approach : a nmmory-based learning algorithm constructs a classifier for a task by storing a set of examples .</sentence>
				<definiendum id="0">Memory-Based Shallow Syntactic Analysis Memory-Based Learning ( MBL )</definiendum>
				<definiens id="0">a classificationbased , supervised learning approach : a nmmory-based learning algorithm constructs a classifier for a task by storing a set of examples</definiens>
			</definition>
			<definition id="2">
				<sentence>Many test instances contain a word not occurring in the training instances ( in that feature ) .</sentence>
				<definiendum id="0">Many test instances</definiendum>
				<definiens id="0">contain a word not occurring in the training instances</definiens>
			</definition>
			<definition id="3">
				<sentence>A tile is defined as a substring of the situated hypothesis containing a bracket , and the score of a tile depends on the number of times it is found in the training material divided by the total number of times the string of tags occurs ( i.e. including occurrences with another or no bracket ) .</sentence>
				<definiendum id="0">tile</definiendum>
				<definiens id="0">a substring of the situated hypothesis containing a bracket , and the score of a tile depends on the number of times it is found in the training material divided by the total number of times the string of tags occurs ( i.e. including occurrences with another or no bracket )</definiens>
			</definition>
			<definition id="4">
				<sentence>More importantly , MBL is more flexible in the definition of the shallow parsingtasks : it allows nested relations to be detected ; it allows the addition and integration into the task of various additional sources of information apart from POS tags ; it can segment a tagged sentence into different types of constituent chunks in one pass ; it can scan a chunked sentence for different relation types in one pass ( though separating subject-verb detection from object-verb detection is surely an option that must be investigated ) .</sentence>
				<definiendum id="0">MBL</definiendum>
				<definiens id="0">various additional sources of information apart from POS tags ; it can segment a tagged sentence into different types of constituent chunks in one pass ; it can scan a chunked sentence for different relation types in one pass</definiens>
			</definition>
			<definition id="5">
				<sentence>MBT : A memory-based part of speech tagger generator .</sentence>
				<definiendum id="0">MBT</definiendum>
				<definiens id="0">A memory-based part of speech tagger generator</definiens>
			</definition>
</paper>

		<paper id="0107">
			<definition id="0">
				<sentence>To examine the phenomenon of reference in discourse , and to analyze how discourse structure and reference interact , we need a tool , which allows several kinds of functionality including mark-up , visualization , and evaluation .</sentence>
				<definiendum id="0">tool</definiendum>
				<definiens id="0">allows several kinds of functionality including mark-up , visualization , and evaluation</definiens>
			</definition>
			<definition id="1">
				<sentence>Drawing on the feature sets used in Connolly et al. ( 1997 ) and Ge et al. ( 1998 ) , we believe the following factors might indicate co-referenco : • Syntactic role ( e.g. Subject , Object , Prepositional Object , ... ) , • Pronominalization ( yea or no ) , • Distance between EA and Ee ( an integer ) , • Definiteness ( yes or no ) , • Semantic role ( e.g. indicating location , manner , time , ... ) , • Nesting depth of an N'P ( an integer ) , • Information status ( as defined by Strube ( 1998 ) ) of the DE , • Gender , Number , Animacy .</sentence>
				<definiendum id="0">Information status</definiendum>
				<definiens id="0">Drawing on the feature sets used in Connolly et al. ( 1997 ) and Ge</definiens>
				<definiens id="1">Syntactic role ( e.g. Subject , Object , Prepositional Object , ... ) , • Pronominalization ( yea or no ) , • Distance between EA and Ee ( an integer ) , • Definiteness ( yes or no ) , • Semantic role ( e.g. indicating location , manner , time , ... ) , • Nesting depth of an N'P ( an integer</definiens>
			</definition>
			<definition id="2">
				<sentence>Dale suggests the principlea of efficiency and adequacy which favor generating the smallest referring expression that distinguishes the object in question from all others in the context .</sentence>
				<definiendum id="0">Dale</definiendum>
				<definiens id="0">suggests the principlea of efficiency and adequacy which favor generating the smallest referring expression that distinguishes the object in question from all others in the context</definiens>
			</definition>
			<definition id="3">
				<sentence>56 0 6 0 0 0 0 0 0 0 0 e 0 0 0 0 I 0 0 0 6 0 0 0 0 0 0 0 0 0 @ 0 0 0 0 0 0 0 O e 0 0 0 e o e @ e O @ @ e e e @ e , @ e @ @ @ e @ 0 e @ @ @ @ @ @ @ e e e e e e e @ e @ o @ _e @ In this context , a markable is a text span representing a discourse entity which can be anaphoricaily referred to in a text or dialog .</sentence>
				<definiendum id="0">markable</definiendum>
				<definiens id="0">a text span representing a discourse entity which can be anaphoricaily referred to in a text or dialog</definiens>
			</definition>
			<definition id="4">
				<sentence>To avoid finding such undesirable NP 's , our system has a heuristic ( HI ) which says : Pass overan~NP which is a leftmost child of a top-level NP .</sentence>
				<definiendum id="0">Pass overan~NP</definiendum>
			</definition>
			<definition id="5">
				<sentence>A co-reference relation holds between A and B when A and B are expressions which both refer to the same discourse entity .</sentence>
				<definiendum id="0">co-reference relation</definiendum>
			</definition>
			<definition id="6">
				<sentence>N \ ] where c~ ( v , f ) is the number of times coder i assigned value v to feature f. Thus , if the coders have used the values in a perfectly even distribution among the IV I values , P ( E ) -\ [ ~ .</sentence>
				<definiendum id="0">c~</definiendum>
				<definiendum id="1">f )</definiendum>
				<definiendum id="2">P ( E</definiendum>
				<definiens id="0">the number of times coder i assigned value v to feature f. Thus , if the coders have used the values in a perfectly even distribution among the IV I values ,</definiens>
			</definition>
			<definition id="7">
				<sentence>n _ P ( E ) where P ( A ) is the proportion oftlmes the annotators agree and P ( E ) is the proportion of times the annotators are expected to agree by chance .</sentence>
				<definiendum id="0">P ( E )</definiendum>
				<definiens id="0">the proportion of times the annotators are expected to agree by chance</definiens>
			</definition>
			<definition id="8">
				<sentence>Easy visualization of the co-reference equivalence classes could aid the user as he clicks through the text and sees how the co-reference chains thread through discourse .</sentence>
				<definiendum id="0">Easy visualization of the co-reference equivalence classes</definiendum>
				<definiens id="0">aid the user as he clicks through the text and sees how the co-reference chains thread through discourse</definiens>
			</definition>
			<definition id="9">
				<sentence>Segment mode allows the user to break the text into arbitrarily nesting and overlapping segments .</sentence>
				<definiendum id="0">Segment mode</definiendum>
				<definiens id="0">allows the user to break the text into arbitrarily nesting and overlapping segments</definiens>
			</definition>
			<definition id="10">
				<sentence>Referee fills this niche , and greatly reduces the workload placed on the human users .</sentence>
				<definiendum id="0">Referee</definiendum>
				<definiens id="0">fills this niche , and greatly reduces the workload placed on the human users</definiens>
			</definition>
</paper>

		<paper id="0202">
			<definition id="0">
				<sentence>The tool used for comparing contexts , the Context Thesaurus ( CT ) , is a Talent tool that takes arbitrary text as input and returns a ranked list of terms that are related to the input text with respect to a given collection of documents .</sentence>
				<definiendum id="0">Context Thesaurus</definiendum>
				<definiens id="0">a Talent tool that takes arbitrary text as input and returns a ranked list of terms that are related to the input text with respect to a given collection of documents</definiens>
			</definition>
			<definition id="1">
				<sentence>v ... .i z 777 Figure 1 ( Context Thesaurus ) The CT works with a collection concordance , listing the collection contexts in which a particular canonical string occurs .</sentence>
				<definiendum id="0">CT</definiendum>
			</definition>
			<definition id="2">
				<sentence>The CT is an ordinary information retrieval document index -we use IBM 's Net-Question query system \ [ IBM99\ ] -which indexes special documents , referred to as `` pseudo documents '' ( Figure 1 ) .</sentence>
				<definiendum id="0">CT</definiendum>
				<definiens id="0">an ordinary information retrieval document index -we use IBM 's Net-Question query system</definiens>
			</definition>
			<definition id="3">
				<sentence>A pseudo document contains collection contexts in which a particular canonical string occurs .</sentence>
				<definiendum id="0">pseudo document</definiendum>
			</definition>
</paper>

		<paper id="0101">
			<definition id="0">
				<sentence>Example HI involves a contextually determined domain restriction , with a quantificationai determiner every , innstrating that domain restriction must be handled in a ~imilar way for a broader class of expressions than those which are normally regarded as rderring expr_~-_qjons or presupposition triggers .</sentence>
				<definiendum id="0">Example HI</definiendum>
				<definiens id="0">involves a contextually determined domain restriction , with a quantificationai determiner every</definiens>
			</definition>
			<definition id="1">
				<sentence>Roberts defines the structure of a discourse at a given point , its Information Structure , as a tupie which includes ( among other things ) the ordered set of moves in the discourse ( M ) , CG , and the set of the questions currently under discussion at that point ( QUD ) .</sentence>
				<definiendum id="0">Information Structure</definiendum>
				<definiens id="0">a tupie which includes ( among other things ) the ordered set of moves in the discourse ( M ) , CG , and the set of the questions currently under discussion at that point</definiens>
			</definition>
			<definition id="2">
				<sentence>Weak famifiarity ( cf. the slightly different notion of familiarity in H_m'~ 1982 ) is the theoretical realization of anaphoricity , and is licensed by existential entailments of the common ground , not requiring an explicit NP antecedent or even perceptual salience of the intended referent : ( 2 ) Weak Familiarity : A discourse referent i is weakly familiar in a context C ( i E Domain ( C ) and C encodes the information that i has properties Pi ... . , Pk ) iff the Common Ground of C entails the existence of an entity with properties P~ , . . . , Pk .</sentence>
				<definiendum id="0">Weak famifiarity</definiendum>
			</definition>
			<definition id="3">
				<sentence>Pronouns carry an additional presuppomtion of maxima\ ] salience : ( 4 ) Presuppositions of Pronmmm ( informal ) : Given a context C , use of a pronoun Pros presuplz3ses that there is a discourse referent i in C which is the unique weakly familiar discourse referent that is both maximally salient and satisfies the descriptive content suggested by the person , number and gender of Proi .</sentence>
				<definiendum id="0">Pronouns</definiendum>
			</definition>
			<definition id="4">
				<sentence>goal of which is to produce a refined logical form ( CULF ) and a set of discourse referents ( CDRS ) by .</sentence>
				<definiendum id="0">CULF</definiendum>
				<definiendum id="1">CDRS</definiendum>
				<definiens id="0">to produce a refined logical form</definiens>
			</definition>
			<definition id="5">
				<sentence>While the Utterance LF ( ULF ) describes only the literal content of an utterance , the CULF , along with the CDRS , can be thought of as a record of what the utterance really means , in the context in which it is said .</sentence>
				<definiendum id="0">Utterance LF ( ULF</definiendum>
				<definiens id="0">the literal content of an utterance , the CULF , along with the CDRS , can be thought of as a record of what the utterance really means , in the context in which it is said</definiens>
			</definition>
			<definition id="6">
				<sentence>Salience is a partial ordering on this set determined primarily by two factors .</sentence>
				<definiendum id="0">Salience</definiendum>
				<definiens id="0">a partial ordering on this set determined primarily by two factors</definiens>
			</definition>
			<definition id="7">
				<sentence>Although definite descriptions can often be identified with antecedents from the CDRS in essentially the same way as pronouns ( since the set of CDRS is a subset of the CG Domain ) , they are not required to corder with a maximally salient discourse referent .</sentence>
				<definiendum id="0">CDRS</definiendum>
				<definiens id="0">a subset of the CG Domain</definiens>
			</definition>
			<definition id="8">
				<sentence>NS is a placeholder for the unspecified nuclear scope of the def operator .</sentence>
				<definiendum id="0">NS</definiendum>
				<definiens id="0">a placeholder for the unspecified nuclear scope of the def operator</definiens>
			</definition>
			<definition id="9">
				<sentence>NS is a placeholder for the , ,n~ecified nuclear scope of the def operator .</sentence>
				<definiendum id="0">NS</definiendum>
				<definiens id="0">a placeholder for the , ,n~ecified nuclear scope of the def operator</definiens>
			</definition>
			<definition id="10">
				<sentence>restriction produces the refined description ( DEF 3 '' ) : ( DP .</sentence>
				<definiendum id="0">restriction</definiendum>
			</definition>
			<definition id="11">
				<sentence>CULF ( NewExpr , Level ) if NewExpr is a generalized quanClfier , let SubsCLF = march , substitute ( QUD-CULF , resCricCion ( NevExpr ) , NewExpr ) else ( NewExpr iS a predicate ) let SubstLF ffi matchksubstiCute ( QUD-CULF , NevExpr , NevExpr ) if null ( SubstLF ) or SubstLF is not Snterpretable as a subquestion of ~ID-CULF , pop ( QUV ) else rectum ( SubsCLF , priorizy_union ( CDRSl , QUD-CDRS ) ) 7,7,7 , priority-union ( X , Y ) is like set un $ on , but vhen some members of X 7,7 , Y , and Y have the same type , only the member of X is included Sn the result. }</sentence>
				<definiendum id="0">resCricCion</definiendum>
				<definiens id="0">a generalized quanClfier</definiens>
			</definition>
			<definition id="12">
				<sentence>We have described an integrated approach to resolving presuppositions , which includes pronominal and definite reference resolution Central to our approach is the maintenance of discourse structures , especially the QUD stack , which captures the hierarchical organization of the discourse .</sentence>
				<definiendum id="0">QUD stack</definiendum>
				<definiens id="0">captures the hierarchical organization of the discourse</definiens>
			</definition>
</paper>

		<paper id="0113">
			<definition id="0">
				<sentence>Discourses consist of constituent segments and each segment is represented as part of a discourse model .</sentence>
				<definiendum id="0">Discourses</definiendum>
				<definiens id="0">consist of constituent segments and each segment is represented as part of a discourse model</definiens>
			</definition>
			<definition id="1">
				<sentence>D ) is a sp~l member of the C : , which represents the discourse entity that the utt~ance U most omtrally concermL ... The Ct entity links the current utterance to the previous discour~ ... ( or not more thaa one ) ... The set of I~01~WARDwoxmo cm~m~ .</sentence>
				<definiendum id="0">Ct entity</definiendum>
				<definiens id="0">a sp~l member of the C : , which represents the discourse entity that the</definiens>
			</definition>
			<definition id="2">
				<sentence>In particular , Dynamic Quantifier Logic , the anaphora resolution mechanism based on quantifier scope we are working with here , has been designed to provide the semantic machinery for the Linguistic Discourse Model ( LDM ) .</sentence>
				<definiendum id="0">Dynamic Quantifier Logic</definiendum>
			</definition>
			<definition id="3">
				<sentence>The LDM treats a discourse as a sequence of basic discourse units ( evue ) ranges of values for ~ might be more suitable , such as liar to DO~ we thank eae mmaymous revumer mr pomung out the work of Ranta ( 1991 ) , who 's use of Marthz-16Ps type theory , m~ atso be suttsble ts a~ anal3~t8 tool ela Prfmt , Scha and van den Berg 1991 , • resolution mechanJmn for unification based discourse grammar for verb phrase anaphom is defined , in terms of the Linguistic Discourse Model ( LDM ; PolanyJ and Scha 1984 ; .</sentence>
				<definiendum id="0">LDM</definiendum>
				<definiens id="0">treats a discourse as a sequence of basic discourse units ( evue ) ranges of values</definiens>
			</definition>
			<definition id="4">
				<sentence>The LDM is a compesitional framework .</sentence>
				<definiendum id="0">LDM</definiendum>
				<definiens id="0">a compesitional framework</definiens>
			</definition>
</paper>

		<paper id="0801">
</paper>

		<paper id="0500">
</paper>

		<paper id="0905">
			<definition id="0">
				<sentence>The context vector is the sum of every word vector within the context ( again , neighboring n words ) weighted by its idf score .</sentence>
				<definiendum id="0">context vector</definiendum>
				<definiens id="0">the sum of every word vector within the context ( again , neighboring n words ) weighted by its idf score</definiens>
			</definition>
			<definition id="1">
				<sentence>The WSD algorithm introduced in the previous section represents the sense of a given word , w , as a cluster of contexts ( i.e. , co-occurring words ) in the source language .</sentence>
				<definiendum id="0">WSD algorithm</definiendum>
				<definiens id="0">introduced in the previous section represents the sense of a given word , w , as a cluster of contexts ( i.e. , co-occurring words ) in the source language</definiens>
			</definition>
			<definition id="2">
				<sentence>extracted contexts , where tf-idf score of a word w is the frequency of w ( term frequency ) multiplied by the idf value defined by ( 3 ) in Section to 20 ) .</sentence>
				<definiendum id="0">tf-idf score of a word w</definiendum>
			</definition>
</paper>

		<paper id="0629">
			<definition id="0">
				<sentence>The GR assigner uses several sources of information step by step such as several types of XP chunks ( NP , VP , PP , ADJP and ADVP ) , and adverbial functions assigned to these chunks ( e.g. temporal , local ) .</sentence>
				<definiendum id="0">GR assigner</definiendum>
				<definiens id="0">uses several sources of information step by step such as several types of XP chunks ( NP , VP , PP , ADJP and ADVP ) , and adverbial functions assigned to these chunks ( e.g. temporal , local )</definiens>
			</definition>
			<definition id="1">
				<sentence>Memory-Based Learning ( MBL ) keeps all training data in memory and only abstracts at classification time by extrapolating a class from the most similar item ( s ) in memory .</sentence>
				<definiendum id="0">Memory-Based Learning ( MBL )</definiendum>
				<definiens id="0">keeps all training data in memory and only abstracts at classification time by extrapolating a class from the most similar item ( s ) in memory</definiens>
			</definition>
			<definition id="2">
				<sentence>The distance between a test item and each memory item is defined as the number of features for which they have a different value ( overlap metric ) .</sentence>
				<definiendum id="0">memory item</definiendum>
				<definiens id="0">The distance between a test item and each</definiens>
			</definition>
			<definition id="3">
				<sentence>Precision is the percentage of predicted chunks/relations that are actually correct , recall is the percentage of correct chunks/relations that are actually found .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">the percentage of correct chunks/relations that are actually found</definiens>
			</definition>
			<definition id="4">
				<sentence>MBT : A memory-based part of speech tagger generator .</sentence>
				<definiendum id="0">MBT</definiendum>
				<definiens id="0">A memory-based part of speech tagger generator</definiens>
			</definition>
</paper>

		<paper id="0635">
			<definition id="0">
				<sentence>Nominal compound analysis is one of crucial issues that have been continuously studied by computational and theoretical linguists .</sentence>
				<definiendum id="0">Nominal compound analysis</definiendum>
				<definiens id="0">one of crucial issues that have been continuously studied by computational and theoretical linguists</definiens>
			</definition>
			<definition id="1">
				<sentence>Then , the association degree of nl and n2 is defined as tbllows : ASSOCMH ( ni , n2 ) -1 ×Z freq ( ci , cj ) NMH .</sentence>
				<definiendum id="0">association degree of nl</definiendum>
				<definiendum id="1">n2</definiendum>
			</definition>
			<definition id="2">
				<sentence>Then , the parsing process can be defined as follows : h , ead ( n , : ) = 'at ( 3 ) l = index ( max ( Assoc ( ni , nj ) ) ) j=i+ l , ... , k Here index returns the index of noun nl whose association with ni is the maximum .</sentence>
				<definiendum id="0">parsing process</definiendum>
				<definiendum id="1">ni</definiendum>
				<definiens id="0">h , ead ( n , : ) = 'at ( 3 ) l = index ( max ( Assoc ( ni , nj ) ) ) j=i+ l , ... , k Here index returns the index of noun nl whose association with</definiens>
			</definition>
			<definition id="3">
				<sentence>, 'n,2 ) iI~ ( v , , , 'n : ~ ) /~ ( 'n2 , na ) MUSOG SIN'ANG JEONTONG ( ( nl n2 ) n3 ) MH MH ( private society , religion , tradition ) DAEJUNG MUNHWA BIPAN ( ( nl n2 ) n3 ) MH OBJ ( public , culture , criticism ) FRANCE KEUNDAE MUNHAG ( nl ( n2 n3 ) ) MH MH ( France , modern , literature ) .</sentence>
				<definiendum id="0">DAEJUNG MUNHWA BIPAN</definiendum>
				<definiens id="0">public , culture , criticism ) FRANCE KEUNDAE MUNHAG ( nl ( n2 n3 ) ) MH MH ( France , modern , literature )</definiens>
			</definition>
</paper>

		<paper id="0204">
			<definition id="0">
				<sentence>The GDA tagset is an XML ( eXtensible Markup Language ) tagset which allows machines to automatically infer the semantic structures ( including pragmatic structures ) underlying the raw documents .</sentence>
				<definiendum id="0">GDA tagset</definiendum>
				<definiens id="0">an XML ( eXtensible Markup Language ) tagset which allows machines to automatically infer the semantic structures ( including pragmatic structures ) underlying the raw documents</definiens>
			</definition>
			<definition id="1">
				<sentence>The cost involved here pays , because an annotated document is a generic form of information content from which to compose diverse types of presentations , potentially involving summarization , narration , visualization , translation , information retrieval , information extraction , and so forth .</sentence>
				<definiendum id="0">annotated document</definiendum>
				<definiens id="0">a generic form of information content from which to compose diverse types of presentations , potentially involving summarization , narration , visualization , translation , information retrieval , information extraction</definiens>
			</definition>
			<definition id="2">
				<sentence>GDA is a project to make WWW texts machineunderstandable on the basis of a. linguistic tag set , and to develop applications such as content-based presentation , retrieval , question-answering , summarization , and translation with much higher quality than before .</sentence>
				<definiendum id="0">GDA</definiendum>
				<definiens id="0">a project to make WWW texts machineunderstandable on the basis of a. linguistic tag set , and to develop applications such as content-based presentation , retrieval , question-answering , summarization</definiens>
			</definition>
			<definition id="3">
				<sentence>As the primary purpose of GDA tagging is to encode semantic structure , syntactic annotation is exploited only as far as it contributes to semantic encoding .</sentence>
				<definiendum id="0">GDA tagging</definiendum>
				<definiens id="0">to encode semantic structure , syntactic annotation is exploited only as far as it contributes to semantic encoding</definiens>
			</definition>
			<definition id="4">
				<sentence>Its value represents a binary relation , which may be a grammatical function such as SUBJECT , a thematic role such as AGENT , PATIENT , RECIPIENT , or a rhetorical relation such as CAUSE , CONCESSION , and ELABORATION .</sentence>
				<definiendum id="0">binary relation</definiendum>
				<definiens id="0">a thematic role such as AGENT , PATIENT , RECIPIENT , or a rhetorical relation such as CAUSE , CONCESSION , and ELABORATION</definiens>
			</definition>
			<definition id="5">
				<sentence>sub represents subset , part , or element .</sentence>
				<definiendum id="0">sub</definiendum>
				<definiens id="0">represents subset , part , or element</definiens>
			</definition>
</paper>

		<paper id="0632">
			<definition id="0">
				<sentence>Edinburgh EH8 9LW , UK mlap @ cogsci.ed.ac.uk Chris Brew HCRC Language Technology Group Division of Informatics University of Edinburgh Edinburgh EH8 9LW , UK chrisbr @ cogsci.ed.ac.uk Levin 's ( 1993 ) taxonomy of verbs and their classes is a widely used resource for lexical semantics .</sentence>
				<definiendum id="0">classes</definiendum>
				<definiens id="0">UK mlap @ cogsci.ed.ac.uk Chris Brew HCRC Language Technology Group Division of Informatics University of Edinburgh Edinburgh EH8 9LW</definiens>
			</definition>
			<definition id="1">
				<sentence>Levin provides an index of 3,024 verbs for which she lists the semantic classes and diathesis alternations .</sentence>
				<definiendum id="0">Levin</definiendum>
				<definiens id="0">provides an index of 3,024 verbs for which she lists the semantic classes and diathesis alternations</definiens>
			</definition>
			<definition id="2">
				<sentence>Finally , in sentence ( 4d ) serve is a FULFILLING verb and takes two complements , a noun phrase ( an apprenticeship ) and a prepositional phrase headed by to .</sentence>
				<definiendum id="0">noun phrase</definiendum>
				<definiens id="0">a FULFILLING verb and takes two complements , a</definiens>
			</definition>
			<definition id="3">
				<sentence>We measured the judges ' agreement on the annotation task using the Kappa coefficient ( Siegel and Castellan , 1988 ) which is the ratio of the proportion of times , P ( A ) , that k raters agree to the proportion of times , P ( E ) , that we would expect the raters to agree by chance ( cf. ( 22 ) ) .</sentence>
				<definiendum id="0">Kappa coefficient</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">the ratio of the proportion of times , P ( A ) , that k raters agree to the proportion of times</definiens>
			</definition>
			<definition id="4">
				<sentence>Gsearch : A tool for syntactic investigation of unparsed corpora .</sentence>
				<definiendum id="0">Gsearch</definiendum>
				<definiens id="0">A tool for syntactic investigation of unparsed corpora</definiens>
			</definition>
			<definition id="5">
				<sentence>Introduction to WordNet : An on-line lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0400">
			<definition id="0">
				<sentence>Introduce SESSION III : COLLECTING AND EVALUATING WRITTEN LANGUAGE Modding User Language Proficiency in a Writing Tutor for Deaf Learners of English Lisa Michaud and Kathleen F. McCoy University of Delaware Exploiting the Student Model to Emphasize Language Teaching Pedagogy in Natural Language Processing Trude Heift and Paul McFetfidge Simon Fraser University BREAK A Web-based System for Automatic Language Skill Assessment : EVALING C6drick Fairon Universit6 Paris , LADL Automated Essay Scoring for Nonnative English Speakers Jill Burstein Educational Testing Service Martin Chodorow Hunter College of CUNY Closing discussion PROGRAM CHAIR : Marl Broman Olsen University of Maryland Institute for Advanced Computer Studies A.V. Williams Building College Park , MD 20742 REVIEW COMMITTEE : Charlotte Groff Aldridge ( University of Maryland Language Center Director ) Susan Armstrong ( University of Geneva , ISSCO ) Chris Higgins ( University of Maryland Language Center , IALL-99 conference chair ) Eduard Hovy ( USC , Information Sciences Institute ) Douglas Jones ( U.S. Department of Defense ) Margaret Ann Kassen ( Catholic University , Modem Languages ) Dorry Kenyon ( Center for Applied Linguistics ) Patricia O'Neill Brown ( U.S. Department of Commerce ) Philip Resnik ( University of Maryland Linguistics &amp; Computer Studies ) Roberta Lavine ( University of Maryland , Spanish and Portuguese ) Valerie Malabonga ( Center for Applied Linguistics ) Flo Reeder ( MITRE Corporation ) Carol Van Ess-Dykema ( U.S. Dept. of Defense ) John White ( Litton PRC ) Table of Contents Preface ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ..</sentence>
				<definiendum id="0">Maryland Language Center , IALL-99 conference chair ) Eduard Hovy</definiendum>
				<definiens id="0">COLLECTING AND EVALUATING WRITTEN LANGUAGE Modding User Language Proficiency in a Writing Tutor for Deaf Learners of English Lisa Michaud and Kathleen F. McCoy University of Delaware Exploiting the Student Model to Emphasize Language Teaching Pedagogy in Natural Language Processing Trude Heift and Paul McFetfidge Simon Fraser University BREAK A Web-based</definiens>
				<definiens id="1">Center for Applied Linguistics ) Patricia O'Neill Brown ( U.S. Department of Commerce ) Philip Resnik ( University of Maryland Linguistics &amp; Computer Studies ) Roberta Lavine ( University of Maryland , Spanish and Portuguese ) Valerie Malabonga ( Center for Applied Linguistics</definiens>
			</definition>
			<definition id="1">
				<sentence>1 COLLECTING AND EVALUATING ORAL LANGUAGE Eliciting Natural Speech from Non-native Users : Collecting Speech data for LVCSR Laura Mayfield Tomokiyo and Susanne Burger Carnegie Mellon University ... ... ... ... ... ... ... ... ... ... ... . 5 Speech Comparision in the Rosetta StoneTM John Fairfield James Madison University ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... . 12 Multimedia Computer Technology and Performance-Based Language Testing : A Demonstration of the Computerized Oral Proficiency Instrument ( COPI ) Valerie Malabonga and Dorry Kenyon Center for Applied Linguistics ... ... ... ... ... ... ... ... ... ... ... ... ... ..</sentence>
				<definiendum id="0">COLLECTING AND EVALUATING ORAL LANGUAGE Eliciting Natural Speech from Non-native Users</definiendum>
				<definiens id="0">A Demonstration of the Computerized Oral Proficiency Instrument ( COPI</definiens>
			</definition>
</paper>

		<paper id="0602">
			<definition id="0">
				<sentence>Here , we choose to view alignments as mathematical relations between linguistic entities : Given two texts , A and B , seen as sets of linguistic units : A = { al , a2 , ... , am } and B = { bl , b2 , ... , bn } , we define a binary alignment XAB as a relation on A tj B : XAB= { ( al , bl ) , ( a2 , b2 ) , ( a2 , b3 ) , ... } 2 The interpretation of XAB is : ( a , b ) belongs to XAB if and only if some translation equivalence exists between a and b , total or partial .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">a relation on A tj</definiens>
			</definition>
			<definition id="1">
				<sentence>In general , we will say that , given N versions of a text A1 , ... , AN , a N-lingual alignment XA~ is a relation on UiN=iAi .</sentence>
				<definiendum id="0">N-lingual alignment XA~</definiendum>
			</definition>
			<definition id="2">
				<sentence>Translation equivalences can be viewed at different levels of resolution , from the level of documents to those of structural divisions ( chapters , sections , etc. ) , paragraphs , sentences , words , morphemes and eventually , characters .</sentence>
				<definiendum id="0">Translation equivalences</definiendum>
			</definition>
			<definition id="3">
				<sentence>A Strategy for the Rapid Multiple Alignment of Proteine Sequences .</sentence>
				<definiendum id="0">Strategy for</definiendum>
			</definition>
			<definition id="4">
				<sentence>ARCADE : A Cooperative Research Project on Parallel Text Alignment Evaluation .</sentence>
				<definiendum id="0">ARCADE</definiendum>
			</definition>
			<definition id="5">
				<sentence>Bilingual Concordances : A New Tool for Bilingual Lexicographers .</sentence>
				<definiendum id="0">Bilingual Concordances</definiendum>
			</definition>
</paper>

		<paper id="0610">
			<definition id="0">
				<sentence>We produce a-covers to extend them into n-gram collocations 1 According to the definition of Kjellmer and Cowie , a fossilized phrase is a sequence , where the occurrence of one word almost predicts the rest of the phrase and one word predicts a very limited number of words in a semi-fossilized phrase ( Kjellmer , 1995 ) ( Cowie , 1981 ) .</sentence>
				<definiendum id="0">fossilized phrase</definiendum>
				<definiens id="0">a sequence , where the occurrence of one word almost predicts the rest of the phrase and one word predicts a very limited number of words in a semi-fossilized phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>Korean is one of agglutinative languages as well as a propositional language .</sentence>
				<definiendum id="0">Korean</definiendum>
				<definiens id="0">one of agglutinative languages as well as a propositional language</definiens>
			</definition>
			<definition id="2">
				<sentence>Xij denotes the frequency of mk that occurs at the j-th position before mi .</sentence>
				<definiendum id="0">Xij</definiendum>
				<definiens id="0">the frequency of mk that occurs at the j-th position before mi</definiens>
			</definition>
			<definition id="3">
				<sentence>Cn~ , m , ) ( o } ~1 , o~ol ) ( drink , much ) ( 3 } ~l , t -- t ~ = ) ( drink , too ) ( Ot h l , gt ) ( ~nk , ~lcan ) ( 3t , ~l , OH °J ) ( drink , everyday ) ( fl\ [ hl , ~OI ) ( drink , boil ) ( OtJ , l , ~ ) ( drink , ,iot ) ( Ot~ , l , @ ~l ) ( drink , t.bgether ) ( 0~1 , ~ ==~ ) ( drink , a tittle ) ( OH , ~ ) ( drink , take ) ( OtAI , _~ ) ( drink , a little ) syntactic relation VD VD VJ VD W VD VD VD W VD preferring position 1 2 4 3 2 1 3 1 2 3 Figure 1 : meaningful bigrams of ~\ [ z\ ] ( drink ) by Xtract ~rr~ : ~y of k object .</sentence>
				<definiendum id="0">OH °J )</definiendum>
				<definiendum id="1">,iot )</definiendum>
				<definiendum id="2">relation VD VD VJ VD W VD VD VD W VD preferring position</definiendum>
			</definition>
			<definition id="4">
				<sentence>F ( x ) =l-~ - '' *~ o &lt; x &lt; ~ ~h~ ~ &gt; 0 , ~ &gt; 0 ( 3 ) 5Idioms have no ambiguous meaning but requires rigid patterns to preserve the idiomatic meaning .</sentence>
				<definiendum id="0">F ( x</definiendum>
				<definiens id="0">no ambiguous meaning but requires rigid patterns to preserve the idiomatic meaning</definiens>
			</definition>
			<definition id="5">
				<sentence>According to Benson 's definition , a collocation is a recurrent word combination ( Benson et al. , 1986 ) .</sentence>
				<definiendum id="0">collocation</definiendum>
				<definiens id="0">a recurrent word combination</definiens>
			</definition>
			<definition id="6">
				<sentence>R on X x X , where Xis the set of all meaningful bigrams which contain ; , , l ) ~se morpheme mi , means a cohesive relation a.nd partitions of ' set X obtained by R correspond to n-gram collocations .</sentence>
				<definiendum id="0">Xis</definiendum>
				<definiens id="0">a cohesive relation a.nd partitions of ' set X obtained by R correspond to n-gram collocations</definiens>
			</definition>
			<definition id="7">
				<sentence>A fuzzy compatability relation R ( X , X ) is represented as a matrix by a membership function .</sentence>
				<definiendum id="0">fuzzy compatability relation R</definiendum>
			</definition>
			<definition id="8">
				<sentence>IxAyl means how often two pairs x and y co-occur in the same concordances under the distance constraint .</sentence>
				<definiendum id="0">IxAyl</definiendum>
				<definiens id="0">means how often two pairs x and y co-occur in the same concordances under the distance constraint</definiens>
			</definition>
			<definition id="9">
				<sentence>A relation which is reflexive , symmetric and transitive is called as an equivalence relation or similarity relation .</sentence>
				<definiendum id="0">relation</definiendum>
				<definiens id="0">an equivalence relation or similarity relation</definiens>
			</definition>
			<definition id="10">
				<sentence>The transitive closure of a relation is defined as the smallest fuzzy relation which is transitive and has the fewest possible members with containing the relation itself .</sentence>
				<definiendum id="0">transitive closure of a relation</definiendum>
				<definiens id="0">the smallest fuzzy relation which is transitive and has the fewest possible members with containing the relation itself</definiens>
			</definition>
			<definition id="11">
				<sentence>When R is a fuzzy compa , tibility relation , compatibility classes are , l ( , .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">a fuzzy compa , tibility relation</definiens>
			</definition>
</paper>

		<paper id="0212">
			<definition id="0">
				<sentence>A query indicates an informational need by the user to the search engine .</sentence>
				<definiendum id="0">query</definiendum>
			</definition>
			<definition id="1">
				<sentence>This relationship is given with a weight of I ( wl , w2 ) /N where N is a normalization constant .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">a normalization constant</definiens>
			</definition>
			<definition id="2">
				<sentence>Since these term expansions are weighted the score for for a particular term w2 and a query term Wl is : S ( Wl , w2 ) = idf ( wl ) x weightwl ( W2 ) where weightwl is the weight assigned during one of the previous term expansion phases and idf is defined above .</sentence>
				<definiendum id="0">weightwl</definiendum>
				<definiens id="0">the weight assigned during one of the previous term expansion phases</definiens>
			</definition>
</paper>

		<paper id="0513">
			<definition id="0">
				<sentence>~ dl lnteresse , e qum &amp; anche sulla finanza pubbhca , c ) tl Governo avrebbe adottato con la massima urgenza provve &amp; mentl dl nsanamento della finanza pubbhca , senza tuttavta fare ncorso a m~sure che Incldessero sull 'm &amp; ce del prezz~ al consumo Quest~ nchmmi hanno ormm sapore stonco , ma sono uUh per megho mettere a fuoco la situaz~one attuale In parucolare la prima affermaz~one ( l'essere c~oe ' la stabd~tb , del carabao asse portante di tutta la pohuca economica ) ci sembra ancora p~enamente vahda rasse portante non c'e ' pda e con esso e ' sparita anche la pohtica econom~ca Schematlcamente sembra che esistano due alternative posslbdl dl pohtlca economica La prima ( che nproduce m sostanza , pur helle con &amp; zlom mo &amp; ficate , la hnea pre-svalutazlone tratteggmta sopra ) potrebbe arucolarsi nei seguenu termini a ) aggmstamento fiscale come ob~ett~vo della mass~ma urgenza , b ) naffermaz~one del ruolo autonomo della Banca centrale , degh lmpegm assuntt m vista del mercato umco ( m part~colare m matena di hbera c~rcolaztone dei cap~tah ) , c ) mass~mo contemmento deUe spmte , mflazlomsuche denvanti dalla svalutazione della hra e rmffermazione dl un obletUvo antHnflaziomstlco preciso ( tradotto m un target ngoroso e tmpegnatwo , e qumdt cred~bde , d~ cresctta monetana ) Part~colarmente importante quest'ulttmo punto , m quanto non e'affatto mewtabde che gh effett~ della svalutaz~one s~ traducano lntegralmente m una mflaztomst~ca aggtuntiva Se la cresc~ta monetarm e ' tenuta sotto controllo , e graz~e agh effetti restnttiv~ della manovra d~ bflanclo , la svalutaz~one pub tradurs~ anz~che ' m un fattore mflaz~omstlco , m uno d~ mutamento dei prezz~ lelatlvi La seconda lmea punta mvece a un abbassamento de~ tass~ dt mtetesse e a impart~re stimoh espansiw all'economia ( entramb~ gh obtett~v~ potrebbero rlcevere una motwaz~one aggluntwa grazle al solhevo che , nel breve penodo , potrebbe~o portare alia tmanza pubbhca ) Una tale hnea nchiederebbe certamente I'accantonamento , almeno temporaneo , di qualslasl ob~ettlVO ant~mflaziomstico E ' anz~ probablle che i suo~ effettt p~fa sigmficauv~ e durevoh sarebbero quelh prodott~ dall'mflaz~one sulla dastnbuztone del red &amp; to , e soprattutto della ncchezza , e sul valore reale dello stock del deb~to pubbhco Sl notl chela seconda hnea e ' certamente mcompat~bde con un r~torno m temp~ brew a un regime di cambio fisso A frequency hst which contams terminological compound nouns give us the posstbthty to Immediately understand the specific content of this article Such an index prowdes a p~cture of the content of the text ( the mdex which follows was budt on the whole article ) 8 pohttca econom~ca 5 finanza pubbhca 4 pohtlca monetana 4 cresctta monetana 3 prlonth assoluta 3 tass~ d~ mteresse 3 asse portante 2 valore reale 2 stabtl~th det camb~o 2 svalutazlone della hra 2 manovra dl bdanclo 95 2 tasso d~ inflazlone 1 contrattazmm salanah 1 deblto pubbhco I Polmcaeconom , ca I abbassamento de~ tassl I hnea dl condotta 1 dlstnbuzlone del reddlto 1 Banca d'Itaha i dffferenzmh dl mteresse 1 hbera mrcolazlone 1 tltoll pubbhcl 1 spmte mflazmmstlche 1 cambm flsso 1 spmta mflazmnlstlca I stabdlzzamone del cambm I mercato umco 1 premm dl nschm 1 indlce de~ prezz~ l settore pubbhco 1 prezzl al consumo 1 umone monetana Electronic dlcttonartes give us the posslblhty of recognlzmg wlthm texts words and sequences of words as defined by dictionaries INTEX allows to recogntze combmatmns of simple and compound words , thanks to the interaction between dlctmnarles and grammars INTEX contains a tool whtch allows to construct local grammars on the model of fimte state automata These grammars can be based not only on words but also on the non-terminal symbols contained in the dictionaries For example , m order to identify all compound nouns followed by an adjective , which agrees in gender and number with them , we construct the following grammar ~ N~+NPN ~ &gt; ~ N~+NA ms &gt; \ [ ~L-~ If we apply such a grammar to a text , INTEX will hlghhght all occurrences of th~s pattetn and subsequently construct concordances for that pattern trovare espressmne sm in accrescmu dffferenzlah dl interesse reah , sm In un deprezzamen utta la pohtlca econom~ca ~tahana La hnea dt condotta segmta helle prime setumane dal Gov ppresentava l'asse portante d~ tutta la polmca econormca ltahana La hnea dl candotta segul ant~-mflazmmsuca Se questa e ' la polmca economica ltahana Sl sarebbe tentitl dl dire zmne s~ traducano mtegralmente in una spmta lnflazmmst~ca agglunttva Se la cresmta monet apttah ) , c ) masslmo contemmento delle spmte mflazlomstmhe denvant~ dalla svalutazmne de vl sufflclentemeute sald~ per tollerare tasst d~ mteresse penahzzantt a qualche asta , accompag una scelta realmente ~mpegnat~va 2 II tasso dt mflazmne programmato e ' stato portato dal 3 , rzata dalla prospemva dl adeslone all'umone monetarla europea ) dalla prmntg assoluta dell ' 96 Hence , electromc dxctlonanes on one side , and the posslblhty of construct , .</sentence>
				<definiendum id="0">che nproduce m sostanza</definiendum>
				<definiens id="0">adottato con la massima urgenza provve &amp; mentl dl nsanamento della finanza pubbhca , senza tuttavta fare ncorso a m~sure che Incldessero sull 'm &amp; ce del prezz~ al consumo Quest~ nchmmi hanno ormm sapore stonco , ma sono uUh per megho mettere a fuoco la situaz~one attuale In parucolare la prima affermaz~one</definiens>
				<definiens id="1">la hnea pre-svalutazlone tratteggmta sopra ) potrebbe arucolarsi nei seguenu termini a ) aggmstamento fiscale come ob~ett~vo della mass~ma urgenza , b</definiens>
				<definiens id="2">e qumdt cred~bde , d~ cresctta monetana ) Part~colarmente importante quest'ulttmo punto , m quanto non e'affatto mewtabde che gh effett~ della svalutaz~one s~ traducano lntegralmente m una mflaztomst~ca aggtuntiva Se la cresc~ta monetarm e ' tenuta sotto controllo , e graz~e agh effetti restnttiv~ della manovra d~ bflanclo</definiens>
				<definiens id="3">entramb~ gh obtett~v~ potrebbero rlcevere una motwaz~one aggluntwa grazle al solhevo che , nel breve penodo , potrebbe~o portare alia tmanza pubbhca ) Una tale hnea nchiederebbe certamente I'accantonamento , almeno temporaneo , di qualslasl ob~ettlVO ant~mflaziomstico E ' anz~ probablle che i suo~ effettt p~fa sigmficauv~ e durevoh sarebbero quelh prodott~ dall'mflaz~one sulla dastnbuztone del red &amp; to , e soprattutto della ncchezza , e sul valore reale dello stock del deb~to pubbhco Sl notl chela seconda hnea e ' certamente mcompat~bde con un r~torno m temp~ brew a un regime di cambio fisso A frequency hst which contams terminological compound nouns give us the posstbthty to Immediately understand the specific content of this article Such an index prowdes a p~cture of the content of the text ( the mdex which follows was budt on the whole article</definiens>
				<definiens id="4">give us the posslblhty of recognlzmg wlthm texts words and sequences of words as defined by dictionaries INTEX allows to recogntze combmatmns of simple and compound words , thanks to the interaction between dlctmnarles and grammars INTEX contains a tool whtch allows to construct local grammars on the model of fimte state automata These grammars can be based not only on words but also on the non-terminal symbols contained in the dictionaries For example , m order to identify all compound nouns followed by an adjective , which agrees in gender and number with them</definiens>
			</definition>
</paper>

		<paper id="0104">
			<definition id="0">
				<sentence>C0cErIIL covers both nominal and pronoun corder~ce , but distinct sets of heuristics operate for different forms of anaphors .</sentence>
				<definiendum id="0">C0cErIIL</definiendum>
				<definiens id="0">covers both nominal and pronoun corder~ce , but distinct sets of heuristics operate for different forms of anaphors</definiens>
			</definition>
			<definition id="1">
				<sentence>Brevity imposes the omission of heuristics for other forms of pronoun resolution .</sentence>
				<definiendum id="0">Brevity</definiendum>
				<definiens id="0">imposes the omission of heuristics for other forms of pronoun resolution</definiens>
			</definition>
			<definition id="2">
				<sentence>This search is employed by heuristics for possessive pronoun resolution : Oif ( Pron is possessive ) ( i.e. we have a sequence \ [ Pron nouno\ ] , where nouno is the head of the NP containing Pron ) then apply suco , ~_~sieely : o Henris6¢ .</sentence>
				<definiendum id="0">possessive )</definiendum>
				<definiens id="0">the head of the NP containing Pron ) then apply suco</definiens>
			</definition>
			<definition id="3">
				<sentence>Based on this evidence , COCKTtIL implements special rules for name alias identification and for robust recognition of appositions .</sentence>
				<definiendum id="0">COCKTtIL</definiendum>
				<definiens id="0">implements special rules for name alias identification and for robust recognition of appositions</definiens>
			</definition>
			<definition id="4">
				<sentence>name ( adj ( NP ) , adj ( Ne ' ) ) ) then if ( Noun ' belongs to core/erence chain CO ) then Pick the element ~vm CC which is closest to Noun in Text .</sentence>
				<definiendum id="0">adj ( NP</definiendum>
				<definiens id="0">the element ~vm CC which is closest to Noun in Text</definiens>
			</definition>
			<definition id="5">
				<sentence>l~st , CICERO generates the knowledge upon which the abductions can be performed .</sentence>
				<definiendum id="0">CICERO</definiendum>
				<definiens id="0">generates the knowledge upon which the abductions can be performed</definiens>
			</definition>
			<definition id="6">
				<sentence>CICERO is a system still under development , and at present we did not evaluate the precision of its results .</sentence>
				<definiendum id="0">CICERO</definiendum>
				<definiens id="0">a system still under development</definiens>
			</definition>
</paper>

		<paper id="0615">
			<definition id="0">
				<sentence>Kupiec ( Kupiec , 1992 ) describes a technique of augmenting the Hidden Markov Models for part-of-speech tagging by the use of networks .</sentence>
				<definiendum id="0">Kupiec</definiendum>
				<definiens id="0">describes a technique of augmenting the Hidden Markov Models for part-of-speech tagging by the use of networks</definiens>
			</definition>
			<definition id="1">
				<sentence>2 `` Standard '' Part-of-Speech Tagging Model based on HMM From the statistical point of view , the tagging problem can be defined as the problem of finding the proper sequence of categories c : ,r~ = Cl , c2 , ... , cn ( n _ &gt; 1 ) given the sequence of words w : ,n = wl , w2 , ... , wn ( We denote the i'th word by wi , and the category assigned to the wi by ci ) , which is formally defined by the following equation : `` \ ] - ( Wl , n ) -= argmaxP ( Cl , nlW : ,~ ) ( 1 ) Charniak ( Charniak et al. , 1993 ) describes the `` standard '' HMM-based tagging model as Equation 2 , which is the simplified version of Equation 1 .</sentence>
				<definiendum id="0">Standard</definiendum>
				<definiendum id="1">) describes the `` standard '' HMM-based tagging model</definiendum>
				<definiens id="0">'' Part-of-Speech Tagging Model based on HMM From the statistical point of view</definiens>
				<definiens id="1">the problem of finding the proper sequence of categories c : ,r~ = Cl , c2 , ... , cn ( n _ &gt; 1 ) given the sequence of words w : ,n = wl , w2 , ... , wn ( We denote the i'th word by wi , and the category assigned to the wi by ci ) , which is formally defined by the following equation : `` \ ] - ( Wl , n ) -= argmaxP ( Cl , nlW : ,~ ) ( 1 ) Charniak ( Charniak et al. , 1993</definiens>
			</definition>
			<definition id="2">
				<sentence>The random variable XcJ then represents a process of assigning a conditional probability p ( cilc j ) to every category c i ( e i ranges over cl ... c C ) xc ( c = P ( d = P ( c21cJ ) Xc ) ( c C ) = p ( cClc j ) We convert the process of Xcj into the state transition vector , VcJ , which consists of the corresponding conditional probabilities , e.g. , Vprep -- - ( P ( adjectiveiprep ) , ... , P ( verbiprep ) ) T. The ( squared ) distance between two arbitrary vectors is then computed as follows : l~ ( Vl , V2 ) = ( Vl -v2 ) T ( v1 V2 ) ( 5 ) Similarly , we define the lexicalized state transition vector 1 , VO , wk , e.g. , Vprep , i n -~ ( P ( adjectivelprep , in ) , ... , P ( verblprep , in ) ) Y In this situation , it is possible to regard each lexicMized state transition vector , VcJ , wk , of the same category cJ as members of a cluster whose centroid is the state transition vector , Vc ) .</sentence>
				<definiendum id="0">, P</definiendum>
				<definiens id="0">a process of assigning a conditional probability p ( cilc j</definiens>
				<definiens id="1">e i ranges over cl ... c C ) xc ( c = P ( d = P ( c21cJ ) Xc ) ( c C ) = p ( cClc j ) We convert the process of Xcj into the state transition vector , VcJ , which consists of the corresponding conditional probabilities , e.g. , Vprep -- - ( P ( adjectiveiprep ) , ...</definiens>
			</definition>
			<definition id="3">
				<sentence>2The Viterbi algorithm for finding the best tags runs in O ( n 2 ) where n is the number of states .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of states</definiens>
			</definition>
			<definition id="4">
				<sentence>number ( NN ) so ( CS ) due ( J J ) World ( NP ) Christian ( NP ) difficult ( J J ) tell ( VB ) going ( VBG ) kind ( NN ) let ( VB ) continue ( VB ) series ( NN ) part ( NN ) radio ( NN ) sure ( J J ) want ( VB ) front ( NN ) seem ( VB ) total ( NN ) decided ( VBD ) expected ( VBN ) right ( NN ) based ( VBN ) White ( NP ) except ( IN ) told ( VBD ) James ( NP ) fact ( NN ) March ( NP ) sort ( NN ) example ( NN ) designed ( VBN ) respect ( NN ) talk ( VB ) Department ( NP ) single ( AP ) Negro ( NP ) wanted ( VBD ) Western ( NP ) yes ( RB ) become ( VBN ) necessary ( J J ) speak ( VB ) about ( RB ) amount ( NN ) down ( IN ) like ( VB ) S. ( NP ) same ( AP ) too ( RB ) General ( NP ) began ( VBD ) use ( NN ) tax ( NN ) got ( VBN ) 127 T. Brants .</sentence>
				<definiendum id="0">NN ) so ( CS</definiendum>
				<definiendum id="1">VB ) about</definiendum>
				<definiens id="0">total ( NN ) decided ( VBD ) expected ( VBN ) right ( NN ) based ( VBN ) White ( NP ) except ( IN ) told ( VBD ) James</definiens>
			</definition>
</paper>

		<paper id="0304">
			<definition id="0">
				<sentence>• Definition : Items which mainly contribute to clarifying discourse structure but not to problem solving • Surface forms : `` ja ( ok ) '' , `` dewa ( then , ok ) '' , `` soredewa ( then , ok ) '' , `` soushitara ( then , in that case ) '' , `` deshitara ( then , in that case ) '' , `` souieba ( I 've just remembered , aah '' , `` de ( you see , so ) '' , `` sorede ( and so ) '' , `` sousuruto ( and so , in that case ) '' , `` soushimasuto ( so you mean , in that case ) '' , `` tsumari ( I mean , that means that ) '' , `` yousuruni ( so you mean , ) '' , `` mazu ( first , firstly ) '' , `` saishoni ( first , firstly ) '' , `` kondo ( then , next ) '' , `` tsugini ( then , next ) '' , `` saigoni ( last , lastly ) '' , `` ma~ ( well ) '' The phrases such as `` hanashi wa kawarimasuga ( by the way ) '' and `` tsugi ni ikimasu Table 5 : Correlation between markers and discourse boundaries discourse Before After Else Total No Segment , 5 ( } 121 633 804 ( 36 % ) ( 88 ~ ) ( 73 % ) ( 70 ~ ) Segment level 1 56 7 140 203 ( 41 % ) ( 5 % ) ( 16 % ) ( 18 % ) Segment level 2 32 10 94 136 ( 23 % } ( 7 % ) ( 11 % ) ( 12 % ) ( go ahead ) '' are also included in discourse markers , which are not identified by surface forms , but by their functions .</sentence>
				<definiendum id="0">soushitara</definiendum>
				<definiendum id="1">sousuruto</definiendum>
				<definiendum id="2">`` yousuruni</definiendum>
				<definiendum id="3">mazu</definiendum>
				<definiens id="0">soushimasuto ( so you mean , in that case ) '' , `` tsumari ( I mean , that means that ) '' ,</definiens>
			</definition>
			<definition id="1">
				<sentence>The chance level is 30 % , and therefore , surface forms of discourse markers were found to be effective cue for recognizing discourse boundaries .</sentence>
				<definiendum id="0">chance level</definiendum>
			</definition>
</paper>

		<paper id="0404">
			<definition id="0">
				<sentence>Introduction The Computerized Oral Proficiency Instrument ( COPI ) is a multi-media , computer-administered adaptation of the tape-mediated Simulated Oral Proficiency Interview ( SOPI ) .</sentence>
				<definiendum id="0">Computerized Oral Proficiency Instrument</definiendum>
			</definition>
			<definition id="1">
				<sentence>Since June of 1998 , the Educational Testing Service ( ETS ) has administered the Test of English as a Foreign Language ( TOEFL ) by computer in many parts of the world .</sentence>
				<definiendum id="0">Educational Testing Service</definiendum>
				<definiens id="0">administered the Test of English as a Foreign Language ( TOEFL ) by computer in many parts of the world</definiens>
			</definition>
			<definition id="2">
				<sentence>With almost one million test takers a year , the TOEFL is the world 's largest language test .</sentence>
				<definiendum id="0">TOEFL</definiendum>
				<definiens id="0">the world 's largest language test</definiens>
			</definition>
			<definition id="3">
				<sentence>The ACTFL Guidelines stand in a tradition of oral proficiency testing in the United States that dates to the 1950s , when the then Secretary of State called for the creation of criteria that could be used to identify the foreign language proficiency of U.S. government employees ( Stansfield , 1996 ) .</sentence>
				<definiendum id="0">ACTFL Guidelines</definiendum>
				<definiens id="0">the foreign language proficiency of U.S. government employees</definiens>
			</definition>
			<definition id="4">
				<sentence>The ACTFL Guidelines define proficiency as `` the ability to use the language effectively and appropriately in real-life situations '' ( Buck , Byrnes , and Thompson , 1989 , 1.1 ) .</sentence>
				<definiendum id="0">ACTFL Guidelines define proficiency</definiendum>
				<definiens id="0">the ability to use the language effectively and appropriately in real-life situations '' ( Buck , Byrnes</definiens>
			</definition>
			<definition id="5">
				<sentence>Underlying the COPI is a large pool of assessment tasks that cover a wide variety of content areas and topics .</sentence>
				<definiendum id="0">Underlying the COPI</definiendum>
			</definition>
			<definition id="6">
				<sentence>The COPI uses an algorithm which allows examinees ( within some limits ) to choose the following aspects of the test : amount of preparation and response time , speaking function , topic , level of difficulty ( i.e. , ACTFL level of task ) , and language of the directions ( English or Spanish for Advanced and Superior level tasks ) for each performance task .</sentence>
				<definiendum id="0">COPI</definiendum>
				<definiens id="0">uses an algorithm which allows examinees ( within some limits ) to choose the following aspects of the test : amount of preparation and response time</definiens>
				<definiens id="1">ACTFL level of task ) , and language of the directions ( English or Spanish for Advanced and Superior level tasks</definiens>
			</definition>
			<definition id="7">
				<sentence>estion , describe the kindsofactivities people usually do ~ at , the beach ; , I oo , oo , Ol Figure 1 Operationalized The COPI provides time for examinees to think about their response and time to give their response .</sentence>
				<definiendum id="0">estion</definiendum>
			</definition>
</paper>

		<paper id="0704">
			<definition id="0">
				<sentence>For instancebased algorithms , this approach has been demonstrated to correct invalid independence assumptions made by the algorithm \ [ Pazzani , 1998\ ] : e.g. , for the Naive Bayes classifier ( Duda &amp; Hart , 1973 ) , the unwarranted assumption that in general the various attributes a , = v , are independent , and form a joint probability model for the prediction of the class C : It is a widely held proposition that inductive learning models , such as decision trees \ [ Quinlan , 1993\ ] or knearest neighbor models \ [ Aha , Kibler &amp; Albert , 1991\ ] , are heavily dependent upon their representational biases .</sentence>
				<definiendum id="0">Naive Bayes classifier</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">independent , and form a joint probability model for the prediction of the class</definiens>
			</definition>
			<definition id="1">
				<sentence>Aiming at reducing similarity between an exemplar and its misclassifying nearest neighbor , IB3-CI uses a conjunctive operator forming an attribute that discriminates between these two .</sentence>
				<definiendum id="0">IB3-CI</definiendum>
				<definiens id="0">uses a conjunctive operator forming an attribute that discriminates between these two</definiens>
			</definition>
			<definition id="2">
				<sentence>The MVDM defines the difference between two values x and y respective to a class C , as 5 ( x , y ) = Z \ [ P ( C , ix ) P ( C , \ [ y ) \ [ ( 4 ) z -- -- I i.e. , it uses the probabilities of the various classes conditioned on the two values to determine overlap .</sentence>
				<definiendum id="0">MVDM</definiendum>
				<definiens id="0">the difference between two values x and y respective to a class C , as 5 ( x , y ) = Z \ [</definiens>
			</definition>
			<definition id="3">
				<sentence>IGTREE is a tree-based k-nearest neighbor algorithm , where information gain is used as a heuristic to insert nodes in the tree .</sentence>
				<definiendum id="0">IGTREE</definiendum>
				<definiendum id="1">information gain</definiendum>
				<definiens id="0">a tree-based k-nearest neighbor algorithm</definiens>
			</definition>
			<definition id="4">
				<sentence>STRESS is a selection of secondary stress assignment patterns from the Dutch version of the Celex lexical database \ [ Baayen , Piepenbrock &amp; van Rijn , 1993\ ] , on the basis of phonemic representations of syllabified words .</sentence>
				<definiendum id="0">STRESS</definiendum>
				<definiens id="0">a selection of secondary stress assignment patterns from the Dutch version of the Celex lexical database \</definiens>
			</definition>
			<definition id="5">
				<sentence>The WSJNPVP set consists of part-of speech tagged Wall Street Journal material ( Marcus , Santorini &amp; Marcinkiewicz , 1993 ) , supplemented with syntactic tags indicating noun phrase and verb phrase boundaries ( Daelemans et al , 1999iii ) .</sentence>
				<definiendum id="0">WSJNPVP set</definiendum>
			</definition>
			<definition id="6">
				<sentence>wsJ-POS is a fragment of the Wall Street Journal part-of-speech tagged material ( Marcus , Santorini and Marcinkiewicz , 1993 ) .</sentence>
				<definiendum id="0">wsJ-POS</definiendum>
				<definiens id="0">a fragment of the Wall Street Journal part-of-speech tagged material</definiens>
			</definition>
			<definition id="7">
				<sentence>GRAPHON constitutes a grapheme-to-phoneme learning task for English , based on the Celex lexical database .</sentence>
				<definiendum id="0">GRAPHON</definiendum>
				<definiens id="0">constitutes a grapheme-to-phoneme learning task for English , based on the Celex lexical database</definiens>
			</definition>
			<definition id="8">
				<sentence>BSJ-IG does so for the STRESS set ( tabel 4 ) .</sentence>
				<definiendum id="0">BSJ-IG</definiendum>
			</definition>
			<definition id="9">
				<sentence>IBI-IG &amp; MVDM with BSJ-IG is the only type of classifier that is able to trap the important interaction between nucleus and coda in the STRESS set .</sentence>
				<definiendum id="0">BSJ-IG</definiendum>
				<definiens id="0">the only type of classifier that is able to trap the important interaction between nucleus and coda in the STRESS set</definiens>
			</definition>
</paper>

		<paper id="0305">
			<definition id="0">
				<sentence>MATE aims to develop general methodological guidelines for the creation , annotation , retrieval and analysis of annotated corpora .</sentence>
				<definiendum id="0">MATE</definiendum>
				<definiens id="0">aims to develop general methodological guidelines for the creation , annotation , retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>The Discourse Resource Initiative ( DRI ) group provided input on a third possibility : Developing best practice methods for scheme design , documentation and annotation .</sentence>
				<definiendum id="0">Discourse Resource Initiative</definiendum>
				<definiens id="0">Developing best practice methods for scheme design , documentation and annotation</definiens>
			</definition>
			<definition id="2">
				<sentence>Suggested dimensions are • Communicative Status which records whether an utterance is intelligible and whether it was 37 successfully completed , • In\ ] ormation Level which represents the semantic content of an utterance on an abstract level , • Forward Looking Function which describes how an utterance constraints the future beliefs and actions of the participants , and affects the discourse , and • Backward Looking Function which characterizes how an utterance relates to the previous discourse .</sentence>
				<definiendum id="0">Communicative Status</definiendum>
				<definiens id="0">records whether an utterance is intelligible and whether it was 37 successfully completed , • In\ ] ormation Level which represents the semantic content of an utterance on an abstract level , • Forward Looking Function which describes how an utterance constraints the future beliefs and actions of the participants , and affects the discourse , and • Backward Looking Function which characterizes how an utterance relates to the previous discourse</definiens>
			</definition>
</paper>

		<paper id="0108">
</paper>

	</volume>
