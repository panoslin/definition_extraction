<?xml version="1.0" encoding="UTF-8"?>
	<volume id="W04">

		<paper id="2420">
			<definition id="0">
				<sentence>SVM is a well-known machine learning algorithm with high generalization performance in high dimensional feature spaces ( H. Yamada , 2003 ) .</sentence>
				<definiendum id="0">SVM</definiendum>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>The DUC corpus contains 11,867 files organized in a three-level hierarchy of directories totalling 62MB .</sentence>
				<definiendum id="0">DUC corpus</definiendum>
				<definiens id="0">contains 11,867 files organized in a three-level hierarchy of directories totalling 62MB</definiens>
			</definition>
			<definition id="1">
				<sentence>The top level identifies the source year and exists simply to avoid the name collision which occurs when different years use same-named subdirectories .</sentence>
				<definiendum id="0">top level</definiendum>
				<definiens id="0">identifies the source year and exists simply to avoid the name collision which occurs when different years use same-named subdirectories</definiens>
			</definition>
			<definition id="2">
				<sentence>HEAD SUM • Summary phrase is substring of document phrase .</sentence>
				<definiendum id="0">Summary phrase</definiendum>
				<definiens id="0">substring of document phrase</definiens>
			</definition>
</paper>

		<paper id="2502">
			<definition id="0">
				<sentence>For instance , the example above uses some of the most potent general schemas : POSSESSION , EVASION , SPATIAL RELATION , EVENT STRUCTURE , and SOURCEPATH-GOAL which involves an agent trying to obtain a particular goal ( finding WMD ) by moving along a path of actions .</sentence>
				<definiendum id="0">POSSESSION</definiendum>
				<definiens id="0">involves an agent trying to obtain a particular goal ( finding WMD ) by moving along a path of actions</definiens>
			</definition>
			<definition id="1">
				<sentence>A5 Content : Biological Weapons Program : develop ( Iraq , Viral_Agent ( instance_of : new ) ) Justification : POSSESSION Schema Previous ( Intent and Ability ) : Prevent ( ability , Inspection ) ; Inspection terminated ; Possible resumption of ability Status : Attempt ongoing Likelihood : Medium Confirmability : difficult , obtuse , hidden possess ( Iraq , Chemical and Biological Weapons ) Justification : POSSESSION Schema Previous ( Intent and Ability ) : Hidden from Inspectors Likelihood : Medium possess ( Iraq , delivery Systems ( type : rockets , target : Other countries ) ) Justification : POSSESSION Schema Previous ( Intent and Ability ) : Hidden from Inspectors Status : Ongoing Likelihood : Medium possess ( Iraq , delivery Systems ( type : scud missiles , target : Other countries ) ) Justification : POSSESSION Schema Previous ( Intent and Ability ) : Hidden from Inspectors Status : Ongoing Likelihood : Medium possess ( Iraq , delivery Systems ( type : launchers , target : Other countries ) ) Justification : POSSESSION Schema Previous ( Intent and Ability ) : Hidden from Inspectors Status : Ongoing Likelihood : Medium possess ( Iraq , fuel stocks ( purpose : power ( launchers ) ) ) Justification : POSSESSION Schema Previous ( Intent and Ability ) : Hidden from Inspectors Status : Ongoing Likelihood : Medium hide ( Iraq , Seeker : UN Inspectors , Hidden : CBW stockpiles ) Justification : POSSESSION Schema Detection Process : Inspection Status : Past Likelihood : Medium Source : UN document , US Intelligence Source .</sentence>
				<definiendum id="0">delivery Systems</definiendum>
				<definiens id="0">Other countries ) ) Justification : POSSESSION Schema Previous ( Intent and Ability ) : Hidden from Inspectors Status : Ongoing Likelihood : Medium possess</definiens>
				<definiens id="1">Other countries ) ) Justification : POSSESSION Schema Previous ( Intent and Ability ) : Hidden from Inspectors Status : Ongoing Likelihood : Medium possess</definiens>
				<definiens id="2">Other countries ) ) Justification : POSSESSION Schema Previous ( Intent and Ability ) : Hidden from Inspectors Status : Ongoing Likelihood</definiens>
			</definition>
</paper>

		<paper id="1610">
			<definition id="0">
				<sentence>In this paper , Naive Bayes ( NB ) which is a statistical machine learning algorithm , is used to classify non-vocalized Arabic web documents ( after their words have been transformed to the corresponding canonical form , i.e. , roots ) to one of five pre-defined categories .</sentence>
				<definiendum id="0">Naive Bayes ( NB )</definiendum>
				<definiens id="0">a statistical machine learning algorithm , is used to classify non-vocalized Arabic web documents ( after their words have been transformed to the corresponding canonical form , i.e. , roots ) to one of five pre-defined categories</definiens>
			</definition>
			<definition id="1">
				<sentence>For each root w k in Vocabulary Compute P ( w k /C j ) = ( N k , j +1 ) / ( n j +| Text j | ) ( 3 ) where N k , j is the number of times w k occurs in C j , n j is the total number of distinct terms in all training documents labeled C j , and Text j is a single documents generated by concatenating all the training documents for category C j .</sentence>
				<definiendum id="0">j</definiendum>
				<definiendum id="1">Text j</definiendum>
				<definiens id="0">the total number of distinct terms in all training documents labeled C j , and</definiens>
			</definition>
			<definition id="2">
				<sentence>TF-IDF ( term frequency-inverse document frequency ) is one of the widely used feature selection techniques in information retrieval ( Yates and Neto , 1999 ) .</sentence>
				<definiendum id="0">TF-IDF ( term frequency-inverse document frequency )</definiendum>
				<definiens id="0">one of the widely used feature selection techniques in information retrieval</definiens>
			</definition>
			<definition id="3">
				<sentence>While the TF measurement concerns the importance of a term in a given document , IDF seeks to measure the relative importance of a term in a collection of documents .</sentence>
				<definiendum id="0">TF measurement</definiendum>
				<definiens id="0">concerns the importance of a term in a given document , IDF seeks to measure the relative importance of a term in a collection of documents</definiens>
			</definition>
			<definition id="4">
				<sentence>TF is given by TF D , t , and it denotes frequency of term t in document D. IDF is given by IDF t = log ( N/df t ) , where N is the number of documents in the collection , and df t is the number of documents containing the term t. ( Salton and Yang , 1973 ) proposed the combination of TF and IDF as weighting schemes , and it has been shown that their product gave better performance .</sentence>
				<definiendum id="0">TF</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">df t</definiendum>
				<definiens id="0">the number of documents containing the term t. ( Salton and Yang , 1973 ) proposed the combination of TF and IDF as weighting schemes , and it has been shown that their product gave better performance</definiens>
			</definition>
			<definition id="5">
				<sentence>Two ( English ) document categorization algorithms have been reported to produce best results : Support Vector Machines ( SVM ) and AdaBoost .</sentence>
				<definiendum id="0">English ) document categorization algorithms</definiendum>
				<definiens id="0">reported to produce best results : Support Vector Machines ( SVM ) and AdaBoost</definiens>
			</definition>
			<definition id="6">
				<sentence>If the similarity between NB’s performance for English and Arabic is any indication , SVM and AdaBoost should be the next candidates for application to Arabic Document categorization .</sentence>
				<definiendum id="0">Arabic</definiendum>
				<definiens id="0">any indication</definiens>
			</definition>
</paper>

		<paper id="0402">
			<definition id="0">
				<sentence>AnLVC is a verb phrase ( “kandou-o ataeta ( made an impression ) ” in ( 1s ) ) that consists of a light-verb ( “ataeta ( give-PAST ) ” ) that grammatically governs a nomi1 For each example , s denotes an input and t denotes its paraphrase .</sentence>
				<definiendum id="0">AnLVC</definiendum>
			</definition>
			<definition id="1">
				<sentence>In this paper , we propose a novel lexical semantics-based account of the LVC paraphrasing , which uses the theory of Lexical Conceptual Structure ( LCS ) of Japanese verbs ( Kageyama , 1996 ; Takeuchi et al. , 2001 ) .</sentence>
				<definiendum id="0">LVC paraphrasing</definiendum>
				<definiens id="0">uses the theory of Lexical Conceptual Structure ( LCS ) of Japanese verbs</definiens>
			</definition>
			<definition id="2">
				<sentence>This could also , however , be regarded as a combination of a simpler pattern of lexical paraphrasing ( “purchase ⇒ buy” ) and a voice activization ( “X Adjective Noun + Case particle '' no '' ( GEN ) Nominalized verb + Case particle Noun + Case Particle Adverb Light-verb ( +suffixes ) Embedded clause LVC Target of this paper ( a ) ( b ) ( c ) ( d ) ( e ) Figure 1 : Dependency structure showing the range which the LVC paraphrasing affects .</sentence>
				<definiendum id="0">Adverb Light-verb</definiendum>
				<definiens id="0">a combination of a simpler pattern of lexical paraphrasing ( “purchase ⇒ buy” ) and a voice activization ( “X Adjective Noun + Case particle '' no '' ( GEN ) Nominalized verb + Case particle Noun + Case Particle</definiens>
			</definition>
			<definition id="3">
				<sentence>An LCS consists of semantic predicates ( “CONTROL , ” “BE AT , ” etc. ) and their argument slots ( x , y , z ) .</sentence>
				<definiendum id="0">LCS</definiendum>
				<definiens id="0">consists of semantic predicates ( “CONTROL , ” “BE AT , ” etc. ) and their argument slots ( x , y , z )</definiens>
			</definition>
			<definition id="4">
				<sentence>Argument slots x , y , and z correspond to the semantic roles “Agent , ” “Theme , ” and “Goal , ” respectively .</sentence>
				<definiendum id="0">Argument slots</definiendum>
				<definiens id="0">y , and z correspond to the semantic roles “Agent , ” “Theme , ” and “Goal , ” respectively</definiens>
			</definition>
			<definition id="5">
				<sentence>4 A sahen-noun is a verbal noun in Japanese , which acts as a verb in the form of “sahen-noun + suru” .</sentence>
				<definiendum id="0">sahen-noun</definiendum>
				<definiens id="0">acts as a verb in the form of “sahen-noun + suru”</definiens>
			</definition>
			<definition id="6">
				<sentence>Verbs of obtaining ( Levin , 1993 ) : In contrast with “ataeru ( give ) , ” the nominative case of “ukeru ( receive ) ” and “eru ( acquire ) ” is the “Goal” of the “Theme , ” while the ablative case indicates “Source.”</sentence>
				<definiendum id="0">”</definiendum>
				<definiens id="0">give ) , ” the nominative case of “ukeru ( receive ) ” and “eru ( acquire )</definiens>
			</definition>
			<definition id="7">
				<sentence>Semantic transformation ( LCS transformation ) : The model then transfers the obtained semantic structure to another semantic structure so that the target structure consists of the LCS of the nominalized verb of the input .</sentence>
				<definiendum id="0">Semantic transformation ( LCS transformation )</definiendum>
				<definiens id="0">The model then transfers the obtained semantic structure to another semantic structure so that the target structure consists of the LCS of the nominalized verb of the input</definiens>
			</definition>
			<definition id="8">
				<sentence>Given an input sentence , which we assume to be a simple clause with an LVC , we first look up the LCS template LCS V0 for the given light-verb , and then apply the case assignment rule , below ( Takeuchi et ( 2 ) LCS transformation ( 3 ) Surface generation LCS dictionary [ x’ ACT ON y’ ] [ BECOME [ z BE WITH [ y MOVE FROM x TO z ] ] ] Paraphrased sentence Input sentence ukeru ( receive ) shigeki-suru ( inspire ) Ken-ga ( Ken-NOM ) eiga-ni ( film-DAT ) shigeki-o ( inspiration-ACC ) uketa ( receive-PAST ) .</sentence>
				<definiendum id="0">LCS template LCS V0</definiendum>
				<definiens id="0">for the given light-verb , and then apply the case assignment rule</definiens>
			</definition>
			<definition id="9">
				<sentence>[ [ film ] x’ ACT ON [ Ken ] y’ ] [ BECOME [ [ Ken ] z BE WITH ] ] + [ BECOME [ [ Ken ] z BE WITH [ [ inspiration ] y MOVE FROM [ film ] x TO [ Ken ] z ] ] ] [ x’ ACT ON y’ ] ( b ) Argument matching ( a ) Predicate matching ( c ) Attaching the remaining structure LCS N0 LCS N1 LCS V1 Figure 3 : LCS transformation .</sentence>
				<definiendum id="0">Argument matching</definiendum>
				<definiens id="0">LCS transformation</definiens>
			</definition>
			<definition id="10">
				<sentence>Since the example in Figure 2 satisfies the second condition , the model chooses “s-are-ru ( passive ) ” and passivizes the sentence so that “Ken” fills the nominative case .</sentence>
				<definiendum id="0">“s-are-ru</definiendum>
				<definiens id="0">( passive ) ” and passivizes the sentence so that “Ken” fills the nominative case</definiens>
			</definition>
			<definition id="11">
				<sentence>Similarly , our approach can be extended to ( i ) over-generate paraphrase candidates by considering the polysemy of not only assigned LCS types , but also that of nominalized verbs ( see ( 15s ) and ( 16s ) ) and whether the given 〈n , c , v〉 is an LVC , and ( ii ) revise or reject the incorrect candidates by using handcrafted solid rules or statistical language models .</sentence>
				<definiendum id="0">v〉</definiendum>
				<definiens id="0">whether the given 〈n , c ,</definiens>
			</definition>
</paper>

		<paper id="3249">
			<definition id="0">
				<sentence>Given a certain domain , DRE distinguishes between relevant and non-relevant texts by means of a Gaussian Mixture model that describes the frequency distribution of domain words inside a large-scale corpus .</sentence>
				<definiendum id="0">DRE</definiendum>
				<definiens id="0">describes the frequency distribution of domain words inside a large-scale corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Then , an Expectation Maximization algorithm computes the parameters that maximize the likelihood of the model on the empirical data .</sentence>
				<definiendum id="0">Expectation Maximization algorithm</definiendum>
				<definiens id="0">computes the parameters that maximize the likelihood of the model on the empirical data</definiens>
			</definition>
			<definition id="2">
				<sentence>Then , an Expectation Maximization algorithm computes the parameters that maximize the likelihood of the empirical data .</sentence>
				<definiendum id="0">Expectation Maximization algorithm</definiendum>
				<definiens id="0">computes the parameters that maximize the likelihood of the empirical data</definiens>
			</definition>
			<definition id="3">
				<sentence>DDD is an unsupervised WSD methodology that makes use of only domain information .</sentence>
				<definiendum id="0">DDD</definiendum>
				<definiens id="0">an unsupervised WSD methodology that makes use of only domain information</definiens>
			</definition>
			<definition id="4">
				<sentence>WORDNET DOMAINS is an extension of WORDNET ( version 1.6 ) ( Fellbaum , 1998 ) , in which each synset is annotated with one or more domain labels , selected from a hierarchically organized set of about two hundred labels .</sentence>
				<definiendum id="0">WORDNET DOMAINS</definiendum>
				<definiens id="0">an extension of WORDNET ( version 1.6 ) ( Fellbaum , 1998 ) , in which each synset is annotated with one or more domain labels , selected from a hierarchically organized set of about two hundred labels</definiens>
			</definition>
			<definition id="5">
				<sentence>In the rest of the paper we use the notation F ( Dk ; t ) to refer to F ( Dk ; t ; m ) , where m is the integer part of q=2 ( i.e. the central point of the text q is the text length ) .</sentence>
				<definiendum id="0">m</definiendum>
			</definition>
			<definition id="6">
				<sentence>The domain relevance function for a word R : D V ) [ 0 ; 1 ] is de ned as follows : Rword ( Di ; w ) = 1jsenses ( w ) j X s2senses ( w ) Rsyn ( Di ; s ) ( 3 ) 3P ( D ) denotes the power set of D As explained at the beginning of this section , the simple local frequency count expressed by formula ( 1 ) is not a good domain relevance measure .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">D )</definiendum>
				<definiens id="0">the power set of D As explained at the beginning of this section , the simple local frequency count expressed by formula ( 1 ) is not a good domain relevance measure</definiens>
			</definition>
			<definition id="7">
				<sentence>The Gaussian Mixture approach consists of a parameter estimation technique based on statistics of word distribution in a large-scale corpus .</sentence>
				<definiendum id="0">Gaussian Mixture approach</definiendum>
				<definiens id="0">consists of a parameter estimation technique based on statistics of word distribution in a large-scale corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>The goal of the technique is to estimate parameters describing the distribution of the noise along texts , in order to as4The British National Corpus is a very large ( over 100 million words ) corpus of modern English , both spoken and written .</sentence>
				<definiendum id="0">Corpus</definiendum>
				<definiens id="0">a very large ( over 100 million words</definiens>
			</definition>
			<definition id="9">
				<sentence>DDD is a WSD methodology that only makes use of domain information .</sentence>
				<definiendum id="0">DDD</definiendum>
				<definiens id="0">a WSD methodology that only makes use of domain information</definiens>
			</definition>
			<definition id="10">
				<sentence>The DDD methodology is performed basically in three steps : biguated score ( s ; w ; t ) = P ( sjw ) sim ( ~s ; ~t ) P s2Senses ( w ) P ( sjw ) sim ( ~s ; ~t ) threshold ) select sense ^s , else do not provide any answer The similarity metric used is the cosine vector similarity , which takes into account only the direction of the vector ( i.e. the information regarding the domain ) .</sentence>
				<definiendum id="0">metric used</definiendum>
				<definiens id="0">takes into account only the direction of the vector ( i.e. the information regarding the domain</definiens>
			</definition>
</paper>

		<paper id="0608">
			<definition id="0">
				<sentence>Proteus is a collaborative initiative of French , German and Belgium companies , universities and research institutes aimed at developing a European generic software platform usable for implementation of web-based e-maintenance centers .</sentence>
				<definiendum id="0">Proteus</definiendum>
				<definiens id="0">a collaborative initiative of French , German and Belgium companies , universities and research institutes aimed at developing a European generic software platform usable for implementation of web-based e-maintenance centers</definiens>
			</definition>
			<definition id="1">
				<sentence>Besides , XML enables easy human readability as well as efficient machine interpretability .</sentence>
				<definiendum id="0">XML</definiendum>
			</definition>
			<definition id="2">
				<sentence>RDF ( Resource Description Framework ) and OWL ( Web Ontology Language ) build upon the XML syntax to describe the actual semantics of a document and provide useful reasoning and inference mechanisms .</sentence>
				<definiendum id="0">RDF</definiendum>
				<definiens id="0">OWL ( Web Ontology Language ) build upon the XML syntax to describe the actual semantics of a document and provide useful reasoning and inference mechanisms</definiens>
			</definition>
			<definition id="3">
				<sentence>Server 1Server 2Server 3 AnnoteaRDF TEI/XML DocTEI/XML Doc TEI/XML Doc Header Body Header Body Header Body Figure 2.1 : Simplified view of the distributed document server architecture The e-Doc server consists of several functional layers that inter-communicate and holistically , serve the cumulative purpose of document management .</sentence>
				<definiendum id="0">e-Doc server</definiendum>
			</definition>
			<definition id="4">
				<sentence>This layer forms an integral part of the e-Doc server as it enables annotation capability and RDFdescribable semantics to the actively retrieved document or existing documents in the server [ 7 ] .</sentence>
				<definiendum id="0">RDFdescribable</definiendum>
				<definiens id="0">an integral part of the e-Doc server as it enables annotation capability</definiens>
			</definition>
			<definition id="5">
				<sentence>Annotations can have many distinguishing properties , which can be broadly classified as : • Physical location : An annotation can be stored locally or on one or more annotation servers ; • Scope : An annotation can be associated with a document as a whole or to a sub-portion of a document .</sentence>
				<definiendum id="0">Scope</definiendum>
				<definiens id="0">An annotation can be stored locally or on one or more annotation servers ; •</definiens>
			</definition>
			<definition id="6">
				<sentence>OWL provides formal mechanisms for describing ontology of documents .</sentence>
				<definiendum id="0">OWL</definiendum>
				<definiens id="0">provides formal mechanisms for describing ontology of documents</definiens>
			</definition>
			<definition id="7">
				<sentence>Monolinguality specifies a one to one relation between a term and a concept or a term to its equivalences or a term to the related documents , while multilinguality specifies relation between term to certain target terms or term to certain target documents .</sentence>
				<definiendum id="0">Monolinguality</definiendum>
				<definiens id="0">specifies a one to one relation between a term and a concept or a term to its equivalences or a term to the related documents</definiens>
			</definition>
			<definition id="8">
				<sentence>Terminological model serves as a gateway to the Ontology-based Conceptual model of the domain ( Figure lates to set of relevant concepts , which can further be used to retrieve the desired set of documents .</sentence>
				<definiendum id="0">Terminological model</definiendum>
				<definiens id="0">a gateway to the Ontology-based Conceptual model of the domain ( Figure lates to set of relevant concepts</definiens>
			</definition>
			<definition id="9">
				<sentence>The three layers consist of General concepts ( General Maintenance Ontology ) , Application Profiles , and the industrial contexts respectively .</sentence>
				<definiendum id="0">three layers</definiendum>
				<definiens id="0">consist of General concepts ( General Maintenance Ontology ) , Application Profiles , and the industrial contexts respectively</definiens>
			</definition>
			<definition id="10">
				<sentence>The second layer ( Application Profiles ) consists of concepts , which are specific to a certain application , for instance pertinent to a train manufacturing company , or an aviation company .</sentence>
				<definiendum id="0">Application Profiles )</definiendum>
				<definiens id="0">consists of concepts , which are specific to a certain application</definiens>
			</definition>
			<definition id="11">
				<sentence>C e Conceptual system E-Doc Operator dedicated to one single site Maintenance doc ( including needed tools ) , Parameters setting , User manual of this List of available maintenance docs , parameters setting , user manual portal Figure 4.9 : Visual search of documents via ontology The various models ( terminology , annotations , etc. ) and functionalities ( access primitives to an e-doc server ) have to be defined in such a way that a similar piece of information ( e.g. author , subject field , term , etc. ) means the same thing from one place to another .</sentence>
				<definiendum id="0">Conceptual system E-Doc Operator</definiendum>
				<definiens id="0">terminology , annotations , etc. ) and functionalities ( access primitives to an e-doc server</definiens>
			</definition>
</paper>

		<paper id="0411">
			<definition id="0">
				<sentence>Multiword Expressions ( MWEs ) can be defined as idiosyncratic interpretations that cross word boundaries ( or spaces ) ( from Sag et al. ( 2002 ) .</sentence>
				<definiendum id="0">Multiword Expressions</definiendum>
				<definiendum id="1">MWEs</definiendum>
			</definition>
			<definition id="1">
				<sentence>That is the case of the LinGO ERG ( Copestake and Flickinger , 2000 ) lexicon , which adopts for its database version , a compatible but more complex encoding which is successfully used to describe simplex words ( Copestake et al. , 2004 ) .</sentence>
				<definiendum id="0">LinGO ERG</definiendum>
			</definition>
			<definition id="2">
				<sentence>A great part of the idioms in this sample seems to form natural classes that follow similar patterns ( e.g. the class of verb-object idioms , where an idiom consists of a specific verb that takes a specific object such as rock boat and spill beans ) .</sentence>
				<definiendum id="0">great part of the idioms</definiendum>
				<definiens id="0">form natural classes that follow similar patterns ( e.g. the class of verb-object idioms , where an idiom consists of a specific verb that takes a specific object such as rock boat and spill beans )</definiens>
			</definition>
			<definition id="3">
				<sentence>In this approach , each idiomatic component of an idiom could be defined as a separate entry similar to that of a simplex word , except that it would also be possible to specify a paraphrase for its meaning .</sentence>
				<definiendum id="0">idiomatic component of an idiom</definiendum>
			</definition>
			<definition id="4">
				<sentence>Thus , a sentence like He threw the cat among the pigeons has a possible idiomatic interpretation available , but this interpretation is not available in a sentence like He held the cat and she threw the bread among the pigeons , even though it has all the obligatory elements for the idiom ( throw , cat , among , pigeons ) , because cat did not occur as a semantic argument ( the agent ) of throw .</sentence>
				<definiendum id="0">throw</definiendum>
				<definiens id="0">a semantic argument ( the agent ) of throw</definiens>
			</definition>
			<definition id="5">
				<sentence>Likewise , this prevents idiomatic entries from being used outside the context of the MWE ( e.g. the idiomatic spill being interpreted as reveal in spill some water ) .</sentence>
				<definiendum id="0">MWE ( e.g.</definiendum>
				<definiens id="0">the idiomatic spill being interpreted as reveal in spill some water )</definiens>
			</definition>
</paper>

		<paper id="2328">
			<definition id="0">
				<sentence>The ICSI-MR corpus consists of 75 one-hour recordings of sta meetings , each involving up to eight speakers on separate mike channels .</sentence>
				<definiendum id="0">ICSI-MR corpus</definiendum>
				<definiens id="0">consists of 75 one-hour recordings of sta meetings , each involving up to eight speakers on separate mike channels</definiens>
			</definition>
			<definition id="1">
				<sentence>We use a Maximum Entropy ( ME ) classi er ( Manning and Klein , 2003 ) which allows an e cient combination of many overlapping features .</sentence>
				<definiendum id="0">Maximum Entropy</definiendum>
				<definiens id="0">allows an e cient combination of many overlapping features</definiens>
			</definition>
</paper>

		<paper id="2327">
			<definition id="0">
				<sentence>The scheme has served as the basis for a number of annotation projects , such as the development of the GNOME corpus ( Poesio , 2000a ) and , more recently , of the VENEX corpus of anaphora in Italian spoken dialogue and text ( Poesio et al. , 2004a ) .</sentence>
				<definiendum id="0">GNOME corpus</definiendum>
			</definition>
			<definition id="1">
				<sentence>The design of an annotation scheme involves a number of decisions : what has to be annotated , how , and how the annotation should be recorded ( the markup scheme ) .</sentence>
				<definiendum id="0">design of an annotation scheme</definiendum>
				<definiens id="0">involves a number of decisions : what has to be annotated</definiens>
			</definition>
			<definition id="2">
				<sentence>As van Deemter and Kibble ( 2000 ) point out , however , the result is rather ad hoc ; the IDENT relation as defined by the instructions doesn’t capture any coherent definition of ‘coreference’ .</sentence>
				<definiendum id="0">IDENT relation</definiendum>
				<definiens id="0">the instructions doesn’t capture any coherent definition of ‘coreference’</definiens>
			</definition>
			<definition id="3">
				<sentence>The main difference from MUCCS is that whereas in MUCCS anaphoric relations are annotated using an attribute of the markables , in the MATE markup scheme– following the recommendations of the Text Encoding Initiative ( Burnard and Sperberg-McQueen , 2002 ) , and of Bruneseaux and Romary ( 1998 ) –the distinction between these two steps of annotation is mirrored by a distinction between two XML elements : 〈de〉 , used to indicate the markables , and 〈link〉 , used to mark information about anaphoric relations ( or any other semantic relation ) .3 However , unlike in the TEI proposals , in the MATE markup scheme 〈link〉 elements are structured elements , containing one or more 〈anchor〉 element .</sentence>
				<definiendum id="0">Text Encoding Initiative</definiendum>
				<definiens id="0">〈de〉 , used to indicate the markables</definiens>
			</definition>
			<definition id="4">
				<sentence>The 〈link〉 element specifies the anaphoric expression ( using XML’sHREFmechanism ) and the relation between the anaphoric expression and its antecedent ; whereas the 〈anchor〉 element specifies the antecedent , as in ( 1 ) where , for example , the first 〈link〉 elements encodes the information that the discourse entities realized by the NPs the engine E3 and it denote the same object .</sentence>
				<definiendum id="0">〈link〉 element</definiendum>
				<definiens id="0">specifies the anaphoric expression ( using XML’sHREFmechanism ) and the relation between the anaphoric expression</definiens>
				<definiens id="1">the information that the discourse entities realized by the NPs the engine E3 and it denote the same object</definiens>
			</definition>
			<definition id="5">
				<sentence>This types of anaphora can be annotated in the MATE markup scheme using additional relations , as in ( 3 ) , where the discourse entity realized by LES FUSEES QUI ONT BIEN VOLE‘ denotes a subset of the set denoted by discourse entity DE 88 , LES MODELES DE FUSEES .</sentence>
				<definiendum id="0">LES FUSEES QUI ONT BIEN VOLE‘</definiendum>
				<definiens id="0">a subset of the set denoted by discourse entity DE 88 , LES MODELES DE FUSEES</definiens>
			</definition>
			<definition id="6">
				<sentence>The museum subcorpus consists of descriptions of museum objects , generally with an associated picture , and brief texts about the artists that produced them .</sentence>
				<definiendum id="0">museum subcorpus</definiendum>
				<definiens id="0">consists of descriptions of museum objects , generally with an associated picture , and brief texts about the artists that produced them</definiens>
			</definition>
			<definition id="7">
				<sentence>The pharmaceutical subcorpus is a selection of leaflets providing the patients with legally mandatory information about their medicine .</sentence>
				<definiendum id="0">pharmaceutical subcorpus</definiendum>
			</definition>
			<definition id="8">
				<sentence>Secondly , in this project we are attempting to identify markables automatically as far a possible , and data are stored in a standoff format , using a modern annotation tool ( MMAX ) for the annotation .</sentence>
				<definiendum id="0">MMAX</definiendum>
				<definiens id="0">far a possible , and data are stored in a standoff format , using a modern annotation tool</definiens>
			</definition>
			<definition id="9">
				<sentence>While having multiple paths is not a problem as far as evaluating the results of an anaphoric resolver ( any path in the graph counts as a valid solution ) , it is a serious problems both for scripts attempting to ensure consistency ( e.g. , that all references to the same object are marked as either generic or non-generic– this is of course impossible when one of the possible antecedents is generic while the other isn’t ) as well for annotation tools ( the problem is of course worsened when the tool only uses a single attribute to indicate membership in a coreference chain ) .</sentence>
				<definiendum id="0">anaphoric resolver</definiendum>
				<definiens id="0">a serious problems both for scripts attempting to ensure consistency ( e.g. , that all references to the same object</definiens>
			</definition>
</paper>

		<paper id="3229">
			<definition id="0">
				<sentence>Because Russian is a highly inflected language with a high degree of morpheme homonymy ( cf. Table 11 ) the tags involved are more numerous and elaborate than those typically used for English .</sentence>
				<definiendum id="0">Russian</definiendum>
				<definiens id="0">a highly inflected language with a high degree of morpheme homonymy</definiens>
			</definition>
			<definition id="1">
				<sentence>TnT records some lexical information in the emission probabilities of its second order Markov Model .</sentence>
				<definiendum id="0">TnT</definiendum>
				<definiens id="0">records some lexical information in the emission probabilities of its second order Markov Model</definiens>
			</definition>
			<definition id="2">
				<sentence>A paradigm is a set of endings and POS tags that can go with a particular set of stems .</sentence>
				<definiendum id="0">paradigm</definiendum>
				<definiens id="0">a set of endings and POS tags that can go with a particular set of stems</definiens>
			</definition>
			<definition id="3">
				<sentence>Instead we select the best tag from those offered by our morphological analyzer using the following formula : ( 6 ) bestTag = argmaxt∈TMAval ( t ) TMA – the set of tags offered by MA val ( t ) =summationtext14k=0 Nk ( t ) /Nk Nk ( t ) – # of taggers voting for k-th slot of t Nk – the total # of taggers on slot k That means , that the best tag is the tag that received the highest average percentage of votes for each of full-tag all best 1 best 3 overall 69.5 70.3 70.7 71.1 1 ( P ) 89.0 88.9 89.1 89.2 2 ( S ) 86.6 86.5 86.9 86.9 3 ( g ) 81.4 81.8 83.0 83.2 4 ( n ) 92.4 92.6 93.1 93.2 5 ( c ) 80.9 82.1 83.0 83.2 6 ( G ) 98.5 98.5 98.7 98.7 7 ( N ) 99.6 99.7 99.8 99.8 8 ( p ) 98.3 98.2 98.4 98.3 9 ( t ) 97.0 97.0 97.0 97.0 10 ( G ) 96.0 96.0 96.0 96.0 11 ( a ) 97.0 97.0 96.9 97.0 12 ( v ) 97.4 97.3 97.5 97.4 15 ( V ) 99.1 99.1 99.0 99.0 Table 6 : Combining sub-taggers ( development data ) Baseline Direct Russified Russified Tagger random full-tag full-tag voting Accuracy Tags 33.6 69.4 72.6 73.5 1 ( POS ) 63.2 88.5 90.1 90.4 2 ( SubPOS ) 57.0 86.8 88.1 88.6 3 ( Gender ) 59.2 82.5 84.5 85.0 4 ( Number ) 75.9 91.2 92.6 93.4 5 ( Case ) 47.3 80.4 84.1 85.3 6 ( PossGen ) 83.4 98.4 98.8 99.0 7 ( PossNr ) 99.6 99.6 99.6 99.8 8 ( Person ) 97.1 99.3 98.9 98.9 9 ( Tense ) 86.6 96.5 97.6 97.6 10 ( Grade ) 90.1 95.9 96.6 96.6 11 ( Neg ) 81.4 95.3 95.5 95.5 12 ( Voice ) 86.4 97.2 97.9 97.9 15 ( Variant ) 97.0 99.1 99.5 99.5 Table 7 : Tagging with various parameters ( test data ) its slots .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">POS</definiendum>
				<definiens id="0">the best tag from those offered by our morphological analyzer using the following formula : ( 6 ) bestTag = argmaxt∈TMAval ( t ) TMA – the set of tags offered by MA val ( t ) =summationtext14k=0 Nk ( t ) /Nk Nk ( t ) – # of taggers voting for k-th slot of t Nk – the total # of taggers on slot k That means , that the best tag is the tag that received the highest average percentage</definiens>
				<definiens id="1">Combining sub-taggers ( development data</definiens>
			</definition>
</paper>

		<paper id="3011">
			<definition id="0">
				<sentence>CYBERPUNC : a lightweight punctuation annotation system for speech .</sentence>
				<definiendum id="0">CYBERPUNC</definiendum>
				<definiens id="0">a lightweight punctuation annotation system for speech</definiens>
			</definition>
			<definition id="1">
				<sentence>Verbmobil : the use of prosody in the linguistic components of a speech understanding system .</sentence>
				<definiendum id="0">Verbmobil</definiendum>
				<definiens id="0">the use of prosody in the linguistic components of a speech understanding system</definiens>
			</definition>
</paper>

		<paper id="2312">
			<definition id="0">
				<sentence>Existing spoken language understanding systems , that are not shallow and thusly produce deep syntactic and semantic representations for multiple domains , e.g. the production system approach described by Engel ( 2002 ) or unification-based approaches described by Crysmann et al. ( 2002 ) , have shown to be more suitable for well-formed input but less robust in case of imperfect input .</sentence>
				<definiendum id="0">Existing spoken language understanding systems</definiendum>
				<definiens id="0">not shallow and thusly produce deep syntactic and semantic representations for multiple domains</definiens>
			</definition>
			<definition id="1">
				<sentence>Word graphs : An efficient interface between continuousspeech recognition and language understanding .</sentence>
				<definiendum id="0">Word graphs</definiendum>
			</definition>
			<definition id="2">
				<sentence>Word Sense Disambiguation : The Case for Combining Knowldge Sources .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
			</definition>
</paper>

		<paper id="0853">
			<definition id="0">
				<sentence>Hyper-Desc ( a8 ) glosses denotes concatenating descriptive glosses all the way upto the root .</sentence>
				<definiendum id="0">Hyper-Desc ( a8 )</definiendum>
				<definiens id="0">glosses denotes concatenating descriptive glosses all the way upto the root</definiens>
			</definition>
			<definition id="1">
				<sentence>The inverse gloss frequency ( igf ) of a token is the inverse of the number of glosses which contain that token and it captures the “commonness” of that particular token .</sentence>
				<definiendum id="0">inverse gloss frequency</definiendum>
				<definiens id="0">the inverse of the number of glosses which contain that token and it captures the “commonness” of that particular token</definiens>
			</definition>
			<definition id="2">
				<sentence>This method is also more reliable since the igf values come from WordNet which is very exhaustive , unlike sense tagged corpora ( like SemCor ) which will have bias and data-sparsity in terms of which words occur in the corpus and which sense is picked for a word .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">data-sparsity in terms of which words occur in the corpus and which sense is picked for a word</definiens>
			</definition>
			<definition id="3">
				<sentence>PrRank1 and PrRank2 ( precision at rank 1 and 2 respectively ) denote the percentage of cases where the highest scoring sense is the correct sense or one of first two highest scoring senses is the correct sense , respectively .</sentence>
				<definiendum id="0">sense</definiendum>
				<definiens id="0">precision at rank 1 and 2 respectively ) denote the percentage of cases where the highest scoring</definiens>
			</definition>
			<definition id="4">
				<sentence>Stemming ST ContextSize ( in number of sentences ) WS FullContextExpansion FG POS P PrRank1 ( % ) R1 PrRank2 ( % ) R2 Table 1 : List of acronyms used For the Senseval task , we employed hypernym glosses .</sentence>
				<definiendum id="0">Stemming ST ContextSize</definiendum>
				<definiens id="0">in number of sentences</definiens>
			</definition>
</paper>

		<paper id="1105">
			<definition id="0">
				<sentence>Generally , Chinese Lexical Analysis consists of two phases ; one is word segmentation and the other is part-of-speech ( POS ) tagging .</sentence>
				<definiendum id="0">Chinese Lexical Analysis</definiendum>
			</definition>
			<definition id="1">
				<sentence>A probabilistic model of word segmentation and POS tagging can be regarded as an instance of Machine Learning .</sentence>
				<definiendum id="0">probabilistic model of word segmentation</definiendum>
				<definiendum id="1">POS tagging</definiendum>
			</definition>
			<definition id="2">
				<sentence>Here , a Chinese word segmentation and POS tagging system is viewed as with input , nCCC , ... , , 21 where Ci is the i'th Chinese character of the input sentence , and with output pairs , ( nm ≤ )             m m T L T L T L , ... , 2 2 1 1 where Li is the word length of the i’th word in the segmented word sequence , Ti is the word tag , and each ( Li , Ti ) pair is corresponding to a segmented and tagged word , and ∑ = = m i ni 1 .</sentence>
				<definiendum id="0">Ci</definiendum>
				<definiendum id="1">Li</definiendum>
				<definiendum id="2">Ti</definiendum>
				<definiens id="0">the i'th Chinese character of the input sentence , and with output pairs</definiens>
				<definiens id="1">the word length of the i’th word in the segmented word sequence</definiens>
				<definiens id="2">the word tag , and each ( Li , Ti ) pair is corresponding to a segmented and tagged word , and ∑ = = m i ni 1</definiens>
			</definition>
			<definition id="3">
				<sentence>.2.2 For ) ( CP is a constant given a C , we just need to consider ) ) , ( | ( TLCP and ) , ( TLP .</sentence>
				<definiendum id="0">CP</definiendum>
				<definiens id="0">a constant given a</definiens>
			</definition>
			<definition id="4">
				<sentence>The algorithm to implement this model is also rather simple , and using Dynamic Programming , we could finish the algorithm in O ( cn ) , where n is the length of input sentence , and c is a constant related to the maximum ambiguity in a position .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">the length of input sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>Named Entity Recognition is one of the most important parts of word segmentation and POS tagging systems , for the words in word list are limited while the language seems infinite .</sentence>
				<definiendum id="0">Named Entity Recognition</definiendum>
				<definiendum id="1">POS tagging systems</definiendum>
				<definiens id="0">one of the most important parts of word segmentation</definiens>
			</definition>
			<definition id="6">
				<sentence>That paper defined the probability for a Chinese Human Name as : ) ( * ) ( ) | ( kEiFiknsP = ... ... ... ... ... ... ... ... ... .3.2 ) ( * ) ( * ) ( ) | ( kEjMiFijknpP = ... ... ... ... .3.3 Where each one of “i” , “j” , “k” represents a single Chinese characters , “ik ” , “ijk” are the strings which may be a human name , “ns” means a single name when “j” is empty , “np” means plural name when “j” is not empty , F ( i ) is the probability of “i” being a family name , M ( j ) means the probability of “j” being the middle character of a human name , E ( k ) means the probability of “k” being the tailing character of a human name , P ( ns | ik ) is the probability of “ik ” being a single name , and P ( np | ijk ) is the probability of “ijk ” being a plural name .</sentence>
				<definiendum id="0">F ( i )</definiendum>
				<definiens id="0">the probability for a Chinese Human Name as : ) ( * ) ( ) | ( kEiFiknsP = ... ... ... ... ... ... ... ... ... .3.2 ) ( * ) ( * ) ( ) | ( kEjMiFijknpP = ... ... ... ... .3.3 Where each one of “i” , “j” , “k” represents a single Chinese characters , “ik ”</definiens>
				<definiens id="1">the strings which may be a human name , “ns” means a single name when “j” is empty , “np” means plural name when “j” is not empty ,</definiens>
				<definiens id="2">the probability of “i” being a family name , M ( j ) means the probability of “j” being the middle character of a human name , E ( k ) means the probability of “k” being the tailing character of a human name , P ( ns | ik ) is the probability of “ik ” being a single name , and P ( np | ijk ) is the probability of “ijk ” being a plural name</definiens>
			</definition>
			<definition id="7">
				<sentence>However , P ( ns | ik ) and P ( np | ijk ) do not satisfy the requirements of the word length introduced model .</sentence>
				<definiendum id="0">P (</definiendum>
				<definiens id="0">ns | ik ) and P ( np | ijk ) do not satisfy the requirements of the word length introduced model</definiens>
			</definition>
			<definition id="8">
				<sentence>The model needs probabilit ies like ) ) , ( | ( tlwP , where w is a word , t is a word tag , and l is the word length .</sentence>
				<definiendum id="0">w</definiendum>
				<definiendum id="1">l</definiendum>
				<definiens id="0">a word tag , and</definiens>
			</definition>
			<definition id="9">
				<sentence>P ( nh , 2 ) , P ( i ) , P ( k ) are easy to retrieve , which represent the probability of a 2charactered human name , the probability of character “i” and the probability of character “k” .</sentence>
				<definiendum id="0">P ( k</definiendum>
				<definiens id="0">represent the probability of a 2charactered human name , the probability of character “i” and the probability of character “k”</definiens>
			</definition>
			<definition id="10">
				<sentence>WSA ( by word ) : Word Segmentation Accuracy , measured by recall , i.e. the number of correct segments divided by the number of segments in corpus .</sentence>
				<definiendum id="0">WSA</definiendum>
				<definiens id="0">by word ) : Word Segmentation Accuracy , measured by recall , i.e. the number of correct segments divided by the number of segments in corpus</definiens>
			</definition>
			<definition id="11">
				<sentence>PTA ( by word ) : POS Tagging Accuracy based on correct segmentation , the number of words that are correctly segmented and tagged divided by the number of words that are correctly segmented .</sentence>
				<definiendum id="0">PTA</definiendum>
				<definiens id="0">the number of words that are correctly segmented and tagged divided by the number of words that are correctly segmented</definiens>
			</definition>
			<definition id="12">
				<sentence>WSA ( by sentence ) : the number of correctly segmented sentences divided by the number of sentences in corpus .</sentence>
				<definiendum id="0">WSA</definiendum>
				<definiens id="0">the number of correctly segmented sentences divided by the number of sentences in corpus</definiens>
			</definition>
			<definition id="13">
				<sentence>A correctly segmented sentence is a sentence whose words are all correctly segmented .</sentence>
				<definiendum id="0">correctly segmented sentence</definiendum>
			</definition>
			<definition id="14">
				<sentence>PTA ( by sentence ) : the number of correctly tagged sentences divided by the number of correctly segmented sentences in corpus .</sentence>
				<definiendum id="0">PTA</definiendum>
				<definiens id="0">the number of correctly tagged sentences divided by the number of correctly segmented sentences in corpus</definiens>
			</definition>
			<definition id="15">
				<sentence>A correctly tagged sentence is a sentence whose words are all correctly segmented and tagged .</sentence>
				<definiendum id="0">correctly tagged sentence</definiendum>
				<definiens id="0">a sentence whose words are all correctly segmented and tagged</definiens>
			</definition>
</paper>

		<paper id="0209">
			<definition id="0">
				<sentence>The Spanish corpus Cast3LB is a part of the CLIC-TALP corpus , which is made up of 100.000 words from the LexEsp corpus ( Sebasti´an et al. , 2000 ) plus 25.000 words coming from the EFE Spanish Corpus , given by the Agencia EFE ( the official news agency ) for research purposes .</sentence>
				<definiendum id="0">Spanish corpus Cast3LB</definiendum>
				<definiendum id="1">CLIC-TALP corpus</definiendum>
				<definiendum id="2">LexEsp corpus</definiendum>
				<definiendum id="3">Agencia EFE</definiendum>
				<definiens id="0">a part of the</definiens>
				<definiens id="1">Sebasti´an et al. , 2000 ) plus 25.000 words coming from the EFE Spanish Corpus , given by the</definiens>
			</definition>
			<definition id="1">
				<sentence>EuroWordNet synsets are the base of the semantic information added to the resolution process .</sentence>
				<definiendum id="0">EuroWordNet synsets</definiendum>
				<definiens id="0">the base of the semantic information added to the resolution process</definiens>
			</definition>
			<definition id="2">
				<sentence>Due to the pronoun replaces a lexical word ( the antecedent ) , the semantic information of the antecedent must be compatible with the semantic restrictions of the verb .</sentence>
				<definiendum id="0">lexical word</definiendum>
				<definiens id="0">the antecedent ) , the semantic information of the antecedent must be compatible with the semantic restrictions of the verb</definiens>
			</definition>
			<definition id="3">
				<sentence>Main features of this tool are : † it is word-oriented , † it allows different format for input corpus ; basically , the main formats used in corpus annotation : treebank format ( TBF ) and XML format ; † it uses EuroWordNet as a lexical resource .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">formats used in corpus annotation : treebank format</definiens>
			</definition>
</paper>

		<paper id="0412">
			<definition id="0">
				<sentence>In section 4 , we define our own phrases ( maximal frequent sequences ) and explain how they will be better document descriptors than those found in the state of the art .</sentence>
				<definiendum id="0">own phrases</definiendum>
				<definiens id="0">maximal frequent sequences ) and explain how they will be better document descriptors than those found in the state of the art</definiens>
			</definition>
			<definition id="1">
				<sentence>To calculate this weight , we use a tfnormalized version of the “tfc” term-weighted components as described by Salton and Buckley ( 1988 ) , i.e. : tfidfw = tfw ·log N nw max ( tf ) · radicalbiggsummationtext wi∈W parenleftBig tfwi ·log Nnw i parenrightBig2 , where tfw is the term frequency of the word w. N is the total number of documents in the collection and nw the number of documents in which w occurs .</sentence>
				<definiendum id="0">tfw</definiendum>
				<definiens id="0">the term frequency of the word w. N is the total number of documents in the collection and nw the number of documents in which w occurs</definiens>
			</definition>
			<definition id="2">
				<sentence>Note that from here onwards , keyphrase denotes a phrase found in a query , and maximal sequence denotes a phrase extracted from a document .</sentence>
				<definiendum id="0">keyphrase</definiendum>
				<definiens id="0">denotes a phrase found in a query , and maximal sequence denotes a phrase extracted from a document</definiens>
			</definition>
			<definition id="3">
				<sentence>We define the quantity of relevance of the pair AiAj to be : Qrel ( AiAj ) = idf ( AiAj , D ) ·adj ( AiAj ) , where idf ( AiAj , D ) represents the specificity of AiAj in collection D : idf ( AiAj , D ) = log parenleftbiggN n parenrightbigg , and when decomposing the keyphrase A1 ... Am into pairs , adj ( AiAj ) is a score modifier to penalize word pairs AiAj formed from non-adjacent words , and d ( Ai , Aj ) indicates the number of words appearing between the two words Ai and Aj ( d ( Ai , Aj ) = 0 signifies that Ai and Aj are adjacent ) : adj ( AiAj ) =    1 , if d ( Ai , Aj ) = 0 α1 , 0 ≤ α1 ≤ 1 , if d ( Ai , Aj ) = 1 α2 , 0 ≤ α2 ≤ α1 if d ( Ai , Aj ) = 2 ... αm−2 , 0 ≤ αm−2 ≤ αm−3 , if d ( Ai , Aj ) = m−2 Accordingly , the larger the distance between the two words , the lower a quantity of relevance is attributed to the corresponding pair .</sentence>
				<definiendum id="0">idf ( AiAj , D )</definiendum>
				<definiendum id="1">adj</definiendum>
				<definiens id="0">a score modifier to penalize word pairs AiAj formed from non-adjacent words</definiens>
			</definition>
			<definition id="4">
				<sentence>idf ( AC ) d3 AFB AF FB AB AB idf ( AB ) d4 ABC AB BC AC AB BC AC idf ( AB ) + idf ( BC ) + α1 .</sentence>
				<definiendum id="0">idf</definiendum>
				<definiendum id="1">AFB AF FB AB AB idf</definiendum>
				<definiens id="0">d4 ABC AB BC AC AB BC AC idf ( AB ) + idf ( BC ) + α1</definiens>
			</definition>
</paper>

		<paper id="0713">
			<definition id="0">
				<sentence>In ( 2 ) the antecedent of the second occurrence of the pronoun hun ( she ) is the object vores nabo ( our neighbour ) which provides the information requested in the preceding question .</sentence>
				<definiendum id="0">pronoun hun ( she )</definiendum>
				<definiens id="0">the object vores nabo ( our neighbour ) which provides the information requested in the preceding question</definiens>
			</definition>
			<definition id="1">
				<sentence>dar follows the es00 and phora strategy of discriminating between IPAs and APAs by rules looking at the semantic constraints on the predication contexts in which the anaphors occur .</sentence>
				<definiendum id="0">dar</definiendum>
				<definiens id="0">follows the es00 and phora strategy of discriminating between IPAs and APAs by rules looking at the semantic constraints on the predication contexts in which the anaphors occur</definiens>
			</definition>
			<definition id="2">
				<sentence>dar consists of two different functions ResolveDet and ResolveIpa .</sentence>
				<definiendum id="0">dar</definiendum>
				<definiens id="0">consists of two different functions ResolveDet and ResolveIpa</definiens>
			</definition>
			<definition id="3">
				<sentence>The former is applied if the actual pronoun x is third person singular neuter , while the latter is applied in all the remaining cases : if x is singular &amp; neuter then go to ResolveDet ( x ) else go to ResolveIpa ( x ) ResolveIpa takes the IPA x as argument and looks for possible antecedents in the Ilist for the preceding Un−1 or Sm−1 , after having applied syntactic constraints and selectional restrictions on the elements of the list .</sentence>
				<definiendum id="0">ResolveIpa</definiendum>
				<definiens id="0">the preceding Un−1 or Sm−1 , after having applied syntactic constraints and selectional restrictions on the elements of the list</definiens>
			</definition>
			<definition id="4">
				<sentence>If no antecedent has been found ( case A ) , ResolveIpa looks for the highest ranked antecedent in recency order in the Ilists of the preceding discourse .</sentence>
				<definiendum id="0">ResolveIpa</definiendum>
				<definiens id="0">looks for the highest ranked antecedent in recency order in the Ilists of the preceding discourse</definiens>
			</definition>
			<definition id="5">
				<sentence>ResolveDet tests the pronoun x using the IPA and APA discriminating rules discussed in section 3 .</sentence>
				<definiendum id="0">ResolveDet</definiendum>
			</definition>
			<definition id="6">
				<sentence>ResolveApa distinguishes between types of pronoun .</sentence>
				<definiendum id="0">ResolveApa</definiendum>
				<definiens id="0">distinguishes between types of pronoun</definiens>
			</definition>
			<definition id="7">
				<sentence>U2 is an I/A thus it belongs to two synchronising units ( SU1 and SU2 ) .</sentence>
				<definiendum id="0">U2</definiendum>
				<definiens id="0">an I/A thus it belongs to two synchronising units</definiens>
			</definition>
			<definition id="8">
				<sentence>ResolveIpa resolves the occurrence of the pronoun hun ( she ) in U3 to the most salient candidate NP in the Ilist , vores nabo .</sentence>
				<definiendum id="0">ResolveIpa</definiendum>
				<definiens id="0">resolves the occurrence of the pronoun hun ( she ) in U3 to the most salient candidate NP in the Ilist , vores nabo</definiens>
			</definition>
			<definition id="9">
				<sentence>Ilist : [ ] Alist : [ det=U1 ] Figure 5 : Ilists and Alists for example ( 5 ) mon gender singular NPs in the Ilist , musemarkøren ( the mouse cursor ) and skærmen ( the screen ) .</sentence>
				<definiendum id="0">Ilist</definiendum>
				<definiens id="0">the screen )</definiens>
			</definition>
			<definition id="10">
				<sentence>Precision indicates the proportion of the resolved pronouns which are correctly resolved , while recall indicates the proportion of all pronouns resolved by humans which are correctly resolved by the algorithm .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">indicates the proportion of the resolved pronouns which are correctly resolved</definiens>
				<definiens id="1">the proportion of all pronouns resolved by humans which are correctly resolved by the algorithm</definiens>
			</definition>
			<definition id="11">
				<sentence>precis recall 63 87 77 72.41 81.82 Table 3 : Results of dar on texts results of applying dar and es00 on Danish dialogues are reported in table 4.11 In the last colum the overall performance of the two algorithms is given as f-measure ( F ) which is defined as 1α 1 P + ( 1−α ) 1 R where P is precision , R is recall and α is the weight of P and R. We have assigned the same weight to P and R ( α = 0.5 ) and thus F = 2PRP+R. The results of the tests indicate that dar resolves IPAs significantly better than es00 ( which uses str98 ) .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">Results of dar on texts results of applying dar</definiens>
				<definiens id="1">the last colum the overall performance of the two algorithms is given as f-measure ( F ) which is defined as 1α 1 P + ( 1−α ) 1 R where P is precision , R is recall and</definiens>
			</definition>
</paper>

		<paper id="3234">
			<definition id="0">
				<sentence>The co-clustering algorithm chooses the partitions a25 a17 and a47 a17 to ( locally ) maximize the mutual information between them , under a constraint limiting the total number of clusters in each partition .</sentence>
				<definiendum id="0">co-clustering algorithm</definiendum>
				<definiens id="0">chooses the partitions a25 a17 and a47 a17 to ( locally ) maximize the mutual information between them , under a constraint limiting the total number of clusters in each partition</definiens>
			</definition>
			<definition id="1">
				<sentence>TIME , which is scarce in the training and test sets , is insensitive to their inclusion .</sentence>
				<definiendum id="0">TIME</definiendum>
				<definiens id="0">scarce in the training and test sets</definiens>
			</definition>
			<definition id="2">
				<sentence>Bikel , at al ( 1997 ) , reports summary F1 of 0.93 on the same test set , but using a model trained on 450,000 words .</sentence>
				<definiendum id="0">Bikel</definiendum>
				<definiens id="0">reports summary F1 of 0.93 on the same test set , but using a model trained on 450,000 words</definiens>
			</definition>
			<definition id="3">
				<sentence>The labeling method ( seeding ) is an indirect form of corpus annotation .</sentence>
				<definiendum id="0">labeling method ( seeding )</definiendum>
			</definition>
</paper>

		<paper id="2107">
			<definition id="0">
				<sentence>The computerized version of the dictionary , the TLFi ( Trésor de la langue française informatisé ) , contains the same data as the paper version , with its 350 million characters .</sentence>
				<definiendum id="0">TLFi</definiendum>
				<definiens id="0">contains the same data as the paper version , with its 350 million characters</definiens>
			</definition>
			<definition id="1">
				<sentence>exploitation As well as all the textual resources of the laboratory , the textual database FRANTEXT ( www.atilf.fr/frantext ) , the 8 th and 9 th editions of the dictionary of Académie française and several others lexical database ( Bernard et col , 2001 et 2002 ) , the TLFi runs on its own specially software program STELLA , written in the laboratory , Stella allows a compact data storage ( with a mathematically demonstrable optimality ) of structured texts ( Dendien , 1996 ) .</sentence>
				<definiendum id="0">TLFi</definiendum>
				<definiens id="0">runs on its own specially software program STELLA , written in the laboratory</definiens>
			</definition>
			<definition id="2">
				<sentence>Stella offers the users : An environment to make the requests .</sentence>
				<definiendum id="0">Stella</definiendum>
			</definition>
			<definition id="3">
				<sentence>A good quality of service : Stella contains a linguistic “knowledge” ( flexions , categorized databases ) which allows a user to make complex requests .</sentence>
				<definiendum id="0">Stella</definiendum>
				<definiens id="0">contains a linguistic “knowledge” ( flexions , categorized databases ) which allows a user to make complex requests</definiens>
			</definition>
			<definition id="4">
				<sentence>Nowadays , FRANTEXT is a textual database which currently includes 3737 French texts covering a period from 1505 to the present day , amounting in all to more than 217 millions of words .</sentence>
				<definiendum id="0">FRANTEXT</definiendum>
				<definiens id="0">a textual database which currently includes 3737 French texts covering a period from 1505 to the present day , amounting in all to more than 217 millions of words</definiens>
			</definition>
			<definition id="5">
				<sentence>The TLFi is directed at the widest audience with the possibility of making queries without knowing the right spelling of a word .</sentence>
				<definiendum id="0">TLFi</definiendum>
				<definiens id="0">directed at the widest audience with the possibility of making queries without knowing the right spelling of a word</definiens>
			</definition>
			<definition id="6">
				<sentence>Its interest for linguistic research is obvious for it is a powerful tool to help the user who wants to study grammatical classes ( verbs , adjectives , adverbs , for instance ) , syntactical classes ( in studying constructions of a verb , more precisely , the user can find the verbs which are followed by the french preposition “de” ) , etymological classes ( verbs borrowed from a language , Latin or English ) , stylistic classes ( ironical or metaphorical uses , for instance all the adverbs used in slang ) , morphological classes ( the words ending with a suffix , or beginning with a prefix , for instance all the verbs ending with the suffix –age and which are an action of a verb ) .</sentence>
				<definiendum id="0">syntactical classes</definiendum>
				<definiens id="0">instance all the verbs ending with the suffix –age and which are an action of a verb )</definiens>
			</definition>
</paper>

		<paper id="3204">
			<definition id="0">
				<sentence>Word-set MFS Semcor Web Semcor +Web MFS &amp; Web set A ( &gt; 10 ) 51.9 50.5 50.9 51.6 51.9 set B ( &lt; 10 ) 40.1 47.7 47.8 47.8 all words 47.8 47.4 49.8 50.3 50.5 Table 6 : Recall training in Semcor , the acquired web corpus ( Semcor bias ) , and a combination of both , compared to that of the Semcor MFS .</sentence>
				<definiendum id="0">Word-set MFS Semcor Web Semcor +Web MFS</definiendum>
				<definiens id="0">Recall training in Semcor , the acquired web corpus ( Semcor bias ) , and a combination of both , compared to that of the Semcor MFS</definiens>
			</definition>
</paper>

		<paper id="2206">
			<definition id="0">
				<sentence>In this paper , we will consider alternations between transitive ( Vt ) and intransitive ( Vi ) uses of verbs , where the subject of the intransitive verb ( S ) is the same as the object of the transitive verb ( O ) ( e.g. the acid dissolved the metal , the metal dissolved ( in the acid ) ) ( Levin , 1993 , 26 { 33 ) ) .</sentence>
				<definiendum id="0">S )</definiendum>
				<definiens id="0">intransitive ( Vi ) uses of verbs , where the subject of the intransitive verb (</definiens>
				<definiens id="1">the same as the object of the transitive verb ( O )</definiens>
			</definition>
			<definition id="1">
				<sentence>Each entry consists of a pair of Japanese verbs with one or more English glosses .</sentence>
				<definiendum id="0">entry</definiendum>
				<definiens id="0">consists of a pair of Japanese verbs with one or more English glosses</definiens>
			</definition>
</paper>

		<paper id="2314">
			<definition id="0">
				<sentence>The User Experience ( UE ) expert analyzes and de nes by hand the system core functionalities : the system semantic scope ( call-types ) and the dialog manager strategy which will drive the human-machine interaction .</sentence>
				<definiendum id="0">User Experience</definiendum>
				<definiens id="0">the system semantic scope ( call-types ) and the dialog manager strategy which will drive the human-machine interaction</definiens>
			</definition>
			<definition id="1">
				<sentence>Robust speech recognition is a critical component of a spoken dialog system .</sentence>
				<definiendum id="0">Robust speech recognition</definiendum>
			</definition>
			<definition id="2">
				<sentence>More formally , each object in the training data , a3a5a4a7a6a9a8a11a10 , is represented in the form a12a14a13a15a4a16a10a18a17a20a19a21a4a16a10a23a22 , wherea13a24a4a25a10a27a26a29a28a21a10 is the feature set and thea19a30a4a16a10a27a26a32a31a18a10 is the assigned set of classes for that object for the application a33 .</sentence>
				<definiendum id="0">a3a5a4a7a6a9a8a11a10</definiendum>
				<definiendum id="1">wherea13a24a4a25a10a27a26a29a28a21a10</definiendum>
				<definiendum id="2">thea19a30a4a16a10a27a26a32a31a18a10</definiendum>
				<definiens id="0">the feature set</definiens>
				<definiens id="1">the assigned set of classes for that object for the application a33</definiens>
			</definition>
			<definition id="3">
				<sentence>In a mixed-initiative Spoken Dialog System , the Dialog Manager is the key component responsible for the human-machine interaction .</sentence>
				<definiendum id="0">Dialog Manager</definiendum>
				<definiens id="0">the key component responsible for the human-machine interaction</definiens>
			</definition>
			<definition id="4">
				<sentence>The DM keeps track of the speci c discourse context and provides disambiguation and clari cation strategies when the SLU call-types are Flow Controller ATN Clarification Rule-Based Output Processor Input Processor Context Augmented Transition Network Knowledge Tree R ules Concepts Actions VoiceXML SLU output ( XML ) Figure 2 : Dialog Manager Architecture ambiguous or have associated low con dence scores .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiens id="0">keeps track of the speci c discourse context and provides disambiguation and clari cation strategies when the SLU call-types are Flow Controller ATN Clarification Rule-Based Output Processor Input Processor Context Augmented Transition Network Knowledge Tree R ules Concepts Actions VoiceXML SLU output ( XML ) Figure 2 : Dialog Manager Architecture ambiguous or have associated low con dence scores</definiens>
			</definition>
			<definition id="5">
				<sentence>Each dialog motivator consists of a small processing unit which can be combined accordingly to the object hierarchy to build the application .</sentence>
				<definiendum id="0">dialog motivator</definiendum>
				<definiens id="0">consists of a small processing unit which can be combined accordingly to the object hierarchy to build the application</definiens>
			</definition>
			<definition id="6">
				<sentence>Alternatively , VoiceXML ( vxm , 2003 ) provides the basic infrastructure to build spoken dialog system , but the lack of SLU support and of ine tools compromises the use in a data-driven classi cation applications .</sentence>
				<definiendum id="0">VoiceXML</definiendum>
				<definiens id="0">provides the basic infrastructure to build spoken dialog system , but the lack of SLU support and of ine tools compromises the use in a data-driven classi cation applications</definiens>
			</definition>
			<definition id="7">
				<sentence>In order to evaluate the classi er performance for the utterances whose call-types are covered by the bootstrapped model , we have used classi cation accuracy ( CA ) which is the fraction of utterances in which the top scoring call-type is one of the true call-types assigned by a human-labeler and its con dence score is more than some threshold : a19 a73 a38a76a75a62a77a5a78a105a80a82a81a84a83a86a85a88a87a70a89a90a85a42a83a42a83a91a81a42a89a82a92a94a93a96a95a27a89a106a93a103a100a104a101a42a101a106a107a94a87a5a107a49a81a42a98a108a77a5a92a49a92a94a81a84a83a42a100 a34 a89a90a81a91a101 a75a62a77a79a78a62a80a82a81a84a83a86a85a88a87a70a100a47a93a103a93a104a77a5a92a49a92a94a81a84a83a91a100 a34 a89a106a81a42a101 These two measures are actually complementary to each other .</sentence>
				<definiendum id="0">classi cation accuracy</definiendum>
			</definition>
			<definition id="8">
				<sentence>A DMC is a generalization of more speci c intents .</sentence>
				<definiendum id="0">DMC</definiendum>
				<definiens id="0">a generalization of more speci c intents</definiens>
			</definition>
</paper>

		<paper id="1112">
			<definition id="0">
				<sentence>Recognition An ATR procedure consists of two procedures in general .</sentence>
				<definiendum id="0">ATR procedure</definiendum>
				<definiens id="0">consists of two procedures in general</definiens>
			</definition>
			<definition id="1">
				<sentence>, L ) is a simple word .</sentence>
				<definiendum id="0">L )</definiendum>
				<definiens id="0">a simple word</definiens>
			</definition>
			<definition id="2">
				<sentence>A multi-word-unit : MWU is defined by the following CFG rules where the right hand sides are expressed as a regular expression .</sentence>
				<definiendum id="0">MWU</definiendum>
				<definiens id="0">the following CFG rules where the right hand sides are expressed as a regular expression</definiens>
			</definition>
			<definition id="3">
				<sentence>0 otherwise K iCT Kprecision K i ∑ = = 1 ) ( ) ( ( 6 ) where N is the number of the gold standard terms , and in our experiment , N=20 .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of the gold standard terms</definiens>
			</definition>
			<definition id="4">
				<sentence>Certainly ICTCLAS classifies the character that has meaning of both verb and noun into the category of vn ( verb and noun ) .</sentence>
				<definiendum id="0">ICTCLAS</definiendum>
				<definiens id="0">classifies the character that has meaning of both verb</definiens>
			</definition>
</paper>

		<paper id="0838">
			<definition id="0">
				<sentence>We are therefore using ( 1 ) SemCor ( Miller et al. , 1993 ) – a balanced , semantically annotated dataset , with all content words manually tagged by trained lexicographers – to learn a seAssociation for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems mantic language model for the words seen in the training corpus ; and ( 2 ) information drawn from WordNet ( Miller , 1995 ) , to derive semantic generalizations for those words that did not appear in the annotated corpus .</sentence>
				<definiendum id="0">SemCor</definiendum>
				<definiens id="0">Miller et al. , 1993 ) – a balanced , semantically annotated dataset , with all content words manually tagged by trained lexicographers – to learn a seAssociation for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems mantic language model for the words seen in the training corpus</definiens>
			</definition>
</paper>

		<paper id="2317">
			<definition id="0">
				<sentence>Speaker and addressee roles are the basic conversational roles .</sentence>
				<definiendum id="0">Speaker</definiendum>
				<definiens id="0">the basic conversational roles</definiens>
			</definition>
			<definition id="1">
				<sentence>Bystanders are overhearers who are present and the speaker is aware of their presence .</sentence>
				<definiendum id="0">Bystanders</definiendum>
				<definiens id="0">aware of their presence</definiens>
			</definition>
			<definition id="2">
				<sentence>NWB The NITE Workbench is a general-purpose natural interactivity coding tool Speech is the main communication channel used in the meeting conversation .</sentence>
				<definiendum id="0">NITE Workbench</definiendum>
				<definiens id="0">a general-purpose natural interactivity coding tool Speech is the main communication channel used in the meeting conversation</definiens>
			</definition>
			<definition id="3">
				<sentence>Gaze is an important aspect of social interaction ( Argyle , 1973 ) .</sentence>
				<definiendum id="0">Gaze</definiendum>
				<definiens id="0">an important aspect of social interaction</definiens>
			</definition>
</paper>

		<paper id="2602">
			<definition id="0">
				<sentence>A lexicon is a key resource for natural language processing , providing the link between the terms of a language and the semantic and syntactic properties with which they are associated .</sentence>
				<definiendum id="0">lexicon</definiendum>
				<definiens id="0">a key resource for natural language processing , providing the link between the terms of a language and the semantic and syntactic properties with which they are associated</definiens>
			</definition>
			<definition id="1">
				<sentence>We represent the semantics of a term by an associated probability distribution over what we call a grounding space , which we de ne in various relatively conventional ways involving terms that occur in text in the vicinity of the term in question .</sentence>
				<definiendum id="0">grounding space</definiendum>
				<definiens id="0">the semantics of a term by an associated probability distribution over</definiens>
			</definition>
			<definition id="2">
				<sentence>Note that a HMM is under no constraint to handle a given term in a consistent fashion .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">under no constraint to handle a given term in a consistent fashion</definiens>
			</definition>
			<definition id="3">
				<sentence>Lexical ambiguity ( or polysemy ) and xed collocations ( multi-word units ) are two phenomena which clearly lead to sub-optimal clusters .</sentence>
				<definiendum id="0">Lexical ambiguity</definiendum>
				<definiendum id="1">xed collocations</definiendum>
				<definiens id="0">multi-word units ) are two phenomena which clearly lead to sub-optimal clusters</definiens>
			</definition>
</paper>

		<paper id="2113">
			<definition id="0">
				<sentence>Morphological theory : an introduction to word structure in generative grammar .</sentence>
				<definiendum id="0">Morphological theory</definiendum>
				<definiens id="0">an introduction to word structure in generative grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>The Navajo Language : a Grammar and Colloquial Dictionary .</sentence>
				<definiendum id="0">Navajo Language</definiendum>
				<definiens id="0">a Grammar and Colloquial Dictionary</definiens>
			</definition>
</paper>

		<paper id="0107">
			<definition id="0">
				<sentence>Inflection class A is one of the largest and most productive verb inflection classes in English , inflection class B contains the Perfective/Passive suffix -/n/ , and C is a small “irregular” inflection class of strong verbs .</sentence>
				<definiendum id="0">Inflection class A</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">one of the largest and most productive verb inflection classes in English , inflection class B contains the Perfective/Passive suffix -/n/ , and</definiens>
			</definition>
			<definition id="1">
				<sentence>We define a candidate inflection class ( CIC ) to be a set of csuffixes for which there exists at least one c-stem , t , such that each c-suffix in the CIC concatenated to t produces a word form in the vocabulary .</sentence>
				<definiendum id="0">candidate inflection class</definiendum>
				<definiendum id="1">CIC</definiendum>
				<definiens id="0">a set of csuffixes for which there exists at least one c-stem , t , such that each c-suffix in the CIC concatenated to t produces a word form in the vocabulary</definiens>
			</definition>
			<definition id="2">
				<sentence>These considerations led us to propose three parameters for our basic search strategy : L1 SIZE : A level one adherent size cutoff TOP SIZE : An absolute adherent size cutoff RATIO : A parent-to-child adherent size ratio cutoff The L1 SIZE parameter requires a c-suffix to be frequent , while the TOP SIZE and RATIO parameters require a suffix to be substitutable for other csuffixes in a reasonable number of c-stems .</sentence>
				<definiendum id="0">L1 SIZE</definiendum>
				<definiendum id="1">RATIO</definiendum>
				<definiens id="0">A level one adherent size cutoff TOP SIZE : An absolute adherent size cutoff</definiens>
			</definition>
			<definition id="3">
				<sentence>We extend the spirit of Harris’ work in our algorithm through the use of two search parameters : HORIZ RATIO : A cutoff over : sizeadherent character in ending adherents of # argmax c c HORIZ SIZE : An adherent size cutoff Left Blocking In the first variant of horizontal blocking we apply these two horizontal parameters when considering a CIC , C , removed from the list of path CIC’s .</sentence>
				<definiendum id="0">HORIZ RATIO</definiendum>
				<definiens id="0">A cutoff over : sizeadherent character in ending adherents of # argmax c c HORIZ SIZE : An adherent size cutoff Left</definiens>
			</definition>
			<definition id="4">
				<sentence>As defined , recall measures the fraction of unique suffixes in the standard IC’s that are found within those selected CIC’s that are subsets of some inflection class in the standard ; precision measures the fraction of unique suffixes among all the selected CIC’s that are found within those selected CIC’s that are subsets of an inflection class in the standard ; and fragmentation measures redundancy , specifically calculating the ratio of the number of selected CIC’s that are subsets of standard IC’s to the number of inflection classes in the standard .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">measures the fraction of unique suffixes among all the selected CIC’s that are found within those selected</definiens>
			</definition>
			<definition id="5">
				<sentence>For each CIC row , a dot is placed in the columns representing standard IC’s for which that CIC is a subset .</sentence>
				<definiendum id="0">CIC</definiendum>
				<definiens id="0">a subset</definiens>
			</definition>
</paper>

		<paper id="3207">
			<definition id="0">
				<sentence>The joint model used by our bilingual parser is an instance of a stochastic bilingual multitext grammar ( 2MTG ) , formally defined by Melamed ( 2003 ) .</sentence>
				<definiendum id="0">bilingual parser</definiendum>
				<definiens id="0">an instance of a stochastic bilingual multitext grammar ( 2MTG )</definiens>
			</definition>
			<definition id="1">
				<sentence>Melamed defines bilexicalized MTG ( L2MTG ) , which is a synchronous extension of bilexical grammars such as those described in Eisner and Satta ( 1999 ) and applies the latter’s algorithmic speedups to L2MTG-parsing .</sentence>
				<definiendum id="0">MTG</definiendum>
				<definiens id="0">a synchronous extension of bilexical grammars such as those described in Eisner</definiens>
			</definition>
			<definition id="2">
				<sentence>In this model , the probability of a ( sentence , tree ) pair ( E , T ) is given by : Pr ( E , T ) = exp ( f ( E , T ) ·θ ) summationtext Eprime , Tprime exp ( f ( Eprime , Tprime ) ·θ ) ( 1 ) where θ are the model parameters and f is a vector function such that fi is equal to the number of times a feature ( e.g. , a production rule ) fires in ( E , T ) .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">the probability of a ( sentence , tree ) pair ( E , T ) is given by : Pr ( E , T ) = exp ( f ( E , T ) ·θ ) summationtext Eprime</definiens>
			</definition>
			<definition id="3">
				<sentence>Parameter estimation consists of selecting weights θ to maximize the conditional probability of the correct parses given observed sentences:3 productdisplay i Pr ( Ti|Si ) = productdisplay i exp ( f ( Ei , Ti ) ·θ ) summationtext Tprime exp ( f ( Ei , Tprime ) ·θ ) ( 2 ) Another important advantage of moving to log-linear models is the simple handling of data sparseness .</sentence>
				<definiendum id="0">Parameter estimation</definiendum>
				<definiens id="0">consists of selecting weights θ to maximize the conditional probability of the correct parses given observed sentences:3 productdisplay i Pr ( Ti|Si ) = productdisplay i exp ( f ( Ei , Ti ) ·θ ) summationtext Tprime exp ( f ( Ei , Tprime ) ·θ ) ( 2 ) Another important advantage of moving to log-linear models is the simple handling of data sparseness</definiens>
			</definition>
			<definition id="4">
				<sentence>TX is a tag and WX is a word .</sentence>
				<definiendum id="0">TX</definiendum>
				<definiendum id="1">WX</definiendum>
				<definiens id="0">a tag</definiens>
				<definiens id="1">a word</definiens>
			</definition>
			<definition id="5">
				<sentence>Over training sentences , maximize : productdisplay i Pr ( Ti , Mi|lattice ) = productdisplay i exp ( f ( Ti , Mi ) ·θ ) summationtext ( Tprime , Mprime ) ∈lattice exp ( f ( Tprime , Mprime ) ·θ ) ( 3 ) where Ti is the correct tagging for sentence i , Mi is the correct morpheme sequence .</sentence>
				<definiendum id="0">Ti</definiendum>
				<definiendum id="1">Mi</definiendum>
				<definiens id="0">the correct tagging for sentence i ,</definiens>
			</definition>
			<definition id="6">
				<sentence>Tx is a tag , Mx is a morpheme .</sentence>
				<definiendum id="0">Tx</definiendum>
				<definiendum id="1">Mx</definiendum>
				<definiens id="0">a tag</definiens>
			</definition>
			<definition id="7">
				<sentence>The Foreign Broadcast Information Service dataset contains about 99,000 sentences of Korean and 72,000 of English translation .</sentence>
				<definiendum id="0">Foreign Broadcast Information Service dataset</definiendum>
				<definiens id="0">contains about 99,000 sentences of Korean and 72,000 of English translation</definiens>
			</definition>
			<definition id="8">
				<sentence>A starker measure of alignment sparsity is the accuracy of English dependency links projected onto Korean .</sentence>
				<definiendum id="0">alignment sparsity</definiendum>
				<definiens id="0">the accuracy of English dependency links projected onto Korean</definiens>
			</definition>
</paper>

		<paper id="0104">
			<definition id="0">
				<sentence>The semantics of the type system assumed here are extremely simple : the denotation of a parent type in the directed acyclic graph that constitutes a type hierarchy is defined as the union of the denotation of its children , whereas a type node without children denotes a unique singleton set ( A¨ıt-Kaci et al. , 1989 ) .</sentence>
				<definiendum id="0">The semantics of the type system</definiendum>
				<definiens id="0">the union of the denotation of its children , whereas a type node without children denotes a unique singleton set</definiens>
			</definition>
			<definition id="1">
				<sentence>Each phoneme is then mapped to a canonical feature bundle which is based on the phonetic characteristics specified in the International Phonetic Alphabet ( IPA ) ; the features used in Figure 3 serve as an example .</sentence>
				<definiendum id="0">Phonetic Alphabet</definiendum>
				<definiens id="0">mapped to a canonical feature bundle which is based on the phonetic characteristics specified in the International</definiens>
			</definition>
			<definition id="2">
				<sentence>Similarly , type25 is a common parent of type06 and type01 which label the transitions from state 7 to state 17 and state 5 to state 25 respectively .</sentence>
				<definiendum id="0">type25</definiendum>
				<definiens id="0">a common parent of type06 and type01</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally , type35 is a common parent of type10 and type14 which label the transitions from state 17 to state 35 and state 25 to state 35 .</sentence>
				<definiendum id="0">type35</definiendum>
				<definiens id="0">a common parent of type10 and type14</definiens>
			</definition>
</paper>

		<paper id="2310">
			<definition id="0">
				<sentence>The antecedent space of an anaphor Pi consists of all nouns and pronouns whose corresponding nodes in the graph G are reachable from PGi by traversing a single edge belonging to EG .</sentence>
				<definiendum id="0">antecedent space of an anaphor Pi</definiendum>
			</definition>
			<definition id="1">
				<sentence>Wik is computed as follows – let the weight Wp of each path p be defined as the product of the weights of all the edges lying on that path .</sentence>
				<definiendum id="0">Wik</definiendum>
				<definiens id="0">computed as follows – let the weight Wp of each path p be defined as the product of the weights of all the edges lying on that path</definiens>
			</definition>
			<definition id="2">
				<sentence>Then , Wik is the sum of the weights of all the paths from PGi to NGk , i.e. , summationtextp Wp .</sentence>
				<definiendum id="0">Wik</definiendum>
				<definiens id="0">the sum of the weights of all the paths from PGi to NGk , i.e. , summationtextp Wp</definiens>
			</definition>
			<definition id="3">
				<sentence>The weight of an edge is the sum total of the weights awarded by each individual heuristic to the anaphor-antecedent relationship .</sentence>
				<definiendum id="0">weight of an edge</definiendum>
				<definiens id="0">the sum total of the weights awarded by each individual heuristic to the anaphor-antecedent relationship</definiens>
			</definition>
</paper>

		<paper id="0805">
			<definition id="0">
				<sentence>A collection of manually labeled instances was built for three main reasons : gram ) required a Gold Standard list of senses provided by human annotators ; training data , that in our case was twice larger than the test set ; consuming activity , but SENSEVAL represents the framework to build reusable benchmark resources .</sentence>
				<definiendum id="0">SENSEVAL</definiendum>
				<definiens id="0">required a Gold Standard list of senses provided by human annotators ; training data</definiens>
			</definition>
			<definition id="1">
				<sentence>Annotators were provided with a formula that indicated the number of labeled instances for each lemma 1 , so they checked that the words were con1 No. of labeled instances for each lemma = 75 + ( 15*no. of attested senses ) + ( 7* no. of attested multiwords ) , where 75 is a fixed number of examples distributed over all the attested senses .</sentence>
				<definiendum id="0">75</definiendum>
			</definition>
			<definition id="2">
				<sentence>As a consequence , the ITA turned out to be so high and the distribution of the senses in the labeled data set did not reflect the actual frequency in the Italian language , which may have affected the systems’ performance .</sentence>
				<definiendum id="0">Italian language</definiendum>
				<definiens id="0">the ITA turned out to be so high and the distribution of the senses in the labeled data set did not reflect the actual frequency in the</definiens>
			</definition>
			<definition id="3">
				<sentence>IRST-Ties , a generalized pattern abstraction system originally developed for Information Extraction tasks and mainly based on the boosted wrapper induction algorithm , used only lemma and POS as features .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">a generalized pattern abstraction system originally developed for Information Extraction tasks and mainly based on the boosted wrapper induction algorithm , used only lemma and</definiens>
			</definition>
</paper>

		<paper id="2907">
			<definition id="0">
				<sentence>Definition 1 A system ( K , ⊕ , ⊗,0,1 ) is a semiring ( Kuich and Salomaa , 1986 ) if : ( K , ⊕,0 ) is a commutative monoid with identity element 0 ; ( K , ⊗,1 ) is a monoid with identity element 1 ; ⊗ distributes over ⊕ ; and 0 is an annihilator for ⊗ : for all a ∈K , a⊗0 = 0⊗a = 0 .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">a commutative monoid with identity element 0</definiens>
				<definiens id="1">a monoid with identity element 1 ; ⊗ distributes over ⊕</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , a semiring is a ring that may lack negation .</sentence>
				<definiendum id="0">semiring</definiendum>
				<definiens id="0">a ring that may lack negation</definiens>
			</definition>
			<definition id="2">
				<sentence>Definition 2 A weighted finite-state transducer T over a semiring K is an 8-tuple T = ( Σ , ∆ , Q , I , F , E , λ , ρ ) where : Σ is the finite input alphabet of the transducer ; ∆ is the finite output alphabet ; Q is a finite set of states ; I ⊆ Q the set of initial states ; F ⊆ Q the set of final states ; E ⊆ Q× ( Σ∪ { epsilon1 } ) × ( ∆∪ { epsilon1 } ) ×K×Q a finite set of transitions ; λ : I → K the initial weight function ; and ρ : F → K the final weight function mapping F to K. A Weighted automaton A = ( Σ , Q , I , F , E , λ , ρ ) is defined in a similar way by simply omitting the output labels .</sentence>
				<definiendum id="0">Σ</definiendum>
				<definiendum id="1">∆</definiendum>
				<definiendum id="2">Q</definiendum>
				<definiendum id="3">ρ )</definiendum>
				<definiens id="0">an 8-tuple T = ( Σ , ∆ , Q , I , F , E , λ , ρ ) where :</definiens>
				<definiens id="1">a finite set of states ; I ⊆ Q the set of initial states ; F ⊆ Q the set of final states ; E ⊆ Q× ( Σ∪ { epsilon1 } ) × ( ∆∪ { epsilon1 } ) ×K×Q a finite set of transitions ; λ : I → K the initial weight function ; and ρ : F → K the final weight function mapping F to K. A Weighted automaton A = ( Σ , Q , I , F , E , λ ,</definiens>
			</definition>
			<definition id="3">
				<sentence>A cycle pi is a path whose origin and destination states coincide : n [ pi ] = p [ pi ] .</sentence>
				<definiendum id="0">cycle pi</definiendum>
				<definiens id="0">a path whose origin and destination states</definiens>
			</definition>
			<definition id="4">
				<sentence>More generally , Bi defines a probability distribution Pi over all strings x ∈ Σ∗ which is just the sum of the probability of all paths of Bi in which x appears .</sentence>
				<definiendum id="0">Bi</definiendum>
				<definiens id="0">defines a probability distribution Pi over all strings x ∈ Σ∗ which is just the sum of the probability of all paths of Bi in which x appears</definiens>
			</definition>
			<definition id="5">
				<sentence>1In most cases , Fprime is the inverse of F. • Pronunciation Dictionary : a pronunciation dictionary can be used to map word sequences into their phonemic transcriptions , thus transform word lattices into equivalent phone lattices .</sentence>
				<definiendum id="0">Fprime</definiendum>
				<definiens id="0">the inverse of F. • Pronunciation Dictionary : a pronunciation dictionary can be used to map word sequences into their phonemic transcriptions , thus transform word lattices into equivalent phone lattices</definiens>
			</definition>
</paper>

		<paper id="3253">
			<definition id="0">
				<sentence>The present approach emphasizes the use of a variety of diverse information sources , and SVMs provide the ideal tool to bring these sources together .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">the use of a variety of diverse information sources , and</definiens>
			</definition>
			<definition id="1">
				<sentence>Here , the term semantic orientation ( SO ) ( Hatzivassiloglou and McKeown , 2002 ) refers to a real number measure of the positive or negative sentiment expressed by a word or phrase .</sentence>
				<definiendum id="0">semantic orientation</definiendum>
				<definiens id="0">a real number measure of the positive or negative sentiment expressed by a word or phrase</definiens>
			</definition>
			<definition id="2">
				<sentence>PMI is defined by Church and Hanks ( 1989 ) as follows : a0a2a1a4a3a6a5a8a7a10a9a12a11a13a7a15a14a17a16a19a18a21a20a23a22a25a24 a14a27a26a29a28 a5a8a7a10a9a31a30a32a7a15a14a12a16 a28 a5a8a7a10a9a33a16 a28 a5a8a7a15a14a17a16a35a34 ( 1 ) where a28 a5a8a7 a9 a30a36a7 a14a16 is the probability thata7 a9 anda7 a14 co-occur .</sentence>
				<definiendum id="0">PMI</definiendum>
			</definition>
			<definition id="3">
				<sentence>The accuracy value represents the percentage of test texts which were classified correctly by the model .</sentence>
				<definiendum id="0">accuracy value</definiendum>
				<definiens id="0">the percentage of test texts which were classified correctly by the model</definiens>
			</definition>
</paper>

		<paper id="0203">
			<definition id="0">
				<sentence>A CONTIGUITY relation is the basic relation found in narratives .</sentence>
				<definiendum id="0">CONTIGUITY relation</definiendum>
				<definiens id="0">the basic relation found in narratives</definiens>
			</definition>
</paper>

		<paper id="0700">
</paper>

		<paper id="2321">
			<definition id="0">
				<sentence>There is a wide consensus in the scientific community that human-computer dialogue systems based on spoken natural language make mistakes because the Automatic Speech Recognition ( ASR ) component may not hypothesize some of the pronounced words and the various levels of knowledge used for recognizing and reasoning about conceptual entities are imprecise and incomplete .</sentence>
				<definiendum id="0">Speech Recognition</definiendum>
				<definiens id="0">a wide consensus in the scientific community that human-computer dialogue systems based on spoken natural language make mistakes because the Automatic</definiens>
			</definition>
			<definition id="1">
				<sentence>Decoding is a search process which detects combinations of specialized SFSTs and the n-gram LM .</sentence>
				<definiendum id="0">Decoding</definiendum>
			</definition>
			<definition id="2">
				<sentence>The output of the decoding process consists of a n-best list of conceptual interpretations .</sentence>
				<definiendum id="0">decoding process</definiendum>
				<definiens id="0">consists of a n-best list of conceptual interpretations</definiens>
			</definition>
			<definition id="3">
				<sentence>The contribution of a sequence of words W to a conceptual structure is evaluated by the posterior probability P ( j Y ) , where Y is the description of acoustic features .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">the description of acoustic features</definiens>
			</definition>
			<definition id="4">
				<sentence>P ( j W ) is computed by considering that thus : P ( j W ) = P ( s1 j W ) : JY j=2 P ( sj j sj 11 W ) ( 2 ) P ( sj j sj 11 W ) P ( sj j W ) If the conceptual component sj is hypothesized with a sentence pattern j ( W ) recognized in W and k ( W ) triggers a pair sk and there is a training set with which the probabilities P ( k ( W ) j sk ) 8k , can be estimated , then the posterior probability can be obtained as follows : P ( sj j W ) = P ( j ( W ) j sj ) P ( sj ) PK k=1 P ( k ( W ) j sk ) P ( sk ) ( 3 ) where P ( sk ) is a unigram probability of conceptual components .</sentence>
				<definiendum id="0">posterior probability</definiendum>
				<definiendum id="1">P ( sk )</definiendum>
				<definiens id="0">a unigram probability of conceptual components</definiens>
			</definition>
			<definition id="5">
				<sentence>If we keep the 2 best conceptual interpretations C1 , C2 of a transducer L0 and , for each of these , the 2 best word strings , we obtain : 1 : C1 = &lt; c1_1 , c1_2 , .. , c1_x &gt; 2 : C2 = &lt; c2_1 , c2_2 , .. , c2_y &gt; where &lt; ci_1 , ci_2 , .. , ci_y &gt; is the conceptual interpretation at the rank i in the n-best list ; Wi .</sentence>
				<definiendum id="0">Wi</definiendum>
				<definiens id="0">the conceptual interpretation at the rank i in the n-best list ;</definiens>
			</definition>
			<definition id="6">
				<sentence>j_k is the concept value of the kth concept ci_k of the jth word string of interpretation i. In order to select a particular interpretation ( conceptual interpretation + concept values ) from the structured n-best list , we are now interested in computing the probability that is correct , given a set of confidence measures M : P ( j M ) .</sentence>
				<definiendum id="0">j_k</definiendum>
				<definiens id="0">the concept value of the kth concept ci_k of the jth word string of interpretation i. In order to select a particular interpretation ( conceptual interpretation + concept values ) from the structured n-best list</definiens>
			</definition>
			<definition id="7">
				<sentence>This threshold is tuned on a development corpus by minimizing the total risk R expressed as follows : R = fa NfaN total + fr NfrN total ( 5 ) Nfa and Nfr are the numbers of false acceptation and false rejection decisions on the development corpus for a given value of .</sentence>
				<definiendum id="0">Nfr</definiendum>
				<definiens id="0">a development corpus by minimizing the total risk R expressed as follows : R = fa NfaN total +</definiens>
			</definition>
</paper>

		<paper id="1908">
			<definition id="0">
				<sentence>Word senses for verbs are distinguished through corpus-derived syntagmatic patterns mapped to Generative Lexicon Theory ( Pustejovsky ( 1995 ) ) as a linguistic model of interpretation , which guides and constrains the induction of senses from word distributional information .</sentence>
				<definiendum id="0">interpretation</definiendum>
				<definiens id="0">guides and constrains the induction of senses from word distributional information</definiens>
			</definition>
			<definition id="1">
				<sentence>The procedure consists of three subtasks : ( 1 ) the manual discovery of selection context patterns for speci c verbs ; ( 2 ) the automatic recognition of instances of the identi ed patterns ; and ( 3 ) automatic acquisition of patterns for unanalyzed cases .</sentence>
				<definiendum id="0">procedure</definiendum>
			</definition>
			<definition id="2">
				<sentence>The model bias provided by GL acts to guide the interpretation of purely statistically based measures .</sentence>
				<definiendum id="0">model bias</definiendum>
				<definiens id="0">provided by GL acts to guide the interpretation of purely statistically based measures</definiens>
			</definition>
</paper>

		<paper id="0216">
</paper>

		<paper id="3236">
			<definition id="0">
				<sentence>To build a Chinese POS tagger , the following questions naturally arise : ( 1 ) Should we perform Chinese POS tagging strictly after word segmentation in two separate phases ( one-at-a-time approach ) , or perform both word segmentation and POS tagging in a combined , single step simultaneously ( all-at-once approach ) ?</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">word segmentation in two separate phases ( one-at-a-time approach ) , or perform both word segmentation</definiens>
			</definition>
			<definition id="1">
				<sentence>Templates ( a ) − ( c ) refer to a context of five characters ( the current character and two characters to its left and right ) .</sentence>
				<definiendum id="0">Templates</definiendum>
				<definiens id="0">the current character and two characters to its left and right</definiens>
			</definition>
			<definition id="2">
				<sentence>: ) C ( Pu 0 A punctuation symbol is usually a good indication of a word boundary .</sentence>
				<definiendum id="0">punctuation symbol</definiendum>
				<definiens id="0">a good indication of a word boundary</definiens>
			</definition>
			<definition id="3">
				<sentence>Recall is the proportion of correctly segmented words in the gold-standard segmentation , and precision is the proportion of correctly segmented words in word segmenter’s output .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiendum id="1">precision</definiendum>
				<definiens id="0">the proportion of correctly segmented words in the gold-standard segmentation , and</definiens>
				<definiens id="1">the proportion of correctly segmented words in word segmenter’s output</definiens>
			</definition>
			<definition id="4">
				<sentence>93.5 94.0 94.5 95.0 95.5 96.0 96.5 97.0 12345678910 Experiment Number W o r d S e g F-M e a s ur e ( % ) Figure 1 : CTB 10-fold CV word segmentation Fmeasure for our word segmenter As further evaluation , we tested our word segmenter on all the 4 test corpora ( CTB , Academia Sinica ( AS ) , Hong Kong CityU ( HK ) , and Peking University ( PK ) ) of the closed track of the 2003 ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff ( Sproat and Emerson , 2003 ) .</sentence>
				<definiendum id="0">CTB , Academia Sinica</definiendum>
				<definiens id="0">PK ) ) of the closed track of the 2003 ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff ( Sproat and Emerson</definiens>
			</definition>
			<definition id="5">
				<sentence>( Note that the top participant of CTB c ( Zhang et al. , 2003 ) used additional named entity knowledge/data in their word segmenter ) .</sentence>
				<definiendum id="0">CTB</definiendum>
				<definiens id="0">c ( Zhang et al. , 2003 ) used additional named entity knowledge/data in their word segmenter</definiens>
			</definition>
			<definition id="6">
				<sentence>Feature ( e ) encodes the class of characters that constitute the surrounding words ( similar to feature ( f ) of the word segmenter in Section 2.1 ) .</sentence>
				<definiendum id="0">Feature ( e )</definiendum>
				<definiens id="0">encodes the class of characters that constitute the surrounding words</definiens>
			</definition>
</paper>

		<paper id="0306">
			<definition id="0">
				<sentence>Meanwhile , in the way of formal methods , Tomita ( 1986 ) introduced Generalized LR parsing , which offers an interesting hybrid of nondeterministic dynamic programming surrounding LR parsing methods that were originally deterministic .</sentence>
				<definiendum id="0">Generalized LR parsing</definiendum>
				<definiens id="0">offers an interesting hybrid of nondeterministic dynamic programming surrounding LR parsing methods that were originally deterministic</definiens>
			</definition>
			<definition id="1">
				<sentence>( MAL ) grammar problem We formulate the learning task as follows : Definition Given an unannotated corpus S = { S 1 , ... , S |S| } plus a constraining grammar G C , theminimum average lookahead grammar G MAL ( S , G C ) is defined as arg min G⊂G C ∧∀i : parse G ( S i ) negationslash=∅ ˆ k ( G ) where the average lookahead objective function ˆ k ( G ) is the average ( over S ) amount of lookahead that an LR parser for G needs in order to deterministically parse the sample S without any shift-reduce or reduce-reduce conflicts .</sentence>
				<definiendum id="0">MAL ( S , G C</definiendum>
				<definiendum id="1">G )</definiendum>
				<definiens id="0">the learning task as follows : Definition Given an unannotated corpus S = { S 1 , ... , S |S| } plus a constraining grammar G C , theminimum average lookahead grammar G</definiens>
				<definiens id="1">arg min G⊂G C ∧∀i : parse G ( S i ) negationslash=∅ ˆ k ( G ) where the average lookahead objective function ˆ k (</definiens>
				<definiens id="2">the average ( over S ) amount of lookahead that an LR parser for G needs in order to deterministically parse the sample S without any shift-reduce or reduce-reduce conflicts</definiens>
			</definition>
			<definition id="2">
				<sentence>In other words , G MAL is the subset of rules of G C that requires the smallest number of lookaheads on average so as to make parsing S using this subset of G deterministic .</sentence>
				<definiendum id="0">G MAL</definiendum>
				<definiens id="0">the subset of rules of G C that requires the smallest number of lookaheads on average so as to make parsing S using this subset of G deterministic</definiens>
			</definition>
			<definition id="3">
				<sentence>To compute the value of ˆ k ( G ) , one needs the LR table for that particular G , which is expensive to compute .</sentence>
				<definiendum id="0">LR table</definiendum>
				<definiens id="0">for that particular G , which is expensive to compute</definiens>
			</definition>
			<definition id="4">
				<sentence>The algorithm consists of an initialization step followed by an iterative loop .</sentence>
				<definiendum id="0">algorithm</definiendum>
			</definition>
			<definition id="5">
				<sentence>However , find MAL parser processes the example sentences in order , and attempts to find the MAL grammar sentence by sentence .</sentence>
				<definiendum id="0">MAL parser</definiendum>
				<definiens id="0">processes the example sentences in order , and attempts to find the MAL grammar sentence by sentence</definiens>
			</definition>
			<definition id="6">
				<sentence>parses The function find MAL parse selects the full parse F∗ of a given sentence that requires the least average lookahead ˆ k ( A ( F ) ) to resolve any shiftreduce or reduce-reduce conflicts with a set A of parsing action sequences , such that F∗ is a subset of a chart C. The inputs to find MAL parse , more specifically , are a chart C containing all the partial parses in the input sentence , and the set A containing the parsing action sequences of the MAL parse of all sentences processed so far .</sentence>
				<definiendum id="0">F∗</definiendum>
				<definiens id="0">a subset of a chart C. The inputs to find MAL parse , more specifically , are a chart C containing all the partial parses in the input sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>• k : The average lookahead information , in the form of a pair ( m , l ) where l is the minimum average lookahead of all paths leading from the root to this vertex and m is the number of state transitions in that MAL path .</sentence>
				<definiendum id="0">l</definiendum>
				<definiendum id="1">m</definiendum>
				<definiens id="0">The average lookahead information , in the form of a pair</definiens>
				<definiens id="1">the minimum average lookahead of all paths leading from the root to this vertex</definiens>
			</definition>
			<definition id="8">
				<sentence>Suppose n is the maximum length of any sentence in the corpus , and m is the number of rules in the grammar .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">the maximum length of any sentence in the corpus</definiens>
			</definition>
</paper>

		<paper id="1100">
</paper>

		<paper id="2419">
			<definition id="0">
				<sentence>In the maximum entropy framework ( Berger , 1996 ) , the conditional probability of predicting an outcome y given Figure 1 : An example of the semantic role labels and an incremental approach .</sentence>
				<definiendum id="0">maximum entropy framework</definiendum>
				<definiens id="0">the conditional probability of predicting an outcome y given Figure 1 : An example of the semantic role labels and an incremental approach</definiens>
			</definition>
			<definition id="1">
				<sentence>a history x is defined as follows : P ( y|x ) = 1 Z ( x ) exp parenleftBigg k summationdisplay i=1 λ i f i ( x , y ) parenrightBigg where f i ( x , y ) is the feature function , λ i is the weighting parameter of f i ( x , u ) , k is the number of features , and Z ( x ) is the normalization factor for summationtext y p ( y|x ) =1 .</sentence>
				<definiendum id="0">Z ( x</definiendum>
				<definiendum id="1">f i</definiendum>
				<definiendum id="2">y )</definiendum>
				<definiendum id="3">k</definiendum>
				<definiendum id="4">Z ( x )</definiendum>
				<definiendum id="5">summationtext y p</definiendum>
				<definiens id="0">the feature function , λ i is the weighting parameter of f i ( x , u )</definiens>
				<definiens id="1">the number of features</definiens>
			</definition>
			<definition id="2">
				<sentence>R best = argmax R P ( R|c 1n , pred ) = argmax R producttext n i=1 P ( r i |c 1n , pred , r ) ( 1 ) where R is a sequence of the semantic roles , c 1n is a sequence of constituents , pred is the given predicate , r i is the i-th semantic role , n is the number of constituents .</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">c 1n</definiendum>
				<definiendum id="2">n</definiendum>
				<definiens id="0">a sequence of the semantic roles</definiens>
			</definition>
			<definition id="3">
				<sentence>where m is the number of constituents covered by the immediate clause , Φ 1 is a feature set for immediate clause , and Φ 2 is a feature set for upper clauses .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">the number of constituents covered by the immediate clause</definiens>
			</definition>
			<definition id="4">
				<sentence>The predicate-type feature represents the predicate usage such as to-infinitive form ( TO ) , the beginning of the immediate clause ( BEG ) , and otherwise ( SEN ) .</sentence>
				<definiendum id="0">predicate-type feature</definiendum>
				<definiens id="0">represents the predicate usage such as to-infinitive form ( TO ) , the beginning of the immediate clause ( BEG ) , and otherwise</definiens>
			</definition>
</paper>

		<paper id="2609">
			<definition id="0">
				<sentence>Semantic roles are always between verbs ( or nouns derived from verbs ) and other constituents ( run quickly , went to the store , computer maker ) , whereas semantic relations can occur between any constituents , for example in complex nominals ( malaria mosquito ( CAUSE ) ) , genitives ( girl’s mouth ( PART-WHOLE ) ) , prepositional phrases attached to nouns ( man at the store ( LOCATIVE ) ) , or discourse level ( The bus was late .</sentence>
				<definiendum id="0">discourse level</definiendum>
				<definiens id="0">girl’s mouth ( PART-WHOLE ) ) , prepositional phrases attached to nouns ( man at the store ( LOCATIVE ) ) , or</definiens>
			</definition>
			<definition id="1">
				<sentence>The following NP level constructions are considered here ( cf. the classifications provided by ( Quirk et al.1985 ) and ( Semmelmeyer and Bolander 1992 ) ) : ( 1 ) Compound Nominals consisting of two consecutive nouns ( eg night club a TEMPORAL relation indicating that club functions at night ) , ( 2 ) Adjective Noun constructions where the adjectival modifier is derived from a noun ( eg musical clock a MAKE/PRODUCE relation ) , ( 3 ) Genitives ( eg the door of the car a PART-WHOLE relation ) , and ( 4 ) Adjective phrases ( cf. ( Semmelmeyer and Bolander 1992 ) ) in which the modifier noun is expressed by a prepositional phrase which functions as an adjective ( eg toy in the box a LOCATION relation ) .</sentence>
				<definiendum id="0">cf.</definiendum>
				<definiens id="0">the door of the car a PART-WHOLE relation ) , and ( 4 ) Adjective phrases</definiens>
				<definiens id="1">a prepositional phrase which functions as an adjective ( eg toy in the box a LOCATION relation )</definiens>
			</definition>
			<definition id="2">
				<sentence>There are several semantic relations at the noun phrase level : ( 1 ) Saturday’s snowfall is a genitive encoding a TEMPORAL relation , ( 2 ) one-day record is a TOPIC noun compound indicating that record is about one-day snowing an ellipsis here , ( 3 ) record in Hartford is an adjective phrase in a LOCATION relation , ( 4 ) total of 12.5 inches is an of-genitive that expresses MEASURE , ( 5 ) weather service is a noun compound in a TOPIC relation , ( 6 ) car which was driven by a college student encodes a THEME semantic role in an adjectival clause , ( 7 ) college student is a compound nominal in a PART-WHOLE/MEMBER-OF relation , ( 8 ) interstate overpass is a LOCATION noun compound , ( 9 ) mountains of Virginia is an of-genitive showing a PART-WHOLE/PLACE-AREA and LOCATION relation , ( 10 ) concrete barrier is a noun compound encoding PART-WHOLE/STUFF-OF .</sentence>
				<definiendum id="0">Saturday’s snowfall</definiendum>
				<definiendum id="1">college student</definiendum>
				<definiens id="0">an adjective phrase in a LOCATION relation</definiens>
				<definiens id="1">an of-genitive showing a PART-WHOLE/PLACE-AREA and LOCATION relation</definiens>
			</definition>
			<definition id="3">
				<sentence>Complex Nominals Levi ( Levi 1979 ) defines complex nominals ( CNs ) as expressions that have a head noun preceded by one or more modifying nouns , or by adjectives derived from nouns ( usually called denominal adjectives ) .</sentence>
				<definiendum id="0">Complex Nominals Levi</definiendum>
				<definiendum id="1">complex nominals</definiendum>
				<definiens id="0">a head noun preceded by one or more modifying nouns , or by adjectives derived from nouns ( usually called denominal adjectives )</definiens>
			</definition>
			<definition id="4">
				<sentence>; ( Baker , Fillmore , and Lowe 1998 ) includes DURATION ( Navigli and Velardi 2003 ) , DEPICTED ( MERONYMY ) ( Levi 1979 ) , ( Dolan et al. 1993 ) , ( IS-A ) ( Levi 1979 ) , ( Dolan et al. 1993 ) 10 CAUSE an event/state makes another event/state to take place ; ( malaria mosquitoes ; to die of hunger ; The earthquake generated a Tsunami ) , ( Levi 1979 ) 11 MAKE/PRODUCE an animated entity creates or manufactures another entity ; ( honey bees ; nuclear power plant ; GM makes cars ) ( Levi 1979 ) 12 INSTRUMENT an entity used in an event/action as instrument ; ( pump drainage ; the hammer broke the box ) ( Levi 1979 ) 13 LOCATION/SPACE spatial relation between two entities or between an event and an entity ; includes DIRECTION ; ( field mouse ; street show ; I left the keys in the car ) , ( Levi 1979 ) , ( Dolan et al. 1993 ) 14 PURPOSE a state/action intended to result from a another state/event ; ( migraine drug ; wine glass ; rescue mission ; He was quiet in order not to disturb her . )</sentence>
				<definiendum id="0">GM</definiendum>
				<definiendum id="1">INSTRUMENT</definiendum>
				<definiens id="0">an entity used in an event/action as instrument ; ( pump drainage ; the hammer broke the box ) ( Levi 1979 ) 13 LOCATION/SPACE spatial relation between two entities or between an event and an entity ; includes DIRECTION</definiens>
			</definition>
			<definition id="5">
				<sentence>; ( Blaheta and Charniak 2000 ) 35 PREDICATE expresses the property associated with the subject or the object through the verb ; ( He feels [ sleepy ] .</sentence>
				<definiendum id="0">PREDICATE</definiendum>
			</definition>
			<definition id="6">
				<sentence>The annotators’ agreement was measured using the Kappa statistics , one of the most frequently used measure of inter-annotator agreement for classification tasks : a0a2a1a4a3a6a5a8a7a10a9a12a11a14a13a15a3a6a5a16a7a18a17a19a11 a20 a13a21a3a6a5a8a7a10a17a22a11 , where a23a25a24a27a26a29a28a31a30 is the proportion of times the raters agree and a23a25a24a27a26a29a32a33a30 is the probability of agreement by chance .</sentence>
				<definiendum id="0">a23a25a24a27a26a29a28a31a30</definiendum>
				<definiendum id="1">a23a25a24a27a26a29a32a33a30</definiendum>
				<definiens id="0">the proportion of times the raters agree and</definiens>
				<definiens id="1">the probability of agreement by chance</definiens>
			</definition>
			<definition id="7">
				<sentence>The multi-class classification is performed by a function that maps the feature spacea4 into a semantic space a7 , a8a10a9 a4a12a11 a7 , wherea7 is the set of semantic relations from Table 1 , ie a24a14a13 a5 a7 .</sentence>
				<definiendum id="0">wherea7</definiendum>
				<definiens id="0">maps the feature spacea4 into a semantic space a7</definiens>
			</definition>
			<definition id="8">
				<sentence>Let a15 be the training set of examples or instances a15 a1 a26a16a0 a20 a24 a20a18a17 a0a20a19a16a24a21a19 a17a23a22a24a22a25a22a24a17 a0a27a26a24a28a26a30a30a29 a26a16a4a32a31 a7 a30 a26 where a33 is the number of examplesa0 each accompanied by its semantic relation label a24 .</sentence>
				<definiendum id="0">a33</definiendum>
				<definiens id="0">the number of examplesa0 each accompanied by its semantic relation label a24</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>The keyword-clustering component finds headline phrases in the beginning of the text using a list of globally selected keywords .</sentence>
				<definiendum id="0">keyword-clustering component finds headline</definiendum>
			</definition>
			<definition id="1">
				<sentence>The score for each filled template is calculated as follows : score _ t ( i ) = W j j=1 N∑ | desired _ len − template _ len | +1 where score_t ( i ) denotes the final score assigned to template i of up to N placeholders and Wj is the tf .</sentence>
				<definiendum id="0">Wj</definiendum>
				<definiens id="0">calculated as follows : score _ t ( i ) = W j j=1 N∑ | desired _ len − template _ len | +1 where score_t</definiens>
				<definiens id="1">the final score assigned to template i of up to N placeholders and</definiens>
				<definiens id="2">the tf</definiens>
			</definition>
			<definition id="2">
				<sentence>Given a sentence with its position in text , what is the likelihood that it would contain the first appearance of a headline word : Count _ Posi = P ( Hk |W j ) j =1 N∑ k =1 M∑ P ( Posi ) = Count _ Posi Count _ PosQ i =1 Q∑ Over all M texts in the collection and over all words from the corresponding M headlines ( each has up to N words ) , Count_Pos records the number of times that sentence position i has the first appearance of any headline word Wj .</sentence>
				<definiendum id="0">Count_Pos</definiendum>
				<definiens id="0">the likelihood that it would contain the first appearance of a headline word : Count _ Posi = P ( Hk |W j ) j =1 N∑ k =1 M∑ P ( Posi ) = Count _ Posi Count _ PosQ i =1 Q∑ Over all M texts in the collection and over all words from the corresponding M headlines ( each has up to N words )</definiens>
				<definiens id="1">records the number of times that sentence position i has the first appearance of any headline word Wj</definiens>
			</definition>
			<definition id="3">
				<sentence>A score of fullness on the phrase-template match is computed for each candidate template fti : fti = length ( ti ) + matched _ length ( hi ) length ( t i ) + length ( hi ) ti is a candidate template and hi is a headline phrase .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiendum id="1">hi</definiendum>
				<definiens id="0">a headline phrase</definiens>
			</definition>
</paper>

		<paper id="2405">
			<definition id="0">
				<sentence>One important aspect of co-training consists in the relation between the views used in learning .</sentence>
				<definiendum id="0">co-training</definiendum>
				<definiens id="0">consists in the relation between the views used in learning</definiens>
			</definition>
			<definition id="1">
				<sentence>a8 Growth size ( G ) Number of most confidently labeled examples that are added at each iteration to the set of labeled data L. As previously noticed ( Ng and Cardie , 2003 ) , there is no principled method for selecting optimal values for these parameters , which is an important disadvantage of these algorithms .</sentence>
				<definiendum id="0">Growth size</definiendum>
				<definiens id="0">an important disadvantage of these algorithms</definiens>
			</definition>
			<definition id="2">
				<sentence>Description CW ( L ) The word a0a2a1 itself CP ( L ) The part of speech of the word a0a2a1 CF ( L ) Word forms and their part of speech for a window of K words surroundinga0a2a1 COL ( L ) Collocations formed with maximum K words surroundinga0a2a1 HNP ( L ) The head of the noun phrase to which a0a2a1 belongs , if any SK ( T ) Maximum of M keywords occurring at least N times are determined for each sense of the ambiguous word .</sentence>
				<definiendum id="0">Description CW</definiendum>
				<definiens id="0">The part of speech of the word a0a2a1 CF ( L ) Word forms and their part of speech for a window of K words surroundinga0a2a1 COL ( L ) Collocations formed with maximum K words surroundinga0a2a1 HNP ( L ) The head of the noun phrase to which a0a2a1 belongs , if any SK ( T ) Maximum of M keywords occurring at least N times are determined for each sense of the ambiguous word</definiens>
			</definition>
			<definition id="3">
				<sentence>VO ( L ) Verb-object relation involvinga0a2a1 SV ( L ) Subject-verb relation involving a0a2a1 Table 1 : Commonly used features for word sense disambiguation .</sentence>
				<definiendum id="0">VO</definiendum>
				<definiens id="0">Commonly used features for word sense disambiguation</definiens>
			</definition>
			<definition id="4">
				<sentence>a3a5a4 denotes the current ( ambiguous ) word .</sentence>
				<definiendum id="0">a3a5a4</definiendum>
			</definition>
			<definition id="5">
				<sentence>Using the domains attached to word senses , as introduced in ( Magnini et al. , 2002 ) , we observed that words that have a large subset of their senses not belonging to a specific domain ( e.g. restraint , facility ) achieve little or no improvement through co-training , which is perhaps explained again by the noisy automatic annotation that introduces errors since the early iterations of co-training .</sentence>
				<definiendum id="0">word senses</definiendum>
				<definiens id="0">perhaps explained again by the noisy automatic annotation that introduces errors since the early iterations of co-training</definiens>
			</definition>
</paper>

		<paper id="0105">
			<definition id="0">
				<sentence>y = C , where x and y are individual characters ( or the empty character ) and C is some representation of the context licensing the transformation .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">individual characters ( or the empty character ) and</definiens>
				<definiens id="1">some representation of the context licensing the transformation</definiens>
			</definition>
			<definition id="1">
				<sentence>1 = ( fwork , rollg f , ed , ing , erg ) 2 = ( fdin , bikg fe , ed , ing , erg ) 3 = ( fwaitg f , ed , erg ) 4 = ( fcarrg fy , ied , ierg ) 5 = ( fcarryg f , ingg ) 6 = ( fbike , booth , workerg f , sg ) 7 = ( fbeach , matchg f , esg ) Figure 2 : G1 : A Sample Linguistica Grammar sions of Linguistica include some functionality devoted to detecting allomorphs .</sentence>
				<definiendum id="0">G1</definiendum>
			</definition>
			<definition id="2">
				<sentence>A context consists of a string of four characters XtytyfXf , where Xi 2fC ; V ; # g ( consonant , vowel , end-of-word ) and yi is in the set of characters in our text.3 The first half of the context is from the end of the stem , and the second half is from the beginning of the suffix .</sentence>
				<definiendum id="0">context</definiendum>
				<definiens id="0">consists of a string of four characters XtytyfXf , where Xi 2fC ; V ; # g ( consonant , vowel , end-of-word )</definiens>
			</definition>
			<definition id="3">
				<sentence>The next line shows the total length ( in bits ) of each grammar , and this value is then broken down into three different components : the overhead caused by listing the signatures and their suffixes , the length of the stem list ( not including the length required to specify exceptions to rules ) , and the length of the phonological component ( including both rules and exception specifications ) .</sentence>
				<definiendum id="0">phonological component</definiendum>
				<definiens id="0">the overhead caused by listing the signatures and their suffixes , the length of the stem list ( not including the length required to specify exceptions to rules ) , and the length of the</definiens>
			</definition>
			<definition id="4">
				<sentence>Learning is a trade-off between finding an explanation that fits the current data ( maximizing the likelihood ) and maintaining the ability to generalize to new data ( maximizing the prior ) .</sentence>
				<definiendum id="0">Learning</definiendum>
			</definition>
</paper>

		<paper id="1803">
</paper>

		<paper id="3228">
			<definition id="0">
				<sentence>We reIP NP NP NR Zhongguo QP CD shisi CLP M ge NP NN bianjing NN kaifang NN chengshi NP NN jingji NN jianshe NN chengjiu VP VV xianzhu S NP CD 14 NNP Chinese JJ open NN border NNS cities VP VBP make NP NP JJ significant NNS achievements PP IN in NP JJ economic NN construction VV : xianzhu NN : chengshi NR : Zhongguo CD : shisi M : ge NN : bianjing NN : kaifang NN : chengjiu NN : jingji NN : jianshe VV : make NNS : cities CD:14 NNP : Chinese JJ : open NN : border NNS : achievements JJ : significant IN : in NN : construction JJ : economic Figure 1 : Constituent and dependency trees for a sample sentence Alignment Precision Recall Error Rate IBM Model 1 .56 .42 .52 IBM Model 4 .67 .43 .47 Constituent Tree-to-Tree .51 .48 .50 Dependency Tree-to-Tree .44 .38 .60 Dependency , lexicalized reordering .41 .37 .61 Table 2 : Alignment results on Chinese-English corpus .</sentence>
				<definiendum id="0">border NNS</definiendum>
				<definiens id="0">economic Figure 1 : Constituent and dependency trees for a sample sentence Alignment Precision Recall Error Rate IBM Model 1 .56 .42 .52 IBM</definiens>
			</definition>
			<definition id="1">
				<sentence>For scoring the viterbi alignments of each system against goldstandard annotated alignments , we use the alignment error rate ( AER ) of Och and Ney ( 2000 ) , which measures agreement at the level of pairs of words:1 AER = 1 2jA \ GjjAj + jGj where A is the set of word pairs aligned by the automatic system , and G the set aligned in the gold standard .</sentence>
				<definiendum id="0">AER</definiendum>
				<definiens id="0">measures agreement at the level of pairs of words:1 AER = 1 2jA \ GjjAj + jGj where A is the set of word pairs aligned by the automatic system , and G the set aligned in the gold standard</definiens>
			</definition>
			<definition id="2">
				<sentence>“Constituent Tree-to-Tree” indicates the model of Section 2 trained and tested directly on the trees output by the parser , while “Dependency Tree-to-Tree” makes the modifications to the model described in Section 3 .</sentence>
				<definiendum id="0">“Constituent Tree-to-Tree”</definiendum>
			</definition>
</paper>

		<paper id="2606">
			<definition id="0">
				<sentence>Verb classes have proved useful in various ( multilingual ) natural language processing ( NLP ) tasks and applications , such as computational lexicography ( Kipper et al. , 2000 ) , language generation ( Stede , 1998 ) , machine translation ( Dorr , 1997 ) , word sense disambiguation ( Prescher et al. , 2000 ) , document classi cation ( Klavans and Kan , 1998 ) , and subcategorization acquisition ( Korhonen , 2002 ) .</sentence>
				<definiendum id="0">document classi cation</definiendum>
				<definiens id="0">computational lexicography ( Kipper et al. , 2000 ) , language generation ( Stede , 1998 ) , machine translation ( Dorr , 1997 ) , word sense disambiguation</definiens>
			</definition>
			<definition id="1">
				<sentence>This fairly comprehensive classi cation incorporates 163 different subcategorization frames ( SCFs ) , a superset of those listed in the ANLT ( Boguraev et al. , 1987 ) and COMLEX Syntax dictionaries ( Grishman et al. , 1994 ) .</sentence>
				<definiendum id="0">SCFs</definiendum>
			</definition>
			<definition id="2">
				<sentence>The SCFs were evaluated against manually analysed corpus data .</sentence>
				<definiendum id="0">SCFs were</definiendum>
				<definiens id="0">evaluated against manually analysed corpus data</definiens>
			</definition>
			<definition id="3">
				<sentence>We calculated type precision ( the percentage of SCF types that the system proposes which are correct ) , type recall ( the percentage of SCF types in the gold standard that the system proposes ) and Fa5 -measure2 .</sentence>
				<definiendum id="0">type precision</definiendum>
				<definiens id="0">the percentage of SCF types that the system proposes which are correct )</definiens>
			</definition>
</paper>

		<paper id="1312">
			<definition id="0">
				<sentence>The dissociation is taken to support the idea that the division between grammar and the lexicon is one of the constraints that the brain brings to language acquisition .</sentence>
				<definiendum id="0">lexicon</definiendum>
				<definiens id="0">one of the constraints that the brain brings to language acquisition</definiens>
			</definition>
</paper>

		<paper id="0903">
			<definition id="0">
				<sentence>These TSR trees represent an abstract notion of the meaning of the respective text , subjective to an abstract “common” understanding within the World Wide Web .</sentence>
				<definiendum id="0">TSR trees</definiendum>
			</definition>
			<definition id="1">
				<sentence>Furthermore , a number of tools for dealing with RDF already exist – RDF is one of the basic building blocks of the Semantic Web ( O. Lassila and R. Swick , 1999 ) and we expect RDF based TSR trees to be of great use in that domain ( e.g. for classification and information extraction ) .</sentence>
				<definiendum id="0">RDF</definiendum>
				<definiendum id="1">Web</definiendum>
				<definiens id="0">one of the basic building blocks of the Semantic</definiens>
			</definition>
			<definition id="2">
				<sentence>Very specialized domains ( e.g. medical topics ) are also underrepresented in the web directory and hence problematic for the same reason .</sentence>
				<definiendum id="0">Very specialized domains</definiendum>
				<definiens id="0">e.g. medical topics ) are also underrepresented in the web directory and hence problematic for the same reason</definiens>
			</definition>
</paper>

		<paper id="1813">
			<definition id="0">
				<sentence>The specificity of a term X is quantified to positive real number as equation ( 1 ) .</sentence>
				<definiendum id="0">specificity of a term X</definiendum>
				<definiens id="0">quantified to positive real number as equation ( 1 )</definiens>
			</definition>
			<definition id="1">
				<sentence>( ) Spec X R + ∈ ( 1 ) The specificity is a kind of necessary condition for term hierarchy , i.e. , if X 1 is one of ancestors of X 2 , then Spec ( X 1 ) is less than Spec ( X 2 ) .</sentence>
				<definiendum id="0">specificity</definiendum>
				<definiendum id="1">Spec</definiendum>
				<definiens id="0">a kind of necessary condition for term hierarchy</definiens>
				<definiens id="1">one of ancestors of X 2</definiens>
			</definition>
			<definition id="2">
				<sentence>{ |1 } ( ) Prob ( ) kkk Xx knpx Xx=≤≤ = = ( 3 ) where x k is an event of t k is observed in corpus , p ( x k ) is the probability of x k .</sentence>
				<definiendum id="0">x k</definiendum>
				<definiens id="0">the probability of x k</definiens>
			</definition>
			<definition id="3">
				<sentence>In next step , a discrete random variable Y is defined as equation ( 6 ) .</sentence>
				<definiendum id="0">discrete random variable Y</definiendum>
			</definition>
			<definition id="4">
				<sentence>{ |1 } ( ) Prob ( ) iii Yy impy Yy=≤≤ = = ( 6 ) where y i is an event of w i occurs in term t k , p ( y i ) is the probability of y i .</sentence>
				<definiendum id="0">y i )</definiendum>
				<definiens id="0">the probability of y i</definiens>
			</definition>
			<definition id="5">
				<sentence>( ) ( , ) log ( , ) modk ik ik i Ht pmodt pmodt=− ∑ ( 10 ) where p ( mod i , t k ) is the probability of mod i modifies t k and it is estimated as relative frequency of mod i in all modifiers of t k .</sentence>
				<definiendum id="0">p ( mod i</definiendum>
				<definiens id="0">the probability of mod i modifies t k and it is estimated as relative frequency of mod i in all modifiers of t k</definiens>
			</definition>
			<definition id="6">
				<sentence>“metabolic diseases ( C18.452 ) ” node is root of the subtree , and the subtree consists of 436 disease names which are target terms for specificity measuring .</sentence>
				<definiendum id="0">“metabolic diseases</definiendum>
			</definition>
			<definition id="7">
				<sentence>Coverage is the fraction of the terms which have the specificity by given method .</sentence>
				<definiendum id="0">Coverage</definiendum>
				<definiens id="0">the fraction of the terms</definiens>
			</definition>
			<definition id="8">
				<sentence>Precision is the fraction of correct specificity relations values as equation ( 13 ) .</sentence>
				<definiendum id="0">Precision</definiendum>
			</definition>
			<definition id="9">
				<sentence># ( , ) # ( , ) of R p c with correct specificity p of all R p c = ( 13 ) where R ( p , c ) is a parent-child relation in MeSH thesaurus .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiens id="0">) # ( , ) of R p c with correct specificity p of all R p c = ( 13 ) where R ( p ,</definiens>
				<definiens id="1">a parent-child relation in MeSH thesaurus</definiens>
			</definition>
			<definition id="10">
				<sentence>2 MEDLINE is a database of biomedical articles serviced by National Library of Medicine , USA .</sentence>
				<definiendum id="0">MEDLINE</definiendum>
			</definition>
</paper>

		<paper id="0109">
			<definition id="0">
				<sentence>The Boas project ( Oflazer et al. , 2001 ) , ( HakkaniT¨ur et al. , 2000 ) , and ( Oflazer and Nirenburg , 1999 ) has produced excellent results bootstrapping a morphological analyzer , but rely on direct human supervision to produce two-level rules ( Koskenniemi , Barcelona , July 2004 Association for Computations Linguistics ACL Special Interest Group on Computational Phonology ( SIGPHON ) Proceedings of the Workshop of the 1983 ) which are then compiled into a finite state machine .</sentence>
				<definiendum id="0">Boas project</definiendum>
				<definiens id="0">Computations Linguistics ACL Special Interest Group on Computational Phonology ( SIGPHON ) Proceedings of the Workshop of the 1983 ) which are then compiled into a finite state machine</definiens>
			</definition>
</paper>

		<paper id="2905">
			<definition id="0">
				<sentence>Stemming ( Porter , 1980 ; Krovetz , 1993 ) is a method in which the corpus is processed so that semantically and morphologically related words are reduced to a common stem .</sentence>
				<definiendum id="0">Stemming</definiendum>
				<definiens id="0">a method in which the corpus is processed so that semantically and morphologically related words are reduced to a common stem</definiens>
			</definition>
			<definition id="1">
				<sentence>The Soundex code is a combination of the first letter of the word and a three digit code which is representative of its phonetic sound .</sentence>
				<definiendum id="0">Soundex code</definiendum>
				<definiens id="0">representative of its phonetic sound</definiens>
			</definition>
</paper>

		<paper id="2004">
			<definition id="0">
				<sentence>So , we create a structure , called segmentation network ( SN ) , which represents the different segmentations of a sentence and the links between the nodes of the normalized structures .</sentence>
				<definiendum id="0">segmentation network ( SN</definiendum>
				<definiens id="0">represents the different segmentations of a sentence and the links between the nodes of the normalized structures</definiens>
			</definition>
			<definition id="1">
				<sentence>Our representation , called Dependency Matrix ( DM ) , is made up of a couple &lt; L , M &gt; : • L is a list of nodes .</sentence>
				<definiendum id="0">Dependency Matrix</definiendum>
				<definiendum id="1">L</definiendum>
				<definiens id="0">a list of nodes</definiens>
			</definition>
			<definition id="2">
				<sentence>structures The structure correspondence consists in regrouping the nodes representing the same word into a sentence ( the shared minimal data ) .</sentence>
				<definiendum id="0">structure correspondence</definiendum>
			</definition>
			<definition id="3">
				<sentence>In order to represent the correspondences , we create a structure , called segmentation network ( SN ) , that represents the different segmentations of a sentence and links the nodes of the normalized structures .</sentence>
				<definiendum id="0">segmentation network ( SN</definiendum>
				<definiens id="0">that represents the different segmentations of a sentence and links the nodes of the normalized structures</definiens>
			</definition>
			<definition id="4">
				<sentence>A SN is a lattice ; each node of this lattice represents a possible segment of a word and serves to link the nodes of the dependency structures .</sentence>
				<definiendum id="0">SN</definiendum>
				<definiens id="0">a lattice ; each node of this lattice represents a possible segment of a word and serves to link the nodes of the dependency structures</definiens>
			</definition>
			<definition id="5">
				<sentence>Standardized calculation : the combined rate of a data D is equal to the sum of the confidence rates of the data D i divided by the number n of parsers that can provide this data D : € Rcombined ( D ) = ( Rconfidence ( Di ) i ∑ n Where i = parser producing the data D ; n = number of parsers that can provide the data D. For example , let us calculate the combined rate associated to the dependency OBJ ( x , y ) ( the word y is the object of the word x ) provided by the parsers A1 and A2 .</sentence>
				<definiendum id="0">Standardized calculation</definiendum>
			</definition>
			<definition id="6">
				<sentence>If the third parser provides an other dependency , for example SUBJ ( x , y ) ( the word y is the subject of the word x ) , and if the confidence rate of this data is 0.8 , the merged rate associated to SUBJ ( x , y ) is equal to ( 0+0+0.8 ) /3 = 0.26 .</sentence>
				<definiendum id="0">y )</definiendum>
				<definiendum id="1">word y</definiendum>
			</definition>
			<definition id="7">
				<sentence>We have three parsers for this evaluation : IFSP ( Incremental Finite-State Parser ) ( Aït-Mokhtar and Chanod 1997 ) which builds the syntactic groups ( chunks ) of a sentence , and then uses the structure built to extract the syntactic dependencies between words , the parser of the GREYC ( Vergne 1998 ) which combines tagging methods to build not-recursive chunks and a dependency algorithm to calculate the dependency structure and XIP ( Xerox Incremental Parser ) ( Haït-mokhtar and al. 2002 ) which has different linguistic processings organized in an incremental way ( morphological tagging , chunk parsing , dependency extraction ) to obtain an dependency analysis .</sentence>
				<definiendum id="0">XIP</definiendum>
				<definiens id="0">Incremental Finite-State Parser ) ( Aït-Mokhtar and Chanod 1997 ) which builds the syntactic groups ( chunks ) of a sentence</definiens>
				<definiens id="1">has different linguistic processings organized in an incremental way ( morphological tagging , chunk parsing , dependency extraction ) to obtain an dependency analysis</definiens>
			</definition>
			<definition id="8">
				<sentence>The SUSANNE Corpus was created , with the sponsorship of the Economic and Social Research Council ( UK ) , as part of the process of developing a comprehensive languageengineering-oriented taxonomy and annotation scheme for the logical and surface grammar of English .</sentence>
				<definiendum id="0">SUSANNE Corpus</definiendum>
				<definiens id="0">part of the process of developing a comprehensive languageengineering-oriented taxonomy and annotation scheme for the logical and surface grammar of English</definiens>
			</definition>
</paper>

		<paper id="1713">
			<definition id="0">
				<sentence>There is a considerable proportion of Chinese ancient history and culture buried in the texts of Chinese ancient poetry , which evolutes along more than 2,000 years and involves locations all over China .</sentence>
				<definiendum id="0">poetry</definiendum>
				<definiens id="0">evolutes along more than 2,000 years and involves locations all over China</definiens>
			</definition>
			<definition id="1">
				<sentence>Learners participate in one exhibition and go through links fitting to their needs or under instructions , thus personalized learning paths are formed .</sentence>
				<definiendum id="0">Learners</definiendum>
				<definiens id="0">participate in one exhibition and go through links fitting to their needs or under instructions , thus personalized learning paths are formed</definiens>
			</definition>
</paper>

		<paper id="2326">
			<definition id="0">
				<sentence>The Tutor Speech and Student Speech panes show a portion of the tutor and student speech les , while the Tutor Text and Student Text show the associated transcriptions , where vertical lines correspond to turn segmentations.3 There are three additional panes for emotion annotation : The EMOa pane records the annotator’s judgment of the expressed emotion class for each turn , e.g. the six emotion classes described in Section 4.1 : negative , weak negative , neutral , weak positive , positive , mixed .</sentence>
				<definiendum id="0">Tutor Speech</definiendum>
			</definition>
			<definition id="1">
				<sentence>the annotator judges a speci c emotion that is not listed ( or lacks a close substitute ) , s/he selects the label other , and lists the alternative ( s ) in the NOTES pane .</sentence>
				<definiendum id="0">speci c emotion</definiendum>
				<definiens id="0">listed ( or lacks a close substitute ) , s/he selects the label other , and lists the alternative ( s ) in the NOTES pane</definiens>
			</definition>
			<definition id="2">
				<sentence>NPN represents analyses distinguishing negative , neutral and positive emotions , NnN represents negative/non-negative analyses , and EnE represents emotional/non-emotional analyses .</sentence>
				<definiendum id="0">NPN</definiendum>
				<definiendum id="1">NnN</definiendum>
				<definiendum id="2">EnE</definiendum>
				<definiens id="0">negative/non-negative analyses</definiens>
			</definition>
			<definition id="3">
				<sentence>With respect to the binary distinctions , annotating negative/non-negative ( NnN ) can be done most reliably , while predicting emotional/non-emotional ( EnE ) yields a better relative improvement .</sentence>
				<definiendum id="0">EnE )</definiendum>
				<definiens id="0">yields a better relative improvement</definiens>
			</definition>
</paper>

		<paper id="0842">
			<definition id="0">
				<sentence>A SHMM consists of changing the topology of the HMM in order to get a more accurate model Association for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems which includes more information .</sentence>
				<definiendum id="0">SHMM</definiendum>
				<definiens id="0">Third International Workshop on the Evaluation of Systems which includes more information</definiens>
			</definition>
			<definition id="1">
				<sentence>This new vocabulary consists of the concatenation of the relevant input features selected .</sentence>
				<definiendum id="0">new vocabulary</definiendum>
				<definiens id="0">consists of the concatenation of the relevant input features selected</definiens>
			</definition>
</paper>

		<paper id="1111">
			<definition id="0">
				<sentence>We have : ) Pr ( ) |Pr ( maxarg ) , Pr ( * TSTTST T == ( 1 ) T is a word sequence which composed by t1 , t2 , … , tn , where ti could be either Hanja or Hangeul word/character .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">a word sequence which composed by t1 , t2 , … , tn</definiens>
			</definition>
			<definition id="1">
				<sentence>As we have mentioned above , D is data from large dictionary ( word unigram is used at here ) , U is data from very small user corpus , and C is data from Chinese corpus .</sentence>
				<definiendum id="0">U</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">data from very small user corpus , and</definiens>
			</definition>
			<definition id="2">
				<sentence>U is from the same domain of the test set ( computer science and electronic engineering domain at here ) , but there is no overlap with the test set ( so it is a opened test ) .</sentence>
				<definiendum id="0">U</definiendum>
				<definiens id="0">a opened test )</definiens>
			</definition>
</paper>

		<paper id="1114">
			<definition id="0">
				<sentence>A Treebank can be defined as a syntactically processed corpus .</sentence>
				<definiendum id="0">Treebank</definiendum>
				<definiens id="0">a syntactically processed corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Shallow parsing ( or partial parsing ) is usually defined as a parsing process aiming to provide a limited amount of local syntactic information such as non-recursive noun phrases , V-O structures and S-V structures etc .</sentence>
				<definiendum id="0">Shallow parsing</definiendum>
				<definiens id="0">a parsing process aiming to provide a limited amount of local syntactic information such as non-recursive noun phrases</definiens>
			</definition>
			<definition id="2">
				<sentence>The right bracket is appended with syntactic labels as described in the general form of [ Phrase ] SS-FF , where SS is a mandatory syntactic label such as NP ( noun phrase ) and AP ( adjective phrase ) , and FF is an optional label indicating internal structures and semantic functions such as BL ( parallel ) , SB ( a noun is the object of verb within a verb phrase ) .</sentence>
				<definiendum id="0">SS</definiendum>
				<definiendum id="1">FF</definiendum>
				<definiendum id="2">SB ( a noun</definiendum>
				<definiens id="0">syntactic labels as described in the general form of [ Phrase ] SS-FF , where</definiens>
				<definiens id="1">a mandatory syntactic label such as NP ( noun phrase ) and AP ( adjective phrase ) , and</definiens>
				<definiens id="2">an optional label indicating internal structures and semantic functions such as BL ( parallel )</definiens>
			</definition>
			<definition id="3">
				<sentence>Again , maximal-phrase is defined as the phrase with the maximum spanning non-overlapping length , and it is a predicate playing a distinct semantic role and containing more than one lexical word .</sentence>
				<definiendum id="0">maximal-phrase</definiendum>
			</definition>
</paper>

		<paper id="3232">
			<definition id="0">
				<sentence>The simple BP matching algorithm takes in a word ; light-stems it to produce morphological information such as stem , prefix and suffix ; and returns TRUE if the stem matches one of the BP patterns in the list .</sentence>
				<definiendum id="0">simple BP matching algorithm</definiendum>
				<definiens id="0">takes in a word ; light-stems it to produce morphological information such as stem , prefix and suffix ; and returns TRUE if the stem matches one of the BP patterns in the list</definiens>
			</definition>
			<definition id="1">
				<sentence>Recall ( R ) is the fraction of target items that a system selected , while the precision ( P ) is the fraction of selected items that a system got right .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the fraction of target items that a system selected</definiens>
				<definiens id="1">the fraction of selected items that a system got right</definiens>
			</definition>
			<definition id="2">
				<sentence>A third measure known as F-measure ( F ) 2 ( combines R and P ) is used in some situation where R is very high and P is very low ( Manning and Schutze , 1999 ) .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiens id="0">used in some situation where R is very high</definiens>
			</definition>
			<definition id="3">
				<sentence>Identification Approaches The BP matching methods discussed in the previous section were evaluated on a larger unseen data set , data set2 ( the same data set already used to generate test cases to evaluate the decision tree approach , see section 3.4 ) .</sentence>
				<definiendum id="0">BP matching methods</definiendum>
				<definiens id="0">the same data set already used to generate test cases to evaluate the decision tree approach</definiens>
			</definition>
			<definition id="4">
				<sentence>Having implemented the simple and restricted methods , and used them to analyse all the BPs in a large corpus ( A_Corpus2 ) , made a dictionary approach possible .</sentence>
				<definiendum id="0">A_Corpus2</definiendum>
				<definiens id="0">the simple and restricted methods , and used them to analyse all the BPs in a large corpus</definiens>
			</definition>
</paper>

		<paper id="3112">
			<definition id="0">
				<sentence>OMIM ( Online Mendelian Inheritance in Man ) ( OMIM 2000 ) , for example , is a clinical and biomedical information resource on human genes and genetic disorders .</sentence>
				<definiendum id="0">OMIM</definiendum>
				<definiens id="0">a clinical and biomedical information resource on human genes and genetic disorders</definiens>
			</definition>
			<definition id="1">
				<sentence>We discuss the modification of an existing natural language processing system , SemGen ( Rindflesch et al. 2003 ) , that has broad applicability to biomedical text and that takes advantage of online resources such as LocusLink and the Gene Ontology .</sentence>
				<definiendum id="0">SemGen</definiendum>
				<definiens id="0">the modification of an existing natural language processing system</definiens>
				<definiens id="1">Rindflesch et al. 2003 ) , that has broad applicability to biomedical text and that takes advantage of online resources such as LocusLink and the Gene Ontology</definiens>
			</definition>
			<definition id="2">
				<sentence>In addition , LocusLink provides the following GO terms for the two genes : 20 ) EGR1 : early growth response 1 ; LocusID : 1958 Gene Ontology : transcription factor activity ; regulation of transcription , DNA-dependent ; nucleus 21 ) AR : androgen receptor ( dihydrotestosterone receptor ; testicular feminization ; spinal and bulb ar muscular atrophy ; Kennedy disease ) ; LocusID : 367 Gene Ontology : androgen receptor activity ; steroid binding ; receptor activity ; transcription factor activity ; transport ; sex differentiation ; regulation of transcription , DNAdependent ; signal transduction ; cell-cell signaling ; nucleus ( The GO provides additional , hierarchical information for terms , which we have not yet exploited . )</sentence>
				<definiendum id="0">LocusLink</definiendum>
				<definiendum id="1">cell-cell signaling ; nucleus</definiendum>
				<definiendum id="2">GO</definiendum>
				<definiens id="0">provides additional , hierarchical information for terms</definiens>
			</definition>
			<definition id="3">
				<sentence>Even with the present limitations , SemGen could assist in making the scientific literature more accessible and reduce the time it takes for researchers to update their knowledge and expertise .</sentence>
				<definiendum id="0">SemGen</definiendum>
				<definiens id="0">takes for researchers to update their knowledge and expertise</definiens>
			</definition>
</paper>

		<paper id="3238">
			<definition id="0">
				<sentence>Rather than being wellformed sentences , most queries consist of one concept or an enumeration of concepts , many times containing legitimate words that are not found in any traditional lexicon .</sentence>
				<definiendum id="0">most queries</definiendum>
				<definiens id="0">consist of one concept or an enumeration of concepts , many times containing legitimate words that are not found in any traditional lexicon</definiens>
			</definition>
			<definition id="1">
				<sentence>In a noisy channel model framework , as employed for spelling correction by Kernigham et al. ( 1990 ) , the objective function can be written by using Bayesian inversion as the product between the prior probability of words in a language ) ( vP ( the language model ) , and the likelihood of misspelling a word v as w , ) | ( vwP ( which models the noisy channel and will be called the error model ) .</sentence>
				<definiendum id="0">vP</definiendum>
				<definiendum id="1">vwP</definiendum>
				<definiens id="0">the language model ) , and the likelihood of misspelling a word v as w , ) |</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , using the vanilla Damerau-Levenshtein edit distance ( defined as the minimum number of point changes required to transform a string into another , where a point change is one of the following operations : insertion of a letter , deletion of a letter , and substitution of one letter with another letter ) and a threshold 1=δ , the correction donadl duck  donald duck would not be possible .</sentence>
				<definiendum id="0">vanilla Damerau-Levenshtein edit distance</definiendum>
				<definiens id="0">one of the following operations : insertion of a letter , deletion of a letter , and substitution of one letter with another letter</definiens>
			</definition>
</paper>

		<paper id="1601">
</paper>

		<paper id="1110">
			<definition id="0">
				<sentence>The bilingual universal ontology has the merit that it contains more structural and semantic information coverage from two complementary knowledge bases , WordNet and HowNet .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">semantic information coverage from two complementary knowledge bases</definiens>
			</definition>
			<definition id="1">
				<sentence>The final ontology is a merged version of the original ontologies .</sentence>
				<definiendum id="0">final ontology</definiendum>
			</definition>
			<definition id="2">
				<sentence>On the other hand , multi-lingual ontology is very important for natural language processing , such as machine translation ( MT ) , web mining and cross language information retrieval ( CLIR ) .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">machine translation ( MT ) , web mining and cross language information retrieval</definiens>
			</definition>
			<definition id="3">
				<sentence>Generally , a multi-lingual ontology maps the keyword set of one language to another language , or compute the co-occurrence of the words among languages .</sentence>
				<definiendum id="0">multi-lingual ontology</definiendum>
				<definiens id="0">maps the keyword set of one language to another language</definiens>
			</definition>
			<definition id="4">
				<sentence>Some generalpurpose search engine like Google ( http : //www.google.com ) and Altavista ( http : //www.altavista.com/ ) provide the facility to mine the web .</sentence>
				<definiendum id="0">Google ( http</definiendum>
				<definiendum id="1">Altavista ( http</definiendum>
				<definiens id="0">: //www.altavista.com/ ) provide the facility to mine the web</definiens>
			</definition>
			<definition id="5">
				<sentence>According to the representation of web pages , there are three kinds of the content : bag of words ( with order or not ) ( Kargupta et al. 1997 ) ( Nahm and Mooney , 2000 ) , phrases ( Ahonen et al. 1998 ) ( Frank et al. 1999 ) ( Yang et al. 1999 ) , relational terms ( Cohen , 1998 ) ( Junker 1999 ) and concept categories .</sentence>
				<definiendum id="0">relational terms</definiendum>
				<definiens id="0">kinds of the content : bag of words</definiens>
			</definition>
			<definition id="6">
				<sentence>The domain-specific web miners like SPIRAL , Cora ( Cohen , 1998 ) , WebKB ( Martin and Eklund 2000 ) and HelpfulMed ( Chen et al. 2003 ) are employed as the special search engine for the interesting topic .</sentence>
				<definiendum id="0">domain-specific web miners</definiendum>
				<definiens id="0">the special search engine for the interesting topic</definiens>
			</definition>
			<definition id="7">
				<sentence>First , the Sinorama ( Sinorama 2001 ) database is adopted as the bilingual language parallel corpus to compute the conditional probability of the words in WordNet , given the words in HowNet .</sentence>
				<definiendum id="0">Sinorama</definiendum>
				<definiens id="0">the bilingual language parallel corpus to compute the conditional probability of the words in WordNet , given the words in HowNet</definiens>
			</definition>
			<definition id="8">
				<sentence>The purpose of this approach is to increase the relation and structural information coverage by aligning the above two language-dependent ontologies , WordNet and HowNet , with different semantic features .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">to increase the relation and structural information coverage by aligning the above two language-dependent ontologies</definiens>
			</definition>
			<definition id="9">
				<sentence>Synonym pruning is an effective alternative to word sense disambiguation .</sentence>
				<definiendum id="0">Synonym pruning</definiendum>
				<definiens id="0">an effective alternative to word sense disambiguation</definiens>
			</definition>
			<definition id="10">
				<sentence>The steps are listed as follows : Step 1 : Linearization : This step decomposed the tree structure in the universal ontology shown in Figure 2 into the vertex list that is an ordered node sequence starting at the leaf nodes and ending at the root node .</sentence>
				<definiendum id="0">Linearization</definiendum>
				<definiens id="0">an ordered node sequence starting at the leaf nodes and ending at the root node</definiens>
			</definition>
			<definition id="11">
				<sentence>Step 2 : Concept extraction from the corpus : The node is defined as an operative node when the Tfidf value of word i W in the domain corpus is higher than that in its corresponding contrastive ( out-of-domain ) corpus .</sentence>
				<definiendum id="0">Concept extraction from the corpus</definiendum>
				<definiens id="0">an operative node when the Tfidf value of word i W in the domain corpus is higher than that in its corresponding contrastive ( out-of-domain ) corpus</definiens>
			</definition>
			<definition id="12">
				<sentence>The engine consists of natural language interface , web crawler and indexer , relation inference module and axiom inference module .</sentence>
				<definiendum id="0">engine</definiendum>
				<definiens id="0">consists of natural language interface , web crawler and indexer , relation inference module and axiom inference module</definiens>
			</definition>
			<definition id="13">
				<sentence>( ) 12 12 12 12 , , 1 , 1 1 , 1 , max { ( , ) , ( , ) } max { ( , , ... , , , , ... , ) , ( , , ... , , , , ... , ) } max { , } , ii i ii i ii AA APqq qR AA APqq qR PR PR RI RF pr pr pr pr Axiom A q RI A q RF A q RI w w w w w w RF w w w w w w dd == == = = = ∑∑ ( 7 ) where 1 1/2 RI n pr d − = if disease Ap w results in syndrome qr w and qr w is the top-n feature of Ap w .</sentence>
				<definiendum id="0">APqq qR AA APqq qR PR PR RI RF pr pr pr pr Axiom A q RI</definiendum>
				<definiens id="0">max { ( , ) , ( , ) } max { ( , , ... , , , , ... , ) , ( , , ... , , , , ... , ) } max {</definiens>
			</definition>
</paper>

		<paper id="3009">
			<definition id="0">
				<sentence>The major problem of speech-driven IR and QA is the decreasing of the performance due to the recognition errors in ASR systems .</sentence>
				<definiendum id="0">QA</definiendum>
			</definition>
			<definition id="1">
				<sentence>They simplified a statistical machine translation ( MT ) model called an IBM model ( Brown et al. , 1990 ) , and tried to construct a general post-processor that can correct errors generated by any speech recognizer .</sentence>
				<definiendum id="0">IBM model</definiendum>
				<definiens id="0">Brown et al. , 1990 ) , and tried to construct a general post-processor that can correct errors generated by any speech recognizer</definiens>
			</definition>
			<definition id="2">
				<sentence>The model consists of two parts : a channel model , which accounts for errors made by the ASR , and the language model , which accounts for the likelihood of a sequence of words being uttered .</sentence>
				<definiendum id="0">model</definiendum>
				<definiens id="0">consists of two parts : a channel model , which accounts for errors made by the ASR , and the language model , which accounts for the likelihood of a sequence of words being uttered</definiens>
			</definition>
			<definition id="3">
				<sentence>Suppose S = s1 ; s2 ; : : : ; sn is a syllable sequence of ASR output and W = w1 ; w2 ; : : : ; wm is a source word sequence , then our purpose is to find the best word sequence ^W as follows : ^W = arg max W P ( WjS ) ( 5 ) We can apply the same Bayes’ rule and decompose the syllable-to-word channel model into syllable-to-syllable channel model .</sentence>
				<definiendum id="0">sn</definiendum>
				<definiendum id="1">wm</definiendum>
				<definiens id="0">a syllable sequence of ASR output</definiens>
				<definiens id="1">^W = arg max W P ( WjS ) ( 5 ) We can apply the same Bayes’ rule and decompose the syllable-to-word channel model into syllable-to-syllable channel model</definiens>
			</definition>
			<definition id="4">
				<sentence>P ( wjs ) = P ( sjw ) P ( w ) P ( s ) / P ( sjw ) P ( w ) … P ( sjx ) P ( xjw ) P ( w ) ( 6 ) So , final formula can be written as : ^W = arg max W ( P ( W ) P ( XjW ) P ( SjX ) ) ( 7 ) Here , P ( SjX ) is the probability of a syllable-tosyllable transformation , where X = x1 ; x2 ; : : : ; xn is a source syllable sequence .</sentence>
				<definiendum id="0">P ( wjs</definiendum>
				<definiendum id="1">P ( SjX )</definiendum>
				<definiendum id="2">xn</definiendum>
				<definiens id="0">the probability of a syllable-tosyllable transformation</definiens>
			</definition>
			<definition id="5">
				<sentence>Let C ( xi ) be the frequency of source syllable , and C ( xi ; si ) be the frequency of events where xi substitute si .</sentence>
				<definiendum id="0">C ( xi )</definiendum>
			</definition>
			<definition id="6">
				<sentence>For Witten-Bell discounting , we should define Z ( xi ) , which is the number of syllable xi with count zero .</sentence>
				<definiendum id="0">Z ( xi )</definiendum>
				<definiens id="0">the number of syllable xi with count zero</definiens>
			</definition>
			<definition id="7">
				<sentence>A lexico-semantic pattern ( LSP ) is a structure where linguistic entries and semantic types are used in combination to abstract certain sequences of the words in a text .</sentence>
				<definiendum id="0">lexico-semantic pattern</definiendum>
				<definiendum id="1">LSP</definiendum>
				<definiens id="0">a structure where linguistic entries and semantic types are used in combination to abstract certain sequences of the words in a text</definiens>
			</definition>
			<definition id="8">
				<sentence>To measure error correction performance , we use word error rate ( WER ) and term error rate ( TER ) : WER = jSwj + jIwj + jDwjjW truthj ( 10 ) TER = jStj + jItj + jDtjjT truthj ( 11 ) jWtruthj is the number of original words , and jTtruthj is the number of query term ( or keyword ) in original words , that is , an error rate of content words directly related to the performance of IR and QA system ( Fujii et al. , 2002A ) .</sentence>
				<definiendum id="0">WER</definiendum>
				<definiendum id="1">TER</definiendum>
				<definiendum id="2">jWtruthj</definiendum>
				<definiendum id="3">jTtruthj</definiendum>
				<definiens id="0">the number of original words</definiens>
			</definition>
</paper>

		<paper id="1503">
			<definition id="0">
				<sentence>An Extended Context-Free Grammar ( or ECFG for short ) is like a context-free grammar ( CFG ) , except that the right-hand side is a regular expression over the terminal and nonterminal symbols of the grammar .</sentence>
				<definiendum id="0">Extended Context-Free Grammar</definiendum>
				<definiendum id="1">CFG</definiendum>
				<definiendum id="2">right-hand side</definiendum>
				<definiens id="0">a regular expression over the terminal and nonterminal symbols of the grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>If F is a class of grammars ( such as CFG ) , then L ( F ) denote the class of languages generated by the grammars in F. We now give a formal definition , which closely follows that given by Albert et al. ( 1999 ) .7 A Extended Context-Free Grammar is a 4tuple ( VN ; VT ; P ; S ) , where : VN is a finite set of nonterminal symbols , VT is a finite set of terminal symbols ( disjoint from VN ) , P is a finite set of rules , which are ordered pairs consisting of an element of VN and a regular expression over VN [ VT , S , a subset of VN , contains the possible start symbols .</sentence>
				<definiendum id="0">Context-Free Grammar</definiendum>
				<definiendum id="1">VN</definiendum>
				<definiendum id="2">VT</definiendum>
				<definiendum id="3">P</definiendum>
				<definiens id="0">a class of grammars ( such as CFG ) , then L ( F ) denote the class of languages generated by the grammars in F. We now give a formal definition , which closely follows that given by Albert et al. ( 1999 ) .7 A Extended</definiens>
				<definiens id="1">a 4tuple ( VN</definiens>
				<definiens id="2">a finite set of nonterminal symbols</definiens>
				<definiens id="3">a finite set of terminal symbols ( disjoint from VN ) ,</definiens>
				<definiens id="4">a finite set of rules , which are ordered pairs consisting of an element of VN and a regular expression over VN [ VT , S , a subset of VN , contains the possible start symbols</definiens>
			</definition>
			<definition id="2">
				<sentence>When we use a GDG for linguistic description , its lefthand side nonterminal will be interpreted as the lexical category of the lexical item and will represent its maximal projection.8 A Generative Dependency Grammar is a lexicalized ECFG .</sentence>
				<definiendum id="0">Generative Dependency Grammar</definiendum>
				<definiens id="0">a lexicalized ECFG</definiens>
			</definition>
			<definition id="3">
				<sentence>Initialization : For each i , 1 i n , add wi to ti ; i. Completion : If ti ; j contains either the input symbol w or an item ( M ; q ) such that q is a final state of M , and M is a C-rule-FSM , then add to ti ; j all ( M0 ; q0 ) such that M0 is a rule-FSM which transitions from a start state to state q0 on input w or C. Add a single backpointer from ( M0 ; q0 ) in ti ; j to ( M ; q ) or w in ti ; j. 9Recent work in the context of using ECFG for parsing SGML and XML proposes an LL-type parser for ECFG ( Br¨uggemann-Klein and Wood , 2003 ) ; their approach also exploits the automaton representation of the right-hand side of rules , as is natural for an algorithm dealing with ECFG .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">XML</definiendum>
				<definiens id="0">add wi to ti ; i. Completion : If ti ; j contains either the input symbol w or an item</definiens>
				<definiens id="1">a C-rule-FSM</definiens>
				<definiens id="2">proposes an LL-type parser for ECFG ( Br¨uggemann-Klein and Wood , 2003 ) ; their approach also exploits the automaton representation of the right-hand side of rules</definiens>
			</definition>
			<definition id="4">
				<sentence>m1 is a V-rule-FSM corresponding to rule p1 , m2 is an N-rule-FSM which corresponds to rule p2 and m3 is a P-rule-FSM which corresponds to rule p3 P ( 3 ) P ( 2 ) N ( 4 ) N ( 3 ) telescopewith a D ( 2 ) V ( 5 ) V ( 5 ) V ( 4 ) sawV ( 3 ) N ( 4 ) Pilar man N ( 4 ) N ( 3 ) a D ( 2 ) V ( 5 ) P ( 3 ) P ( 2 ) N ( 4 ) N ( 3 ) telescopewith a D ( 2 ) N ( 4 ) man N ( 4 ) N ( 3 ) a D ( 2 ) V ( 4 ) sawV ( 3 ) N ( 4 ) Pilar Figure 6 : A parse forest Scanning : If ( M1 ; q1 ) is in ti ; k , and tk+1 ; j contains either the input symbol w or the item ( M2 ; q2 ) where q2 is a final state and M2 is a C-rule-FSM , then add ( M1 ; q ) to ti ; j ( if not already present ) if M1 transitions from q1 to q on either w or C. Add a double backpointer from ( M1 ; q ) in ti ; j to ( M1 ; q1 ) in ti ; k ( left backpointer ) and to either w or ( M2 ; q2 ) in tk+1 ; j ( right backpointer ) .</sentence>
				<definiendum id="0">m1</definiendum>
				<definiendum id="1">m2</definiendum>
				<definiendum id="2">m3</definiendum>
				<definiendum id="3">M2</definiendum>
				<definiens id="0">a V-rule-FSM corresponding to rule p1 ,</definiens>
				<definiens id="1">A parse forest Scanning : If ( M1 ; q1 ) is in ti ; k , and tk+1 ; j contains either the input symbol w or the item ( M2 ; q2 ) where q2 is a final state</definiens>
			</definition>
</paper>

		<paper id="2604">
			<definition id="0">
				<sentence>WordNet : An Eletronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>Wordnet : A dictionary browser .</sentence>
				<definiendum id="0">Wordnet</definiendum>
				<definiens id="0">A dictionary browser</definiens>
			</definition>
</paper>

		<paper id="1306">
			<definition id="0">
				<sentence>Once these are acquired , they can serve as a basis from which learners can acquire the rest of the grammar , namely , the phonological rules ( and/or constraints ) and the lexical , or underlying , representations .</sentence>
				<definiendum id="0">phonological rules</definiendum>
				<definiens id="0">and/or constraints</definiens>
			</definition>
			<definition id="1">
				<sentence>This is known as the Credit Problem ( cf. Clark 1989 , 1992 , who calls this the Selection Problem ) : a learner can not reliably assign credit or blame to individual parameters when something is wrong .</sentence>
				<definiendum id="0">Credit Problem</definiendum>
				<definiendum id="1">Selection Problem )</definiendum>
			</definition>
</paper>

		<paper id="1608">
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>The new open-access journal , PLoS Biology , offers five “Views” of a paper : HTML , Tables , Figures , Print PDF and Screen PDF .</sentence>
				<definiendum id="0">PLoS Biology</definiendum>
				<definiens id="0">offers five “Views” of a paper : HTML , Tables , Figures , Print PDF and Screen PDF</definiens>
			</definition>
			<definition id="1">
				<sentence>Diagrams form a part of a coordinated discourse , so that diagram summarization can profit from the work done on text summarization that focuses on discourse structure .</sentence>
				<definiendum id="0">Diagrams</definiendum>
				<definiens id="0">form a part of a coordinated discourse</definiens>
			</definition>
</paper>

		<paper id="0204">
</paper>

		<paper id="1605">
			<definition id="0">
				<sentence>Permutation algorithms ( Al-Shalabi and Evens , 1998 ) usetheinputword’sletterstogenerate all possible trilateral or quadrilateral sequences without violation of the original order of the letters whichisthencomparedwithitemsinadictionaryof roots until a match is found .</sentence>
				<definiendum id="0">Permutation algorithms</definiendum>
				<definiens id="0">usetheinputword’sletterstogenerate all possible trilateral or quadrilateral sequences without violation of the original order of the letters whichisthencomparedwithitemsinadictionaryof roots until a match is found</definiens>
			</definition>
			<definition id="1">
				<sentence>The Template table lists all morphosemantic and morphosyntactic patterns used to generate stems from roots of a certain type .</sentence>
				<definiendum id="0">Template table</definiendum>
				<definiens id="0">lists all morphosemantic and morphosyntactic patterns used to generate stems from roots of a certain type</definiens>
			</definition>
			<definition id="2">
				<sentence>Since originally Arabic words can have a maximum of four root radicals , a root radical set R is defined in terms of the ordered letters of the root as follows : R = { rF , rM , rL , rQ } ( 1 ) In the database , pattern , root , variant , and voicetense ids identify a particular morphological pattern s. Templatesareusedtogenerateastemfromaroot .</sentence>
				<definiendum id="0">voicetense ids</definiendum>
				<definiens id="0">the ordered letters of the root as follows : R = { rF , rM , rL , rQ } ( 1 ) In the database , pattern , root , variant , and</definiens>
			</definition>
			<definition id="3">
				<sentence>Thetextof s isdefinedintermsofthelettersanddiacriticsofthetemplateinsequence ( x1 ... xl ) andthe radical position markers or place holders ( hF , hM , hL , and hQ ) , that indicate the positions that letters of the root should be slotted into : s = x1x2 ... hF ... hM ... hL ... hQ ... xn ( 2 ) Stem Generator ( SG ) uses regular expressions as the language for compiling FSTs for morphophonemictransformations .</sentence>
				<definiendum id="0">SG )</definiendum>
				<definiens id="0">uses regular expressions as the language for compiling FSTs for morphophonemictransformations</definiens>
			</definition>
			<definition id="4">
				<sentence>Forexample , hF rehisoَ hM seenisoَ hL meemisoَ ( FraMsaLma ) is an intermediate template formed by the root radical set R = { rehiso , seeniso , meemiso } ( { r , s , m } ) and the morphological pattern s = hFَ hMَ hLَ ( FaMaLa ) .</sentence>
				<definiendum id="0">FaMaLa</definiendum>
				<definiens id="0">an intermediate template formed by the root radical set R = { rehiso , seeniso , meemiso } ( { r , s , m } ) and the morphological pattern s = hFَ hMَ hLَ</definiens>
			</definition>
			<definition id="5">
				<sentence>SG begins with a stem ID from the MainDictionarytableasinputto Stem Transformer ( SeeFigure 1 ) .</sentence>
				<definiendum id="0">SG</definiendum>
			</definition>
			<definition id="6">
				<sentence>Stem Transformer generates a proper stem using the following steps : Equation 3 above creates the initial intermediate template when passed the radical set and morphological template , thus producing : i0 = CompileIntermediate ( R , s ) = alifisoِ hF thalisoْ tehisoَ hM kafisoَ hL rehisoَ ( AiF @ taMkaLra ) The first transformation rule t1 = 1 , t1 ∈ T is a regularexpressionthatsearchesforatehiso ( t ) following hF and replaces tehiso ( t ) with a copy of rF .</sentence>
				<definiendum id="0">Stem Transformer</definiendum>
				<definiendum id="1">t1 ∈ T</definiendum>
				<definiens id="0">generates a proper stem using the following steps : Equation 3 above creates the initial intermediate template when passed the radical set and morphological template</definiens>
				<definiens id="1">a regularexpressionthatsearchesforatehiso ( t ) following hF and replaces tehiso ( t ) with a copy of rF</definiens>
			</definition>
</paper>

		<paper id="3233">
			<definition id="0">
				<sentence>NP Bracketing was the shared task of the Computational Natural Language Learning workshop in 1999 ( CoNLL-99 ) .</sentence>
				<definiendum id="0">NP Bracketing</definiendum>
				<definiens id="0">was the shared task of the Computational Natural Language Learning workshop in 1999 ( CoNLL-99 )</definiens>
			</definition>
			<definition id="1">
				<sentence>Our decoder assumes a maximum depth of tags d has been prespecified and then solves a dynamic programming problem on an n d t array A , where n is the sentence length and t denotes an integer corresponding to the highest possible decoding tag in an enumeration .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the sentence length and t denotes an integer corresponding to the highest possible decoding tag in an enumeration</definiens>
			</definition>
			<definition id="2">
				<sentence>For this task , we get the following optimization problem ( Joachims , 2002 ) : minimize 12jj wjj2 + C NX i=1 i ; j ( 6 ) subject to w xi w xj + 1 i ; j ( 7 ) i ; j 0 ( 8 ) Where the i ; js are drawn from comparable data points and yi yj and C is a regularization parameter that specifies how great the cost of mis-ordering is .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">drawn from comparable data points and yi yj and</definiens>
			</definition>
			<definition id="3">
				<sentence>At a given value of , the segmentation along the Y-axes depict ( a ) along the top ( in yellow where available ) , the proportion of sentences for which the bracketer’s precision ( for the left hand image ) was at least of that of Collins’ ; ( b ) in the middle ( in red ) , the proportion of sentences for which Collins’ was at least better ; and ( c ) along the bottom ( in blue ) , the proportion of sentences where the two systems performed within of each other .</sentence>
				<definiendum id="0">segmentation along the Y-axes depict</definiendum>
			</definition>
</paper>

		<paper id="0804">
			<definition id="0">
				<sentence>XWN is used as a core knowledge base for applications such as question answering , information retrieval , information extraction , summarization , natural language generation , inferences , and other knowledge intensive applications .</sentence>
				<definiendum id="0">XWN</definiendum>
				<definiens id="0">question answering , information retrieval , information extraction , summarization , natural language generation , inferences , and other knowledge intensive applications</definiens>
			</definition>
			<definition id="1">
				<sentence>The Extended WordNet ( XWN ) project has disambiguated the content words ( nouns , verbs , adjectives , and adverbs ) of all glosses , combining human annotation and automated methods using WordNet 1.7.1 .</sentence>
				<definiendum id="0">Extended WordNet</definiendum>
				<definiens id="0">the content words ( nouns , verbs , adjectives , and adverbs ) of all glosses , combining human annotation</definiens>
			</definition>
</paper>

		<paper id="1120">
			<definition id="0">
				<sentence>&lt; W ; POS ; DP &gt; = arg max W ; POS ; DP P ( W ; POS ; DP ) The joint probability distribution P ( W ; POS ; DP ) can be written in the following form using the chain rule of probability : P ( W ; POS ; DP ) =P ( W ) P ( POSjW ) P ( DPjW ; POS ) Where P ( W ) is considered as the probability of the word segmentation layer , P ( POSjW ) is the conditional probability of POS Tagging with a given word segmentation result , P ( DPjW ; POS ) is the conditional probability of a dependency parsing tree with a given word segmentation and POS Tagging result similarly .</sentence>
				<definiendum id="0">DP P</definiendum>
				<definiendum id="1">P</definiendum>
				<definiendum id="2">P ( DPjW ; POS )</definiendum>
				<definiens id="0">the conditional probability of a dependency parsing tree with a given word segmentation</definiens>
			</definition>
			<definition id="1">
				<sentence>Sn = w1s1 +w2s2 +¢¢¢+wnsn ( 2 ) si denotes the score of the ith layer component which we will introduce in Section 3 ; wi denotes the weight of the ith layer components which we will introduce in the next section .</sentence>
				<definiendum id="0">wi</definiendum>
				<definiens id="0">the score of the ith layer component which we will introduce in Section 3 ;</definiens>
				<definiens id="1">the weight of the ith layer components which we will introduce in the next section</definiens>
			</definition>
			<definition id="2">
				<sentence>minSn returns the optimal analysis results with the lowest score .</sentence>
				<definiendum id="0">minSn</definiendum>
				<definiens id="0">returns the optimal analysis results with the lowest score</definiens>
			</definition>
			<definition id="3">
				<sentence>t⁄ = arg min t ErrRate ( t ) ErrRate ( t ) denotes the Error Rate with the threshold t. An error has two deflnitions : † SC is higher than t but the flrst result is fault † SC is lower than t but the flrst result is right Then the Error Rate is the ratio between the error number and the total number of sentences .</sentence>
				<definiendum id="0">SC</definiendum>
				<definiendum id="1">Error Rate</definiendum>
				<definiens id="0">the Error Rate with the threshold t. An error has two deflnitions : † SC is higher than t but the flrst result is fault †</definiens>
				<definiens id="1">the ratio between the error number and the total number of sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>The result of Word-Seg is used to test our system’s performance , which means that the ObjFun ( ⁄ ) returns the F-Score of Word-Seg .</sentence>
				<definiendum id="0">Word-Seg</definiendum>
				<definiendum id="1">system’s performance</definiendum>
				<definiens id="0">means that the ObjFun ( ⁄ ) returns the F-Score of Word-Seg</definiens>
			</definition>
			<definition id="5">
				<sentence>But the MSM synthesizes all the information of Word-Seg , POS Tagging and Parsing .</sentence>
				<definiendum id="0">MSM</definiendum>
				<definiens id="0">synthesizes all the information of Word-Seg , POS Tagging and Parsing</definiens>
			</definition>
			<definition id="6">
				<sentence>In the future we are going to add the Phrase Analysis , WSD ( Word Sense Disambiguation ) and Semantic Analysis components into CUP , because it is impossible to analyze some sentences correctly without semantic understanding and the Phrase Analysis helps to enhance the performance of Parsing .</sentence>
				<definiendum id="0">WSD ( Word Sense Disambiguation</definiendum>
			</definition>
			<definition id="7">
				<sentence>Artiflcial Intelligence : A Modern Approach .</sentence>
				<definiendum id="0">Artiflcial Intelligence</definiendum>
				<definiens id="0">A Modern Approach</definiens>
			</definition>
			<definition id="8">
				<sentence>GAlib : A C++ Library of Genetic Algorithms components .</sentence>
				<definiendum id="0">GAlib</definiendum>
			</definition>
</paper>

		<paper id="2422">
</paper>

		<paper id="0304">
			<definition id="0">
				<sentence>The Mediator interprets the information received from reference and determines how the parser’s chart should be modified .</sentence>
				<definiendum id="0">Mediator</definiendum>
				<definiens id="0">interprets the information received from reference and determines how the parser’s chart should be modified</definiens>
			</definition>
			<definition id="1">
				<sentence>The Monroe domain ( Tetreault et al. , 2004 ; Stent , 2001 ) is a series of task-oriented dialogues between human participants set in a simulated rescue operation domain , where participants collaboratively plan responses to emergency calls .</sentence>
				<definiendum id="0">Monroe domain</definiendum>
				<definiens id="0">a series of task-oriented dialogues between human participants set in a simulated rescue operation domain</definiens>
			</definition>
			<definition id="2">
				<sentence>Gemini : A natural language system for spokenlanguage understanding .</sentence>
				<definiendum id="0">Gemini</definiendum>
			</definition>
			<definition id="3">
				<sentence>Trains95 : Towards a mixed-initiative planning assistant .</sentence>
				<definiendum id="0">Trains95</definiendum>
				<definiens id="0">Towards a mixed-initiative planning assistant</definiens>
			</definition>
</paper>

		<paper id="2610">
			<definition id="0">
				<sentence>Complex Nominals Levi ( Levi 1979 ) defines complex nominals ( CNs ) as expressions that have a head noun preceded by one or more modifying nouns , or by adjectives derived from nouns ( usually called denominal adjectives ) .</sentence>
				<definiendum id="0">Complex Nominals Levi</definiendum>
				<definiendum id="1">complex nominals</definiendum>
				<definiens id="0">a head noun preceded by one or more modifying nouns , or by adjectives derived from nouns ( usually called denominal adjectives )</definiens>
			</definition>
			<definition id="1">
				<sentence>Prepositions play an important role both syntactically and semantically ( ( Dorr 1997 ) .</sentence>
				<definiendum id="0">Prepositions</definiendum>
			</definition>
			<definition id="2">
				<sentence>Often they are introduced by a relative pronoun/adverb ( ie that , which , who , whom , whose , where ) as in the following examples : ( 1 ) Here is the book which I am reading ( book is the THEME of reading ) ( 2 ) The man who was driving the car was a spy ( man is the AGENT of driving ) .</sentence>
				<definiendum id="0">Here</definiendum>
				<definiendum id="1">book</definiendum>
				<definiendum id="2">man</definiendum>
				<definiens id="0">the book which I am reading</definiens>
			</definition>
			<definition id="3">
				<sentence>This type is also called agential nominalization ( Quirk et al.1985 ) as the nominalized noun captures information about both the subject and verb .</sentence>
				<definiendum id="0">agential nominalization</definiendum>
				<definiens id="0">the nominalized noun captures information about both the subject and verb</definiens>
			</definition>
			<definition id="4">
				<sentence>The annotators’ agreement was measured using the Kappa statistics ( Siegel and Castellan 1988 ) , one of the most frequently used measure of inter-annotator agreement for classification tasks : a56a58a57a60a59a6a61a33a62 a10a20a63 a5 a59a6a61a33a62a36a64 a63 a65 a5 a59a28a61a41a62a36a64 a63 , where a66a68a67a49a69a39a70a72a71 is the proportion of times the raters agree and a66a68a67a49a69a39a73a74a71 is the probability of agreement by chance .</sentence>
				<definiendum id="0">Kappa statistics</definiendum>
				<definiendum id="1">a66a68a67a49a69a39a70a72a71</definiendum>
				<definiens id="0">the probability of agreement by chance</definiens>
			</definition>
			<definition id="5">
				<sentence>Support Vector Machines ( SVM ) have a strong mathematical foundation ( Vapnik 1982 ) and have been applied successfully to text classification ( Tong and Koller 2001 ) , speech recognition , and other applications .</sentence>
				<definiendum id="0">Support Vector Machines ( SVM</definiendum>
				<definiens id="0">a strong mathematical foundation ( Vapnik 1982 ) and have been applied successfully to text classification ( Tong and Koller 2001 ) , speech recognition</definiens>
			</definition>
			<definition id="6">
				<sentence>SVM algorithms are a special class of hyperplane classifiers that use the information encoded in the dotproducts of the transformed feature vectors as a similarity measure .</sentence>
				<definiendum id="0">SVM algorithms</definiendum>
				<definiens id="0">a special class of hyperplane classifiers that use the information encoded in the dotproducts of the transformed feature vectors as a similarity measure</definiens>
			</definition>
			<definition id="7">
				<sentence>The Kernel function a56 is the inner product of the non-linear function a15a20a3a21a4a22a9a24a23 that maps the original feature vectors into real feature space .</sentence>
				<definiendum id="0">Kernel function a56</definiendum>
				<definiens id="0">the inner product of the non-linear function a15a20a3a21a4a22a9a24a23 that maps the original feature vectors into real feature space</definiens>
			</definition>
			<definition id="8">
				<sentence>ComLex ( Grishman et al.1994 ) is a computational lexicon providing syntactic information for more than 38,000 English headwords .</sentence>
				<definiendum id="0">ComLex</definiendum>
			</definition>
			<definition id="9">
				<sentence>VerbLeX is an in-house verb lexicon built by enriching VerbNet ( Kipper et al. 2000 ) with verb synsets from WordNet and verbs extracted from the semantic frames of FrameNet .</sentence>
				<definiendum id="0">VerbLeX</definiendum>
				<definiens id="0">with verb synsets from WordNet and verbs extracted from the semantic frames of FrameNet</definiens>
			</definition>
			<definition id="10">
				<sentence>VerbNet classes extended in VerbLeX contain selectional restrictions for different semantic roles inside the verb frame .</sentence>
				<definiendum id="0">VerbNet classes</definiendum>
				<definiens id="0">different semantic roles inside the verb frame</definiens>
			</definition>
			<definition id="11">
				<sentence>The in-house extended verb lexicon VerbLeX shows the following semantic frame for the verb class fillTheme [ +concrete ] Body-part is a subcategory of concrete .</sentence>
				<definiendum id="0">Body-part</definiendum>
				<definiens id="0">a subcategory of concrete</definiens>
			</definition>
</paper>

		<paper id="1611">
			<definition id="0">
				<sentence>One is a phonemic based transcription of sounds for acoustic modelling in Automatic Speech Recognizers and for Text to Speech synthesizer , using ASCII based symbols , rather than International Phonetic Alphabet symbols .</sentence>
				<definiendum id="0">Recognizers</definiendum>
				<definiens id="0">a phonemic based transcription of sounds for acoustic modelling in Automatic Speech</definiens>
			</definition>
			<definition id="1">
				<sentence>( 1 ) a visual and control Graphical User Interface ( GUI ) ; ( 2 ) an Automatic Speech Recognition ( ASR ) subsystem , which works both using Fixed State Grammars ( FSG ) and Language Models ( LM ) , producing n-best lists/lattices along with the decoding confidence scores ; ( 3 ) a Dialog Manager ( DM ) , which receives the output of the speech recognition and machine translation units and subsequently re-scores’’ the data according to the history of the conversation ; ( 4 ) a Machine Translation ( MT ) unit , which works in two modes : Classifier based MT and a fully Stochastic MT ; and finally ( 5 ) a unit selection based Text To Speech synthesizer ( TTS ) , which provides the spoken output .</sentence>
				<definiendum id="0">TTS )</definiendum>
				<definiens id="0">works both using Fixed State Grammars ( FSG ) and Language Models ( LM ) , producing n-best lists/lattices along with the decoding confidence scores</definiens>
				<definiens id="1">receives the output of the speech recognition and machine translation units and subsequently re-scores’’ the data according to the history of the conversation ; ( 4 ) a Machine Translation ( MT ) unit , which works in two modes : Classifier based</definiens>
				<definiens id="2">provides the spoken output</definiens>
			</definition>
			<definition id="2">
				<sentence>Persian Persian is an Indo-European language with a writing system based on the Arabic script .</sentence>
				<definiendum id="0">Persian Persian</definiendum>
			</definition>
			<definition id="3">
				<sentence>The other problem that is common in all languages using the Arabic script is the existance of a large number of homographic words , i.e. , orthographic representations that have a similar form but different pronunciation .</sentence>
				<definiendum id="0">Arabic script</definiendum>
				<definiens id="0">the existance of a large number of homographic words , i.e. , orthographic representations that have a similar form but different pronunciation</definiens>
			</definition>
			<definition id="4">
				<sentence>Persian has a total of 29 sounds in its inventory , six vowels ( Section 2.1 ) and 23 consonants ( Section sounds is a modified version of the International Phonetic Alphabet ( IPA ) , called USCPron ( unciation ) .</sentence>
				<definiendum id="0">Persian</definiendum>
				<definiendum id="1">Phonetic Alphabet</definiendum>
				<definiens id="0">a total of 29 sounds in its inventory , six vowels ( Section 2.1 ) and 23 consonants ( Section sounds is a modified version of the International</definiens>
			</definition>
			<definition id="5">
				<sentence>These consonants are represented in Table 3 based on the place ( bilabial ( BL ) , lab-dental ( LD ) , dental ( DE ) , alveopalatal ( AP ) , velar ( VL ) , uvular ( UV ) and glottal ( GT ) ) and manner of articulation ( stops ( ST ) , fricatives ( FR ) , affricates ( AF ) , liquids ( LQ ) , nasals ( NS ) and glides ( GL ) ) and their voicing ( [ -v ( oice ) ] and [ +v ( oice ) ] .</sentence>
				<definiendum id="0">articulation ( stops</definiendum>
				<definiendum id="1">voicing</definiendum>
				<definiens id="0">fricatives ( FR ) , affricates ( AF ) , liquids ( LQ ) , nasals ( NS ) and glides ( GL )</definiens>
			</definition>
			<definition id="6">
				<sentence>The Persian writing system is a consonantal system with 32 letters in its alphabet ( Windfuhr , 1987 ) .</sentence>
				<definiendum id="0">Persian writing system</definiendum>
			</definition>
			<definition id="7">
				<sentence>USCPers , therefore , provides us with a way to capture each letter of the alphabet with one and only one ASCII symbol , creating a comparable system to USCPron for the orthography .</sentence>
				<definiendum id="0">USCPers</definiendum>
				<definiens id="0">provides us with a way to capture each letter of the alphabet with one and only one ASCII symbol , creating a comparable system to USCPron for the orthography</definiens>
			</definition>
			<definition id="8">
				<sentence>These two properties can give rise to two sources of ambiguity in Persian which can pose a problem for speech-to-speech machine translation : ( i ) in which two distinct words have the same pronunciation ( homophones ) , like pair and pear in English and the Persian words like sd and $ d , which are both pronounced as [ sad ] and ( ii ) in which one orthographic representation can have more than one pronunciation ( homographs ) similar to the distinction between the two English words convict ( n ) and convict ( v ) , which are both spelled c-o-n-vi-c-t , but different stress assignments create different pronunciations .</sentence>
				<definiendum id="0">convict ( v )</definiendum>
				<definiens id="0">give rise to two sources of ambiguity in Persian which can pose a problem for speech-to-speech machine translation : ( i ) in which two distinct words have the same pronunciation</definiens>
			</definition>
			<definition id="9">
				<sentence>bbr [ bebor ] tiger bbr [ babr ] Table 9 : Same Spelling , Different Pronunciations Here , we see that in the middle column two words that have the same orthographic representation correspond to different pronunciations ( Column 3 ) , marking different meanings , as is indicated by the gloss .</sentence>
				<definiendum id="0">tiger bbr</definiendum>
				<definiens id="0">the same orthographic representation correspond to different pronunciations</definiens>
			</definition>
			<definition id="10">
				<sentence>In other words , USCPers+ provides both the orthographic information as well as some phonological information , giving rise to unique words .</sentence>
				<definiendum id="0">USCPers+</definiendum>
				<definiens id="0">provides both the orthographic information as well as some phonological information , giving rise to unique words</definiens>
			</definition>
</paper>

		<paper id="1310">
			<definition id="0">
				<sentence>Average inter-coder reliability ( measured for each coder as the percentage of items coded exactly the same way they were coded by each other coder ) was 86.1 % .</sentence>
				<definiendum id="0">Average inter-coder reliability</definiendum>
				<definiens id="0">the percentage of items coded exactly the same way they were coded by each other coder</definiens>
			</definition>
</paper>

		<paper id="2507">
			<definition id="0">
				<sentence>HITIQA is an interactive open-domain question answering technology designed to allow analysts to pose complex exploratory questions in natural language and obtain relevant information units to prepare their briefing reports in order to satisfy a given scenario .</sentence>
				<definiendum id="0">HITIQA</definiendum>
				<definiens id="0">an interactive open-domain question answering technology designed to allow analysts to pose complex exploratory questions in natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>HITIQA project is part of the ARDA AQUAINT program that aims to make significant advances in the state of the art of automated question answering .</sentence>
				<definiendum id="0">HITIQA project</definiendum>
				<definiens id="0">part of the ARDA AQUAINT program that aims to make significant advances in the state of the art of automated question answering</definiens>
			</definition>
			<definition id="2">
				<sentence>The Answer Panel displays the user’s current answer at any given time during the interaction for a single question .</sentence>
				<definiendum id="0">Answer Panel</definiendum>
				<definiens id="0">displays the user’s current answer at any given time during the interaction for a single question</definiens>
			</definition>
			<definition id="3">
				<sentence>The Visual panel offers the user an alternative to reading text by providing a tool for visually browsing the entire answer space .</sentence>
				<definiendum id="0">Visual panel</definiendum>
				<definiens id="0">offers the user an alternative to reading text by providing a tool for visually browsing the entire answer space</definiens>
			</definition>
			<definition id="4">
				<sentence>HTIQA provides the user with a tool to find the passages needed to complete a report for a given scenario .</sentence>
				<definiendum id="0">HTIQA</definiendum>
				<definiens id="0">provides the user with a tool to find the passages needed to complete a report for a given scenario</definiens>
			</definition>
</paper>

		<paper id="1502">
			<definition id="0">
				<sentence>Vibhakti is a Sanskrit grammatical term that encompasses postpositionals and case endings for nouns , as well as inflection and auxiliaries for verbs .</sentence>
				<definiendum id="0">Vibhakti</definiendum>
				<definiens id="0">a Sanskrit grammatical term that encompasses postpositionals and case endings for nouns , as well as inflection and auxiliaries for verbs</definiens>
			</definition>
			<definition id="1">
				<sentence>The syntactic role of inflection in Arabic is well defined ( cf. ( Fischer , 2002 ) ) , and the relevant rules ( for the examples under consideration ) can be summarised as follows : • Nominative case : ( -un or -u ) marksthe subject • Verbs agree in number and gender with the subject • Where a verbal argument is absent , a pronominal aﬃx ( e.g. -h¯a ) is attached to the verb , which will agree in number and gender with the missing item .</sentence>
				<definiendum id="0">relevant rules</definiendum>
				<definiendum id="1">pronominal aﬃx</definiendum>
				<definiens id="0">-un or -u ) marksthe subject • Verbs agree in number and gender with the subject • Where a verbal argument is absent , a</definiens>
			</definition>
			<definition id="2">
				<sentence>Tomakethismoreexplicit , wehaveseparated the resumptive pronoun from the complement in the PGF analysis and shown the karaka relation that exists between them .</sentence>
				<definiendum id="0">Tomakethismoreexplicit</definiendum>
				<definiens id="0">wehaveseparated the resumptive pronoun from the complement in the PGF analysis and shown the karaka relation that exists between them</definiens>
			</definition>
			<definition id="3">
				<sentence>Usability Evaluation of Grammar Formalisms for Free Word Order Natural Language Processing .</sentence>
				<definiendum id="0">Usability Evaluation</definiendum>
			</definition>
</paper>

		<paper id="3220">
			<definition id="0">
				<sentence>More formally , the model is a factored representation of a joint distribution over these variables and the data : the verb sense ( V ) , the verb SCF ( C ) , the unordered context “bag-of-words” ( W ) , and the sentence as an ordered sequence of words ( S ) .</sentence>
				<definiendum id="0">verb SCF</definiendum>
				<definiens id="0">a factored representation of a joint distribution over these variables and the data : the verb sense ( V ) , the</definiens>
			</definition>
			<definition id="1">
				<sentence>( For the Senseval-2 corpus , this collection includes not only the words in the sentence in which the verb occurs , but also the words in surrounding sentences . )</sentence>
				<definiendum id="0">the Senseval-2 corpus</definiendum>
				<definiens id="0">the words in the sentence in which the verb occurs , but also the words in surrounding sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>We learn the marginal over verb sense with maximum likelihood estimation ( MLE ) from the sense annotated data .</sentence>
				<definiendum id="0">MLE</definiendum>
				<definiens id="0">the marginal over verb sense with maximum likelihood estimation (</definiens>
			</definition>
			<definition id="3">
				<sentence>The verb SCF component of our model P.SjC/ represents the probability of particular sentences given each possible SCF .</sentence>
				<definiendum id="0">model P.SjC/</definiendum>
				<definiens id="0">the probability of particular sentences given each possible SCF</definiens>
			</definition>
			<definition id="4">
				<sentence>40.5 38.8 59.9 70.8 60.2 72.8 54.7 59.7 55.6 61.4 35 40 45 50 55 60 65 70 75 80 Sense Subcat T e s t A c c u r a c y Baseline Individual 10-fold Joint 10-fold Individual test Joint test Figure 2 : Chart comparing results of independent and joint systems on the verb sense and SCF tasks , evaluated with 10-fold cross-validation on the training sets and on the test sets .</sentence>
				<definiendum id="0">e</definiendum>
				<definiendum id="1">SCF</definiendum>
				<definiens id="0">s t A c c u r a c y Baseline Individual 10-fold Joint 10-fold Individual test Joint test Figure 2 : Chart comparing results of independent and joint systems on the verb sense</definiens>
			</definition>
			<definition id="5">
				<sentence>40.5 38.8 52.4 68.5 54.7 69.8 54.0 59.3 55.9 61.4 35 40 45 50 55 60 65 70 75 80 Sense Subcat T e s t A c c u r a c y Baseline Individual 10-fold Joint 10-fold Individual test Joint test Figure 3 : Chart comparing results of independent and joint systems on the verb sense and SCF tasks .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">s t A c c u r a c y Baseline Individual 10-fold Joint 10-fold Individual test Joint test Figure 3 : Chart comparing results of independent and joint systems on the verb sense</definiens>
			</definition>
			<definition id="6">
				<sentence>40.5 38.8 45.0 68.5 49.2 69.1 46.2 59.3 50.7 59.6 35 40 45 50 55 60 65 70 75 80 Sense Subcat T e s t A c c u r a c y Baseline Individual 10-fold Joint 10-fold Individual test Joint test Figure 4 : Chart comparing results of independent and joint systems on the verb sense and SCF tasks .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">s t A c c u r a c y Baseline Individual 10-fold Joint 10-fold Individual test Joint test Figure 4 : Chart comparing results of independent and joint systems on the verb sense</definiens>
			</definition>
</paper>

		<paper id="1118">
			<definition id="0">
				<sentence>The translation model links the source language sentence to the target language sentence .</sentence>
				<definiendum id="0">translation model</definiendum>
				<definiens id="0">links the source language sentence to the target language sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The argmax operation denotes the search problem , i.e. the generation of the output sentence in the target language .</sentence>
				<definiendum id="0">argmax operation</definiendum>
				<definiens id="0">the search problem , i.e. the generation of the output sentence in the target language</definiens>
			</definition>
			<definition id="2">
				<sentence>The alignment model Pr ( fJ1 ; aJ1jeI1 ) introduces a ‘hidden’ alignment a = aJ1 , which describes 1The notational convention will be as follows : we use the symbol Pr ( ¢ ) to denote general probability distributions with ( nearly ) no specific assumptions .</sentence>
				<definiendum id="0">alignment model Pr</definiendum>
				<definiens id="0">introduces a ‘hidden’ alignment a = aJ1 , which describes 1The notational convention will be as follows : we use the symbol Pr ( ¢ ) to denote general probability distributions with ( nearly ) no specific assumptions</definiens>
			</definition>
			<definition id="3">
				<sentence>† WER ( word error rate ) : The WER is computed as the minimum number of substitution , insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence .</sentence>
				<definiendum id="0">† WER</definiendum>
				<definiendum id="1">WER</definiendum>
				<definiens id="0">the minimum number of substitution , insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>The PER compares the words in the two sentences ignoring the word order .</sentence>
				<definiendum id="0">PER</definiendum>
				<definiens id="0">compares the words in the two sentences ignoring the word order</definiens>
			</definition>
</paper>

		<paper id="2210">
			<definition id="0">
				<sentence>Each monolingual volume consists in a set of word senses ( lexies ) , each lexie being described using a structure derived from the Explanatory and Combinatory Dictionary ( Mel’čuk et al. , 1995 ; Mel’čuk et al. , 1984 1989 1995 1996 ) .</sentence>
				<definiendum id="0">monolingual volume</definiendum>
				<definiendum id="1">Combinatory Dictionary</definiendum>
				<definiens id="0">consists in a set of word senses ( lexies ) , each lexie being described using a structure derived from the Explanatory and</definiens>
			</definition>
			<definition id="1">
				<sentence>The first step is to define the set of elements that will appear in the &lt; element name= '' lexie '' &gt; &lt; complexType &gt; &lt; sequence &gt; &lt; element ref= '' d : headword '' minOccurs= '' 1 '' macOccurs= '' 1 '' / &gt; &lt; element ref= '' d : writing '' ... / &gt; &lt; element ref= '' d : reading '' ... / &gt; &lt; element ref= '' d : pronunciation '' ... / &gt; &lt; element ref= '' d : pos '' ... / &gt; &lt; element ref= '' d : language-levels '' ... / &gt; &lt; element ref= '' d : semantic-formula '' ... / &gt; &lt; element ref= '' d : government-pattern '' ... / &gt; &lt; element ref= '' d : lexical-functions '' ... / &gt; &lt; element ref= '' d : examples '' ... / &gt; &lt; element ref= '' d : full-idioms '' ... / &gt; &lt; element ref= '' d : more-info '' ... / &gt; &lt; /sequence &gt; &lt; attribute ref= '' d : id '' use= '' required '' / &gt; &lt; /complexType &gt; &lt; /element &gt; ... &lt; element name= '' pos '' type= '' d : posType '' / &gt; &lt; simpleType name= '' posType '' &gt; &lt; restriction base= '' string '' / &gt; &lt; /simpleType &gt; ... Figure 7 : General structure shared by all volumes of the Papillon dictionary ; showing the part of speech element pos defined as a textual element .</sentence>
				<definiendum id="0">d</definiendum>
				<definiendum id="1">element ref= '' d</definiendum>
				<definiens id="0">the set of elements that will appear in the &lt; element name= '' lexie '' &gt; &lt; complexType &gt; &lt; sequence &gt; &lt; element ref= '' d : headword '' minOccurs= '' 1 '' macOccurs= '' 1 '' / &gt; &lt; element ref= '' d : writing '' ... / &gt; &lt; element ref= '' d : reading '' ... / &gt; &lt; element ref= '' d : pronunciation '' ... / &gt; &lt; element ref= '' d : pos '' ... / &gt; &lt; element ref= '' d : language-levels '' ... / &gt; &lt; element ref= ''</definiens>
				<definiens id="1">id '' use= '' required '' / &gt; &lt; /complexType &gt; &lt; /element &gt; ... &lt; element name= '' pos '' type= '' d : posType '' / &gt; &lt; simpleType name= '' posType '' &gt; &lt; restriction base= '' string '' / &gt; &lt; /simpleType &gt; ... Figure 7 : General structure shared by all volumes of the Papillon dictionary ; showing the part of speech element pos defined as a textual element</definiens>
			</definition>
			<definition id="2">
				<sentence>Ding : a Dictionary Lookup Program .</sentence>
				<definiendum id="0">Ding</definiendum>
			</definition>
			<definition id="3">
				<sentence>Jeminie : A flexible system for the automatic creation of interlingual databases .</sentence>
				<definiendum id="0">Jeminie</definiendum>
				<definiens id="0">A flexible system for the automatic creation of interlingual databases</definiens>
			</definition>
</paper>

		<paper id="2702">
			<definition id="0">
				<sentence>Mapping between syntax and semantics is one of the most promising research topics in corpus annotation .</sentence>
				<definiendum id="0">semantics</definiendum>
				<definiens id="0">one of the most promising research topics in corpus annotation</definiens>
			</definition>
			<definition id="1">
				<sentence>SESCO is a tagging system which allows the semantic representation of a linguistic corpus ( Alcántara , 2003 ) .</sentence>
				<definiendum id="0">SESCO</definiendum>
			</definition>
			<definition id="2">
				<sentence>Besides the linguistic background , there are three main differences between the syntactically annotated UAM Treebank and SESCO : First , whereas the Treebank is a corpus of written texts , SESCO contains only spontaneous speech orthografic transcriptions .</sentence>
				<definiendum id="0">SESCO</definiendum>
				<definiendum id="1">Treebank</definiendum>
				<definiens id="0">a corpus of written texts</definiens>
			</definition>
			<definition id="3">
				<sentence>First of all , SST searches for the main verb and its lemma .</sentence>
				<definiendum id="0">SST</definiendum>
				<definiens id="0">searches for the main verb and its lemma</definiens>
			</definition>
</paper>

		<paper id="2318">
			<definition id="0">
				<sentence>The utterances used in the analysis of discourse segmentation for human-computer interaction were drawn from approximately 60 hours of user interactions in a field trial of the Sun Microsystems SpeechActs system ( Yankelovich et al. , 1995 ) .</sentence>
				<definiendum id="0">utterances</definiendum>
			</definition>
			<definition id="1">
				<sentence>As the SpeechActs system consists of 6 different applications , we chose to focus on changes from application to application as reliable indicators of topic initiation .</sentence>
				<definiendum id="0">SpeechActs system</definiendum>
				<definiens id="0">consists of 6 different applications</definiens>
			</definition>
</paper>

		<paper id="3226">
</paper>

		<paper id="0712">
			<definition id="0">
				<sentence>If O is the old , defeasible information and N is new , strict information , then the credulous default unification of O and N is the unification of O’ with N , where O’ is a minimal structure that subsumes O such that O’ and N unify : O &gt; uc N = fO0uNjO0 w O minimal s.t. O0uN 6= ?</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">O’</definiendum>
				<definiens id="0">the old , defeasible information</definiens>
			</definition>
			<definition id="1">
				<sentence>GENRE is a set-valued feature .</sentence>
				<definiendum id="0">GENRE</definiendum>
			</definition>
</paper>

		<paper id="0824">
			<definition id="0">
				<sentence>Word senses , however , are not just independent entities but are connected by several semantic relations ; e.g. , the is-a , which specifies a relation of inclusion among classes such as “car is-a vehicle” .</sentence>
				<definiendum id="0">Word senses</definiendum>
				<definiendum id="1">is-a</definiendum>
				<definiens id="0">specifies a relation of inclusion among classes such as “car is-a vehicle”</definiens>
			</definition>
			<definition id="1">
				<sentence>The classifier consists of two components based on the averaged multiclass perceptron ( Collins , 2002 ; Crammer and Singer , 2003 ) .</sentence>
				<definiendum id="0">classifier</definiendum>
				<definiens id="0">consists of two components based on the averaged multiclass perceptron</definiens>
			</definition>
			<definition id="2">
				<sentence>For each word a38 a training set of pairs a39a41a40a43a42a45a44a24a46a35a42a48a47a11a49 a42a51a50a53a52 , a46a35a42a55a54a57a56a58a39 a38 a47 , is generated from the task-specific data ; a40 a42 is a vector of features and a56a59a39 a38 a47 is the set of possible senses for a38 .</sentence>
				<definiendum id="0">a40 a42</definiendum>
				<definiens id="0">a vector of features</definiens>
				<definiens id="1">the set of possible senses for a38</definiens>
			</definition>
			<definition id="3">
				<sentence>The perceptron algorithm defines a sequence of weight matrices a1 a49a61a60a20a53 a44a4a3a4a3a4a3a66a44 a1 a49a49 a53 , where a1 a49a42 a53 is the weight matrix after the first a2 training items have been processed .</sentence>
				<definiendum id="0">perceptron algorithm</definiendum>
			</definition>
</paper>

		<paper id="1602">
			<definition id="0">
				<sentence>Because of the frequency of obvious weaknesses among very literate and educated native speakers in their knowledge of the rules of ‘ &lt; iErAb’ ( i.e. , case ending marking ) , it became necessary to test the grammatical knowledge of each new potential annotator , and to continue occasional annotation testing at intervals in order to maintain consistency. While we have been able to take care of the first factor so far , the second one seems to be a very persistent problem because of the difficulty level encountered by Arab and foreign annotators alike in reaching a consistent and agreed upon use of case-ending annotation. The Penn Arabic Treebank uses a level of annotation more accurately described as morphological analysis than as part-of-speech tagging. The automatic Arabic morphological analysis and part-of-speech tagging was performed with the Buckwalter Arabic Morphological Analyzer , an open-source software package distributed by the Linguistic Data Consortium ( LDC catalog number LDC2002L49 ) . The analyzer consists primarily of three ArabicEnglish lexicon files : prefixes ( 299 entries ) , suffixes ( 618 entries ) , and stems ( 82158 entries representing 38600 lemmas ) . The lexicons are supplemented by three morphological compatibility tables used for controlling prefixstem combinations ( 1648 entries ) , stem-suffix combinations ( 1285 entries ) , and prefix-suffix combinations ( 598 entries ) . The Arabic Treebank : Part 2 corpus contains 125,698 Arabic-only word tokens ( prior to the separation of clitics ) , of which 124,740 ( 99.24 % ) were provided with an acceptable morphological analysis and POS tag by the morphological parser , and 958 ( 0.76 % ) were items that the morphological parser failed to analyze correctly. Items with solution 124740 99.24 % Items with no solution 958 0.76 % Total 125698 100.00 % Table 1. Buckwalter lexicon coverage , UMAAH The ANNAHAR coverage statistics after POS 1 ( dated January 2004 ) are as follows : The ANNAHAR Corpus contains 340,281 tokens , of which 47,246 are punctuation , numbers , and Latin strings , and 293,035 are Arabic word tokens. Punctuation , Numbers , Latin strings 47,246 Arabic Word Tokens 293,035 TOTAL 340,281 Table 2. Token distribution , ANNAHAR Of the 293,035 Arabic word tokens , 289,722 ( 98.87 % ) were provided with an accurate morphological analysis and POS tag by the Buckwalter Arabic Morphological Analyzer. 3,313 ( 1.13 % ) Arabic word tokens were judged to be incorrectly analyzed , and were flagged with a comment describing the nature of the inaccuracy. ( Note that 204 of the 3,313 tokens for which no correct analysis was found were typos in the original text ) . Accurately analyzed Arabic Word Tokens 289,722 98.87 % Commented Arabic Word Tokens/ items with no solution 3,313 1.13 % TOTAL 293,035 100.00 % Table 3. Lexicon coverage , ANNAHAR COMMENTS ON ITEMS WITH NO SOLUTION ( no comment ) 1741 52.55 % MISC comment 566 17.08 % ADJ 250 7.55 % NOUN 233 7.03 % TYPO 204 6.16 % PASSIVE_FORM 110 3.32 % DIALECTAL_FORM 68 2.05 % VERB 37 1.12 % FOREIGN WORD 34 1.03 % IMPERATIVE 24 0.73 % ADV 9 0.27 % GRAMMAR_PROBLEM 9 0.27 % NOUN_SHOULD_BE_ADJ 7 0.21 % A_NAME 6 0.18 % NUMERICAL 6 0.18 % ABBREV 5 0.15 % INTERR_PARTICLE 4 0.12 % TOTAL 3313 100.00 % Table 4. Distribution of items with no solution , ANNAHAR In order to improve the speed and accuracy of the hand annotation , we automatically pre-parse the data after POS annotation and before TB annotation using Dan Bikel 's parsing engine ( Bikel , 2002 ) . Automatically pre-parsing the data allows the TB annotators to concentrate on the task of correcting a given parse and providing information about syntactic function ( subject , direct object , adverbial , etc. ) . The parsing engine is capable of implementing a variety of generative , PCFG-style models ( probabilistic context free grammar ) , including that of Mike Collins. As such , in English , it gets results that are as good if not slightly better than the Collins parser. Currently , this means that , for Section 00 of the WSJ of the English Penn Treebank ( the development test set ) , the parsing engine gets a recall of 89.90 and a precision of 90.15 on sentences of length &lt; = 40 words. The Arabic version of this parsing engine currently brackets AFP data with recall of 75.6 and precision of 77.4 on sentences of 40 words or less , and we are in the process of analyzing and improving the parser results. Our annotation procedure is to use the automatic tools we have available to provide an initial pass through the data. Annotators then correct the automatic output. First , Tim Buckwalter’s lexicon and morphological analyzer is used to generate a candidate list of “POS tags” for each word ( in the case of Arabic , these are compound tags assigned to each morphological segment for the word ) . The POS annotation task is to select the correct POS tag from the list of alternatives provided. Once POS is done , clitics are automatically separated based on the POS selection in order to create the segmentation necessary for treebanking. Then , the data is automatically parsed using Dan Bikel’s parsing engine for Arabic. Treebank annotators correct the automatic parse and add semantic role information , empty categories and their coreference , and complete the parse. After that is done , we check for inconsistencies between the treebank and POS annotation. Many of the inconsistencies are corrected manually by annotators or automatically by script if reliably safe and possible to do so. Five files with a total of 853 words ( and a varying number of POS choices per word ) were each tagged independently by five annotators for a quality control comparison of POS annotators. Out of the total of 853 words , 128 show some disagreement. All five annotators agreed on 85 % of the words ; the pairwise agreement is at least 92.2 % . For 82 out of the 128 words with some disagreement , four annotators agreed and only one disagreed. Of those , 55 are items with “no match” having been chosen from among the POS choices , due to one annotator’s definition of good-enough match differing from all of the others’. The annotators have since reached agreement on which cases are truly “no match , ” and thus the rate of this disagreement should fall markedly in future POS files , raising the rate of overall agreement. Treebank annotation guidelines The guidelines for the POS annotators are relatively straightforward , since the task essentially involves choosing the correct analysis from the list of alternatives provided by the morphological analyzer and adding the correct case ending. The difficulties encountered by annotators in assigning POS and case endings are somewhat discussed above and will be reviewed by Tim Buckwalter in a separate presentation at COLING 2004. For the most part , our syntactic/predicateargument annotation of newswire Arabic follows the bracketing guidelines for the Penn English Treebank where possible. ( Bies , et al. 1995 ) Our updated Arabic Treebank Guidelines is available on-line from the Linguistic Data Consortium at : http : //www.ldc.upenn.edu/Catalog/docs/LDC2004 T02/ Some points where the Penn Arabic Treebank differs from the Penn English Treebank : • Arabic subjects are analyzed as VP internal , following the verb. • Matrix clause ( S ) coordination is possible and frequent. • The function of NP objects of transitive verbs is directly shown as NP-OBJ. We are also informed by on-going efforts to share data and reconcile annotations with the Prague Arabic Dependency Treebank ( two PraguePenn Arabic Treebanking Workshops took place in 2002 and 2003 ) . Some points where the Penn Arabic Treebank differs from the Prague Arabic Dependency Treebank : • Specific adverbial functions ( LOC , TMP , etc. ) are shown on the adverbial ( PP , ADVP , clausal ) modification of predicates. • The argument/adjunct distinction within NP is shown for noun phrases and clauses. • Empty categories ( pro-drop subjects and traces of syntactic movement ) are inserted. • Apposition is distinguished from other modification of nouns only for proper names. In spite of the considerable differences in word order between Modern Standard Arabic and English , we found that for the most part , it was relatively straightforward to adapt the guidelines for the Penn English Treebank to our Arabic Treebank. In the interest of speed in starting annotation and of using existing tools to the greatest extent possible , we chose to adapt as much as possible from the English Treebank guidelines. There exists a long-standing , extensive , and highly valued paradigm of traditional grammar in Classical Arabic. We chose to adapt the constituency approach from the Penn English Treebank rather than keeping to a strict and difficult adherence to a traditional Arabic grammar approach for several reasons : • Compatibility with existing treebanks , processing software and tools , • We thought it would be easier and more efficient to teach annotators , who come trained in Arabic grammar , to use our constituency approach than to teach computational linguists an old and complex Arabic-specific syntactic terminology. Nonetheless , it was important to adhere to an approach that did not strongly conflict with the traditional approach , in order to ease the cognitive load on our annotators , and also in order to be taken seriously by modern Arabic grammarians. Since there has been little work done on large data corpora in Arabic under any of the current syntactic theories in spite of the theoretical syntactic work being done ( Mohamed , 2000 ) , we have been working out solutions to Arabic syntax by combining the Penn Treebank constituency approach with pertinent insights from traditional grammar as well as modern theoretical syntax. For example , we analyze the underlying basic sentence structure as verb-initial , following the traditional grammar approach. However , since the verb is actually not the first element in many sentences in the data , we adopt a topicalization structure for arguments that are fronted before the verb ( as in Example 2 , where the subject is fronted ) and allow adverbials and conjunctions to appear freely before the verb ( as in Example 3 , where a prepositional phrase is pre-verbal ) . Example 2 ( S ( NP-TPC-1 Huquwq+u ُق ﻮ ُﻘ ُﺣ ( NP Al+ &lt; inosAn+i ِن ﺎ َﺴ ْﻧ ِﻹ ا ) ) ( VP ta+qaE+u ُﻊ َﻘ َﺗ ( NP-SBJ-1 *T* ) ( PP Dimona َﻦ ْﻤ ِﺿ ( NP &lt; ihotimAm+i+nA ﺎ ﻨ ِﻣ ﺎ ﻤ ِﺘ ْه إ ) ) ) ) ﺎ ﻨ ِﻣ ﺎ ﻤ ِﺘ ْه إ َﻦ ْﻤ ِﺿ ُﻊ َﻘ َﺗ ِن ﺎ َﺴ ْﻧ ِﻹ ا ُق ﻮ ُﻘ ُﺣ human rights exist within our concern Example 3 ( S ( PP min ﻦِﻣ ( NP jih+ap+K ٍﺔ َﻬ ِﺟ &gt; uxoraY ىَﺮﺧُأ ) ) ( VP ka $ af+at َﺸ َآﺖَﻔ ( NP-SBJ maSAdir+u ُر ِد ﺎ ﺼ َﻣ miSoriy~+ap+N ٌﺔ ﱠﻳ ِﺮ ْﺼ ِﻣ muT~aliE+ap+N ٌﺔ َﻌ ِﻠ ﱠﻄ ُﻣ ) ) ( NP-OBJ Haqiyqata َﺔ َﻘ ﻴ ِﻘ َﺣ ( NP Al- &gt; amri ِﺮ ﻣ َﻷ ا ) ) ) ِﺮ ﻣ َﻷ ا ﺔ َﻘ ﻴ ِﻘ َﺣ ٌﺔ َﻌ ِﻠ ﱠﻄ ُﻣ ٌﺔ ﱠﻳ ِﺮ ْﺼ ِﻣ ُر ِد ﺎ ﺼ َﻣ َﻔ َﺸ َآﺖ ىَﺮﺧُأ ٍﺔ َﻬ ِﺟ ﻦِﻣ from another side , well-informed Egyptian sources revealed the truth of the matter For many structures , the traditional approach and the treebank approach come together very easily .</sentence>
				<definiendum id="0">POS annotation task</definiendum>
				<definiens id="0">foreign annotators alike in reaching a consistent and agreed upon use of case-ending annotation. The Penn Arabic Treebank uses a level of annotation more accurately described as morphological analysis than as part-of-speech tagging. The automatic Arabic morphological analysis</definiens>
				<definiens id="1">an open-source software package distributed by the Linguistic Data Consortium ( LDC catalog number LDC2002L49 ) . The analyzer consists primarily of three ArabicEnglish lexicon files : prefixes ( 299 entries ) , suffixes ( 618 entries ) , and stems ( 82158 entries representing 38600 lemmas ) . The lexicons are supplemented by three morphological compatibility tables used for controlling prefixstem combinations ( 1648 entries ) , stem-suffix combinations ( 1285 entries ) , and prefix-suffix combinations ( 598 entries ) . The Arabic Treebank : Part 2 corpus contains 125,698 Arabic-only word tokens ( prior to the separation of clitics ) , of which 124,740 ( 99.24 % ) were provided with an acceptable morphological analysis and POS tag by the morphological parser</definiens>
				<definiens id="2">ANNAHAR coverage statistics after POS 1 ( dated January 2004 ) are as follows : The ANNAHAR Corpus contains 340,281 tokens , of which 47,246 are punctuation , numbers , and Latin strings</definiens>
				<definiens id="3">98.87 % ) were provided with an accurate morphological analysis and POS tag by the Buckwalter Arabic Morphological Analyzer. 3,313 ( 1.13 % ) Arabic word tokens were judged to be incorrectly analyzed , and were flagged with a comment describing the nature of the inaccuracy. ( Note that 204 of the 3,313 tokens for which no correct analysis was found were typos in the original text ) . Accurately analyzed Arabic Word Tokens 289,722 98.87 % Commented Arabic Word Tokens/ items with no solution</definiens>
				<definiens id="4">the speed and accuracy of the hand annotation , we automatically pre-parse the data after POS annotation and before TB annotation using Dan Bikel 's parsing engine ( Bikel , 2002 ) . Automatically pre-parsing the data allows the TB annotators to concentrate on the task of correcting a given parse and providing information about syntactic function ( subject , direct object , adverbial , etc. ) . The parsing engine is capable of implementing a variety of generative , PCFG-style models ( probabilistic context free grammar ) , including that of Mike Collins. As such , in English</definiens>
				<definiens id="5">the development test set ) , the parsing engine gets a recall of 89.90 and a precision of 90.15 on sentences of length &lt; = 40 words. The Arabic version of this parsing engine currently brackets AFP data with recall of 75.6 and precision of 77.4 on sentences of 40 words or less , and we are in the process of analyzing and improving the parser results. Our annotation procedure is to use the automatic tools we have available to provide an initial pass through the data. Annotators then correct the automatic output. First , Tim Buckwalter’s lexicon and morphological analyzer is used to generate a candidate list of “POS tags” for each word</definiens>
				<definiens id="6">to select the correct POS tag from the list of alternatives provided. Once POS is done , clitics are automatically separated based on the POS selection in order to create the segmentation necessary for treebanking. Then , the data is automatically parsed using Dan Bikel’s parsing engine for Arabic. Treebank annotators correct the automatic parse and add semantic role information , empty categories and their coreference , and complete the parse. After that is done , we check for inconsistencies between the treebank and POS annotation. Many of the inconsistencies are corrected manually by annotators or automatically by script if reliably safe and possible to do so. Five files with a total of 853 words ( and a varying number of POS choices per word ) were each tagged independently by five annotators for a quality control comparison of POS annotators. Out of the total of 853 words , 128 show some disagreement. All five annotators agreed on 85 % of the words</definiens>
				<definiens id="7">items with “no match” having been chosen from among the POS choices , due to one annotator’s definition of good-enough match differing from all of the others’. The annotators have since reached agreement on which cases are truly “no match , ” and thus the rate of this disagreement should fall markedly in future POS files , raising the rate of overall agreement. Treebank annotation guidelines The guidelines for the POS annotators are relatively straightforward , since the task essentially involves choosing the correct analysis from the list of alternatives provided by the morphological analyzer and adding the correct case ending. The difficulties encountered by annotators in assigning POS and case endings are somewhat discussed above and will be reviewed by Tim Buckwalter in a separate presentation at COLING 2004. For the most part , our syntactic/predicateargument annotation of newswire Arabic follows the bracketing guidelines for the Penn English Treebank where possible. ( Bies , et al. 1995 ) Our updated Arabic Treebank Guidelines is available on-line from the Linguistic Data Consortium at : http : //www.ldc.upenn.edu/Catalog/docs/LDC2004 T02/ Some points where the Penn Arabic Treebank differs from the Penn English Treebank : • Arabic subjects are analyzed as VP internal , following the verb. • Matrix clause ( S ) coordination is possible and frequent. • The function of NP objects of transitive verbs is directly shown as NP-OBJ. We are also informed by on-going efforts to share data and reconcile annotations with the Prague Arabic Dependency Treebank ( two PraguePenn Arabic Treebanking Workshops took place in 2002 and 2003 ) . Some points where the Penn Arabic Treebank differs from the Prague Arabic Dependency Treebank : • Specific adverbial functions ( LOC , TMP , etc. ) are shown on the adverbial ( PP , ADVP , clausal</definiens>
				<definiens id="8">possible from the English Treebank guidelines. There exists a long-standing , extensive , and highly valued paradigm of traditional grammar in Classical Arabic. We chose to adapt the constituency approach from the Penn English Treebank rather than keeping to a strict and difficult adherence to a traditional Arabic grammar approach for several reasons : • Compatibility with existing treebanks , processing software and tools , • We thought it would be easier and more efficient to teach annotators , who come trained in Arabic grammar , to use our constituency approach than to teach computational linguists an old and complex Arabic-specific syntactic terminology. Nonetheless , it was important to adhere to an approach that did not strongly conflict with the traditional approach , in order to ease the cognitive load on our annotators , and also in order to be taken seriously by modern Arabic grammarians. Since there has been little work done on large data corpora in Arabic under any of the current syntactic theories in spite of the theoretical syntactic work being done</definiens>
				<definiens id="9">the subject is fronted ) and allow adverbials and conjunctions to appear freely before the verb ( as in Example 3 , where a prepositional phrase is pre-verbal ) . Example 2 ( S ( NP-TPC-1 Huquwq+u ُق ﻮ ُﻘ ُﺣ ( NP Al+ &lt; inosAn+i ِن ﺎ َﺴ ْﻧ ِﻹ ا ) ) ( VP ta+qaE+u ُﻊ َﻘ َﺗ ( NP-SBJ-1 *T* ) ( PP Dimona َﻦ ْﻤ ِﺿ ( NP &lt; ihotimAm+i+nA ﺎ ﻨ ِﻣ ﺎ ﻤ ِﺘ ْه إ ) ) ) ) ﺎ ﻨ ِﻣ ﺎ ﻤ ِﺘ ْه إ َﻦ ْﻤ ِﺿ ُﻊ َﻘ َﺗ ِن ﺎ َﺴ ْﻧ ِﻹ ا ُق ﻮ ُﻘ ُﺣ human rights exist within our concern Example 3 ( S ( PP min ﻦِﻣ ( NP jih+ap+K ٍﺔ َﻬ ِﺟ &gt; uxoraY ىَﺮﺧُأ</definiens>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>In our approach , each document/summary is represented as a document graph ( DG ) , which is a directed graph of concepts/entities and the relations between them .</sentence>
				<definiendum id="0">DG</definiendum>
			</definition>
			<definition id="1">
				<sentence>A DG contains two kinds of nodes , concept/entity nodes and relation nodes .</sentence>
				<definiendum id="0">DG</definiendum>
				<definiens id="0">contains two kinds of nodes , concept/entity nodes and relation nodes</definiens>
			</definition>
			<definition id="2">
				<sentence>N is the number of concept/entity nodes in DG1 , and M stands for number of relations in DG1 ; n is the number of matched concept/entity nodes in two DGs , and m is the number of matched relations .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">m</definiendum>
				<definiens id="0">the number of concept/entity nodes in DG1 , and M stands for number of relations in DG1</definiens>
				<definiens id="1">the number of matched concept/entity nodes in two DGs , and</definiens>
			</definition>
			<definition id="3">
				<sentence>The target DG is the one for the extract in comparing an extract with its source text .</sentence>
				<definiendum id="0">DG</definiendum>
			</definition>
			<definition id="4">
				<sentence>The F-factor is calc ulated from the following equation ( Rijsbergen , 1979 ) : ) ( 2 RP RPF + ××= where P is the precision and R is the recall .</sentence>
				<definiendum id="0">F-factor</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">the precision and R is the recall</definiens>
			</definition>
			<definition id="5">
				<sentence>In this case , DG1 is the machine generated extract and DG2 is the human generated extract .</sentence>
				<definiendum id="0">DG1</definiendum>
				<definiendum id="1">DG2</definiendum>
				<definiens id="0">the human generated extract</definiens>
			</definition>
			<definition id="6">
				<sentence>In this case , DG1 is an extract and DG2 is the corresponding original document .</sentence>
				<definiendum id="0">DG1</definiendum>
				<definiendum id="1">DG2</definiendum>
				<definiens id="0">an extract and</definiens>
			</definition>
			<definition id="7">
				<sentence>BLEU : A Method for Automatic Evaluation of Machine Translation .</sentence>
				<definiendum id="0">BLEU</definiendum>
			</definition>
			<definition id="8">
				<sentence>Kavanah : An active user interface Information Retrieval Agent Technology .</sentence>
				<definiendum id="0">Kavanah</definiendum>
				<definiens id="0">An active user interface Information Retrieval Agent Technology</definiens>
			</definition>
</paper>

		<paper id="2002">
			<definition id="0">
				<sentence>Three baseline models are also included in the evaluation : word frequency , bigram and trigram probability ( as predicted by a language model ) , and part of speech ( POS ) probability ( as predicted by a POS tagger ) .</sentence>
				<definiendum id="0">trigram probability</definiendum>
				<definiens id="0">predicted by a language model ) , and part of speech ( POS ) probability ( as predicted by a POS tagger )</definiens>
			</definition>
			<definition id="1">
				<sentence>However , the models differ as to whether they predict early or late measures : the PCFG and the Collins model significantly predict late reading time measures ( total time and gaze duration ) , but not early measures ( first fixation time and skipping rate ) .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">total time and gaze duration ) , but not early measures</definiens>
			</definition>
</paper>

		<paper id="3203">
			<definition id="0">
				<sentence>The parsing automaton is a discrete dynamical system which we want to learn to control .</sentence>
				<definiendum id="0">parsing automaton</definiendum>
				<definiens id="0">a discrete dynamical system which we want to learn to control</definiens>
			</definition>
			<definition id="1">
				<sentence>Shift-Reduce : The SR parser’s shift action dequeues an input item and pushes it on the stack .</sentence>
				<definiendum id="0">Shift-Reduce</definiendum>
				<definiens id="0">The SR parser’s shift action dequeues an input item and pushes it on the stack</definiens>
			</definition>
			<definition id="2">
				<sentence>The project ( cat ) action pops a completed item from the stack , and makes it the left corner of a new incomplete node labeled cat , which is pushed onto the stack .</sentence>
				<definiendum id="0">cat ) action</definiendum>
				<definiens id="0">pops a completed item from the stack , and makes it the left corner of a new incomplete node labeled cat , which is pushed onto the stack</definiens>
			</definition>
			<definition id="3">
				<sentence>LC : the third and fourth stack items , the left and right children of the rst stack item , and the left children of the second and third stack items .</sentence>
				<definiendum id="0">LC</definiendum>
				<definiens id="0">the third and fourth stack items , the left and right children of the rst stack item</definiens>
			</definition>
			<definition id="4">
				<sentence>Coverage : Coverage is the fraction of the test set for which the parser found a complete parse .</sentence>
				<definiendum id="0">Coverage</definiendum>
			</definition>
</paper>

		<paper id="0855">
			<definition id="0">
				<sentence>Word Sense Disambiguation ( WSD ) is the process of identifying the correct meanings of words in particular contexts ( Manning and Schutze , 1999 ) .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
				<definiendum id="1">WSD</definiendum>
				<definiens id="0">the process of identifying the correct meanings of words in particular contexts</definiens>
			</definition>
			<definition id="1">
				<sentence>The vector of a context c of the target word w is deflned as : † ~c = ( w1 ; ¢¢¢ ; wjWj ) where wi is the number of occurences of the word vi in the context c and vi is a word from the entire trained corpus of j W j words .</sentence>
				<definiendum id="0">wi</definiendum>
				<definiens id="0">the number of occurences of the word vi in the context c and vi is a word from the entire trained corpus of j W j words</definiens>
			</definition>
			<definition id="2">
				<sentence>W £ W , where W is the set of words .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">the set of words</definiens>
			</definition>
			<definition id="3">
				<sentence>Therefore , if w is a word and C is a context , we say that w occurs in C ifi exists a word w2 2 C so that ( w ; w2 ) 2 – .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a word and</definiens>
			</definition>
			<definition id="4">
				<sentence>If Max1 is obtained for a sense s1 and if Max2 is obtained for a sense s2 and if Max1¡Max2 • P where P = Max1¡Min ( Ns¡1 ) and Min is the minimum score from S , then s1 and s2 are reported as the appropriate senses for C. Experimentally , we proved that the above improvements grow the precision of the disambiguation process .</sentence>
				<definiendum id="0">Min</definiendum>
				<definiens id="0">the minimum score from S</definiens>
			</definition>
</paper>

		<paper id="2216">
			<definition id="0">
				<sentence>RCV1 : a new benchmark collection for text categorization research .</sentence>
				<definiendum id="0">RCV1</definiendum>
			</definition>
			<definition id="1">
				<sentence>The psycho-biology of language : an introduction to dynamic phililogy .</sentence>
				<definiendum id="0">psycho-biology of language</definiendum>
				<definiens id="0">an introduction to dynamic phililogy</definiens>
			</definition>
</paper>

		<paper id="2208">
			<definition id="0">
				<sentence>The Advance Telecommunications Research dialogue database ( ATR , 1992 ) is a parallel treebank corpus between Japanese and English .</sentence>
				<definiendum id="0">Advance Telecommunications Research dialogue database</definiendum>
			</definition>
			<definition id="1">
				<sentence>In this figure , “S-ID” means the sentence ID in the Kyoto University text corpus .</sentence>
				<definiendum id="0">“S-ID”</definiendum>
				<definiens id="0">means the sentence ID in the Kyoto University text corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>EOJ means the boundary between a Japanese parsed sentence andanEnglishparsedsentence .</sentence>
				<definiendum id="0">EOJ</definiendum>
			</definition>
			<definition id="3">
				<sentence>The Chinese sentence is the translation of the Japanese sentence in Figure 1 .</sentence>
				<definiendum id="0">Chinese sentence</definiendum>
				<definiens id="0">the translation of the Japanese sentence in Figure 1</definiens>
			</definition>
</paper>

		<paper id="0843">
</paper>

		<paper id="0841">
</paper>

		<paper id="2204">
			<definition id="0">
				<sentence>In this case , English is the intermediate language and shared Chinese characters between Korean and Japanese are used as pivots .</sentence>
				<definiendum id="0">English</definiendum>
				<definiens id="0">the intermediate language</definiens>
			</definition>
			<definition id="1">
				<sentence>The overlap similarity score S2 for a Japanese word j and a Korean word k is given in Equation ( 2 ) , where E ( w ) is the set of English translations of w and J ( E ) is the bag of Japanese translations of all translations of E. S2 ( j ; k ) = jjj ; j 2 J ( E ( k ) ) ; ( 2 ) After that , we test the narrowing down of translation pairs by extracting the overlapped words in the Japanese translation sets .</sentence>
				<definiendum id="0">overlap similarity score S2</definiendum>
				<definiendum id="1">E ( w )</definiendum>
				<definiens id="0">the set of English translations of w and J ( E ) is the bag of Japanese translations of all translations of E. S2 ( j ; k ) = jjj</definiens>
			</definition>
			<definition id="2">
				<sentence>Lexical Resources : We used a K ) E dictionary ( 50,826 entries ) , the same as the one used in section 3.2 and a E ) J dictionary ( 52,369 entries ) .</sentence>
				<definiendum id="0">Lexical Resources</definiendum>
				<definiens id="0">We used a K ) E dictionary ( 50,826 entries ) , the same as the one used in section 3.2 and a E ) J dictionary ( 52,369 entries )</definiens>
			</definition>
			<definition id="3">
				<sentence>From the Korean speaker’s point of view , the E ) K dictionary covers all English words , includes explanatory equivalents , and example sentences showing usage .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">includes explanatory equivalents , and example sentences showing usage</definiens>
			</definition>
			<definition id="4">
				<sentence>Evaluation : We use similarity score S3 in Equation ( 3 ) as a threshold which is used to extract good matches .</sentence>
				<definiendum id="0">Evaluation</definiendum>
				<definiens id="0">a threshold which is used to extract good matches</definiens>
			</definition>
			<definition id="5">
				<sentence>S3 ( k ; j ) = jK ( E ( k ) \ E ( j ) ) j + jJ ( E ( k ) \ E ( j ) ) jjE ( k ) \ E ( j ) j ( 3 ) K ( W ) : bag of Korean translations of set W J ( W ) : bag of Japanese translations of set W E ( w ) : set of English translations of word w jK ( E ) j means the number of Korean translation equivalents , andjJ ( E ) j means the number of Japanese translation equivalents .</sentence>
				<definiendum id="0">andjJ</definiendum>
				<definiens id="0">E ( k ) \ E ( j ) ) j + jJ ( E ( k ) \ E ( j ) ) jjE ( k ) \ E ( j ) j ( 3 ) K ( W ) : bag of Korean translations of set W J ( W ) : bag of Japanese translations of set W E ( w ) : set of English translations of word w jK ( E ) j means the number of Korean translation equivalents</definiens>
			</definition>
			<definition id="6">
				<sentence>N represents the number of intermediate English words .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
			<definition id="7">
				<sentence>Directionality is an important matter for building dictionaries automatically .</sentence>
				<definiendum id="0">Directionality</definiendum>
				<definiens id="0">an important matter for building dictionaries automatically</definiens>
			</definition>
			<definition id="8">
				<sentence>In a K ) E ( or J ) E ) dictionary an index word contains non-conjugated forms whereas an index word in E ) K ( or E ) J ) dictionary contains POS and conjugated forms .</sentence>
				<definiendum id="0">K ) E</definiendum>
				<definiens id="0">contains non-conjugated forms whereas an index word in E ) K ( or E ) J ) dictionary contains POS and conjugated forms</definiens>
			</definition>
			<definition id="9">
				<sentence>Therefore , it is natural that the matching rate is far less than the combination of K ) E and J ) E. Considering the size of dictionaries used in K ) E and J ) E ( estimated maximum matches : 28,310 K ) J pairs ) and the one used in K ) E and E ) J ( estimated maximum matches : 50,826 K ) J pairs ) , we extrapolate from Table 5 that the method using K ) E and J ) E is better than the method using K ) E and E ) J. We concluded that : K ) E + J ) E outperforms K ) E + E ) J which outperforms E ) K + E ) J. The following brie y summarizes the three methods .</sentence>
				<definiendum id="0">J ( estimated maximum</definiendum>
				<definiens id="0">better than the method using K ) E and E ) J. We concluded that : K ) E + J ) E outperforms K ) E + E ) J which outperforms E ) K + E</definiens>
			</definition>
</paper>

		<paper id="2303">
</paper>

		<paper id="0200">
</paper>

		<paper id="0606">
			<definition id="0">
				<sentence>OntoMap is a web-site that provides access to upper-level ontologies and handcrafted mappings between them ( Kiryakov et al. , 2001 ) .</sentence>
				<definiendum id="0">OntoMap</definiendum>
			</definition>
			<definition id="1">
				<sentence>DL are a family of logical formalisms that originated in the eld of arti cial intelligence as a tool for representation of conceptual knowledge .</sentence>
				<definiendum id="0">DL</definiendum>
				<definiens id="0">a family of logical formalisms that originated in the eld of arti cial intelligence as a tool for representation of conceptual knowledge</definiens>
			</definition>
			<definition id="2">
				<sentence>names ( unary predicates ) and role names ( binary predicates ) using the set of concept and role constructors provided by a particular DL ( Lutz , 2003 ) .</sentence>
				<definiendum id="0">names</definiendum>
				<definiens id="0">unary predicates</definiens>
			</definition>
			<definition id="3">
				<sentence>SHIQ is the basic logic ALC augmented with qualifying number restrictions , role restrictions , role hierarchies , inverse roles , and transitive roles .</sentence>
				<definiendum id="0">SHIQ</definiendum>
				<definiens id="0">the basic logic ALC augmented with qualifying number restrictions , role restrictions , role hierarchies</definiens>
			</definition>
			<definition id="4">
				<sentence>class-def ( primitivejde ned ) CN CN ( vj : = ) &gt; subclass-of C1 : : : Cn u 2 ( C1 ) u : : : u ( Cn ) slot-constraint1 u ( slot-constraint1 ) ... ... slot-constraintm u ( slot-constraintm ) topjthingjbottom Ct : CjCt : CjCu : C ( C1 and : : : and Cn ) ( ( C1 ) u : : : u ( Cn ) ) ( C1 or : : : or Cn ) ( ( C1 ) t : : : t ( Cn ) ) ( not C ) ( : ( C ) ) ( one-of i1 : : : in ) ( Pi1 t : : : tPin ) slot-constraint SN &gt; has-value C1 : : : Cn u9SN : ( C1 ) u : : : u9SN : ( Cn ) value-type C1 : : : Cn u8SN : ( C1 ) u : : : u8SN : ( Cn ) max-cardinality n C u nSN : ( C ) min-cardinality n C u nSN : ( C ) cardinality n C u nSN : ( C ) u nSN : ( C ) hasller d u9SN : ( d ) slot-def SN subslot-of SN1 : : : SNn ( SNvSN1 ) : : : ( SNvSNn ) domain C1 : : : Cn 9SN : &gt; v ( C1 ) u : : : u ( Cn ) range C1 : : : Cn &gt; v8SN : ( C1 ) u : : : u ( Cn ) inverse RN ( SN vRN ) ( RN vSN ) properties transitive SN2S+ properties symmetric ( SNvSN ) ( SN vSN ) properties functional &gt; v 1SN disjoint C1 C2 : : : Cn ( ( C1 ) v : ( C2 ) ) covered C by C1 : : : Cn ( C ) v ( C1 ) t : : : t ( Cn ) disjoint-covered C by C1 : : : Cn ( ( C1 ) v : ( C2 ) ) ( ( C ) v ( C1 ) t : : : t ( Cn ) ) equivalent CC1 : : : Cn ( ( C ) = ( C1 ) ) : : : ( ( Cn 1 ) = ( Cn ) ) instance-of iC1 : : : Cn Piv ( C1 ) u : : : u ( Cn ) related SNij Piv9SN : Pj Table 2 : Denotational semantics for language de nition sense of structuring the ontology .</sentence>
				<definiendum id="0">slot-constraintm u</definiendum>
				<definiens id="0">: : t ( Cn ) ) ( not C ) ( : ( C ) ) ( one-of i1 : : : in ) ( Pi1 t : : : tPin ) slot-constraint SN &gt; has-value C1 : : : Cn u9SN : ( C1 ) u : : : u9SN : ( Cn ) value-type C1 : : : Cn u8SN : ( C1 ) u : : : u8SN : ( Cn ) max-cardinality n C u nSN : ( C ) min-cardinality n C u nSN : ( C ) cardinality n C u nSN : ( C ) u nSN : ( C ) hasller d u9SN : ( d ) slot-def SN subslot-of SN1 : : : SNn ( SNvSN1 ) : : : ( SNvSNn ) domain C1 : : : Cn 9SN : &gt; v ( C1 ) u : : : u ( Cn ) range C1 : : : Cn &gt; v8SN : ( C1 ) u : : : u ( Cn ) inverse RN ( SN vRN ) ( RN vSN ) properties transitive SN2S+ properties symmetric ( SNvSN ) ( SN vSN ) properties functional &gt; v 1SN disjoint C1 C2 : : : Cn ( ( C1 ) v : ( C2 ) ) covered C by C1 : : : Cn ( C ) v ( C1 ) t : : : t ( Cn ) disjoint-covered C by C1 : : : Cn ( ( C1 ) v : ( C2 ) ) ( ( C ) v ( C1 ) t : : : t ( Cn ) ) equivalent CC1 : : : Cn ( ( C ) = ( C1 )</definiens>
				<definiens id="1">Denotational semantics for language de nition sense of structuring the ontology</definiens>
			</definition>
			<definition id="5">
				<sentence>Additional sources of information about superclasses such as RECORDs where CN appears as FILLER and SUBCLASSES appears as SLOT actually encode redundant information and are therefore discarded .</sentence>
				<definiendum id="0">CN</definiendum>
				<definiens id="0">SLOT actually encode redundant information and are therefore discarded</definiens>
			</definition>
			<definition id="6">
				<sentence>DL provide the way to carry out complex inference and reasoning tasks .</sentence>
				<definiendum id="0">DL</definiendum>
				<definiens id="0">provide the way to carry out complex inference and reasoning tasks</definiens>
			</definition>
</paper>

		<paper id="3202">
			<definition id="0">
				<sentence>Active learning ( AL ) promises to reduce the cost of annotating labeled datasets for trainable human language technologies .</sentence>
				<definiendum id="0">Active learning ( AL</definiendum>
				<definiens id="0">reduce the cost of annotating labeled datasets for trainable human language technologies</definiens>
			</definition>
			<definition id="1">
				<sentence>The ERG is a hand-built broad-coverage HPSG grammar that provides an explicit grammar for the treebank .</sentence>
				<definiendum id="0">ERG</definiendum>
				<definiens id="0">a hand-built broad-coverage HPSG grammar that provides an explicit grammar for the treebank</definiens>
			</definition>
			<definition id="2">
				<sentence>is given as : P ( ti|s , Mk ) = exp ( summationtextm j=1 fj ( ti ) wj ) Z ( s ) ( 1 ) where fj ( ti ) returns the number of times feature j occurs in analysis t , wj is a weight from model Mk , and Z ( s ) is a normalization factor for the sentence .</sentence>
				<definiendum id="0">fj ( ti )</definiendum>
				<definiendum id="1">Z</definiendum>
				<definiens id="0">returns the number of times feature j occurs in analysis t</definiens>
				<definiens id="1">a normalization factor for the sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>We create our ensemble model ( called a product model ) using the productof-experts formulation ( Hinton , 1999 ) : P ( ti|s , M1 ... Mn ) = producttextn j=1 P ( ti|s , Mj ) Z ( s ) ( 4 ) Note that each individual model Mi is a well-defined distribution usually taken from a fixed set of models .</sentence>
				<definiendum id="0">ensemble model</definiendum>
				<definiens id="0">a well-defined distribution usually taken from a fixed set of models</definiens>
			</definition>
			<definition id="4">
				<sentence>Uncertainty sampling ( also called tree entropy by Hwa ( 2000 ) ) , measures the uncertainty of a model over the set of parses of a given sentence , based on the conditional 1This eyeball step is not always taken , but Redwoods does not contain information about when this occurred , so we apply the cost for the step uniformly for all examples .</sentence>
				<definiendum id="0">Uncertainty sampling</definiendum>
				<definiendum id="1">tree entropy</definiendum>
				<definiens id="0">measures the uncertainty of a model over the set of parses of a given sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>Following Hwa , we use the following measure to quantify uncertainty : fus ( s , τ , Mk ) = −summationdisplay t∈τ P ( t|s , Mk ) logP ( t|s , Mk ) ( 5 ) τ denotes the set of analyses produced by the ERG for the sentence and Mk is some model .</sentence>
				<definiendum id="0">Mk</definiendum>
				<definiens id="0">the set of analyses produced by the ERG for the sentence and</definiens>
			</definition>
			<definition id="6">
				<sentence>It can be improved by simply replacing the probability of a single log-linear ( or perceptron ) model with a product probability : fenus ( s , τ , M ) = −summationdisplay t∈τ P ( t|s , M ) logP ( t|s , M ) ( 6 ) M is the set of models M1 ... Mn .</sentence>
				<definiendum id="0">M</definiendum>
			</definition>
			<definition id="7">
				<sentence>Hwa et al. ( 2003 ) showed that for parsers , AL outperforms the closely related co-training , and that some of the labeling could be automated .</sentence>
				<definiendum id="0">AL</definiendum>
				<definiens id="0">outperforms the closely related co-training</definiens>
			</definition>
</paper>

		<paper id="0212">
			<definition id="0">
				<sentence>The Penn Discourse TreeBank ( PDTB ) is a new resource built on top of the Penn Wall Street Journal corpus , in which discourse connectives are annotated along with their arguments .</sentence>
				<definiendum id="0">Penn Discourse TreeBank</definiendum>
				<definiendum id="1">PDTB )</definiendum>
			</definition>
			<definition id="1">
				<sentence>Its use of standoff annotation allows integration with a stand-off version of the Penn TreeBank ( syntactic structure ) and PropBank ( verbs and their arguments ) , which adds value for both linguistic discovery and discourse modeling .</sentence>
				<definiendum id="0">PropBank</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Penn Discourse TreeBank ( PDTB ) adds low-level discourse structure and semantics through the annotation of discourse connectives and their arguments , using connective-specific semantic role labels .</sentence>
				<definiendum id="0">Penn Discourse TreeBank</definiendum>
				<definiendum id="1">PDTB )</definiendum>
				<definiens id="0">adds low-level discourse structure and semantics through the annotation of discourse connectives and their arguments , using connective-specific semantic role labels</definiens>
			</definition>
			<definition id="3">
				<sentence>The PDTB project builds on basic ideas presented in Webber and Joshi ( 1998 ) , Webber et al. ( 1999b ) and Webber et al. ( 2003 ) – that connectives are discourse-level predicates which project predicateargument structure on a par with verbs at the sentence level .</sentence>
				<definiendum id="0">PDTB project</definiendum>
				<definiens id="0">builds on basic ideas presented in Webber and Joshi ( 1998 ) , Webber et al. ( 1999b ) and Webber et al. ( 2003 ) – that connectives are discourse-level predicates which project predicateargument structure on a par with verbs at the sentence level</definiens>
			</definition>
			<definition id="4">
				<sentence>PDTB annotation indicates two things : the arguments of each explicit discourse connective and the lexical tokens that actually play a role as discourse connectives .</sentence>
				<definiendum id="0">PDTB annotation</definiendum>
			</definition>
			<definition id="5">
				<sentence>While some of these functions correlate with POS-tags other than those used in annotating connectives , the PTB POStags themselves can not always be reliably distinguished , given inconsistencies in how the lexical items are analyzed .</sentence>
				<definiendum id="0">PTB POStags</definiendum>
				<definiens id="0">themselves can not always be reliably distinguished , given inconsistencies in how the lexical items are analyzed</definiens>
			</definition>
			<definition id="6">
				<sentence>The multi-layered annotations for PDTB , PTB ( and soon to be available PropBank ) are rendered in XML within a “stand-off” annotation architecture in which multiple ( independently conducted ) annotations refer to the same primary document .</sentence>
				<definiendum id="0">PTB</definiendum>
				<definiens id="0">available PropBank ) are rendered in XML within a “stand-off” annotation architecture in which multiple ( independently conducted ) annotations refer to the same primary document</definiens>
			</definition>
			<definition id="7">
				<sentence>LOC can take four defined values : SS for when the anaphoric argument occurs in the same sentence as the connective ( Examples 7 , 10 and 11 ) , PS for when the argument occurs in the immediately previous sentence ( Examples 12 and 13 ) , PP for when the argument occurs in the immediately preceding sequence of sentences ( Example 8 ) , and NC for when the argument occurs in some non-contiguous sentence ( s ) ( Example 9 ) .</sentence>
				<definiendum id="0">PS for</definiendum>
				<definiendum id="1">NC for</definiendum>
				<definiens id="0">when the argument occurs in the immediately previous sentence ( Examples 12 and 13 ) , PP for when the argument occurs in the immediately preceding sequence of sentences</definiens>
			</definition>
			<definition id="8">
				<sentence>The PDTB encodes low-level discourse structure information , marking discourse connectives as indicators of discourse relations , and their arguments .</sentence>
				<definiendum id="0">PDTB</definiendum>
			</definition>
</paper>

		<paper id="2607">
			<definition id="0">
				<sentence>Case relations come in two varieties : general and specific ( to a sentence ) .</sentence>
				<definiendum id="0">Case relations</definiendum>
				<definiens id="0">come in two varieties : general and specific ( to a sentence )</definiens>
			</definition>
</paper>

		<paper id="2311">
			<definition id="0">
				<sentence>Constituents ( and thereby words ) appear in particular orders because those orders can reliably indicate the content speakers wish to communicate .</sentence>
				<definiendum id="0">Constituents</definiendum>
				<definiens id="0">thereby words ) appear in particular orders because those orders can reliably indicate the content speakers wish to communicate</definiens>
			</definition>
			<definition id="1">
				<sentence>Table 2 shows the frequency of the properties of hearer-newness and relative heaviness of indirect objects ( IOs ) and direct objects ( DOs ) with respect to the two ditransitive alternations .</sentence>
				<definiendum id="0">DOs</definiendum>
				<definiens id="0">the frequency of the properties of hearer-newness and relative heaviness of indirect objects ( IOs ) and direct objects</definiens>
			</definition>
</paper>

		<paper id="2802">
			<definition id="0">
				<sentence>Evaluation of the Automatic Speech Recognition Performance : The commonly used word error rate ( WER ) can be calculated by aligning any two sets word sequences and adding the number of substitutions S , deletions D and insertions I. The WER is then given by the following formula where N is the total number of words in the test set .</sentence>
				<definiendum id="0">WER</definiendum>
			</definition>
			<definition id="1">
				<sentence>We can now calculate the total number of values as : V S = nX i=1 V Si Based on this we can compute the task-specific proportional baseline for task Tw , i.e. , BTw , over the entire test set as : BTw = 1V S nX i=1 V Si Bi = 1V S nX i=1 V maxi Thus , BTw calculates the average of correct guesses for the majority baseline .</sentence>
				<definiendum id="0">BTw</definiendum>
			</definition>
</paper>

		<paper id="3004">
			<definition id="0">
				<sentence>A conceptual framework is established which utilizes two input channels : the original speech channel and an additional channel called Virtual Modality .</sentence>
				<definiendum id="0">conceptual framework</definiendum>
				<definiens id="0">the original speech channel and an additional channel called Virtual Modality</definiens>
			</definition>
			<definition id="1">
				<sentence>Virtual Modality represents an abstraction in this sense .</sentence>
				<definiendum id="0">Virtual Modality</definiendum>
				<definiens id="0">an abstraction in this sense</definiens>
			</definition>
			<definition id="2">
				<sentence>The abstraction provided by the Virtual Modality enables the developer to focus on the interrelation of the speech and the additional modalities , in terms of their temporal correlation , in order to study and experiment with various usage scenarios and usability issues .</sentence>
				<definiendum id="0">Virtual Modality</definiendum>
				<definiens id="0">enables the developer to focus on the interrelation of the speech and the additional modalities , in terms of their temporal correlation</definiens>
			</definition>
			<definition id="3">
				<sentence>CL is a classifier and integrator that transforms and fuses a sequence of words , wi , and Virtual Modality inputs , mi , into a corresponding sequence of concepts Ck . )</sentence>
				<definiendum id="0">CL</definiendum>
				<definiens id="0">a classifier and integrator that transforms and fuses a sequence of words , wi , and Virtual Modality inputs , mi</definiens>
			</definition>
			<definition id="4">
				<sentence>These systems are implemented within the Galaxy Communicator architecture , which is a multimodal conversational system framework ( Seneff et al. , 1998 ) .</sentence>
				<definiendum id="0">Galaxy Communicator architecture</definiendum>
			</definition>
			<definition id="5">
				<sentence>Outspoken is an imaginary user who never uses the Virtual Modality , and communicates with the system using only the speech modality .</sentence>
				<definiendum id="0">Outspoken</definiendum>
				<definiens id="0">an imaginary user who never uses the Virtual Modality , and communicates with the system using only the speech modality</definiens>
			</definition>
			<definition id="6">
				<sentence>The evaluation procedure An experimental framework has been introduced , called Virtual Modality , which aims to assist in the development and testing of multimodal systems .</sentence>
				<definiendum id="0">Virtual Modality</definiendum>
				<definiens id="0">aims to assist in the development and testing of multimodal systems</definiens>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>The sentence compression rate is a parameter which can be set for each sentence .</sentence>
				<definiendum id="0">sentence compression rate</definiendum>
				<definiens id="0">a parameter which can be set for each sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>OTI is a VP-selecting complementizer .</sentence>
				<definiendum id="0">OTI</definiendum>
				<definiens id="0">a VP-selecting complementizer</definiens>
			</definition>
			<definition id="2">
				<sentence>The parallel corpus consists of transcripts of television programs on the one hand and the subtitles of these television programs on the other hand .</sentence>
				<definiendum id="0">parallel corpus</definiendum>
				<definiens id="0">consists of transcripts of television programs on the one hand and the subtitles of these television programs on the other hand</definiens>
			</definition>
			<definition id="3">
				<sentence>The reduction probability of a word would then play its role in the estimated probability of the compressed sentence alternative containing this reduced word .</sentence>
				<definiendum id="0">reduction probability</definiendum>
				<definiens id="0">estimated probability of the compressed sentence alternative containing this reduced word</definiens>
			</definition>
			<definition id="4">
				<sentence>The lowest score of the two raters is the score which the sentence gets .</sentence>
				<definiendum id="0">lowest score of the two raters</definiendum>
			</definition>
			<definition id="5">
				<sentence>The combination of using statistics and filtering out invalid results because they are ungrammatical by using a set of rules is a feasible way for automated sentence compression .</sentence>
				<definiendum id="0">rules</definiendum>
				<definiens id="0">a feasible way for automated sentence compression</definiens>
			</definition>
</paper>

		<paper id="0857">
			<definition id="0">
				<sentence>The FrameNet corpus contains annotations for all of the model components described above .</sentence>
				<definiendum id="0">FrameNet corpus</definiendum>
				<definiens id="0">contains annotations for all of the model components described above</definiens>
			</definition>
			<definition id="1">
				<sentence>We decided to use the following attributes from the parse trees and FrameNet examples : Target Position : The position of the target word as 1 The heuristic chooses the preposition for PP’s and the last word of the phrase for all other phrases .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">The position of the target word as 1 The heuristic chooses the preposition for PP’s and the last word of the phrase for all other phrases</definiens>
			</definition>
			<definition id="2">
				<sentence>Depth : The depth of the constituent in the parse tree .</sentence>
				<definiendum id="0">Depth</definiendum>
				<definiens id="0">The depth of the constituent in the parse tree</definiens>
			</definition>
</paper>

		<paper id="1209">
			<definition id="0">
				<sentence>l GO:0045786 term : negative regulation of cell cycle GO annotation 55 CD MUD MBD MBDP 10 Baseline 50.47 % 52.60 % 34.82 % 37.91 % Table 2 : Comparison of performances on the 139 abstracts , , argmax ( ) ( | ) j ai NBjkij vV iSkW vPvPwv ∈ ∈∈ =×∏∏ where vj is one of the nine positions aforementioned , S is the set of 9 sentence positions , Wa , i is the set of all word positions in sentence i in abstract a , wk , i is the occurrence of the normalized word at position k in sentence i and V is the set of 9 classes .</sentence>
				<definiendum id="0">vj</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">V</definiendum>
				<definiens id="0">the set of 9 sentence positions</definiens>
			</definition>
</paper>

		<paper id="2709">
			<definition id="0">
				<sentence>The project participants include the Computing Research Laboratory at NMSU , the Language Technologies Institute at CMU , the Information Science Institute at USC , UMIACS at the University of Maryland , the MITRE Corporation and Columbia University .</sentence>
				<definiendum id="0">project participants</definiendum>
				<definiens id="0">include the Computing Research Laboratory at NMSU , the Language Technologies Institute at CMU , the Information Science Institute at USC</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , for any given corpus , the annotation effort is to assign interlingual content to a set of 4 parallel texts , 3 of which are in the same language , English , and all of which theoretically communicate the same information .</sentence>
				<definiendum id="0">annotation effort</definiendum>
				<definiens id="0">to assign interlingual content to a set of 4 parallel texts , 3 of which are in the same language , English , and all of which theoretically communicate the same information</definiens>
			</definition>
			<definition id="2">
				<sentence>IL0 is a deep syntactic dependency representation .</sentence>
				<definiendum id="0">IL0</definiendum>
				<definiens id="0">a deep syntactic dependency representation</definiens>
			</definition>
			<definition id="3">
				<sentence>IL0 is constructed by hand-correcting the output of a dependency parser ( details in section 6 ) and is a useful starting point for semantic annotation at IL1 , since it allows annotators to see how textual units relate syntactically when making semantic judgments .</sentence>
				<definiendum id="0">IL0</definiendum>
				<definiens id="0">allows annotators to see how textual units relate syntactically when making semantic judgments</definiens>
			</definition>
			<definition id="4">
				<sentence>IL1 is an intermediate semantic representation .</sentence>
				<definiendum id="0">IL1</definiendum>
				<definiens id="0">an intermediate semantic representation</definiens>
			</definition>
			<definition id="5">
				<sentence>The ontology , which has been used in several projects in recent years ( Hovy et al. , 2001 ) , can be browsed using the DINO browser at http : //blombos.isi.edu:8000/dino ; this browser forms a part of the annotation environment .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">a part of the annotation environment</definiens>
			</definition>
			<definition id="6">
				<sentence>Omega remains under continued development and extension .</sentence>
				<definiendum id="0">Omega</definiendum>
				<definiens id="0">remains under continued development and extension</definiens>
			</definition>
			<definition id="7">
				<sentence>Theta roles are abstractions of deep semantic relations that generalize over verb classes .</sentence>
				<definiendum id="0">Theta roles</definiendum>
				<definiens id="0">abstractions of deep semantic relations that generalize over verb classes</definiens>
			</definition>
			<definition id="8">
				<sentence>At this time , the Kappa statistic’s expected agreement is defined as 1/ ( N+1 ) where N is the number of choices at a given data point .</sentence>
				<definiendum id="0">Kappa statistic’s expected agreement</definiendum>
				<definiendum id="1">N</definiendum>
			</definition>
</paper>

		<paper id="1214">
</paper>

		<paper id="3245">
			<definition id="0">
				<sentence>transducers Given a source sentence a0 , the goal of MT is to find a target sentence a1t that maximizes : a1t a0 argmax t a1a3a2a5a4 t a6 sa7a8a0 argmax t a1a8a2a5a4 t a9 sa7 ( 1 ) The joint distribution a1a8a2a5a4 ta9 sa7 can be modeled by a Stochastic Finite State Transducer a10 ( Pic´o and Casacuberta , 2001 ) : a1t a0 argmax t a1a8a2a11a4 t a9 sa7a8a12 argmax t a1a3a2a14a13a15a4 t a9 sa7 ( 2 ) A Stochastic Finite-State Transducer ( SFST ) is a finite-state network whose transitions are labeled by three items : guage vocabulary ) ; target language vocabulary ) and They have been successfully applied into many translation tasks ( Vidal , 1997 ; Amengual et al. , 2000 ; Casacuberta et al. , 2001 ) .</sentence>
				<definiendum id="0">Stochastic Finite-State Transducer</definiendum>
				<definiens id="0">to find a target sentence a1t that maximizes : a1t a0 argmax t a1a3a2a5a4 t a6 sa7a8a0 argmax</definiens>
				<definiens id="1">a finite-state network whose transitions are labeled by three items : guage vocabulary ) ; target language vocabulary</definiens>
			</definition>
			<definition id="1">
				<sentence>In our experiments , the alignments are obtained using the GIZA software ( Och and Ney , 2000 ; Al-Onaizan et al. , 1999 ) , which implements IBM statistical models ( Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">GIZA software</definiendum>
			</definition>
			<definition id="2">
				<sentence>ta17 represents a prefix in the target language obtained as a result of the interaction between the human translator and the machine translation system .</sentence>
				<definiendum id="0">ta17</definiendum>
				<definiens id="0">a prefix in the target language obtained as a result of the interaction between the human translator and the machine translation system</definiens>
			</definition>
			<definition id="3">
				<sentence>A word graph represents the set of all possible translations for a given source sentence s that were embeded in the SFST a10 .</sentence>
				<definiendum id="0">word graph</definiendum>
				<definiens id="0">the set of all possible translations for a given source sentence s that were embeded in the SFST a10</definiens>
			</definition>
			<definition id="4">
				<sentence>A TT2 interactive prototype , which uses the searching techniques presented in the previous sections , has been implemented .</sentence>
				<definiendum id="0">TT2 interactive prototype</definiendum>
				<definiens id="0">uses the searching techniques presented in the previous sections</definiens>
			</definition>
			<definition id="5">
				<sentence>This simplification consists on tokenization , case normalization and the substitution of numbers , printer codes , etc. by their correspondent category labels .</sentence>
				<definiendum id="0">simplification</definiendum>
				<definiens id="0">consists on tokenization , case normalization and the substitution of numbers , printer codes</definiens>
			</definition>
</paper>

		<paper id="0809">
</paper>

		<paper id="0405">
			<definition id="0">
				<sentence>Investigating a reasonably sized set of Japanese linguistic data , keeping the strategy exemplified above in mind , revealed that NPS of a natural Japanese sentence can be generally formulated as a nested functional form ; ( 6 ) M n [ M n-1 … [ M 2 [ M 1 [ S ] ] ] … ] , where S is a propositional , kernel sentence ; M i ( 1� i� n ) , a NPF .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">a propositional , kernel sentence</definiens>
				<definiens id="1">1� i� n ) , a NPF</definiens>
			</definition>
			<definition id="1">
				<sentence>Employing MWEs as NPCIs enabled us to describe the outermost structure of a Japanese sentence by the following production rules ; ( 7 ) S 0 → BP * ·PRED , ( 8 ) S i → S i-1 ·m i , ( 1� i� n ) , where S 0 denotes a kernel sentence ; BP , a basic phrase called bunsetsu ; PRED , a predicate of the kernel sentence ; S i , a sentence , m i , a NPCI and a symbol ‘*’ , closure operator on the concatenation , ‘·’ .</sentence>
				<definiendum id="0">S 0</definiendum>
				<definiens id="0">a basic phrase called bunsetsu ; PRED , a predicate of the kernel sentence ; S i , a sentence , m i , a NPCI and a symbol ‘*’ , closure operator on the concatenation , ‘·’</definiens>
			</definition>
			<definition id="2">
				<sentence>( ENGL simply denotes the verb’s inflected form by -ed , -en , etc. ) ( 13 ) nps ( “�� /·p ·M� ; manan/·de·iru” ) = 1 PROGRESSING 1 [ study ] = be study-ing , = 2 PROGRESSING 2 [ study ] = have be-en studying , = 3 COMPLETED 1 [ study ] =have study-en ( 14 ) nps ( “ 2V /· �� · o · M� ; aruki/·hajime·te·iru” ) =COMPLETED 1 [ INCHOATIVE [ walk ] ] = have begin-en walk-ing ( 15 ) nps ( “j` /·o ·M� ; aisi/·te·iru” ) = STATE-OF-THINGS [ love ] = love ( 16 ) nps ( “ �T` /·o ·� /·o ·� ·�M /·w ·p`� /· O /· T ; ugokasi/·te·mi/·te·mo·yoi/·no·desho/·u/·ka” ) =NTERROGATIVE [ GUESS 1 [ DECLARATION [ PERMISSIVE [ TRIAL [ move ] ] ] ] ] = Will it be allowed that ... try to move ... . ?</sentence>
				<definiendum id="0">ENGL</definiendum>
				<definiens id="0">the verb’s inflected form by -ed , -en , etc. ) ( 13 ) nps ( “�� /·p ·M�</definiens>
				<definiens id="1">begin-en walk-ing ( 15 ) nps ( “j` /·o ·M�</definiens>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>LIDAS is a computational discourse parser implementing the Unified Linguistic Discourse Model ( U-LDM ) .</sentence>
				<definiendum id="0">LIDAS</definiendum>
			</definition>
			<definition id="1">
				<sentence>After sentential parsing is complete , the XLE sentence parse trees are segmented into BDUs using a set of robust sentence and discourse level rules described in detail in Polanyi et al 2004a , b. After parsing , BDUs ( which need not be contiguous ) are recombined into one or more discourse trees corresponding to ( parts of ) the sentence , called BDUtrees .</sentence>
				<definiendum id="0">BDUs</definiendum>
				<definiens id="0">need not be contiguous ) are recombined into one or more discourse trees corresponding to ( parts of ) the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Evidence attachment is a subordination Syntactic promotion : If the subject of an M-BDU co-refers with the object of the AP .</sentence>
				<definiendum id="0">Evidence attachment</definiendum>
				<definiens id="0">If the subject of an M-BDU co-refers with the object of the AP</definiens>
			</definition>
			<definition id="3">
				<sentence>Evidence attachment is a coordination Narrative : If the verbs express events .</sentence>
				<definiendum id="0">Evidence attachment</definiendum>
				<definiens id="0">If the verbs express events</definiens>
			</definition>
			<definition id="4">
				<sentence>Summarization methods based on discourse structure all rely on assigning a numeric value to all intermediate and leaf nodes encoding their importance , based on the labels at the nodes .</sentence>
				<definiendum id="0">Summarization methods</definiendum>
			</definition>
			<definition id="5">
				<sentence>if R is subordination and ci is the head of n : V ( ci ) : = V ( c0 ) if V ( ci ) &lt; V ( c0 ) if R is coordination or n-aries : for all i=n , V ( ci ) : = V ( c0 ) if V ( ci ) &lt; V ( c0 ) , Figure 1 : General percolation algorithm .</sentence>
				<definiendum id="0">ci</definiendum>
				<definiens id="0">the head of n : V ( ci ) : = V ( c0 ) if V ( ci ) &lt; V ( c0 ) if R is coordination or n-aries : for all i=n , V ( ci ) : = V ( c0 ) if V ( ci ) &lt; V ( c0 ) , Figure 1 : General percolation algorithm</definiens>
			</definition>
			<definition id="6">
				<sentence>Both statistical seeds ( V=S ) and structural seeds ( V=T ) are percolated according to this algorithm , resulting in values S ( n ) and T ( n ) for nodes n. tree structured representation of the structure of the text produce excellent summaries that preserve the style and “flavor” of the original text .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">( n ) for nodes n. tree structured representation of the structure of the text produce excellent summaries that preserve the style</definiens>
			</definition>
</paper>

		<paper id="0311">
			<definition id="0">
				<sentence>Formally , a constraint satisfaction problem ( CSP ) can be viewed as a triple ( X ; D ; C ) where X = fx1 ; : : : ; xng is a nite set of variables with respective domains D = fD1 ; : : : ; Dng , and a set of constraints C = fC1 ; : : : ; Ctg .</sentence>
				<definiendum id="0">CSP</definiendum>
				<definiendum id="1">xng</definiendum>
				<definiens id="0">a triple ( X ; D ; C ) where X = fx1 ; : : : ;</definiens>
			</definition>
			<definition id="1">
				<sentence>A solution of a CSP is a complete instantiation of variables hx1 ; : : : ; xni with values hdi1 ; : : : ; dini with dik 2 Dk found in a CN that is consistent with all constraints .</sentence>
				<definiendum id="0">CSP</definiendum>
				<definiens id="0">a complete instantiation of variables hx1 ; : : : ; xni with values hdi1 ; : : : ; dini with dik 2 Dk found in a CN that is consistent with all constraints</definiens>
			</definition>
			<definition id="2">
				<sentence>A COP is denoted as a quadruple ( X ; D ; C ; f ) , where ( X ; D ; C ) is a CSP and f is a cost function on ( partial ) variable instantiations .</sentence>
				<definiendum id="0">COP</definiendum>
				<definiendum id="1">f</definiendum>
				<definiens id="0">a cost function on ( partial ) variable instantiations</definiens>
			</definition>
			<definition id="3">
				<sentence>A solution of a COP is a complete instantiation , where f ( hdi1 ; : : : ; dini ) is optimal .</sentence>
				<definiendum id="0">solution of a COP</definiendum>
				<definiens id="0">a complete instantiation , where f ( hdi1 ; : : : ; dini ) is optimal</definiens>
			</definition>
			<definition id="4">
				<sentence>A dynamic constraint satisfaction problem ( DynCSP ) is construed as a series of CSPs P0 ; P1 ; : : : that change periodically over time by loss of gain of values , variables or constraints ( Pi+1 = Pi + Pi+1 ) .</sentence>
				<definiendum id="0">DynCSP</definiendum>
				<definiens id="0">a series of CSPs P0 ; P1 ; : : : that change periodically over time by loss of gain of values , variables or constraints</definiens>
			</definition>
			<definition id="5">
				<sentence>A CDG is a quadruple ( ; R ; L ; C ) , where is a lexicon of known words , R is a set of roles of a word .</sentence>
				<definiendum id="0">CDG</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a quadruple</definiens>
				<definiens id="1">a lexicon of known words</definiens>
				<definiens id="2">a set of roles of a word</definiens>
			</definition>
			<definition id="6">
				<sentence>L is a set of labels for each role ( e.g. f‘SUBJ’ , ’OBJ’g , f‘AGENT’ , ‘PATIENT’g ) , and C is a constraint grammar consisting of atomic logical formulas .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">a constraint grammar consisting of atomic logical formulas</definiens>
			</definition>
			<definition id="7">
				<sentence>Hence a dependency tree of an utterance of length n is a set of dependency edges s = fei ; j j i 2 f1 ; : : : ; ng ; j 2 f1 ; : : : ; ng [ frootg ; i 6= jg .</sentence>
				<definiendum id="0">dependency tree of an utterance of length n</definiendum>
				<definiens id="0">a set of dependency edges s = fei</definiens>
			</definition>
			<definition id="8">
				<sentence>In ( Schr oder , 2002 ) the foundations of dependency parsing have been carried over to COPs using weighted constraint dependency grammars ( WCDG ) , a framework to model language using all-quanti ed logical formulas on dependency structures .</sentence>
				<definiendum id="0">constraint dependency grammars</definiendum>
				<definiendum id="1">WCDG</definiendum>
				<definiens id="0">a framework to model language using all-quanti ed logical formulas on dependency structures</definiens>
			</definition>
			<definition id="9">
				<sentence>The second constraint SUBJ-dist is a soft one , such as every edge with label SUBJ attached more than two words away induces a penalty calculated by the term length in SUBJ-dist is quite arbitrary and should be extracted from a corpus automatically as well as the grade of increasing penalization .</sentence>
				<definiendum id="0">second constraint SUBJ-dist</definiendum>
				<definiens id="0">a soft one , such as every edge with label SUBJ attached more than two words away induces a penalty calculated by the term length in SUBJ-dist is quite arbitrary and should be extracted from a corpus automatically as well as the grade of increasing penalization</definiens>
			</definition>
			<definition id="10">
				<sentence>The following de nitions explain some of the primitives that are part of the constraint language : X is a variable for a dependency edge of the form ei ; j = hr ; wi ; l ; wji , REF SEM SYN semantic constraints syntaxconstraints reference constraints syntax { semantic constraints syntax { reference constraints semantic { reference constraints Lexicon Chunker Tagger Ontology Figure 1 : Architecture of WCDG X @ word ( X^word ) refers to the word form wi 2 ( wj 2 ) X @ id ( X @ id ) refers to the position i ( j ) X.label refers to the label l 2 L X @ cat ( X^cat ) refers to the POS-tag of the modi er ( modi ee ) root ( X^id ) true i wj = root X.length is de ned as ji jj .</sentence>
				<definiendum id="0">REF SEM SYN semantic constraints syntaxconstraints reference</definiendum>
				<definiendum id="1">X @ word</definiendum>
				<definiendum id="2">modi ee</definiendum>
				<definiens id="0">some of the primitives that are part of the constraint language : X is a variable for a dependency edge of the form ei</definiens>
				<definiens id="1">constraints syntax { semantic constraints syntax { reference constraints semantic { reference constraints Lexicon Chunker Tagger Ontology Figure 1 : Architecture of WCDG</definiens>
			</definition>
			<definition id="11">
				<sentence>So given two edges ei1 ; i2 = hr ; wi1 ; l0 ; wi2i and ej1 ; j2 = the big blue bouncing DET ADJ ADJ ADJ the big blue bouncing w DET ADJ ADJ ADJ ( a ) ( b ) ( c ) the big blue bouncing ball w DET ADJ ADJ ADJ SUBJ Figure 2 : Example sentence pre x hr ; wj1 ; l00 ; wj2i with X ei1 ; i2 and Y ej1 ; j2 : X^id = Y^id false i wi2 6= wj2 2 _ wi2 = wj2 = w , and true otherwise X.length ji1 i2j i wi1 ; wi2 2 , and n+1 i wi2 = w , ( n : length of the current sentence pre x ) X^cat = hPOS tagi false i wi2 = w nonspec ( X^id ) true i wi2 = w spec ( X^id ) true i wi2 2 Although every nonspec dependency in Figure ( 2b ) points to the same word w , two nonspec dependency edges are not taken to be connected at the top ( X^id = Y^id false ) as we don’t know yet whether wi and wj will be modifying the same word in the future .</sentence>
				<definiendum id="0">ADJ ADJ</definiendum>
				<definiendum id="1">X^id</definiendum>
				<definiendum id="2">top</definiendum>
				<definiens id="0">the same word w , two nonspec dependency edges are not taken to be connected at the</definiens>
			</definition>
</paper>

		<paper id="3227">
			<definition id="0">
				<sentence>The duality of term frequency ( tf ) and inverse document frequency ( idf ) , document space and collection space respectively , can smoothly predict the probability of terms being informative ( Roelleke , 2003 ) .</sentence>
				<definiendum id="0">duality of term frequency</definiendum>
				<definiendum id="1">inverse document frequency</definiendum>
			</definition>
			<definition id="1">
				<sentence>Each phrase translation pair , which can be represented as a triple } , { pts v v → , is now converted into a “Bag-of-Words” D consisting of a collection of both source and target words appearing in the phrase pair , as shown in ( 2 ) : } , , , , , { } , { 2121 JI tttsssDpts LL v v =⇒→ ( 2 ) Given each phrase pair as one document , the whole transducer is a collection of such documents .</sentence>
				<definiendum id="0">phrase translation pair</definiendum>
				<definiens id="0">a triple } , { pts v v → , is now converted into a “Bag-of-Words” D consisting of a collection of both source and target words appearing in the phrase pair , as shown in ( 2 ) : } , , , , , { }</definiens>
				<definiens id="1">a collection of such documents</definiens>
			</definition>
			<definition id="2">
				<sentence>The idf model selected is as in Equation ( 4 ) : ) log ( + +− = df dfN idf ( 4 ) where N is the total number of documents in the transducer , i.e. the total number of translation pairs , and df is the document frequency , i.e. in how many phrase pairs a given word occurs .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">df</definiendum>
				<definiens id="0">the total number of documents in the transducer , i.e. the total number of translation pairs</definiens>
			</definition>
			<definition id="3">
				<sentence>The following version of tf is chosen , so that longer target phrases with more words than average will be slightly down-weighted : ) ( / ) ( 5.15.0 ' vavglenvlentf tf tf vv ⋅++ = ( 5 ) where tf is the term frequency , ) ( vlen v is the length in words of the phrase v v , and ) ( vavglen v is the average length of source or target phrase calculated from the transducer .</sentence>
				<definiendum id="0">tf</definiendum>
				<definiendum id="1">) ( vavglen v</definiendum>
				<definiens id="0">the term frequency</definiens>
				<definiens id="1">the length in words of the phrase v v , and</definiens>
				<definiens id="2">the average length of source or target phrase calculated from the transducer</definiens>
			</definition>
			<definition id="4">
				<sentence>The test data consists of 878 Chinese sentences or 24,337 words after word segmentation .</sentence>
				<definiendum id="0">test data</definiendum>
				<definiens id="0">consists of 878 Chinese sentences or 24,337 words after word segmentation</definiens>
			</definition>
			<definition id="5">
				<sentence>BiBr extracts sub-tree mappings from Bilingual Bracketing alignments ( Wu , 1997 ) ; HMM extracts partial path mappings from the Viterbi path in the Hidden Markov Model alignments ( Vogel et .</sentence>
				<definiendum id="0">BiBr</definiendum>
				<definiens id="0">extracts sub-tree mappings from Bilingual Bracketing alignments ( Wu , 1997 ) ; HMM extracts partial path mappings from the Viterbi path in the Hidden Markov Model alignments ( Vogel et</definiens>
			</definition>
			<definition id="6">
				<sentence>ISA is an integrated segmentation and alignment for phrases ( Zhang et .</sentence>
				<definiendum id="0">ISA</definiendum>
				<definiens id="0">an integrated segmentation and alignment for phrases</definiens>
			</definition>
			<definition id="7">
				<sentence>N is the total number of phrase pairs in the transducer .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of phrase pairs in the transducer</definiens>
			</definition>
			<definition id="8">
				<sentence>LDC is the largest one having 425K entries , as the other transducers are restricted to ‘useful’ entries , i.e. those translation pairs where the source phrase matches a sequence of words in one of the test sentence .</sentence>
				<definiendum id="0">LDC</definiendum>
				<definiens id="0">the other transducers are restricted to ‘useful’ entries , i.e. those translation pairs where the source phrase matches a sequence of words in one of the test sentence</definiens>
			</definition>
</paper>

		<paper id="3214">
			<definition id="0">
				<sentence>A pattern encodes the argument structure information present in one annotated corpus sentence .</sentence>
				<definiendum id="0">pattern</definiendum>
				<definiens id="0">encodes the argument structure information present in one annotated corpus sentence</definiens>
			</definition>
</paper>

		<paper id="1301">
			<definition id="0">
				<sentence>Everyparameter ( exceptthoseassociatedwithprimitivecategories suchasS ) isoriginallysettoINACTIVE , i.e. no categories ( exceptprimitives ) areknownuponthe commencementoflearning .</sentence>
				<definiendum id="0">Everyparameter ( exceptthoseassociatedwithprimitivecategories suchasS ) isoriginallysettoINACTIVE , i.e. no categories (</definiendum>
				<definiens id="0">exceptprimitives ) areknownuponthe commencementoflearning</definiens>
			</definition>
</paper>

		<paper id="0714">
			<definition id="0">
				<sentence>In the centering theory ( Grosz and Sidner , 1986 ; Grosz et al , 1995 ; Walker et al. , 1994 ; Strube and Hahn , 1996 ) , the 'attentional state ' was identified as a basic component of discourse structure that consisted of two levels of focusing : global and local .</sentence>
				<definiendum id="0">centering theory</definiendum>
				<definiens id="0">a basic component of discourse structure that consisted of two levels of focusing</definiens>
			</definition>
			<definition id="1">
				<sentence>The forward-looking centers of U n , C f ( U n ) , depend only on the expressions that constitute that utterance .</sentence>
				<definiendum id="0">C f</definiendum>
				<definiens id="0">U n ) , depend only on the expressions that constitute that utterance</definiens>
			</definition>
			<definition id="2">
				<sentence>Definition 1 : A Triple T is characterized by a 3-tuple : T = [ S , P , O ] where z S is a list of nouns whose grammatical role is the subject of a clause .</sentence>
				<definiendum id="0">Triple T</definiendum>
				<definiendum id="1">z S</definiendum>
				<definiens id="0">a list of nouns whose grammatical role is the subject of a clause</definiens>
			</definition>
			<definition id="3">
				<sentence>z O is a list of nouns whose grammatical role is the object of a clause .</sentence>
				<definiendum id="0">z O</definiendum>
				<definiens id="0">a list of nouns whose grammatical role is the object of a clause</definiens>
			</definition>
			<definition id="4">
				<sentence>In the Triple4 , the co-conj ( P ) denotes a coordinating conjunction appearing in the initial position of a clause .</sentence>
				<definiendum id="0">co-conj ( P )</definiendum>
				<definiens id="0">a coordinating conjunction appearing in the initial position of a clause</definiens>
			</definition>
			<definition id="5">
				<sentence>ZA identification constraints For each ZA candidate c in a discourse : discourse segment NP + bei + NP + VP + c NP ( topic ) + NP ( subject ) + VP + c In the antecedent identification phase , we employ the concept , ‘backward-looking center’ of centering model to identify the antecedent of each ZA .</sentence>
				<definiendum id="0">ZA identification constraints</definiendum>
				<definiens id="0">discourse segment NP + bei + NP + VP + c NP ( topic ) + NP ( subject ) + VP + c In the antecedent identification phase</definiens>
			</definition>
			<definition id="6">
				<sentence>In the experiment of ZA resolution , we use a test corpus which is a collection of 150 news articles contained 998 paragraphs , 4631 utterances , and 40884 Chinese words .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiens id="0">a collection of 150 news articles contained 998 paragraphs , 4631 utterances</definiens>
			</definition>
</paper>

		<paper id="1207">
			<definition id="0">
				<sentence>The Caderige project aims at designing and integrating Natural Language Processing ( NLP ) and Machine Learning ( ML ) techniques to explore , analyze and extract targeted information in biological textual databases .</sentence>
				<definiendum id="0">Caderige project</definiendum>
				<definiens id="0">aims at designing and integrating Natural Language Processing ( NLP ) and Machine Learning ( ML ) techniques to explore , analyze and extract targeted information in biological textual databases</definiens>
			</definition>
			<definition id="1">
				<sentence>We chose this example because Bacillus subtilis is a model bacterium and transcription is a central phenomenon in functional genomics involved in genic interaction , a popular IE problem .</sentence>
				<definiendum id="0">transcription</definiendum>
				<definiens id="0">a central phenomenon in functional genomics involved in genic interaction , a popular IE problem</definiens>
			</definition>
			<definition id="2">
				<sentence>GerE stimulates cotD transcription and inhibits cotA transcription in vitro by sigma K RNA polymerase , as expected from in vivo studies , and , unexpectedly , profoundly inhibits in vitro transcription of the gene ( sigK ) that encode sigma K. Figure 1 : A sentence describing a genic interaction Once relevant abstracts have been retrieved , templates should be filled by hand since there is no available IE tool operational in genomics Type : positive Agent : GerE Interaction Target : transcription of the gene sigK Figure 2 : A template describing a genic interaction .</sentence>
				<definiendum id="0">sigK</definiendum>
				<definiens id="0">A sentence describing a genic interaction Once relevant abstracts have been retrieved</definiens>
				<definiens id="1">A template describing a genic interaction</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , Genia uses a combination of parsers to finally perform an HPSG-like analysis .</sentence>
				<definiendum id="0">Genia</definiendum>
				<definiens id="0">uses a combination of parsers to finally perform an HPSG-like analysis</definiens>
			</definition>
			<definition id="4">
				<sentence>The normalization process , by providing an abstract representation of the sentences , allows the identification of regularities that simplify the acquisition or learning of pattern rules .</sentence>
				<definiendum id="0">normalization process</definiendum>
				<definiens id="0">allows the identification of regularities that simplify the acquisition or learning of pattern rules</definiens>
			</definition>
			<definition id="5">
				<sentence>A typical error is the omission of the determinant before some nouns that require one .</sentence>
				<definiendum id="0">typical error</definiendum>
			</definition>
			<definition id="6">
				<sentence>Practically , each annotation aims at highlighting the set of words in the sentence describing : − Agents ( A ) : the entities activating or controlling the interaction − Targets ( T ) : the entities that are produced or controlled − Interaction ( I ) : the kind of control performed during the interaction − Confidence ( C ) : the confidence level in this interaction .</sentence>
				<definiendum id="0">Confidence</definiendum>
				<definiens id="0">highlighting the set of words in the sentence describing : − Agents ( A ) : the entities activating or controlling the interaction − Targets ( T ) : the entities that are produced or controlled − Interaction ( I ) : the kind of control performed during the interaction −</definiens>
			</definition>
			<definition id="7">
				<sentence>Learning IE rules is seen as a discrimination task , where the concept to learn is a n-ary relation between arguments which correspond to the template fields .</sentence>
				<definiendum id="0">Learning IE rules</definiendum>
			</definition>
</paper>

		<paper id="0211">
			<definition id="0">
				<sentence>4 Palo Alto , CA 94304 { polanyi|culy|vdberg|thione } @ fxpal.com , ahn @ science.uva.nl 1 In this paper , we describe how the LIDAS System ( Linguistic Discourse Analysis System ) , a discourse parser built as an implementation of the Unified Linguistic Discourse Model ( U-LDM ) uses information from sentential syntax and semantics along with lexical semantic information to build the Open Right Discourse Parse Tree ( DPT ) that serves as a representation of the structure of the discourse ( Polanyi et al. , 2004 ; Thione 2004a , b ) .</sentence>
				<definiendum id="0">LIDAS System</definiendum>
				<definiens id="0">a discourse parser built as an implementation of the Unified Linguistic Discourse Model ( U-LDM ) uses information from sentential syntax and semantics along with lexical semantic information to build the Open Right Discourse Parse Tree ( DPT ) that serves as a representation of the structure of the discourse ( Polanyi et al. , 2004</definiens>
			</definition>
			<definition id="1">
				<sentence>1 Current address : Language and Inference Technology Group , Informatics Institute Kruislaan 403 1098 SJ Amsterdam , The Netherlands The U-LDM builds upon the insights and mechanisms of the Linguistic Discourse Model ( LDM ) ( Polanyi 1988 ) .</sentence>
				<definiendum id="0">U-LDM</definiendum>
				<definiendum id="1">Discourse Model</definiendum>
				<definiens id="0">builds upon the insights and mechanisms of the Linguistic</definiens>
			</definition>
			<definition id="2">
				<sentence>Minimal meaning units are units that express information about not more than one event , 3 If a sentence is sufficiently complex , it may consist of two or more completely different independent discourse units .</sentence>
				<definiendum id="0">Minimal meaning units</definiendum>
				<definiens id="0">units that express information about not more than one event</definiens>
			</definition>
			<definition id="3">
				<sentence>The U-LDM defines segmentation in purely sentence syntactic terms .</sentence>
				<definiendum id="0">U-LDM</definiendum>
				<definiens id="0">defines segmentation in purely sentence syntactic terms</definiens>
			</definition>
			<definition id="4">
				<sentence>The XLE is a robust Lexical Functional Grammar ( LFG ) parser .</sentence>
				<definiendum id="0">XLE</definiendum>
			</definition>
			<definition id="5">
				<sentence>The XLE tries to parse the input , and returns either a packed representation of all possible parses or the most probable parse as selected by its stochastic disambiguation component ( Riezler et al. 2002 ) .</sentence>
				<definiendum id="0">XLE</definiendum>
			</definition>
			<definition id="6">
				<sentence>The parse information consists of a c ( onstituent ) structure ( essentially a standard parse tree ) and a f ( unctional ) structure containing predicateargument information , modification information , and other grammatical information such as tense and agreement features .</sentence>
				<definiendum id="0">parse information</definiendum>
				<definiens id="0">consists of a c ( onstituent ) structure ( essentially a standard parse tree ) and a f ( unctional ) structure containing predicateargument information , modification information , and other grammatical information such as tense and agreement features</definiens>
			</definition>
			<definition id="7">
				<sentence>Attachment always takes place on the right edge of the tree .</sentence>
				<definiendum id="0">Attachment</definiendum>
				<definiens id="0">takes place on the right edge of the tree</definiens>
			</definition>
			<definition id="8">
				<sentence>Rule 3 , which shows a compact syntax for disjunctive constraint , builds a sentence level discourse relation , the Context Binary , that forms a complex context unit from its child constituents .</sentence>
				<definiendum id="0">Context Binary</definiendum>
				<definiens id="0">shows a compact syntax for disjunctive constraint , builds a sentence level discourse relation , the</definiens>
			</definition>
			<definition id="9">
				<sentence>For example , the Narrative rule , which coordinates event clauses , takes precedence over the Discourse Demotion Rule .</sentence>
				<definiendum id="0">Narrative rule</definiendum>
				<definiens id="0">coordinates event clauses , takes precedence over the Discourse Demotion Rule</definiens>
			</definition>
			<definition id="10">
				<sentence>An expression e is a subcase of f if ( 1 ) e is a set that is a subset of f , ( 2 ) e is a subtype of f , or ( 3 ) e is a part of f , among other relations .</sentence>
				<definiendum id="0">expression e</definiendum>
				<definiens id="0">a set that is a subset of f</definiens>
				<definiens id="1">a subtype of f , or ( 3 ) e is a part of f</definiens>
			</definition>
			<definition id="11">
				<sentence>Grammatical function demotion G is a less clear case .</sentence>
				<definiendum id="0">Grammatical function demotion G</definiendum>
				<definiens id="0">a less clear case</definiens>
			</definition>
</paper>

		<paper id="2504">
			<definition id="0">
				<sentence>Entities ( such as noun phrase , verb phrase , preposition phrase , etc ) in a question carry distinctive roles that indicate what is the topic or focus of a question in terms of the overall information seeking discourse .</sentence>
				<definiendum id="0">Entities</definiendum>
				<definiens id="0">such as noun phrase , verb phrase , preposition phrase , etc ) in a question carry distinctive roles that indicate what is the topic or focus of a question in terms of the overall information seeking discourse</definiens>
			</definition>
			<definition id="1">
				<sentence>The second aspect of discourse status relates to discourse transitions that indicate how discourse roles are changed from one question to another as the interaction proceeds and how such changes reflect the progress of user information needs .</sentence>
				<definiendum id="0">discourse status</definiendum>
				<definiens id="0">relates to discourse transitions that indicate how discourse roles are changed</definiens>
			</definition>
			<definition id="2">
				<sentence>Focus indicates the current focus of attention given a particular topic .</sentence>
				<definiendum id="0">Focus</definiendum>
				<definiens id="0">indicates the current focus of attention given a particular topic</definiens>
			</definition>
			<definition id="3">
				<sentence>ActType indicates the type of the activity ; Participant indicates entities that are participating in the activity with different semantic roles .</sentence>
				<definiendum id="0">ActType</definiendum>
				<definiendum id="1">Participant</definiendum>
				<definiens id="0">indicates entities that are participating in the activity with different semantic roles</definiens>
			</definition>
			<definition id="4">
				<sentence>SemRole indicates the semantic role of the entity in a particular activity ( if any ) .</sentence>
				<definiendum id="0">SemRole</definiendum>
				<definiens id="0">indicates the semantic role of the entity in a particular activity</definiens>
			</definition>
			<definition id="5">
				<sentence>Constraint specifies the constraints need to be satisfied to identify the entity , and Id specifies the particular identifier of the entity that particularly corresponds to pronouns , demonstratives , and definite noun phrases .</sentence>
				<definiendum id="0">Id</definiendum>
				<definiens id="0">specifies the particular identifier of the entity that particularly corresponds to pronouns , demonstratives , and definite noun phrases</definiens>
			</definition>
			<definition id="6">
				<sentence>Media indicates the desired information media , which can be further characterized as Format and Genre as shown in Figure 2 .</sentence>
				<definiendum id="0">Media</definiendum>
				<definiens id="0">indicates the desired information media</definiens>
			</definition>
			<definition id="7">
				<sentence>Figure 2 shows the representation of discourse roles of Q1 using typed feature structures ( Carpenter 1992 ) , where Intent indicates that the user is requesting for the system to retrieve an answer .</sentence>
				<definiendum id="0">Intent</definiendum>
				<definiens id="0">requesting for the system to retrieve an answer</definiens>
			</definition>
			<definition id="8">
				<sentence>This activity shift indicates that “kill” activity is a consequence of “destroy” activity ( i.e. , Q18 is a consequence of Q17 ) .</sentence>
				<definiendum id="0">Q18</definiendum>
			</definition>
			<definition id="9">
				<sentence>The discourse roles are higher-level abstracts of the semantic roles as those provided in FrameNet ( Baker et al. , 1998 ) and Propbank ( Kingsbury and Palmer 2002 ) .</sentence>
				<definiendum id="0">discourse roles</definiendum>
			</definition>
			<definition id="10">
				<sentence>In this network , each node is either a specific value ( i.e. , leaf nodes ) or a typed feature structure itself ( i.e. , internal node ) .</sentence>
				<definiendum id="0">node</definiendum>
				<definiens id="0">either a specific value ( i.e. , leaf nodes ) or a typed feature structure itself ( i.e. , internal node )</definiens>
			</definition>
			<definition id="11">
				<sentence>For example , Figure 3 ( a ) represents Q1 , where Topic points an Activity feature structure and Focus points to the Name Element of the Participant1 in the Activity .</sentence>
				<definiendum id="0">Topic</definiendum>
				<definiens id="0">points an Activity feature structure and Focus points to the Name Element of the Participant1 in the Activity</definiens>
			</definition>
</paper>

		<paper id="0859">
			<definition id="0">
				<sentence>Word Sense Disambiguation ( WSD ) is an open research field in Natural Language Processing ( NLP ) .</sentence>
				<definiendum id="0">Word Sense Disambiguation ( WSD )</definiendum>
			</definition>
			<definition id="1">
				<sentence>Our systems use both corpus-based and knowledge-based approaches : Maximum Entropy ( ME ) ( Lau et al. , 1993 ; Berger et al. , 1996 ; Ratnaparkhi , 1998 ) is a corpus-based and supervised method based on linguistic features ; ME is the core of a bootstrapping algorithm that we call re-training inspired ⁄ This paper has been partially supported by the Spanish Government ( CICyT ) under project number TIC-2003-7180 and the Valencia Government ( OCyT ) under project number CTIDIB-2002-151 by co-training ( Blum and Mitchell , 1998 ) ; Relevant Domains ( RD ) ( Montoyo et al. , 2003 ) is a resource built from WordNet Domains ( Magnini and Cavaglia , 2000 ) that is used in an unsupervised method that assigns domain and sense labels ; Specification Marks ( SP ) ( Montoyo and Palomar , 2000 ) exploits the relations between synsets stored in WordNet ( Miller et al. , 1993 ) and does not need any training corpora ; Commutative Test ( CT ) ( Nica et al. , 2003 ) , based on the Sense Discriminators device derived from EWN ( Vossen , 1998 ) , disambiguates nouns inside their syntactic patterns , with the help of information extracted from raw corpus .</sentence>
				<definiendum id="0">ME</definiendum>
				<definiendum id="1">Relevant Domains</definiendum>
				<definiendum id="2">Specification Marks</definiendum>
				<definiens id="0">both corpus-based and knowledge-based approaches : Maximum Entropy ( ME ) ( Lau et al. , 1993 ; Berger et al. , 1996</definiens>
				<definiens id="1">a corpus-based and supervised</definiens>
				<definiens id="2">the core of a bootstrapping algorithm that we call re-training inspired ⁄ This paper has been partially supported by the Spanish Government ( CICyT ) under project number TIC-2003-7180 and the Valencia Government ( OCyT ) under project number</definiens>
				<definiens id="3">Miller et al. , 1993 ) and does not need any training corpora ; Commutative Test ( CT ) ( Nica et al. , 2003 ) , based on the Sense Discriminators device derived from EWN ( Vossen , 1998 ) , disambiguates nouns inside their syntactic patterns , with the help of information extracted from raw corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>Specification Marks is an unsupervised WSD method over nouns .</sentence>
				<definiendum id="0">Specification Marks</definiendum>
			</definition>
			<definition id="3">
				<sentence>The re-training method is a proposal that we are trying to incorporate into text retrieval and question answering systems that could take advantage of sense disambiguation of a subset of words .</sentence>
				<definiendum id="0">re-training method</definiendum>
				<definiens id="0">a proposal that we are trying to incorporate into text retrieval and question answering systems that could take advantage of sense disambiguation of a subset of words</definiens>
			</definition>
</paper>

		<paper id="2805">
			<definition id="0">
				<sentence>Embodied Construction Grammar ( ECG ) ( Chang et al. , 2002 ) , ( Bergen and Chang , 2002 ) is a rigorous , formalism incorporating such insight .</sentence>
				<definiendum id="0">Embodied Construction Grammar ( ECG )</definiendum>
				<definiens id="0">a rigorous , formalism incorporating such insight</definiens>
			</definition>
			<definition id="1">
				<sentence>Analysis is the process of mapping forms to context-independent meanings , providing the input parameters for enactment .</sentence>
				<definiendum id="0">Analysis</definiendum>
				<definiens id="0">the process of mapping forms to context-independent meanings , providing the input parameters for enactment</definiens>
			</definition>
			<definition id="2">
				<sentence>Enactment uses an active , simulation-based model to generate contextspecific inference .</sentence>
				<definiendum id="0">Enactment</definiendum>
				<definiens id="0">uses an active , simulation-based model to generate contextspecific inference</definiens>
			</definition>
			<definition id="3">
				<sentence>ECG combines a syntax and knowledge representation in a unification-based framework .</sentence>
				<definiendum id="0">ECG</definiendum>
				<definiens id="0">combines a syntax and knowledge representation in a unification-based framework</definiens>
			</definition>
			<definition id="4">
				<sentence>A construction recognizer is the chunk of active knowledge into which a construction gets transformed .</sentence>
				<definiendum id="0">construction recognizer</definiendum>
			</definition>
</paper>

		<paper id="3254">
			<definition id="0">
				<sentence>We have presented a new information-based summarization metric called weighted factoid score , which uses multiple summaries as gold standard and which measures information overlap , not string overlap .</sentence>
				<definiendum id="0">factoid score</definiendum>
				<definiens id="0">uses multiple summaries as gold standard and which measures information overlap , not string overlap</definiens>
			</definition>
</paper>

		<paper id="1401">
			<definition id="0">
				<sentence>Although this could be seen as a type of machine-aided human translation ( MAHT ) , we would like to emphasise the issue of knowledge , corporate knowledge in particular , which precisely ought to be captured into the translation system’s knowledge base .</sentence>
				<definiendum id="0">MAHT</definiendum>
				<definiens id="0">the issue of knowledge , corporate knowledge in particular , which precisely ought to be captured into the translation system’s knowledge base</definiens>
			</definition>
			<definition id="1">
				<sentence>Its main assets would be an overall corporate knowledge base linked to various LR4Trans , as appropriate , and maintained by all agents 8 intervening in the workflow , plus a content management system , or CMS , that would reflect the business roles controlling the workflow , data production and update flow , user roles and access privileges , costing rules , etc .</sentence>
				<definiendum id="0">CMS</definiendum>
				<definiens id="0">appropriate , and maintained by all agents 8 intervening in the workflow , plus a content management system , or</definiens>
			</definition>
</paper>

		<paper id="0401">
			<definition id="0">
				<sentence>An LVC occurs when a light verb , such as take , give , or make in ( 1 ) , is used in conjunction with a complement to form a multiword expression .</sentence>
				<definiendum id="0">LVC</definiendum>
				<definiens id="0">occurs when a light verb , such as take , give</definiens>
			</definition>
			<definition id="1">
				<sentence>We focus on the “LV a V” constructions because we are interested in the hypothesis that the complement to the LV is a verb , and think that the properties of this construction may place interesting restrictions on what forms a valid LVC .</sentence>
				<definiendum id="0">LV</definiendum>
				<definiens id="0">a verb</definiens>
			</definition>
			<definition id="2">
				<sentence>While I ( lv ; aV ) should tell us whether “LV a V” is a good collocation ( Church et al. , 1991 ) , the difference between the two , I ( lv ; aV ) I ( lv ; detV ) , should tell us whether the collocation is an LVC .</sentence>
				<definiendum id="0">detV</definiendum>
				<definiens id="0">a good collocation ( Church et al. , 1991 ) , the difference between the two</definiens>
			</definition>
			<definition id="3">
				<sentence>A ‘*’ indicates a random subset of verbs in the class .</sentence>
				<definiendum id="0">‘*’</definiendum>
				<definiens id="0">indicates a random subset of verbs in the class</definiens>
			</definition>
			<definition id="4">
				<sentence>Even the 100M words of the British National CorTo measure mutual information , we gather several counts for each potential LVC : the frequency of the LVC ( e.g. , give a cry ) , the frequency of the light verb ( e.g. , give ) , and the frequency of the complement of the LVC ( e.g. , a cry ) .</sentence>
				<definiendum id="0">LVC</definiendum>
				<definiendum id="1">LVC</definiendum>
				<definiens id="0">the frequency of the LVC ( e.g. , give a cry ) , the frequency of the light verb</definiens>
			</definition>
			<definition id="5">
				<sentence>Since we are interested in the differences across determiners , we search for both the LVC ( “give [ det ] cry” ) and the complement alone ( “ [ det ] cry” ) using all singular determiners .</sentence>
				<definiendum id="0">LVC</definiendum>
				<definiens id="0">“give [ det ] cry” ) and the complement alone ( “ [ det ] cry” ) using all singular determiners</definiens>
			</definition>
			<definition id="6">
				<sentence>N is the number of test verbs .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
			<definition id="7">
				<sentence>On our development set , we tested several of these measures and found that the following had the best correlations with human ratings : a0 MI : I ( lv ; aV ) a0 DiffAll : 2 a3 I ( lv ; aV ) I ( lv ; detV ) where I ( lv ; detV ) is the mutual information over strings “LV [ det ] V” , and det is any determiner other than a , an , or the .</sentence>
				<definiendum id="0">detV</definiendum>
				<definiendum id="1">det</definiendum>
				<definiens id="0">the mutual information over strings</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>After calculating the scores for all relations and all connectors within each relation , we calculate their normalized scores The normalized relation score is the ratio of the count for the current relation ( how many times we see the relation within a sentence in the input ) over the overall count of all relations .</sentence>
				<definiendum id="0">normalized relation score</definiendum>
				<definiens id="0">the ratio of the count for the current relation ( how many times we see the relation within a sentence in the input</definiens>
			</definition>
			<definition id="1">
				<sentence>The normalized connector score is the ratio of the count for the current connector ( how many times we see this connector for the current relation ) over the overall count for all connectors for this relation .</sentence>
				<definiendum id="0">normalized connector score</definiendum>
				<definiens id="0">the ratio of the count for the current connector ( how many times we see this connector for the current relation ) over the overall count for all connectors for this relation</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus , out of the above procedural definition , an atomic event is a triplet of two named entities ( or frequent nouns ) connected by a verb or an actiondenoting noun .</sentence>
				<definiendum id="0">atomic event</definiendum>
				<definiens id="0">a triplet of two named entities ( or frequent nouns ) connected by a verb or an actiondenoting noun</definiens>
			</definition>
			<definition id="3">
				<sentence>Add the concepts covered by this textual unit to the list of concepts covered in the final output .</sentence>
				<definiendum id="0">Add the</definiendum>
				<definiens id="0">concepts covered by this textual unit to the list of concepts covered in the final output</definiens>
			</definition>
			<definition id="4">
				<sentence>This collection contains 30 test document sets , each with approximately 10 news stories on different events ; document sets vary significantly in their internal coherence .</sentence>
				<definiendum id="0">test document</definiendum>
				<definiens id="0">sets , each with approximately 10 news stories on different events ; document sets vary significantly in their internal coherence</definiens>
			</definition>
			<definition id="5">
				<sentence>We have introduced atomic events as a feature that can be automatically extracted from text and used for summarization , and described algorithms that utilize this feature to select sentences for the summary while minimizing the overlap of information in the output .</sentence>
				<definiendum id="0">atomic events</definiendum>
				<definiens id="0">utilize this feature to select sentences for the summary while minimizing the overlap of information in the output</definiens>
			</definition>
</paper>

		<paper id="0817">
			<definition id="0">
				<sentence>To tag and parse the data , we used LoPar ( Schmid , 2000 ) , a probabilistic contextfree parser , which comes with a Head-Lexicalised Grammar for English ( Carroll and Rooth , 1998 ) .</sentence>
				<definiendum id="0">probabilistic contextfree parser</definiendum>
				<definiens id="0">comes with a Head-Lexicalised Grammar for English</definiens>
			</definition>
			<definition id="1">
				<sentence>FrameNet provides semantic roles as character offsets .</sentence>
				<definiendum id="0">FrameNet</definiendum>
			</definition>
			<definition id="2">
				<sentence>In a first model , we derived a probability distribution a0a2a1a4a3a6a5 for pairs a3a8a7a9a1a10a3a2a11a13a12a14a3a16a15a17a5 , where a3a18a11 is a target : role combination and a3 a15 is the head lemma of a role filler .</sentence>
				<definiendum id="0">a3a18a11</definiendum>
				<definiens id="0">the head lemma of a role filler</definiens>
			</definition>
			<definition id="3">
				<sentence>Our first classifier was a log-linear model , where the probability of a class a19 given an feature vector a40a41 is defined as a0a2a1 a19 a38 a40 a41a6a5a36a7a43a42 a44 a45a8a46a33a47a49a48a51a50a13a48a10a52a51a53a55a54 a31a33a56 where a44 is a normalisation constant , a57 a45 a1a10a41a6a12 a19 a5 the value of feature a41 a45 for class a19 , and a58 a45 the weight assigned to a57 a45 .</sentence>
				<definiendum id="0">a44</definiendum>
				<definiens id="0">a log-linear model , where the probability of a class a19 given an feature vector a40a41 is defined as a0a2a1 a19 a38 a40 a41a6a5a36a7a43a42 a44 a45a8a46a33a47a49a48a51a50a13a48a10a52a51a53a55a54 a31a33a56 where</definiens>
			</definition>
			<definition id="4">
				<sentence>Table 5 gives the improvements made over the baseline through adding data gained by each FN hierarchy ( sem ) : a88 10,000 instances head lemma FN hierarchy ( syn ) : a88 10,000 instances phrase type , path , prep. , path seen , is subcategorised , voice , target POS Peripherals : a88 55,000 instances head lemma , phrase type , path , prep. , path seen , is subcategorised , voice , target POS EM head : a88 1,000,000 instances head lemma EM path : a88 433,000 instances phrase type , mother phrase type , path , path length , prep. , path seen , is subcategorised , voice , target POS Table 4 : Similarity-based generalisation : Features retained and number of generated instances a85 F-score Strategy Split 1 Split 2 FN hierarchy ( sem ) 0.3 -0.5 FN hierarchy ( syn ) -0.2 -0.4 Peripherals 0.2 -0.1 EM head 0.4 0.5 EM path 1.0 0.2 Table 5 : Contribution of generalization strategies generalisation strategy .</sentence>
				<definiendum id="0">FN hierarchy</definiendum>
				<definiendum id="1">0.3 -0.5 FN hierarchy</definiendum>
				<definiens id="0">syn ) : a88 10,000 instances phrase type , path , prep. , path seen , is subcategorised , voice , target POS Peripherals : a88 55,000 instances head lemma , phrase type , path , prep. , path seen , is subcategorised , voice , target POS EM head : a88 1,000,000 instances head lemma EM path : a88 433,000 instances phrase type , mother phrase type , path , path length , prep. , path seen , is subcategorised , voice</definiens>
			</definition>
</paper>

		<paper id="1220">
			<definition id="0">
				<sentence>On the other hand , conditional random fields ( CRFs ) ( [ Lafferty , 2001 ] ) is a probabilistic framework for labelling and segmenting sequential data , which is much faster comparing with SVM .</sentence>
				<definiendum id="0">CRFs )</definiendum>
				<definiens id="0">a probabilistic framework for labelling and segmenting sequential data , which is much faster comparing with SVM</definiens>
			</definition>
			<definition id="1">
				<sentence>Support Vector Machine ( SVM ) is a well-known machine learning technique showing a good performance in several classification problems .</sentence>
				<definiendum id="0">Support Vector Machine ( SVM )</definiendum>
				<definiens id="0">a well-known machine learning technique showing a good performance in several classification problems</definiens>
			</definition>
			<definition id="2">
				<sentence>Named entity token is a compound token that consists of the constituents of some other named entities , and all other un-related tokens are considered as outside tokens .</sentence>
				<definiendum id="0">Named entity token</definiendum>
				<definiens id="0">a compound token that consists of the constituents of some other named entities</definiens>
			</definition>
			<definition id="3">
				<sentence>Conditional random fields ( CRFs ) ( [ Wallach , 2004 ] is a probabilistic framework for labelling and segmenting a sequential data .</sentence>
				<definiendum id="0">Conditional random fields</definiendum>
				<definiendum id="1">CRFs )</definiendum>
				<definiens id="0">a probabilistic framework for labelling and segmenting a sequential data</definiens>
			</definition>
			<definition id="4">
				<sentence>Then ) , ( YX is a conditional random field , and when conditioned on X , the random variables Yv obey the Markov property with respect to the graph : ) , ~ , ,| ( ) , ,|| ( vwYwXYvpvwYwXYvp =≠ where vw ~ means that w and v are neighbours in G. Let X and Y be jointly distributed random variables respectively representing observation sequences and corresponding label sequences .</sentence>
				<definiendum id="0">YX</definiendum>
				<definiens id="0">a conditional random field</definiens>
			</definition>
			<definition id="5">
				<sentence>A CRF is an undirected graphical model , globally conditioned on X ( the observation sequence ) .</sentence>
				<definiendum id="0">CRF</definiendum>
				<definiens id="0">an undirected graphical model</definiens>
			</definition>
			<definition id="6">
				<sentence>SVM predicts the named entities based on feature information of words collected in a predefined window size while CRF predicts them based on the information of the whole sentence .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">predicts the named entities based on feature information of words collected in a predefined window size while CRF predicts them based on the information of the whole sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>Parentheses occur in the named entity more than 700 times in the training data .</sentence>
				<definiendum id="0">Parentheses</definiendum>
				<definiens id="0">occur in the named entity more than 700 times in the training data</definiens>
			</definition>
			<definition id="8">
				<sentence>A CRF has different characteristics from SVM , and is good at handling different kinds of data .</sentence>
				<definiendum id="0">CRF</definiendum>
				<definiens id="0">has different characteristics from SVM</definiens>
			</definition>
</paper>

		<paper id="3208">
			<definition id="0">
				<sentence>A parallel corpus is a sentence-aligned corpus containing bilingual translations of the same document .</sentence>
				<definiendum id="0">parallel corpus</definiendum>
				<definiens id="0">a sentence-aligned corpus containing bilingual translations of the same document</definiens>
			</definition>
			<definition id="1">
				<sentence>A noisy parallel corpus , sometimes also called a “comparable” corpus , contains non-aligned sentences that are nevertheless mostly bilingual translations of the same document .</sentence>
				<definiendum id="0">noisy parallel corpus</definiendum>
				<definiens id="0">contains non-aligned sentences that are nevertheless mostly bilingual translations of the same document</definiens>
			</definition>
			<definition id="2">
				<sentence>The lexical matching score is then defined as the sum of the mutual information score of a known set of word pairs that appear in the corpus : ∑ = = ) , ( ) , ( ) ( ) ( ) , ( ) , ( ec WWall ec ec ec ec WWSS WfWf WWf WWS where f ( Wc , We ) is the co-occurrence frequency of bilexicon pair ( Wc , We ) in the matched sentence pairs .</sentence>
				<definiendum id="0">lexical matching score</definiendum>
				<definiendum id="1">( )</definiendum>
				<definiendum id="2">ec WWall ec ec ec ec WWSS WfWf WWf WWS where f ( Wc , We )</definiendum>
				<definiens id="0">the sum of the mutual information score of a known set of word pairs that appear in the corpus : ∑ = = ) , ( ) , ( ) ( ) ( ) ,</definiens>
				<definiens id="1">the co-occurrence frequency of bilexicon pair ( Wc , We ) in the matched sentence pairs</definiens>
			</definition>
			<definition id="3">
				<sentence>f ( Wc ) and f ( We ) are the occurrence frequencies of Chinese word Wc and English word We , in the bilingual corpus .</sentence>
				<definiendum id="0">f ( Wc</definiendum>
				<definiens id="0">the occurrence frequencies of Chinese word Wc and English word We , in the bilingual corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>We evaluated different combinations of term weighting of each word in the corpus : term frequency ( tf ) ; inverse document frequency ( idf ) ; tf .</sentence>
				<definiendum id="0">term frequency</definiendum>
				<definiendum id="1">inverse document frequency</definiendum>
				<definiens id="0">term weighting of each word in the corpus</definiens>
			</definition>
</paper>

		<paper id="1208">
			<definition id="0">
				<sentence>Such examples were translated into the following four patterns : ( 1 ) the X protein , ( 2 ) the protein X , ( 3 ) T domain of NP , and ( 4 ) NP is a protein .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">a protein</definiens>
			</definition>
			<definition id="1">
				<sentence>The X denotes a single token and T represents a selection of concepts which are known to be used in conjunction with a protein .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a single token and T represents a selection of concepts which are known to be used in conjunction with a protein</definiens>
			</definition>
			<definition id="2">
				<sentence>Integrated patterns identify nomenclature equivalent to AA [ 0-9 ] + AA , where AA denotes all variants of an amino acid or nucleic acid .</sentence>
				<definiendum id="0">AA</definiendum>
				<definiens id="0">all variants of an amino acid or nucleic acid</definiens>
			</definition>
			<definition id="3">
				<sentence>As a result , XML elements used as meta data are not allowed to contain themselves .</sentence>
				<definiendum id="0">XML elements</definiendum>
				<definiens id="0">used as meta data are not allowed to contain themselves</definiens>
			</definition>
</paper>

		<paper id="0602">
			<definition id="0">
				<sentence>Metadata is a key source of information towards realization of the Semantic Web that could be exploited in many different ways .</sentence>
				<definiendum id="0">Metadata</definiendum>
				<definiens id="0">a key source of information towards realization of the Semantic</definiens>
			</definition>
			<definition id="1">
				<sentence>Domain – Sub-domain size Type MD Formal State Harvesting Type Comment HoA Fotothek very large MIDAS Iconclass non validated XML export from a database HoA Lineamenta small close to DC non val XML export from a database HoA – Maps of Rome small self-defined non val XML export from a database HoS – Berlin Collection large close to DC validated XML export from a database HoS – IMSS pot large DC non val XML export from a database E – Ethnology Museum Leiden RMV very large OMV OMV Thesaurus validated OAI export from a database E – NECEP database small self defined validated XML export from a database L – IMDI Domain large IMDI set validated XMLAI true XML domain P – Collection of Texts small self defined non val XML XML texts History of arts ( HoA ) , History of Science ( HoS ) , Linguistics ( L ) , Ethnology ( E ) , Phylosophy ( P ) Also the way in which the content of resources is described differs substantially .</sentence>
				<definiendum id="0">HoS ) , Linguistics ( L</definiendum>
				<definiendum id="1">P ) Also</definiendum>
				<definiens id="0">Sub-domain size Type MD Formal State Harvesting Type Comment HoA Fotothek very large MIDAS Iconclass non validated XML export from a database HoA Lineamenta small close to DC non val XML export from a database HoA – Maps of Rome small self-defined non val XML export from a database HoS – Berlin Collection large close to DC validated XML export from a database HoS – IMSS pot large DC non val XML export from a database E – Ethnology Museum Leiden RMV very large OMV OMV Thesaurus validated OAI export from a database E – NECEP database small self defined validated XML export from a database L – IMDI Domain large IMDI set validated XML/OAI true XML domain P – Collection of Texts small self defined non val XML XML texts History of arts ( HoA )</definiens>
				<definiens id="1">the way in which the content of resources is described differs substantially</definiens>
			</definition>
			<definition id="2">
				<sentence>Semantically , RDF Schema offers the user the option to define the value range of any userdefined relation ( property ) used in an RDF file with user-defined classes , while XML only offers basic data types .</sentence>
				<definiendum id="0">RDF Schema</definiendum>
				<definiens id="0">offers the user the option to define the value range of any userdefined relation ( property ) used in an RDF file with user-defined classes</definiens>
			</definition>
			<definition id="3">
				<sentence>The usage of ISO 11179 and ISO 12620 compliant open Data Category Registries for machine readable definitions of metadata concepts within INTERA is a first step in the right direction .</sentence>
				<definiendum id="0">INTERA</definiendum>
				<definiens id="0">a first step in the right direction</definiens>
			</definition>
</paper>

		<paper id="0303">
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>Therefore , in the presentation of a final summary , we propose to preserve this organization of the structures of the text in order to build a table style summary with five themes : DECISION DATA contains the name of the jurisdiction , the place of the hearing , the date of the decision , the identity of the author , names of parties , title of proceeding , authority and doctrine .</sentence>
				<definiendum id="0">DECISION DATA</definiendum>
				<definiens id="0">contains the name of the jurisdiction</definiens>
			</definition>
			<definition id="1">
				<sentence>CONTEXT explains the facts in chronological order , or by description .</sentence>
				<definiendum id="0">CONTEXT</definiendum>
				<definiens id="0">explains the facts in chronological order , or by description</definiens>
			</definition>
			<definition id="2">
				<sentence>JURIDICAL ANALYSIS describes the comments of the judge and finding of facts , and the application of the law to the facts as found .</sentence>
				<definiendum id="0">JURIDICAL ANALYSIS</definiendum>
				<definiens id="0">describes the comments of the judge and finding of facts , and the application of the law to the facts as found</definiens>
			</definition>
			<definition id="3">
				<sentence>CONCLUSION expresses the disposition which is the final part of a decision containing the information about what is decided by the court .</sentence>
				<definiendum id="0">CONCLUSION</definiendum>
				<definiens id="0">expresses the disposition which is the final part of a decision containing the information about what is decided by the court</definiens>
			</definition>
</paper>

		<paper id="0703">
			<definition id="0">
				<sentence>Chains A co-reference chain in a document denotes an equivalence class of noun phrases .</sentence>
				<definiendum id="0">co-reference chain</definiendum>
				<definiens id="0">an equivalence class of noun phrases</definiens>
			</definition>
			<definition id="1">
				<sentence>( 4 ) For each sentence that is not selected , count the number of noun co-reference chains , which are covered by this sentence , and add the count to the number of verbal terms in this sentence which also appear in the headline .</sentence>
				<definiendum id="0">noun co-reference chains</definiendum>
				<definiens id="0">the number of verbal terms in this sentence which also appear in the headline</definiens>
			</definition>
			<definition id="2">
				<sentence>22 2 2 1 log inii j ij ij sss df N tf w +⋅⋅⋅++ × = ( 1 ) where tf ij is frequency of term t j in summary i , N is total number of summaries in the collection being examined , df j is number of summaries that term t j occurs , and s ij denotes the TF-IDF value of term t j in summary i. A single-pass complete link clustering algorithm incrementally divides the documents into several event clusters .</sentence>
				<definiendum id="0">tf ij</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">total number of summaries in the collection being examined , df j is number of summaries that term t j occurs , and s ij denotes the TF-IDF value of term t j in summary i. A single-pass complete link clustering algorithm incrementally divides the documents into several event clusters</definiens>
			</definition>
			<definition id="3">
				<sentence>th ) /w_sizedist ( D ) /w_sizedist ( D DDthd × + + = 1 1 ) , ( _ 2 1 21 ( 3 ) where dist ( day distance ) denotes the number of days away from the day at which the event happens , and w_size ( window size ) keeps the threshold unchanged within the same window .</sentence>
				<definiendum id="0">dist</definiendum>
				<definiens id="0">the number of days away from the day at which the event happens , and w_size ( window size ) keeps the threshold unchanged within the same window</definiens>
			</definition>
			<definition id="4">
				<sentence>tijj it it Ns N TFsMax TFs Ws log ) ( ×= ( 5 ) where TFs it denotes term frequency of term t in the i-th story , N is total number of stories , and Ns t is the number of stories where term t occurs .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">Ns t</definiendum>
				<definiens id="0">Ns N TFsMax TFs Ws log ) ( ×= ( 5 ) where TFs it denotes term frequency of term t in the i-th story</definiens>
				<definiens id="1">total number of stories</definiens>
			</definition>
</paper>

		<paper id="1402">
			<definition id="0">
				<sentence>CESTA protocol specifications have been communicated to participants in particular as regards data formatting , test schedule , metrics and adaptation phase .</sentence>
				<definiendum id="0">CESTA protocol specifications</definiendum>
				<definiens id="0">communicated to participants in particular as regards data formatting , test schedule , metrics and adaptation phase</definiens>
			</definition>
			<definition id="1">
				<sentence>The IBM BLEU metric used by the DARPA for its 2001 evaluation campaign , uses co-occurrence measures based on N-Grams .</sentence>
				<definiendum id="0">IBM BLEU metric</definiendum>
				<definiens id="0">uses co-occurrence measures based on N-Grams</definiens>
			</definition>
			<definition id="2">
				<sentence>The score of statistical significance is computed for each word ( with absolute frequency ≥ 2 in the particular text ) for each text in the corpus , as follows : ( ) ] [ ] [ ] [ ] [ ] [ ln corpallword foundnottxtswordcorprestwordtextword textword P NPP S − −−− ×− = where : S word [ text ] is the score of statistical significance for a particular word in a particular text P word [ text ] is the relative frequency of the word in the text ; P word [ rest-corp ] is the relative frequency of the same word in the rest of the corpus , without this text ; N word [ txt-not-found ] is the proportion of texts in the corpus , where this word is not found ( number of texts , where it is not found divided by number of texts in the corpus ) P word [ all-corp ] is the relative frequency of the word in the whole corpus , including this particular text significant words for corresponding texts together with their S word [ text ] scores are compared across different MT systems .</sentence>
				<definiendum id="0">N word</definiendum>
				<definiens id="0">the relative frequency of the word in the text</definiens>
				<definiens id="1">the proportion of texts in the corpus , where this word is not found ( number of texts</definiens>
			</definition>
			<definition id="3">
				<sentence>CESTA is the first European Campaign dedicated to MT Evaluation .</sentence>
				<definiendum id="0">CESTA</definiendum>
			</definition>
</paper>

		<paper id="0904">
			<definition id="0">
				<sentence>Ontological Semantics ( OntoSem ) is a multilingual text processing environment that takes as input unrestricted text and , using a suite of static resources and processors , automatically creates text-meaning representations ( TMRs ) which can then be used as the basis for any NLP application , including MT , question answering , summarization , etc .</sentence>
				<definiendum id="0">Ontological Semantics</definiendum>
				<definiendum id="1">OntoSem</definiendum>
				<definiendum id="2">TMRs</definiendum>
				<definiens id="0">a multilingual text processing environment that takes as input unrestricted text and , using a suite of static resources and processors</definiens>
			</definition>
			<definition id="1">
				<sentence>The SIMPLE project takes a different approach to achieving the dual goals of multilinguality and resource utility across applications .</sentence>
				<definiendum id="0">SIMPLE project</definiendum>
				<definiens id="0">takes a different approach to achieving the dual goals of multilinguality and resource utility across applications</definiens>
			</definition>
			<definition id="2">
				<sentence>OntoSem takes as input unrestricted raw text and carries out preprocessing , morphological analysis , syntactic analysis and semantic analysis , with the results of semantic analysis represented as formal text-meaning representations ( TMRs ) that can then be used as the basis for a wide variety of NLP applications .</sentence>
				<definiendum id="0">TMRs</definiendum>
				<definiens id="0">input unrestricted raw text and carries out preprocessing , morphological analysis , syntactic analysis and semantic analysis</definiens>
			</definition>
			<definition id="3">
				<sentence>• An OntoSem lexicon for each language processed , which contains syntactic and semantic zones ( linked using variables ) as well as calls to “meaning procedures” ( i.e. , programs that carry out procedural semantics , see McShane et al. 2004a ) when applicable .</sentence>
				<definiendum id="0">OntoSem lexicon</definiendum>
				<definiens id="0">contains syntactic and semantic zones ( linked using variables ) as well as calls to “meaning procedures” ( i.e. , programs that carry out procedural semantics</definiens>
			</definition>
			<definition id="4">
				<sentence>• A fact repository , which contains real-world facts represented as numbered “remembered instances” of ontological concepts ( e.g. , SPEECHACT-3366 is the 3366 th instantiation of the concept SPEECH-ACT in the world model constructed during the given run of the analyzer ) .</sentence>
				<definiendum id="0">fact repository</definiendum>
				<definiendum id="1">SPEECHACT-3366</definiendum>
				<definiens id="0">contains real-world facts represented as numbered “remembered instances” of ontological concepts ( e.g. ,</definiens>
			</definition>
			<definition id="5">
				<sentence>A very simple example of a TMR ( simple because most of the sentences we process are much longer ) , which reflects the meaning of the sentence He asked the UN to authorize the war , is as follows : REQUEST-ACTION-69 AGENT HUMAN-72 THEME ACCEPT-70 BENEFICIARY ORGANIZATION-71 SOURCE-ROOT-WORD ask TIME ( &lt; ( FIND-ANCHOR-TIME ) ) ACCEPT-70 THEME WAR-73 THEME-OF REQUEST-ACTION-69 SOURCE-ROOT-WORD authorize ORGANIZATION-71 HAS-NAME UNITED-NATIONS BENEFICIARY-OF REQUEST-ACTION-69 SOURCE-ROOT-WORD UN HUMAN-72 HAS-NAME COLIN POWELL AGENT-OF REQUEST-ACTION-69 SOURCE-ROOT-WORD he ; ref .</sentence>
				<definiendum id="0">TMR</definiendum>
				<definiens id="0">reflects the meaning of the sentence He asked the UN to authorize the war , is as follows : REQUEST-ACTION-69 AGENT HUMAN-72 THEME ACCEPT-70 BENEFICIARY ORGANIZATION-71 SOURCE-ROOT-WORD ask TIME</definiens>
			</definition>
			<definition id="6">
				<sentence>syn-struc root $ var1 cat v mods root $ var0 cat adv type pre-verb-post-clause sem-struc ^ $ var1 time combine-time ( find-anchor-time ) ( day 1 ) before As already shown in the examples of might and yesterday , calls to procedural semantic routines ( which may or may not be listed in the meaningprocedure zone of the lexicon entry ) are used widely in OntoSem lexical description .</sentence>
				<definiendum id="0">combine-time ( find-anchor-time )</definiendum>
				<definiens id="0">calls to procedural semantic routines ( which may or may not be listed in the meaningprocedure zone of the lexicon entry ) are used widely in OntoSem lexical description</definiens>
			</definition>
			<definition id="7">
				<sentence>Example ( d ) is analyzed using the information that PUDDING is a PREPARED-FOOD and , as such , is the THEME-OF PREPARE-FOOD , which in turn is a child of CREATE-ARTIFACT .</sentence>
				<definiendum id="0">THEME-OF PREPARE-FOOD</definiendum>
			</definition>
</paper>

		<paper id="0813">
			<definition id="0">
				<sentence>The features for Basque were diﬀerent , as Basque is an agglutinative language , and syntactic information is given by inflectional suﬃxes .</sentence>
				<definiendum id="0">Basque</definiendum>
				<definiens id="0">an agglutinative language , and syntactic information is given by inflectional suﬃxes</definiens>
			</definition>
			<definition id="1">
				<sentence>Regarding Support Vector Machines ( SVM ) we utilized SVM-Light ( Joachims , 1999 ) , a public distribution of SVM .</sentence>
				<definiendum id="0">Regarding Support Vector Machines</definiendum>
				<definiens id="0">a public distribution of SVM</definiens>
			</definition>
			<definition id="2">
				<sentence>Basque is an agglutinative language , and syntactic information is given by inflectional suffixes .</sentence>
				<definiendum id="0">Basque</definiendum>
				<definiens id="0">an agglutinative language , and syntactic information is given by inflectional suffixes</definiens>
			</definition>
</paper>

		<paper id="1513">
			<definition id="0">
				<sentence>A Dependency Insertion Grammars ( DIG ) is a generative grammar formalism that captures word order phenomena within the dependency representation .</sentence>
				<definiendum id="0">Dependency Insertion Grammars ( DIG )</definiendum>
				<definiens id="0">a generative grammar formalism that captures word order phenomena within the dependency representation</definiens>
			</definition>
			<definition id="1">
				<sentence>Synchronous Dependency Insertion Grammars ( SDIG ) is the synchronous version of DIG which aims at capturing structural divergences across the languages .</sentence>
				<definiendum id="0">Synchronous Dependency Insertion Grammars ( SDIG )</definiendum>
			</definition>
			<definition id="2">
				<sentence>Section 5 specifies the Synchronous DIG and Section 6 gives the probabilistic extension of SDIG .</sentence>
				<definiendum id="0">Synchronous DIG</definiendum>
				<definiens id="0">gives the probabilistic extension of SDIG</definiens>
			</definition>
			<definition id="3">
				<sentence>Formally , the Dependency Insertion Grammar is defined as a six tuple ) , , , , , ( RSBALC .</sentence>
				<definiendum id="0">Dependency Insertion Grammar</definiendum>
			</definition>
			<definition id="4">
				<sentence>C is a set of syntactic categories and L is a set of lexical items .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">L</definiendum>
			</definition>
			<definition id="5">
				<sentence>R is a set of word order rules local to each node of the trees .</sentence>
				<definiendum id="0">R</definiendum>
			</definition>
			<definition id="6">
				<sentence>Each node in the DIG has three fields : A Node consists of : We define two types of elementary trees in DIG : Type-A trees and Type-B trees .</sentence>
				<definiendum id="0">Node</definiendum>
			</definition>
			<definition id="7">
				<sentence>and CFG We prove the weak equivalence between DIG and CFG by first showing that the language that a DIG generates is a subset of one that a CFG generates , i.e. ) ( ) ( CFGLDIGL ⊆ .</sentence>
				<definiendum id="0">CFG</definiendum>
				<definiendum id="1">i.e. ) ( )</definiendum>
				<definiens id="0">a subset of one that a CFG generates ,</definiens>
			</definition>
			<definition id="8">
				<sentence>{ H CANT is the nonterminal created for this Type-A tree , and H C is the category of the head ( root ) .</sentence>
				<definiendum id="0">{ H CANT</definiendum>
				<definiendum id="1">H C</definiendum>
				<definiens id="0">the category of the head ( root )</definiens>
			</definition>
			<definition id="9">
				<sentence>It is known that a context free grammar can be converted to Greibach Normal Form , where each production will have the form : *aVA → , where V is the set of nonterminals We simply construct a corresponding Type-A dependency tree as follows : Figure 7 A Tree Adjoining Grammars is defined as a five tuple ) , , , , ( SAINTΣ , where Σ is a set of terminals , NT is a set of nonterminals , I is a finite set of finite initial trees ( α trees ) , A is a finite set of auxiliary trees ( β trees ) , and S is a set of starting symbols .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">Σ</definiendum>
				<definiendum id="2">NT</definiendum>
				<definiendum id="3">S</definiendum>
				<definiens id="0">the set of nonterminals We simply construct a corresponding Type-A dependency tree as follows : Figure 7 A Tree Adjoining Grammars is defined as a five tuple ) , , , , ( SAINTΣ , where</definiens>
				<definiens id="1">a set of terminals</definiens>
				<definiens id="2">a set of nonterminals</definiens>
				<definiens id="3">a finite set of finite initial trees ( α trees ) , A is a finite set of auxiliary trees ( β trees ) , and</definiens>
				<definiens id="4">a set of starting symbols</definiens>
			</definition>
			<definition id="10">
				<sentence>A TAG derives a phrase-structure tree , called the “derived tree” and at the same time , in each step of the derivation process , two elementary trees are connected through either the substitution or adjunction operation .</sentence>
				<definiendum id="0">TAG</definiendum>
				<definiens id="0">derives a phrase-structure tree , called the “derived tree”</definiens>
			</definition>
			<definition id="11">
				<sentence>Please note that the Bleu/NIST scorers , while based on n-gram matching , do not model syntax during evaluation , which means a direct comparison between a syntax based MT system and a string based statistical MT system using the above scorer would favor the string based systems .</sentence>
				<definiendum id="0">Please note</definiendum>
				<definiens id="0">means a direct comparison between a syntax based MT system and a string based statistical MT system using the above scorer would favor the string based systems</definiens>
			</definition>
</paper>

		<paper id="0810">
			<definition id="0">
				<sentence>The Logic Form ( LF ) that we use is a flat , scope-free first order logic representation that embeds lexical and syntactic information .</sentence>
				<definiendum id="0">Logic Form ( LF</definiendum>
				<definiens id="0">a flat , scope-free first order logic representation that embeds lexical and syntactic information</definiens>
			</definition>
			<definition id="1">
				<sentence>Predicate level performance is defined as the number of predicates with correct arguments divided by the total number of predicates .</sentence>
				<definiendum id="0">Predicate level performance</definiendum>
				<definiens id="0">the number of predicates with correct arguments divided by the total number of predicates</definiens>
			</definition>
			<definition id="2">
				<sentence>Gloss level performance is the number of entire glosses correctly transformed into logic forms divided by the total number of glosses attempted .</sentence>
				<definiendum id="0">Gloss level performance</definiendum>
				<definiens id="0">the number of entire glosses correctly transformed into logic forms divided by the total number of glosses attempted</definiens>
			</definition>
			<definition id="3">
				<sentence>Precision at predicate level is the number of correctly and fully identified predicates ( with ALL arguments correctly identified ) divided by the number of all attempted predicates .</sentence>
				<definiendum id="0">predicate level</definiendum>
				<definiens id="0">the number of correctly and fully identified predicates ( with ALL arguments correctly identified ) divided by the number of all attempted predicates</definiens>
			</definition>
			<definition id="4">
				<sentence>Recall at predicate level is the number of correctly and fully identified predicates ( with ALL arguments correctly identified ) divided by the number of all predicates that were supposed to be identified .</sentence>
				<definiendum id="0">predicate level</definiendum>
				<definiens id="0">the number of correctly and fully identified predicates ( with ALL arguments correctly identified ) divided by the number of all predicates that were supposed to be identified</definiens>
			</definition>
			<definition id="5">
				<sentence>In addition , we report a more global measure called exact sentence which is defined as the number of sentences whose logic form was fully identified ( all predicates and arguments correctly found ) divided by the number of sentences attempted .</sentence>
				<definiendum id="0">exact sentence</definiendum>
			</definition>
</paper>

		<paper id="1405">
			<definition id="0">
				<sentence>This was a major criterion for our choosing Moodle ( i.e. Modular Object-Oriented Dynamic Learning Environment ) .</sentence>
				<definiendum id="0">Moodle</definiendum>
			</definition>
			<definition id="1">
				<sentence>Moodle is the only open source LMS to truly address the issue of human resource information systems ( HRIS ) integration .</sentence>
				<definiendum id="0">Moodle</definiendum>
				<definiens id="0">the only open source LMS to truly address the issue of human resource information systems</definiens>
			</definition>
			<definition id="2">
				<sentence>Bonito is a corpus manager developed by Pavel Rychly of the Faculty of Informatics , Masaryk University in Brno .</sentence>
				<definiendum id="0">Bonito</definiendum>
				<definiens id="0">a corpus manager developed by Pavel Rychly of the Faculty of Informatics</definiens>
			</definition>
</paper>

		<paper id="1615">
			<definition id="0">
				<sentence>FarsiSum is an attempt to create an automatic text summarization system for Persian .</sentence>
				<definiendum id="0">FarsiSum</definiendum>
				<definiens id="0">an attempt to create an automatic text summarization system for Persian</definiens>
			</definition>
			<definition id="1">
				<sentence>FarsiSum is an attempt to create an automatic text summarization system for Persian ( Mazdak , 2004 ) .</sentence>
				<definiendum id="0">FarsiSum</definiendum>
			</definition>
			<definition id="2">
				<sentence>The stop-list is a file including the most common verbs , pronouns , adverbs , conjunctions , prepositions and articles in Persian .</sentence>
				<definiendum id="0">stop-list</definiendum>
				<definiens id="0">a file including the most common verbs , pronouns , adverbs , conjunctions , prepositions and articles in Persian</definiens>
			</definition>
			<definition id="3">
				<sentence>SweSum 1 ( Dalianis 2000 ) is a web-based automatic text summarizer developed at the Royal Institute of Technology ( KTH ) in Sweden .</sentence>
				<definiendum id="0">SweSum 1</definiendum>
				<definiens id="0">a web-based automatic text summarizer developed at the Royal Institute of Technology ( KTH ) in Sweden</definiens>
			</definition>
			<definition id="4">
				<sentence>SweSum is a client/server application .</sentence>
				<definiendum id="0">SweSum</definiendum>
				<definiens id="0">a client/server application</definiens>
			</definition>
			<definition id="5">
				<sentence>FarsiSum is a web-based text summarizer for Persian based upon SweSum .</sentence>
				<definiendum id="0">FarsiSum</definiendum>
				<definiens id="0">a web-based text summarizer for Persian based upon SweSum</definiens>
			</definition>
			<definition id="6">
				<sentence>The stop-list is a HTML file ( UTF-8 encoding ) containing about 200 high-frequency Persian words including the most common verbs , pronouns , adverbs , conjunctions , prepositions and articles .</sentence>
				<definiendum id="0">stop-list</definiendum>
				<definiens id="0">a HTML file ( UTF-8 encoding ) containing about 200 high-frequency Persian words including the most common verbs , pronouns , adverbs , conjunctions , prepositions and articles</definiens>
			</definition>
</paper>

		<paper id="0862">
			<definition id="0">
				<sentence>Because of the nature of the bug-fix , evaluating our system based on the official results will yield less informative results than an evaluation of results after fixing 1As mentioned previously , Spanish is a special case and we will report only our official results .</sentence>
				<definiendum id="0">Spanish</definiendum>
				<definiens id="0">a special case</definiens>
			</definition>
</paper>

		<paper id="0702">
			<definition id="0">
				<sentence>We compute the match probability score for the records using the following form of Bayes’ rule : P ( M|E ) is the probability that the template and authority records refer to the same person , given match evidence E. P ( M ) is the prior probability that the reference records refer to the same person .</sentence>
				<definiendum id="0">match probability score</definiendum>
				<definiens id="0">the probability that the template and authority records refer to the same person</definiens>
				<definiens id="1">the prior probability that the reference records refer to the same person</definiens>
			</definition>
</paper>

		<paper id="3230">
			<definition id="0">
				<sentence>Moreover , B/I tagging produces a number of redundant candidates which makes the decoding speed slower .</sentence>
				<definiendum id="0">B/I tagging</definiendum>
				<definiens id="0">produces a number of redundant candidates which makes the decoding speed slower</definiens>
			</definition>
			<definition id="1">
				<sentence>A lattice represents all candidate paths or all candidate sequences of tokens , where each token denotes a word with its partof-speech 1 .</sentence>
				<definiendum id="0">lattice</definiendum>
				<definiens id="0">represents all candidate paths or all candidate sequences of tokens</definiens>
			</definition>
			<definition id="2">
				<sentence>CRFs have a single exponential model for the joint probability of the entire paths given the input sentence , while MEMMs consist of a sequential combination of exponential models , each of which estimates a conditional probability of next tokens given the current state .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiens id="0">a single exponential model for the joint probability of the entire paths given the input sentence , while MEMMs consist of a sequential combination of exponential models , each of which estimates a conditional probability of next tokens given the current state</definiens>
			</definition>
			<definition id="3">
				<sentence>In order to accomodate this , we define CRFs for Japanese morphological analysis as the conditional probability of an output path y = ( hw1 ; t1i ; : : : ; hw # y ; t # yi ) given an input sequence x : P ( yjx ) = 1Z x exp # yX i=1 X k kfk ( hwi 1 ; ti 1i ; hwi ; tii ) ; where Zx is a normalization factor over all candidate paths , i.e. , Zx = X y02Y ( x ) exp # y0X i=1 X k kfk ( hw0i 1 ; t0i 1i ; hw0i ; t0ii ) ; fk ( hwi 1 ; ti 1i ; hwi ; tii ) is an arbitrary feature function over i-th tokenhwi ; tii , and its previous token hwi 1 ; ti 1i5 .</sentence>
				<definiendum id="0">Zx</definiendum>
				<definiendum id="1">y0X i=1 X k kfk</definiendum>
				<definiendum id="2">tii )</definiendum>
				<definiens id="0">a normalization factor over all candidate paths</definiens>
			</definition>
			<definition id="4">
				<sentence>CRFs is thus trained to discriminate the correct path from all other candidates , which reduces the influences of the label and length bias in encoding .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiens id="0">reduces the influences of the label and length bias in encoding</definiens>
			</definition>
			<definition id="5">
				<sentence>EP ( yjx ) [ Fk ( y ; x ) ] = X fhw0 ; t0i ; hw ; tig2B ( x ) hw0 ; t0i f k exp ( Pk0 k0f k0 ) hw ; ti Zx ; where f k is an abbreviation for fk ( hw0 ; t0i ; hw ; ti ) , B ( x ) is a set of all bi-gram sequences observed in the lattice for x , and hw ; ti and hw ; ti are the forward-backward costs given by the following recursive definitions : hw ; ti = X hw0 ; t0i2LT ( hw ; ti ) hw0 ; t0i exp X k kfk ( hw0 ; t0i ; hw ; ti ) hw ; ti = X hw0 ; t0i2RT ( hw ; ti ) hw0 ; t0i exp X k kfk ( hw ; ti ; hw0 ; t0i ) ; where LT ( hw ; ti ) and RT ( hw ; ti ) denote a set of tokens each of which connects to the token hw ; ti from the left and the right respectively .</sentence>
				<definiendum id="0">EP</definiendum>
				<definiendum id="1">f k</definiendum>
				<definiendum id="2">B ( x )</definiendum>
				<definiens id="0">an abbreviation for fk ( hw0 ; t0i ; hw ; ti ) ,</definiens>
				<definiens id="1">a set of all bi-gram sequences observed in the lattice for x</definiens>
				<definiens id="2">the forward-backward costs given by the following recursive definitions : hw ; ti = X hw0 ; t0i2LT ( hw ; ti ) hw0 ; t0i exp X k kfk ( hw0 ; t0i ; hw ; ti ) hw ; ti = X hw0 ; t0i2RT ( hw ; ti ) hw0 ; t0i exp X k kfk ( hw ; ti ; hw0 ; t0i ) ; where LT ( hw ; ti ) and RT ( hw ; ti ) denote a set of tokens each of which connects to the token hw ; ti from the left and the right respectively</definiens>
			</definition>
			<definition id="6">
				<sentence>In Table 3 ( KC data set ) , the results of a variant of maximum entropy Markov models ( MEMMs ) ( Uchimoto et al. , 2001 ) and a rule-based analyzer ( JUMAN7 ) are also shown .</sentence>
				<definiendum id="0">KC</definiendum>
				<definiens id="0">data set ) , the results of a variant of maximum entropy Markov models ( MEMMs ) ( Uchimoto et al. , 2001 ) and a rule-based analyzer</definiens>
			</definition>
			<definition id="7">
				<sentence>Table 3 : Results of KC , ( F =1 ( precision/recall ) ) system seg top all L2-CRFs ( C=1:2 ) 98.96 ( 99.04/98.88 ) 98.31 ( 98.39/98.22 ) 96.75 ( 96.83/96.67 ) L1-CRFs ( C=3:0 ) 98.80 ( 98.84/98.77 ) 98.14 ( 98.18/98.11 ) 96.55 ( 96.58/96.51 ) MEMMs ( Uchimoto 01 ) 96.44 ( 95.78/97.10 ) 95.81 ( 95.15/96.47 ) 94.27 ( 93.62/94.92 ) JUMAN ( rule-based ) 98.70 ( 98.88/98.51 ) 98.09 ( 98.27/97.91 ) 93.73 ( 93.91/93.56 ) HMMs-bigram ( baseline ) 96.22 ( 96.16/96.28 ) 94.96 ( 94.90/95.02 ) 91.85 ( 91.79/91.90 ) Table 4 : Results of RWCP , ( F =1 ( precision/recall ) ) system seg top all L2-CRFs ( C=2:4 ) 99.11 ( 99.03/99.20 ) 98.73 ( 98.65/98.81 ) 97.66 ( 97.58/97.75 ) L1-CRFs ( C=3:0 ) 99.00 ( 98.86/99.13 ) 98.58 ( 98.44/98.72 ) 97.30 ( 97.16/97.43 ) E-HMMs ( Asahara 00 ) 98.87 ( 98.77/98.97 ) 98.33 ( 98.23/98.43 ) 96.95 ( 96.85/97.04 ) HMMs-bigram ( baseline ) 98.82 ( 98.69/98.94 ) 98.10 ( 97.97/98.22 ) 95.90 ( 95.78/96.03 ) a0sea a1particle a2a4a3a6a5bet a7a9a8a6a10a12a11romanticist a7a9a8a13a10romance a11particle The romance on the sea they bet is … a14a16a15rough waves a1particle a17 a3lose a18a20a19not a21heart a18a22a19 a21one’s heart A heart which beats rough waves is … MEMMs select MEMMs select Figure 3 : Errors with MEMMs ( Correct paths are marked with bold boxes . )</sentence>
				<definiendum id="0">JUMAN</definiendum>
				<definiendum id="1">97.16/97.43 ) E-HMMs</definiendum>
				<definiens id="0">Results of RWCP</definiens>
			</definition>
			<definition id="8">
				<sentence>L2-CRFs perform slightly better than L1-CRFs , which indicates that most of given features ( i.e. , overlapping features , POS hierarchies , suffixes/prefixes and character types ) are relevant to both of two datasets .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">hierarchies , suffixes/prefixes and character types</definiens>
			</definition>
</paper>

		<paper id="3103">
			<definition id="0">
				<sentence>Alternative representations were tried involving stemming and term weighting ( no weights versus TF*IDF weights ) .</sentence>
				<definiendum id="0">term weighting (</definiendum>
			</definition>
</paper>

		<paper id="1509">
</paper>

		<paper id="0849">
			<definition id="0">
				<sentence>Supervised systems for word-sense disambiguation ( WSD ) often rely upon word collocations ( i.e. , sense-specific keywords ) to provide clues on the most likely sense for a word given the context .</sentence>
				<definiendum id="0">word-sense disambiguation ( WSD</definiendum>
				<definiens id="0">word collocations ( i.e. , sense-specific keywords ) to provide clues on the most likely sense for a word given the context</definiens>
			</definition>
			<definition id="1">
				<sentence>WordColl ∗ represents a set of non-sensespecific collocations ( i.e. , not necessarily indicative of any one sense ) , chosen via the G 2 criteria ( Wiebe et al. , 1998 ) .</sentence>
				<definiendum id="0">WordColl ∗</definiendum>
			</definition>
</paper>

		<paper id="0413">
			<definition id="0">
				<sentence>Multiword expressions : a pain in the the neck for NLP .</sentence>
				<definiendum id="0">Multiword expressions</definiendum>
				<definiens id="0">a pain in the the neck for NLP</definiens>
			</definition>
</paper>

		<paper id="1221">
			<definition id="0">
				<sentence>B-DNA labels the first word of a DNA mention , I-DNA labels all subsequent words ( likewise for other entities ) , and O labels non-entities .</sentence>
				<definiendum id="0">I-DNA</definiendum>
				<definiens id="0">labels all subsequent words ( likewise for other entities</definiens>
			</definition>
			<definition id="1">
				<sentence>I prepared a total of 17 such lexicons , which include 7 that were entered by hand ( Greek letters , amino acids , chemical elements , known viruses , plus abbreviations of all these ) , and 4 corresponding to genes , chromosome locations , proteins , and cell lines , drawn from online public databases ( Cancer GeneticsWeb,2 BBID,3 SwissProt,4 and the Cell Line Database5 ) .</sentence>
				<definiendum id="0">Greek letters</definiendum>
			</definition>
			<definition id="2">
				<sentence>In a previous attempt to use a Hidden Markov Model to simultaneously recognize multiple biomedical entities ( Collier et al. , 2000 ) , HMM performance for a particular entity seemed more or less proportional to its frequency in the data .</sentence>
				<definiendum id="0">HMM performance</definiendum>
				<definiens id="0">use a Hidden Markov Model to simultaneously recognize multiple biomedical entities</definiens>
			</definition>
</paper>

		<paper id="0831">
			<definition id="0">
				<sentence>In their case , a41 is the position of the joining point .</sentence>
				<definiendum id="0">a41</definiendum>
				<definiens id="0">the position of the joining point</definiens>
			</definition>
</paper>

		<paper id="1406">
			<definition id="0">
				<sentence>The World Wide Web comprises a massive repository of documents and databases which translators can use for resolving terminology queries , and for identifying and verifying new term coinages and their foreign-language equivalents .</sentence>
				<definiendum id="0">World Wide Web</definiendum>
				<definiens id="0">comprises a massive repository of documents and databases which translators can use for resolving terminology queries</definiens>
			</definition>
			<definition id="1">
				<sentence>Electronic business developments : A final factor worthy of mention with regard to translators and Internet is the rise of electronic business in the past few years .</sentence>
				<definiendum id="0">Electronic business developments</definiendum>
				<definiendum id="1">Internet</definiendum>
				<definiens id="0">the rise of electronic business in the past few years</definiens>
			</definition>
			<definition id="2">
				<sentence>Communication tools : These tools include e-mail and messaging programs , file transfer applications , and online discussion groups .</sentence>
				<definiendum id="0">Communication tools</definiendum>
				<definiens id="0">file transfer applications , and online discussion groups</definiens>
			</definition>
			<definition id="3">
				<sentence>The resultant questionnaire was organised into the following sections : Translator profile : demographic data ; details of translator training and qualifications ; ICT knowledge and skills .</sentence>
				<definiendum id="0">Translator profile</definiendum>
				<definiens id="0">demographic data ; details of translator training and qualifications</definiens>
			</definition>
			<definition id="4">
				<sentence>Mean Median Mode Years established 13.95 12 4 Translated words/week 7284 6000 10000 Hours translating/week 25 25 40 Table II : Length of experience and productivity In addition to translation services , some of the translators in the sample offered other services such as linguistic consultancy ( 15 % of the sample ) , subtitling/dubbing ( 15 % ) , website localisation ( 14 % ) , or language training courses ( provided by 24 % of the respondents ) .</sentence>
				<definiendum id="0">Mean Median Mode</definiendum>
			</definition>
			<definition id="5">
				<sentence>They show some awareness of a range of other online terminology resources , online communication tools ( such as online discussion groups and online translation marketplaces ) , and a wide array of document facilities ( such as academic journals , archives , electronic databases , and electronic libraries ) , but do not demonstrate an awareness of online MT systems ( 81 translators ) .</sentence>
				<definiendum id="0">online communication tools</definiendum>
				<definiens id="0">such as academic journals , archives , electronic databases , and electronic libraries ) , but do not demonstrate an awareness of online MT systems ( 81 translators )</definiens>
			</definition>
</paper>

		<paper id="0210">
			<definition id="0">
				<sentence>These results , and the annotated corpus , were used in the development of both symbolic and statistical natural language generation algorithms for sentence planning ( Poesio , 2000a ; Henschel et al. , 2000 ; Cheng et al. , 2001 ) , aggregation ( Cheng , 2001 ) and text planning ( Karamanis , 2003 ) .</sentence>
				<definiendum id="0">, aggregation</definiendum>
				<definiens id="0">used in the development of both symbolic and statistical natural language generation algorithms for sentence planning ( Poesio , 2000a ; Henschel et al. , 2000 ; Cheng et al. , 2001 )</definiens>
			</definition>
			<definition id="1">
				<sentence>The museum subcorpus consists of descriptions of museum objects and brief texts about the artists that produced them.1 The pharmaceutical subcorpus is a selection of leaflets providing the patients with legally mandatory information about their medicine.2 The GNOME corpus also includes tutorial dialogues from the Sherlock corpus collected at the University of Pittsburgh .</sentence>
				<definiendum id="0">museum subcorpus</definiendum>
			</definition>
			<definition id="2">
				<sentence>In order to do this , we marked all spans of text that might be claimed to update the local focus , including sentences ( defined as all units of text ending with a full stop , a question mark , or an exclamation point ) as well as what we called ( DISCOURSE ) UNITS .</sentence>
				<definiendum id="0">DISCOURSE</definiendum>
				<definiens id="0">all units of text ending with a full stop , a question mark</definiens>
			</definition>
			<definition id="3">
				<sentence>In the GNOME corpus , anaphoric information is marked by means of a special 〈ante〉 element ; the 〈ante〉 element itself specifies the index of the anaphoric expression ( a 〈ne〉 element ) and the type of semantic relation ( e.g. , identity ) , whereas one or more embedded 〈anchor〉 elements indicate possible antecedents.6 ( See ( 8 ) . )</sentence>
				<definiendum id="0">GNOME corpus</definiendum>
				<definiens id="0">anaphoric information is marked by means of a special 〈ante〉 element ; the 〈ante〉 element itself specifies the index of the anaphoric expression ( a 〈ne〉 element</definiens>
			</definition>
			<definition id="4">
				<sentence>Besides identity ( IDENT ) we only marked up three associative relations ( Hawkins , 1978 ) : set membership ( ELEMENT ) , subset ( SUBSET ) , and ‘generalized possession’ ( POSS ) , which includes partof relations as well as ownership relations .</sentence>
				<definiendum id="0">SUBSET</definiendum>
				<definiendum id="1">POSS</definiendum>
				<definiens id="0">includes partof relations as well as ownership relations</definiens>
			</definition>
</paper>

		<paper id="2115">
			<definition id="0">
				<sentence>We will concentrate on multiword expressions ( MWE ) , particularly on multiword nouns , ( i ) illustrating their most relevant morphological features , and ( ii ) pointing out the methods and techniques adopted to generate the inflected forms from lemmas .</sentence>
				<definiendum id="0">MWE</definiendum>
			</definition>
			<definition id="1">
				<sentence>MWEs have been viewed , for long time , as marginal idiosyncratic combinations of words .</sentence>
				<definiendum id="0">MWEs</definiendum>
				<definiens id="0">marginal idiosyncratic combinations of words</definiens>
			</definition>
			<definition id="2">
				<sentence>Special attention will be given to their formalization and generation , using INTEX , a public FST ( Finite-State Transducer ) based NLP system [ Silberztein , 1993 ] .</sentence>
				<definiendum id="0">INTEX</definiendum>
			</definition>
</paper>

		<paper id="3001">
</paper>

		<paper id="3243">
			<definition id="0">
				<sentence>The question that significance tests for association , such as X 2 , G 2 , and Fisher’s exact test , are designed to answer is , given the sample size and the marginal frequencies of the two items in question , what is the probability ( or p-value ) of seeing by chance as many or more joint occurrences as were observed ?</sentence>
				<definiendum id="0">Fisher’s exact test</definiendum>
				<definiens id="0">designed to answer is , given the sample size and the marginal frequencies of the two items in question</definiens>
				<definiens id="1">the probability ( or p-value ) of seeing by chance as many or more joint occurrences as were observed</definiens>
			</definition>
			<definition id="1">
				<sentence>For each combination , compute the association score for each possible joint count ( given the marginals and the sample size ) , starting from the smallest one greater than the expected joint count C ( x ) C ( y ) /N ( where C ( x ) and C ( y ) are the marginals and N is the sample size ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">compute the association score for each possible joint count ( given the marginals and the sample size ) , starting from the smallest one greater than the expected joint count C ( x ) C ( y ) /N ( where C ( x ) and C ( y ) are the marginals and</definiens>
				<definiens id="1">the sample size )</definiens>
			</definition>
			<definition id="2">
				<sentence>Our estimate of the number of pairs seen by chance for a particular value of the association measure is based on considering all possible pairs as nonassociated , which is a valid approximation only if the number 2log bracketleftBigg p ( y|x ) C ( x , y ) · p ( y|¬x ) C ( ¬x , y ) · p ( ¬y|x ) C ( x , ¬y ) · p ( ¬y|¬x ) C ( ¬x , ¬y ) p ( y ) C ( y ) · p ( ¬y ) C ( ¬y ) bracketrightBigg ( 1 ) 2log bracketleftBigg p ( y|x ) C ( x , y ) · p ( y|¬x ) C ( ¬x , y ) · p ( ¬y|x ) C ( x , ¬y ) · p ( ¬y|¬x ) C ( ¬x , ¬y ) p ( y ) C ( x , y ) · p ( y ) C ( ¬x , y ) · p ( ¬y ) C ( x , ¬y ) · p ( ¬y ) C ( ¬x , ¬y ) bracketrightBigg ( 2 ) 2log productdisplay x ?</sentence>
				<definiendum id="0">bracketleftBigg p</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">¬y|¬x ) C ( ¬x , ¬y ) p ( y ) C ( x , y ) · p ( y )</definiens>
			</definition>
			<definition id="3">
				<sentence>C ( y ) and C ( ¬y ) are the observed frequencies of y occurring or not occurring in the corpus ; C ( x , y ) , ... , C ( ¬x , ¬y ) are the joint frequencies of the different possible combinations of x and y occuring and not occuring ; and p ( y ) , p ( ¬y ) , p ( y|x ) , ... , p ( ¬y|¬x ) are the maximum likelihood estimates of the corresponding marginal and conditional probabilities .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">the observed frequencies of y occurring or not occurring in the corpus ; C ( x , y ) , ... , C ( ¬x , ¬y ) are the joint frequencies of the different possible combinations of x and y occuring and not occuring</definiens>
			</definition>
			<definition id="4">
				<sentence>The denominator is an estimate of the probability of the same sequence , based only on the marginal probability of y. Hence the denominator is simply the product of the probabilty of y occuring , to the power of the number of times y occurs , and the probabilty of y not occuring , to the power of the number of times y fails to occur .</sentence>
				<definiendum id="0">denominator</definiendum>
				<definiens id="0">an estimate of the probability of the same sequence</definiens>
			</definition>
			<definition id="5">
				<sentence>( where N is the sample size ) , and p ( y ?</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the sample size</definiens>
			</definition>
			<definition id="6">
				<sentence>The only reference to it we have been able to find in the statistical NLP “literature” is a comment in Pederson’s publically distributed Perl module for computing mutual information ( http : //search.cpan.org/src/TPEDERSE/Text-NSP-0.69/ Measures/tmi .</sentence>
				<definiendum id="0">NLP “literature”</definiendum>
				<definiens id="0">a comment in Pederson’s publically distributed Perl module for computing mutual information ( http : //search.cpan.org/src/TPEDERSE/Text-NSP-0.69/ Measures/tmi</definiens>
			</definition>
</paper>

		<paper id="0507">
			<definition id="0">
				<sentence>To achieve the high accuracy , the QA system processes the semi-structured text data on the Internet and store it in the form of relational database .</sentence>
				<definiendum id="0">QA system</definiendum>
				<definiens id="0">processes the semi-structured text data on the Internet and store it in the form of relational database</definiens>
			</definition>
			<definition id="1">
				<sentence>The QA system consists of two major parts ; the IE ( Information Extractor ) engine and the QA engine .</sentence>
				<definiendum id="0">QA system</definiendum>
			</definition>
			<definition id="2">
				<sentence>A speech processor can be merged with the system when it is used in the home agent robot , which provides speech interface .</sentence>
				<definiendum id="0">speech processor</definiendum>
				<definiens id="0">the system when it is used in the home agent robot , which provides speech interface</definiens>
			</definition>
			<definition id="3">
				<sentence>The ontology for the weather events consists of event concepts , which are similar to Synset in WORDNET ( Fellbaum , 1998 ) .</sentence>
				<definiendum id="0">ontology for the weather events</definiendum>
			</definition>
			<definition id="4">
				<sentence>EVENT : rain DATE : 03/12/04 TIME : 02:20 CITY : Seoul Even though the time , date , and city is not explicitly mentioned in the question , the question analyzer infers the information with the user profile and the inference rules .</sentence>
				<definiendum id="0">question analyzer</definiendum>
				<definiens id="0">infers the information with the user profile and the inference rules</definiens>
			</definition>
			<definition id="5">
				<sentence>The START system ( Katz , 1997 ) is a web-based QA system .</sentence>
				<definiendum id="0">START system</definiendum>
			</definition>
			<definition id="6">
				<sentence>The Jupiter system ( Zue et al. , 2000 ) is a conversational system that provides weather information over the phone .</sentence>
				<definiendum id="0">Jupiter system</definiendum>
				<definiens id="0">a conversational system that provides weather information over the phone</definiens>
			</definition>
			<definition id="7">
				<sentence>We will separate domain dependent resources ( query frames , ontology containing domain-dependent information , and etc. ) and domain independent resources ( linguistic resources , and ontology for domain-independent information ) to allow easier domain expansion .</sentence>
				<definiendum id="0">query</definiendum>
				<definiens id="0">frames , ontology containing domain-dependent information</definiens>
			</definition>
</paper>

		<paper id="2101">
			<definition id="0">
				<sentence>Kanji dictionaries , which need to present a large number of complex characters in an order that makes them accessible by users , traditionally use several indexing techniques that are particularly suited to the printed medium .</sentence>
				<definiendum id="0">Kanji dictionaries</definiendum>
				<definiens id="0">need to present a large number of complex characters in an order that makes them accessible by users</definiens>
			</definition>
			<definition id="1">
				<sentence>One , which was popular in China , is the Four-Corner code , which allocates a number ( 0-9 ) to the pattern of strokes at each corner of the character , leading to a four-digit index .</sentence>
				<definiendum id="0">Four-Corner code</definiendum>
				<definiens id="0">allocates a number ( 0-9 ) to the pattern of strokes at each corner of the character , leading to a four-digit index</definiens>
			</definition>
			<definition id="2">
				<sentence>( The original Nelson uses a slightly modified version of the traditional radical index , and the Spahn &amp; Hadamitzky Kanji Dictionary uses a simplified 79-radical system .</sentence>
				<definiendum id="0">Nelson</definiendum>
				<definiens id="0">uses a slightly modified version of the traditional radical index , and the Spahn &amp; Hadamitzky Kanji Dictionary uses a simplified 79-radical system</definiens>
			</definition>
			<definition id="3">
				<sentence>The compilation of the KANJIDIC database ( Breen 2004 ) , which contains the English meanings for over 12,000 kanji , has enabled this technique to be employed .</sentence>
				<definiendum id="0">KANJIDIC database</definiendum>
				<definiens id="0">contains the English meanings for over 12,000 kanji , has enabled this technique to be employed</definiens>
			</definition>
</paper>

		<paper id="0840">
			<definition id="0">
				<sentence>A Logic Form is a collection of predicate instances derived from text .</sentence>
				<definiendum id="0">Logic Form</definiendum>
				<definiens id="0">a collection of predicate instances derived from text</definiens>
			</definition>
			<definition id="1">
				<sentence>A Logic Prover ( Rus , 2002 ; Moldovan et al. , 2003 ) utilizing the axioms generated by the Logic Form generation system boosts the performance of the Question Answering system .</sentence>
				<definiendum id="0">Logic Prover</definiendum>
				<definiens id="0">utilizing the axioms generated by the Logic Form generation system boosts the performance of the Question Answering system</definiens>
			</definition>
			<definition id="2">
				<sentence>This is a rule that says how a particular parse tree structure must be handled , for instance , 'S - &gt; NP VP ' says that the subject of the main/action verb of VP is the head of phrase of NP .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">a rule that says how a particular parse tree structure must be handled , for instance , 'S - &gt; NP VP ' says that the subject of the main/action verb of</definiens>
				<definiens id="1">the head of phrase of NP</definiens>
			</definition>
</paper>

		<paper id="0206">
			<definition id="0">
				<sentence>Information Structure ( IS ) concerns utterance-internal structural and semantic properties reflecting the speaker’s/writer’s communicative intentions and the relation of the utterance to the discourse context , in terms of the discourse status of the content , the actual and attributed attentional states of the discourse participants , and the participants’ prior and changing attitudes ( knowledge , beliefs , intentions , expectations , etc. ) ( Kruijﬀ-Korbayov´a and Steedman , 2003 ) .</sentence>
				<definiendum id="0">Information Structure</definiendum>
				<definiens id="0">IS ) concerns utterance-internal structural and semantic properties reflecting the speaker’s/writer’s communicative intentions and the relation of the utterance to the discourse context , in terms of the discourse status of the content , the actual and attributed attentional states of the discourse participants , and the participants’ prior and changing attitudes ( knowledge , beliefs , intentions , expectations</definiens>
			</definition>
			<definition id="1">
				<sentence>The MULI corpus consists of extracts from the Tiger treebank for German ( Brants et al. , to appear ) 1 and the Penn treebank for English ( Marcus et al. , 1994 ) 2 .</sentence>
				<definiendum id="0">MULI corpus</definiendum>
				<definiens id="0">consists of extracts from the Tiger treebank for German ( Brants et al. , to appear ) 1 and the Penn treebank for English</definiens>
			</definition>
			<definition id="2">
				<sentence>Objects are further classified according to semantic sorts : human/person , office/profession , organization , animal , plant , physical object , quantity/amount , date/time , location/place , group/collection , abstract entity , other .</sentence>
				<definiendum id="0">Objects</definiendum>
			</definition>
			<definition id="3">
				<sentence>Familiarity Status is a notion that most approaches to IS use as one dimension or level of the IS-partitioning , for example Given/New in ( Halliday , 1985 ) , Background/Focus in ( Steedman , 2000 ) , or as the basis for deriving a higher level of partitioning ( Sgall et al. , 1986 ) .</sentence>
				<definiendum id="0">Familiarity Status</definiendum>
				<definiendum id="1">level</definiendum>
				<definiens id="0">a notion that most approaches to IS use as one dimension or</definiens>
			</definition>
			<definition id="4">
				<sentence>Referential link encodes the type of relation between the discourse entity corresponding to an anaphoric expression , and the one corresponding to the ( most likely ) antecedent .</sentence>
				<definiendum id="0">Referential link</definiendum>
				<definiens id="0">encodes the type of relation between the discourse entity corresponding to an anaphoric expression</definiens>
			</definition>
			<definition id="5">
				<sentence>The discourse entity ( DE ) introduced in the fronted temporal phrase the 1987 crash in ( 1 ) is extensional , abstract , unique , specific singular , and has the information status of unused ( also indicated by remember ) .</sentence>
				<definiendum id="0">discourse entity</definiendum>
				<definiendum id="1">DE )</definiendum>
				<definiens id="0">introduced in the fronted temporal phrase the 1987 crash in ( 1 ) is extensional , abstract , unique , specific singular</definiens>
			</definition>
			<definition id="6">
				<sentence>Furthermore , the adjective construction forms a phrase of its own , delimited by an intonation phrase boundary , which is in turn signalled by a falling-rising contour plus a short pause .</sentence>
				<definiendum id="0">adjective construction</definiendum>
				<definiens id="0">forms a phrase of its own , delimited by an intonation phrase boundary , which is in turn signalled by a falling-rising contour plus a short pause</definiens>
			</definition>
			<definition id="7">
				<sentence>MMAX implements the above-mentioned general concepts of markables with attributes and standing in link relations to one another .</sentence>
				<definiendum id="0">MMAX</definiendum>
				<definiens id="0">implements the above-mentioned general concepts of markables with attributes</definiens>
			</definition>
			<definition id="8">
				<sentence>The MULI corpus facilitates linguistic investigation of how phenomena at diﬀerent annotation levels interact .</sentence>
				<definiendum id="0">MULI corpus</definiendum>
				<definiens id="0">facilitates linguistic investigation of how phenomena at diﬀerent annotation levels interact</definiens>
			</definition>
			<definition id="9">
				<sentence>Another possibility to explore is the to integrate MULI annotation with , e.g. , the SALSA corpus ( Erk et al. , 2003 ) , which provides more detailed semantico-pragmatic information in the style of FrameNet .</sentence>
				<definiendum id="0">SALSA corpus</definiendum>
				<definiens id="0">provides more detailed semantico-pragmatic information in the style of FrameNet</definiens>
			</definition>
</paper>

		<paper id="3104">
			<definition id="0">
				<sentence>Learning a decision list classifier consists of generating and ordering individual tests based on the characteristics of the training data .</sentence>
				<definiendum id="0">Learning a decision list classifier</definiendum>
				<definiens id="0">consists of generating and ordering individual tests based on the characteristics of the training data</definiens>
			</definition>
			<definition id="1">
				<sentence>For a binary classification task with classes { +1 , –1 } , given a training set with n class-labeled instances , ( x1 , y1 ) , ( x2 , y2 ) , ... , ( xi , yi ) , … , ( xn , yn ) , where xi is a feature vector for the ith instance and yi indicates the class , an SVM classifier learns a linear decision rule , which is represented using a hyperplane .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiendum id="1">SVM classifier</definiendum>
				<definiens id="0">a feature vector for the ith instance</definiens>
				<definiens id="1">learns a linear decision rule</definiens>
			</definition>
			<definition id="2">
				<sentence>For each combination of machine learning algorithm and feature representation , we computed the performance using the F-measure , which is defined as 2*P*R/ ( P+R ) , where P is the precision ( the number of citations predicted correctly to the total number of citations being predicted ) and R is the recall ( the number of citations predicted correctly to the total number of citations ) .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiendum id="1">P</definiendum>
				<definiendum id="2">R</definiendum>
				<definiens id="0">the precision ( the number of citations predicted correctly to the total number of citations being predicted ) and</definiens>
			</definition>
</paper>

		<paper id="2009">
			<definition id="0">
				<sentence>First the language learner calls the semantic chunker with the current grammar and utterance .</sentence>
				<definiendum id="0">language learner</definiendum>
				<definiens id="0">calls the semantic chunker with the current grammar and utterance</definiens>
			</definition>
			<definition id="1">
				<sentence>Construction Grammar defines grammaticality as a combination of syntactic and semantic well-formedness .</sentence>
				<definiendum id="0">Construction Grammar</definiendum>
				<definiens id="0">defines grammaticality as a combination of syntactic and semantic well-formedness</definiens>
			</definition>
			<definition id="2">
				<sentence>To describe constructions precisely , Embodied Construction Grammar ( ECG ) combines a grammar formalism and knowledge representation language within a unification-based framework .</sentence>
				<definiendum id="0">ECG )</definiendum>
				<definiens id="0">combines a grammar formalism and knowledge representation language within a unification-based framework</definiens>
			</definition>
			<definition id="3">
				<sentence>The Throw-Action schema evokes the Cause-MotionFrame and their roles are coindexed .</sentence>
				<definiendum id="0">Throw-Action schema</definiendum>
				<definiens id="0">evokes the Cause-MotionFrame and their roles are coindexed</definiens>
			</definition>
			<definition id="4">
				<sentence>The SPG schema is a structured representation of a path with a source ( starting point ) , path ( way traveled ) and goal ( end point ) .</sentence>
				<definiendum id="0">SPG schema</definiendum>
				<definiens id="0">a structured representation of a path with a source ( starting point ) , path</definiens>
			</definition>
			<definition id="5">
				<sentence>Chunkers ( partial parsers ) ( Abney , 1996 ) use finitestate-machines ( FSM ) arranged into levels , to reliably recognize nonrecursive chunks of syntax .</sentence>
				<definiendum id="0">Chunkers</definiendum>
				<definiens id="0">partial parsers ) ( Abney , 1996 ) use finitestate-machines ( FSM ) arranged into levels , to reliably recognize nonrecursive chunks of syntax</definiens>
			</definition>
</paper>

		<paper id="2118">
</paper>

		<paper id="2005">
			<definition id="0">
				<sentence>GETARUNS is a symbolic linguistically-based parser written in Prolog Horn clauses which uses a strong deterministic policy by means of a lookahead mechanism and a WFST .</sentence>
				<definiendum id="0">GETARUNS</definiendum>
				<definiens id="0">a symbolic linguistically-based parser written in Prolog Horn clauses which uses a strong deterministic policy by means of a lookahead mechanism and a WFST</definiens>
			</definition>
			<definition id="1">
				<sentence>Greval is a benchmark for parser evaluation based on Grammatical Relations in a Head Dependency Structure style output , i.e. a word based HeadDependent flat representation enriched with Grammatical Relation information , where each relation is represented as follows , Relation ( introducer , head , dependent ) Relation ( introducer , head , dependent , deep-relation ) where a deep relation is introduced basically for passive constructions , dative shift , and potentially other structures , according to the “Movement” approach invoked by chomskians .</sentence>
				<definiendum id="0">Greval</definiendum>
				<definiens id="0">a benchmark for parser evaluation based on Grammatical Relations in a Head Dependency Structure style output</definiens>
			</definition>
			<definition id="2">
				<sentence>When collecting the IOBJs of the corpus we soon discovered that 9 IOBJS constitute cases of non verbal complementation which we report below , ( iobj to akin future ) ; ; ; non-verbal complementation ( iobj to adherence principle ) ( iobj to applicability people ) ( iobj of independent pressure ) ( iobj of independent volume ) ( iobj notorious for disregard ) ( iobj to atune Whig ) ( iobj to key acceptance ) ( iobj on ruin country ) then , there is one dubious case of IOBJ : in sentence 316 the ellipsed governing adjective predicate “atune” is done away with and the IOBJ relation is assigned to the verb BE , ( 3 ) Indeed , the old Jeffersonians were far more atune to the Hamilton oriented Whigs than they were to the Jacksonian Democrats .</sentence>
				<definiendum id="0">non-verbal complementation</definiendum>
				<definiens id="0">iobj of independent pressure ) ( iobj of independent volume ) ( iobj notorious for disregard ) ( iobj to atune Whig ) ( iobj to key acceptance ) ( iobj on ruin country</definiens>
			</definition>
			<definition id="3">
				<sentence>We then individuated a number of mismatches in the Gold annotation which would not receive a suitable mapping in our output , which were then interpreted as mistakes by Ted Briscoe ( p.c. ) in particular cases of secondary predication for the class of ECM verbs ( consider , believe , term , etc ) which were treated as OBJ2 , as well as the relation of DOBJ associated to complements of verb HAVE , which we compute as copulative verb .</sentence>
				<definiendum id="0">etc</definiendum>
				<definiens id="0">were then interpreted as mistakes by Ted Briscoe ( p.c. ) in particular cases of secondary predication for the class of ECM verbs ( consider , believe , term</definiens>
			</definition>
			<definition id="4">
				<sentence>For instance , English is a language that freely allows compless ( complementizer-less ) complement and relative clauses .</sentence>
				<definiendum id="0">English</definiendum>
				<definiens id="0">a language that freely allows compless ( complementizer-less ) complement and relative clauses</definiens>
			</definition>
			<definition id="5">
				<sentence>Interpretation procedures follows by recovering subcategorization frames for the main tensed verb and assignment of grammatical function and semantic roles takes place .</sentence>
				<definiendum id="0">Interpretation procedures</definiendum>
				<definiens id="0">the main tensed verb and assignment of grammatical function and semantic roles takes place</definiens>
			</definition>
</paper>

		<paper id="0205">
</paper>

		<paper id="1705">
			<definition id="0">
				<sentence>Our test bed , in a first instance , is a set of ontologies such the AKT reference ontology ( describing academic life ) , Newspaper and a Koala ontology ( concerning koalas’ habitat ) .</sentence>
				<definiendum id="0">Koala ontology</definiendum>
				<definiens id="0">a set of ontologies such the AKT reference ontology ( describing academic life</definiens>
			</definition>
			<definition id="1">
				<sentence>The ontological space acts as a mediated schema , a set of virtual relations among knowledge entities related by their degree of similarity .</sentence>
				<definiendum id="0">ontological space</definiendum>
				<definiens id="0">a mediated schema , a set of virtual relations among knowledge entities related by their degree of similarity</definiens>
			</definition>
			<definition id="2">
				<sentence>Page ( Page , 1968 ) makes a useful distinction between marking for syntax ( i.e. linguistic style ) and for content ( subject matter ) which we will use in our outline .</sentence>
				<definiendum id="0">Page</definiendum>
				<definiens id="0">makes a useful distinction between marking for syntax ( i.e. linguistic style ) and for content ( subject matter</definiens>
			</definition>
			<definition id="3">
				<sentence>Dimension reduction methods ( such as LSA ) , when applied to the semantic vector space model , improve information retrieval , information filtering and word sense disambiguation .</sentence>
				<definiendum id="0">Dimension reduction methods</definiendum>
				<definiens id="0">such as LSA ) , when applied to the semantic vector space model , improve information retrieval , information filtering and word sense disambiguation</definiens>
			</definition>
			<definition id="4">
				<sentence>The cosine of the angle between two vectors is defined as the inner product between the vectors v and w divided by the product of the length of the two vectors .</sentence>
				<definiendum id="0">cosine of the angle between two vectors</definiendum>
				<definiens id="0">the inner product between the vectors v and w divided by the product of the length of the two vectors</definiens>
			</definition>
			<definition id="5">
				<sentence>Argument ( student ) Argument ( animal ) Argument ( newspaper ) Classes -0.0001 0.0000 -0.0042 Salesperson ( NO ) -0.0013 0.5563 -0.0084 Parent ( KO ) -0.0006 0.4374 -0.0085 Koala ( KO ) -0.0001 0.0000 0.8112 Newspaper ( NO ) Table 2 – Semantic similarity between arguments and classes belonging to different ontologies For the query containing the term “newspaper” the results shows that the most similar classes are “Newspaper” from APO , “Newspaper” from NO and “Standard Advertising” also from NO .</sentence>
				<definiendum id="0">Argument</definiendum>
				<definiens id="0">Semantic similarity between arguments and classes belonging to different ontologies For the query containing the</definiens>
			</definition>
</paper>

		<paper id="0308">
			<definition id="0">
				<sentence>Deterministic dependency parsing is a robust and efficient approach to syntactic parsing of unrestricted natural language text .</sentence>
				<definiendum id="0">Deterministic dependency parsing</definiendum>
			</definition>
			<definition id="1">
				<sentence>However , with the new algorithm we can also parse structure ( 1 ) incrementally , as Initialization 〈nil , W , ∅〉 Termination 〈S , nil , A〉 Left-Arc 〈wi|S , wj|I , A〉 → 〈S , wj|I , A∪ { ( wj , wi ) } 〉 ¬∃wk ( wk , wi ) ∈ A Right-Arc 〈wi|S , wj|I , A〉 → 〈wj|wi|S , I , A∪ { ( wi , wj ) } 〉 ¬∃wk ( wk , wj ) ∈ A Reduce 〈wi|S , I , A〉 → 〈S , I , A〉 ∃wj ( wj , wi ) ∈ A Shift 〈S , wi|I , A〉 → 〈wi|S , I , A〉 Figure 5 : Left-to-right arc-eager dependency parsing is shown by the following transition sequence : 〈nil , abc , ∅〉 ↓ ( Shift ) 〈a , bc , ∅〉 ↓ ( Right-Arc ) 〈ba , c , { ( a , b ) } 〉 ↓ ( Right-Arc ) 〈cba , nil , { ( a , b ) , ( b , c ) } 〉 We conclude that the arc-eager algorithm is optimal with respect to incrementality in dependency parsing , even though it still holds true that the structures ( 6–7 ) in Figure 4 can not be parsed incrementally .</sentence>
				<definiendum id="0">Reduce 〈wi|S</definiendum>
				<definiendum id="1">A〉 ∃wj</definiendum>
				<definiendum id="2">Shift 〈S</definiendum>
				<definiens id="0">Left-to-right arc-eager dependency parsing is shown by the following transition sequence : 〈nil , abc , ∅〉 ↓ ( Shift ) 〈a , bc</definiens>
			</definition>
</paper>

		<paper id="1108">
			<definition id="0">
				<sentence>Word sense disambiguation ( WSD ) is a method to determine the sense of ambiguous word given the context circumstance .</sentence>
				<definiendum id="0">Word sense disambiguation ( WSD</definiendum>
				<definiens id="0">a method to determine the sense of ambiguous word given the context circumstance</definiens>
			</definition>
			<definition id="1">
				<sentence>Fig1.1 is a construction chart of triple-layer BP neural network .</sentence>
				<definiendum id="0">Fig1.1</definiendum>
				<definiens id="0">a construction chart of triple-layer BP neural network</definiens>
			</definition>
			<definition id="2">
				<sentence>WSD depends on the context to judge the meaning of ambiguous words .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">depends on the context to judge the meaning of ambiguous words</definiens>
			</definition>
			<definition id="3">
				<sentence>Pseudoword is the artificial combination of several real words on the basis of experimental demand to form an unreal word that possesses many features of real words and instead of real word as the experimental object in natural language research .</sentence>
				<definiendum id="0">Pseudoword</definiendum>
				<definiens id="0">the artificial combination of several real words on the basis of experimental demand to form an unreal word that possesses many features of real words</definiens>
			</definition>
			<definition id="4">
				<sentence>But the meaning of pseudoword ( Schütze , 1992 ) need not defined with the aid of dictionary and simulates the real ambiguous word to survey the effect of various algorithms of classified meanings .</sentence>
				<definiendum id="0">meaning of pseudoword</definiendum>
				<definiens id="0">the aid of dictionary and simulates the real ambiguous word to survey the effect of various algorithms of classified meanings</definiens>
			</definition>
			<definition id="5">
				<sentence>The close test means the corpus are same in test and training .</sentence>
				<definiendum id="0">close test</definiendum>
				<definiens id="0">means the corpus are same in test and training</definiens>
			</definition>
</paper>

		<paper id="2301">
			<definition id="0">
				<sentence>In these applications , which we collectively categorize as involving RVHT , the PC simulates a person’s behavior in response to user input .</sentence>
				<definiendum id="0">PC</definiendum>
				<definiens id="0">simulates a person’s behavior in response to user input</definiens>
			</definition>
			<definition id="1">
				<sentence>The Behavior Engine maps Language Processor output and other environmental stimuli to virtual human behaviors .</sentence>
				<definiendum id="0">Behavior Engine</definiendum>
				<definiens id="0">maps Language Processor output and other environmental stimuli to virtual human behaviors</definiens>
			</definition>
			<definition id="2">
				<sentence>Our use of virtual pediatric patients follows models of experiential learning , where abstract conceptualization leads to active engagement and experimentation , which leads to concrete experience , which leads to reflective observation , which leads back to the beginning of the cycle [ 15,21 ] .</sentence>
				<definiendum id="0">experimentation</definiendum>
			</definition>
			<definition id="3">
				<sentence>Interviewers begin with an introduction and then need to respond to a series of objections or questions raised by the virtual respondent .</sentence>
				<definiendum id="0">Interviewers</definiendum>
				<definiens id="0">begin with an introduction and then need to respond to a series of objections or questions raised by the virtual respondent</definiens>
			</definition>
			<definition id="4">
				<sentence>Enjoyment and Reuse : An effective training tool is also one that trainees should enjoy using , would use again , and recommend to others .</sentence>
				<definiendum id="0">Reuse</definiendum>
				<definiens id="0">An effective training tool is also one that trainees should enjoy using</definiens>
			</definition>
</paper>

		<paper id="0913">
			<definition id="0">
				<sentence>GETARUNS , has a highly sophisticated linguistically based semantic module which is used to build up the Discourse Model .</sentence>
				<definiendum id="0">GETARUNS</definiendum>
				<definiens id="0">has a highly sophisticated linguistically based semantic module which is used to build up the Discourse Model</definiens>
			</definition>
			<definition id="1">
				<sentence>An example will be reported below and discussed in details ; D. each wff is an expression of logical form which is made up of a predicate and a number of arguments , `` p ( arg 1 , ... , arg n ) , where 'p ' is a constant and 'arg ' may be a complex term .</sentence>
				<definiendum id="0">'p '</definiendum>
				<definiens id="0">an expression of logical form which is made up of a predicate and a number of arguments , `` p ( arg 1 , ... , arg n</definiens>
			</definition>
			<definition id="2">
				<sentence>A term is made up of a quantifier , a variable and a restriction , `` term ( quant , var , restr ) '' where the quantifier may be a real natural language quantifier existing in a NP or a time operator like `` time '' ; the variable is a syntactic index assigned to the phrase in the fstructure representation by the parser ; the restriction is the structure on which the quantifier/operator takes scope which might coincide with the phrase or clause of f-structure representation or may be a logical expression built for that aim at logical form level , as happens for time formulas .</sentence>
				<definiendum id="0">variable</definiendum>
				<definiens id="0">a syntactic index assigned to the phrase in the fstructure representation by the parser</definiens>
			</definition>
			<definition id="3">
				<sentence>Fig.2 GETARUNS’ Discourse Level Modules In Situation Semantics where reality is represented in Situations which are collections of Facts : in turn facts are made up of Infons which information units characterised as follows : Infon ( Index , Relation ( Property ) , List of Arguments with Semantic Roles , Polarity 1 affirmative , 0 negation , Temporal Location Index , Spatial Location Index ) In addition Arguments have each a semantic identifier which is unique in the Discourse Model and is used to individuate the entity uniquely .</sentence>
				<definiendum id="0">reality</definiendum>
				<definiendum id="1">addition Arguments</definiendum>
				<definiens id="0">a semantic identifier which is unique in the Discourse Model and is used to individuate the entity uniquely</definiens>
			</definition>
			<definition id="4">
				<sentence>On second occurrence of the same nominal head the semantic index is recovered from the history list and the system checks whether it is the same referring expression : in case it is definite or indefinite with a predicative role and no attributes nor modifiers nothing is done ; in case it has different number singular and the one present in the DM is a set or a class nothing happens ; in case it has attributes and modifiers which are different and the one present in the DM has none , nothing happens ; in case it is quantified expression and has no cardinality , and the one present in the DM is a set or a class , again nothing happens .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiens id="0">a set or a class nothing happens</definiens>
				<definiens id="1">a set or a class</definiens>
			</definition>
			<definition id="5">
				<sentence>Natural language support gives users a whole new way of interacting with any information system , and from a knowledge engineering point of view , natural language technology divorces the majority of users from the need to understand formal ontologies .</sentence>
				<definiendum id="0">Natural language support</definiendum>
				<definiens id="0">gives users a whole new way of interacting with any information system</definiens>
			</definition>
</paper>

		<paper id="0505">
			<definition id="0">
				<sentence>If a biography is not found , BioGrapher attempts to find an answer on the web : it retrieves documents using a web search engine , filters these using the biography classifier , and then extracts answers from documents classified as biographies .</sentence>
				<definiendum id="0">BioGrapher</definiendum>
				<definiens id="0">attempts to find an answer on the web : it retrieves documents using a web search engine , filters these using the biography classifier , and then extracts answers from documents classified as biographies</definiens>
			</definition>
			<definition id="1">
				<sentence>Although most current research in question answering ( QA ) is oriented towards open domains , as witnessed by evaluation exercises such as TREC , CLEF , and NTCIR , various significant applications concern restricted domains , e.g. , software manuals .</sentence>
				<definiendum id="0">question answering</definiendum>
				<definiendum id="1">NTCIR</definiendum>
				<definiens id="0">various significant applications concern restricted domains , e.g. , software manuals</definiens>
			</definition>
			<definition id="2">
				<sentence>Document and Text Representation Text classifiers represent a document as a set of features d = { f1 , f2 , . . . , fn } where n is the number of active features , that is , features that occur in the document .</sentence>
				<definiendum id="0">Text Representation Text classifiers</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of active features , that is , features that occur in the document</definiens>
			</definition>
			<definition id="3">
				<sentence>The naive classifier consists of two main stages : ( 1 ) Rules building .</sentence>
				<definiendum id="0">naive classifier</definiendum>
			</definition>
			<definition id="4">
				<sentence>Instead of Ripper’s rule pruning stage , our algorithm assigns a weight to each rule/n-gram r in the rules vector according to the formula g ( n ) ·f ( r ) C , where g ( n ) is an increasing function in the length of the n-gram ( longer ngrams receive higher weights ) , f ( r ) is the ratio of the frequency of r in the positive examples to its frequency in the negative examples , and C is the size of the training set .</sentence>
				<definiendum id="0">g</definiendum>
				<definiendum id="1">f ( r )</definiendum>
				<definiendum id="2">C</definiendum>
				<definiens id="0">assigns a weight to each rule/n-gram r in the rules vector according to the formula g ( n ) ·f ( r</definiens>
				<definiens id="1">an increasing function in the length of the n-gram ( longer ngrams receive higher weights</definiens>
				<definiens id="2">the size of the training set</definiens>
			</definition>
			<definition id="5">
				<sentence>The score of the document is the normalized inner product of vectorx and vectorw given by the function score ( dj ) = vectorx·vectorwlength ( dj ) .</sentence>
				<definiendum id="0">score of the document</definiendum>
				<definiens id="0">the normalized inner product of vectorx and vectorw given by the function score ( dj ) = vectorx·vectorwlength ( dj )</definiens>
			</definition>
			<definition id="6">
				<sentence>Support Vector Machines ( SVMs ) Now we describe the learning of a biography classifier using SVMs .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs</definiendum>
				<definiens id="0">the learning of a biography classifier using SVMs</definiens>
			</definition>
			<definition id="7">
				<sentence>The special feature underlying SVMs is the high dimensional representation of a document , allowing categorization by a hyper-plane of high dimension ; therefore each document was represented by the vector of its stems .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">the high dimensional representation of a document , allowing categorization by a hyper-plane of high dimension</definiens>
			</definition>
			<definition id="8">
				<sentence>Recall , the test questions were such that there were no biographies for the question targets in the biography collection we used ( biography.com ) : the biographies used were ones that BioGrapher identified on the web .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the biographies used were ones that BioGrapher identified on the web</definiens>
			</definition>
</paper>

		<paper id="2407">
			<definition id="0">
				<sentence>The linguistic tradition of dependency grammar comprises a large and fairly diverse family of theories and formalisms that share certain basic assumptions about syntactic structure , in particular the assumption that syntactic structure consists of lexical nodes linked by binary relations called dependencies ( see , e.g. , Tesni`ere ( 1959 ) , Sgall ( 1986 ) , Mel’ˇcuk ( 1988 ) , Hudson ( 1990 ) ) .</sentence>
				<definiendum id="0">linguistic tradition of dependency grammar</definiendum>
				<definiens id="0">comprises a large and fairly diverse family of theories and formalisms that share certain basic assumptions about syntactic structure , in particular the assumption that syntactic structure consists of lexical nodes linked by binary relations called dependencies ( see , e.g. , Tesni`ere ( 1959 )</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , we define dependency graphs in the following way : PP P˚a ( In a7 a4 a63 ADV NN 60-talet the-60’s a7 a4 a63 PR VB m˚alade painted PN han he a7 a4 a63 SUB JJ dj¨arva bold a7 a4 a63 ATT NN tavlor pictures a7 a4 a63 OBJ HP som which a7 a4 a63 ATT VB retade annoyed a63 a7 a4SUB PM Nikita Nikita a7 a4 a63 OBJ PM Chrusjtjov .</sentence>
				<definiendum id="0">PP P˚a</definiendum>
				<definiens id="0">a7 a4 a63 PR VB m˚alade painted PN han he a7 a4 a63 SUB JJ dj¨arva bold a7 a4 a63 ATT NN tavlor pictures a7 a4 a63 OBJ HP som which a7 a4 a63 ATT VB retade annoyed a63 a7 a4SUB PM Nikita Nikita a7 a4 a63 OBJ PM Chrusjtjov</definiens>
			</definition>
			<definition id="2">
				<sentence>w1···wn is a labeled directed graph D = ( W , A ) , where ( a ) W is the set of nodes , i.e. word tokens in the input string , ( b ) A is a set of labeled arcs ( wi , r , wj ) ( where wi , wj ∈ W and r ∈ R ) .</sentence>
				<definiendum id="0">w1···wn</definiendum>
				<definiens id="0">the set of nodes , i.e. word tokens in the input string</definiens>
				<definiens id="1">a set of labeled arcs ( wi , r , wj ) ( where wi , wj ∈ W and r ∈ R )</definiens>
			</definition>
			<definition id="3">
				<sentence>Parser configurations are represented by triples 〈S , I , A〉 , where S is the stack ( represented as a list ) , I is the list of ( remaining ) input tokens , and A is the ( current ) arc relation for the dependency graph .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">the stack ( represented as a list</definiens>
			</definition>
			<definition id="4">
				<sentence>Unique label ( wi r→wj ∧ wi rprime→wj ) ⇒ r = rprime Single head ( wi→wj ∧ wk→wj ) ⇒ wi = wk Acyclic ¬ ( wi→wj ∧ wj→∗wi ) Connected wi↔∗wj Projective ( wi↔wk ∧ wi &lt; wj &lt; wk ) ⇒ ( wi→∗wj ∨ wk→∗wj ) Figure 2 : Well-formedness conditions on dependency graphs Initialization 〈nil , W , ∅〉 Termination 〈S , nil , A〉 Left-Arc 〈wi|S , wj|I , A〉 → 〈S , wj|I , A∪ { ( wj , r , wi ) } 〉 ¬∃wk∃rprime ( wk , rprime , wi ) ∈ A Right-Arc 〈wi|S , wj|I , A〉 → 〈wj|wi|S , I , A∪ { ( wi , r , wj ) } 〉 ¬∃wk∃rprime ( wk , rprime , wj ) ∈ A Reduce 〈wi|S , I , A〉 → 〈S , I , A〉 ∃wj∃r ( wj , r , wi ) ∈ A Shift 〈S , wi|I , A〉 → 〈wi|S , I , A〉 Figure 3 : Parser transitions One way of turning a nondeterministic parser into a deterministic one is to use a guide ( or oracle ) that can inform the parser at each nondeterministic choice point ; cf. Kay ( 2000 ) , Boullier ( 2003 ) .</sentence>
				<definiendum id="0">Unique label</definiendum>
				<definiendum id="1">Reduce 〈wi|S</definiendum>
				<definiendum id="2">A〉 ∃wj∃r</definiendum>
			</definition>
			<definition id="5">
				<sentence>The function we want to approximate is a mapping f from parser configurations to parser actions , where each action consists of a transition and ( unless the transition is Shift or Reduce ) a dependency type : f : Config → { LA , RA , RE , SH } × ( R∪ { nil } ) Here Config is the set of all possible parser configurations and R is the set of dependency types as before .</sentence>
				<definiendum id="0">Config</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a mapping f from parser configurations to parser actions , where each action consists of a transition and ( unless the transition is Shift or Reduce ) a dependency type : f : Config → { LA , RA , RE , SH } × ( R∪ { nil }</definiens>
				<definiens id="1">the set of all possible parser configurations and</definiens>
				<definiens id="2">the set of dependency types as before</definiens>
			</definition>
			<definition id="6">
				<sentence>The final feature ( LOOK ) is a simple lookahead , using the part-of-speech of the next plus one input token .</sentence>
				<definiendum id="0">LOOK</definiendum>
				<definiens id="0">a simple lookahead , using the part-of-speech of the next plus one input token</definiens>
			</definition>
			<definition id="7">
				<sentence>The output of the memory-based learner is a classifier that predicts the next transition ( including dependency type ) , given the current state of the parser .</sentence>
				<definiendum id="0">memory-based learner</definiendum>
				<definiens id="0">a classifier that predicts the next transition ( including dependency type ) , given the current state of the parser</definiens>
			</definition>
			<definition id="8">
				<sentence>Prediction accuracy refers to the quality of the classifier as such , i.e. how well it predicts the next transition given the correct parser state , and is measured by the classification accuracy on unseen transition data ( using a 0-1 loss function ) .</sentence>
				<definiendum id="0">Prediction accuracy</definiendum>
				<definiens id="0">the quality of the classifier as such , i.e. how well it predicts the next transition given the correct parser state , and is measured by the classification accuracy on unseen transition data ( using a 0-1 loss function )</definiens>
			</definition>
			<definition id="9">
				<sentence>The attachment score is computed as the proportion of tokens ( excluding punctuation ) that are assigned the correct head ( or no head if the token is a root ) .</sentence>
				<definiendum id="0">attachment score</definiendum>
				<definiens id="0">a root )</definiens>
			</definition>
			<definition id="10">
				<sentence>• k = 1 , i.e. classification based on a single nearest neighbor.1 1In TiMBL , the value of k in fact refers to k nearest distances rather than k nearest neighbors , which means that , even with k = 1 , the nearest neighbor set can contain several inLabel Dependency Type ADV Adverbial modifier APP Apposition ATT Attribute CC Coordination ( conjunction or second conjunct ) DET Determiner ID Non-first element of multi-word expression IM Infinitive dependent on infinitive marker IP Punctuation mark dependent on lexical head INF Infinitival complement OBJ Object PR Complement of preposition PRD Predicative complement SUB Subject UK Main verb of subordinate clause dependent on complementizer VC Verb chain ( nonfinite verb dependent on other verb ) XX Unclassifiable dependent Table 2 : Dependency types in Swedish treebank Model Default Maximum Non-lexical 86.8 87.4 Lexical 88.4 89.7 Table 3 : Prediction accuracy for MBL models The second column shows the accuracy for the best parameter settings found in the experiments ( averaged over both models ) , which differ from the default in the following respects : • Overlap metric replaced by the modified value distance metric ( MVDM ) ( Stanfill and Waltz , 1986 ; Cost and Salzberg , 1993 ) .</sentence>
				<definiendum id="0">ADV Adverbial modifier APP Apposition ATT Attribute CC Coordination</definiendum>
				<definiendum id="1">averaged over both models</definiendum>
				<definiens id="0">differ from the default in the following respects : • Overlap metric replaced by the modified value distance metric</definiens>
			</definition>
</paper>

		<paper id="0812">
			<definition id="0">
				<sentence>Lo Zaire è uno dei paesi più pericolosi di tutta l'Africa = The Zaire is one of the most dangerous countries of Africa In IWN , sense distinctions are as follows : Paese1– territorio con un governo sovrano e una propria organizzazione politica e amministrativa , ( territory with its own political and administrative organization ) Paese3– insieme di individui legati da stesse tradizioni storiche , lingua , costumi , ( group of people with same historical traditions , languages and customs ) Since annotators could not achieve a satisfactory disambiguation , they take into account both senses , sense1 and sense3 .</sentence>
				<definiendum id="0">Zaire</definiendum>
				<definiens id="0">Paese1– territorio con un governo sovrano e una propria organizzazione politica e amministrativa , ( territory with its own political and administrative organization ) Paese3– insieme di individui legati da stesse tradizioni storiche , lingua , costumi , ( group of people with same historical traditions , languages and customs</definiens>
			</definition>
</paper>

		<paper id="0407">
			<definition id="0">
				<sentence>In contrast , Multiword Lexical Units ( hereafter MWLU ) comprise lexicalized phrases — semantically non-compositional or syntactically idiosyncratic word combinations— which are represented and stored in the lexical database of Basque ( EDBL ) .</sentence>
				<definiendum id="0">Multiword Lexical Units ( hereafter MWLU</definiendum>
				<definiens id="0">) comprise lexicalized phrases — semantically non-compositional or syntactically idiosyncratic word combinations— which are represented and stored in the</definiens>
			</definition>
			<definition id="1">
				<sentence>For the second phase , this list has been enlarged using the Hiztegi Batua , a dictionary of standard Basque that the Basque Language Academy updates regularly ( http : //www2.euskaltzaindia.net/hiztegibatua ) .</sentence>
				<definiendum id="0">Hiztegi Batua</definiendum>
				<definiens id="0">the Basque Language Academy updates regularly ( http : //www2.euskaltzaindia.net/hiztegibatua )</definiens>
			</definition>
			<definition id="2">
				<sentence>• Component_Form : i.e. the word-form itself as it appears in the canonical form of the MWLU .</sentence>
				<definiendum id="0">Component_Form</definiendum>
				<definiens id="0">i.e. the word-form itself as it appears in the canonical form of the MWLU</definiens>
			</definition>
			<definition id="3">
				<sentence>In these expressions the position of the digits indicate the position each component takes in a particular SRS , * indicates that 0 or more words may occur between two components , and ?</sentence>
				<definiendum id="0">position of the digits indicate</definiendum>
				<definiens id="0">the position each component takes in a particular SRS , * indicates that 0 or more words may occur between two components</definiens>
			</definition>
</paper>

		<paper id="0910">
			<definition id="0">
				<sentence>The metagrammar is an abstract specification of the linguistic properties ( phrase structure , valency , realisation of grammatical functions etc. ) encoded in the grammar basic units .</sentence>
				<definiendum id="0">metagrammar</definiendum>
				<definiens id="0">an abstract specification of the linguistic properties ( phrase structure , valency , realisation of grammatical functions etc. ) encoded in the grammar basic units</definiens>
			</definition>
			<definition id="1">
				<sentence>Marie is the child of Jean .</sentence>
				<definiendum id="0">Marie</definiendum>
			</definition>
			<definition id="2">
				<sentence>An FTAG consists of a set of ( auxiliary or initial ) elementary trees and two tree composition operations : substitution and adjunction .</sentence>
				<definiendum id="0">FTAG</definiendum>
				<definiens id="0">consists of a set of ( auxiliary or initial ) elementary trees and two tree composition operations : substitution and adjunction</definiens>
			</definition>
			<definition id="3">
				<sentence>Substitution is the standard tree operation used in phrase structure grammars while adjunction is an operation which inserts an auxiliary tree into a derived tree .</sentence>
				<definiendum id="0">Substitution</definiendum>
				<definiens id="0">the standard tree operation used in phrase structure grammars while adjunction is an operation which inserts an auxiliary tree into a derived tree</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus the semantic representations we assume are simply set of literals of the form P n ( x1 ; : : : ; xn ) where P n is a predicate of arity n and xi is either a constant or a unification variable whose value will be instantiated during processing .</sentence>
				<definiendum id="0">P n</definiendum>
				<definiendum id="1">xi</definiendum>
				<definiens id="0">a predicate of arity n and</definiens>
			</definition>
			<definition id="5">
				<sentence>FrameNet is an online lexical resource for English based on the principles of Frame Semantics .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">an online lexical resource for English based on the principles of Frame Semantics</definiens>
			</definition>
</paper>

		<paper id="1607">
			<definition id="0">
				<sentence>Persian language presents certain challenges to computational analysis : There is a complex verbal conjugation paradigm which includes long-distance morphological dependencies ; phonological alternations apply at morpheme boundaries ; word and noun phrase boundaries are difficult to define since morphemes may be detached from their stems and distinct words can appear without an intervening space .</sentence>
				<definiendum id="0">Persian language</definiendum>
				<definiens id="0">presents certain challenges to computational analysis : There is a complex verbal conjugation paradigm which includes long-distance morphological dependencies ; phonological alternations apply at morpheme boundaries ; word and noun phrase boundaries are difficult to define since morphemes may be detached from their stems and distinct words can appear without an intervening space</definiens>
			</definition>
			<definition id="1">
				<sentence>However , the verbal conjugation consists of a complex paradigm , which includes long-distance dependencies that may be problematic for a linear approach depending solely on surface forms .</sentence>
				<definiendum id="0">verbal conjugation</definiendum>
			</definition>
			<definition id="2">
				<sentence>Persian is an affixal system consisting mainly of suffixes and a number of prefixes appearing in strict morphotactic order .</sentence>
				<definiendum id="0">Persian</definiendum>
				<definiens id="0">an affixal system consisting mainly of suffixes and a number of prefixes appearing in strict morphotactic order</definiens>
			</definition>
			<definition id="3">
				<sentence>The nonverbal paradigm consists of a relatively small number of affixes marking number , indefiniteness or comparatives , but the language has a complete verbal inflectional system , which can be obtained by the various combinations of prefixes , stems , person and number inflections and auxiliaries .</sentence>
				<definiendum id="0">nonverbal paradigm</definiendum>
				<definiens id="0">consists of a relatively small number of affixes marking number , indefiniteness or comparatives , but the language has a complete verbal inflectional system , which can be obtained by the various combinations of prefixes , stems , person and number inflections and auxiliaries</definiens>
			</definition>
			<definition id="4">
				<sentence>The character ‘h’ is pronounced as a consonant in mâh ) ﻩﺎﻣ ( ‘moon’ but as a vowel in bynndh ) ﻩﺪﻨﻨﻴﺑ ( ‘viewer’ ( pronounced ‘binandé’ ) .</sentence>
				<definiendum id="0">character ‘h’</definiendum>
				<definiens id="0">a consonant in mâh ) ﻩﺎﻣ ( ‘moon’ but as a vowel in bynndh</definiens>
			</definition>
			<definition id="5">
				<sentence>If the values of the PFXTYP flag diacritic match at this point , unification takes place allowing the concatenation of the prefix and present stem combination with the personal inflection .</sentence>
				<definiendum id="0">unification</definiendum>
				<definiens id="0">takes place allowing the concatenation of the prefix and present stem combination with the personal inflection</definiens>
			</definition>
			<definition id="6">
				<sentence>The finite state transducer consists of 178,452 states and 928,982 arcs before optimization .</sentence>
				<definiendum id="0">finite state transducer</definiendum>
				<definiens id="0">consists of 178,452 states and 928,982 arcs before optimization</definiens>
			</definition>
</paper>

		<paper id="2003">
			<definition id="0">
				<sentence>Unlike formal grammars to which posthoc statistical disambiguators can be added , Pro3Gres has been designed to be hybrid , carefully distinguishing between tasks that can best be solved by finite-state methods , rule-based methods and statistical methods .</sentence>
				<definiendum id="0">Pro3Gres</definiendum>
				<definiens id="0">has been designed to be hybrid , carefully distinguishing between tasks that can best be solved by finite-state methods , rule-based methods and statistical methods</definiens>
			</definition>
</paper>

		<paper id="1404">
			<definition id="0">
				<sentence>For the purposes of this article we will concentrate on the Data-levels , i.e. annotations of documents ( RDF ) and structure of the semantic information ( Ontologies ) The Resource Description Framework ( RDF ) [ is an entity relationship model used for representing information about resources in the World Wide Web .</sentence>
				<definiendum id="0">RDF</definiendum>
				<definiendum id="1">semantic information ( Ontologies</definiendum>
				<definiendum id="2">RDF</definiendum>
			</definition>
			<definition id="1">
				<sentence>RDF model aims to enrich documents with information about their content .</sentence>
				<definiendum id="0">RDF model</definiendum>
			</definition>
</paper>

		<paper id="1122">
			<definition id="0">
				<sentence>Any Chinese Information Processing ( CIP ) systems beyond character level , such as information retrieval , automatic proofreading , text classification , text-tospeech conversion , syntactic parser , information extraction and machine translation , etc. should have a built-in word segmentation block .</sentence>
				<definiendum id="0">Chinese Information Processing</definiendum>
				<definiens id="0">information retrieval , automatic proofreading , text classification , text-tospeech conversion , syntactic parser , information extraction and machine translation</definiens>
			</definition>
			<definition id="1">
				<sentence>The unknown words are diverse , including proper nouns ( person names , place names , organization names , etc. ) , domain-specific terminological nouns and abbreviations , even author-coined terms , etc. and they appear frequently in real text .</sentence>
				<definiendum id="0">person</definiendum>
				<definiens id="0">names , place names , organization names</definiens>
			</definition>
			<definition id="2">
				<sentence>LR is one of the most stable methods for ATE so far , and more appropriate for sparse data than other metrics .</sentence>
				<definiendum id="0">LR</definiendum>
				<definiens id="0">one of the most stable methods for ATE so far , and more appropriate for sparse data than other metrics</definiens>
			</definition>
			<definition id="3">
				<sentence>Suffix array ( also known as String PATarray ) ( Manber et al , 1993 ) is a compact data structure to handle arbitrary-length strings and performs much powerful on-line string search operations such as the ones supported by PAT-tree , but has less space overhead .</sentence>
				<definiendum id="0">Suffix array</definiendum>
				<definiendum id="1">String PATarray )</definiendum>
				<definiens id="0">a compact data structure to handle arbitrary-length strings and performs much powerful on-line string search operations such as the ones supported by PAT-tree , but has less space overhead</definiens>
			</definition>
</paper>

		<paper id="1217">
			<definition id="0">
				<sentence>88 Word Features wi , wi−1 , wi+1 Disjunction of 5 prev words Disjunction of 5 next words TnT POS POSi , POSi−1 , POSi+1 Prefix/suffix Up to a length of 6 Abbreviations abbri abbri−1 + abbri abbri + abbri+1 abbri−1 + abbri + abbri+1 Word Shape shapei , shapei−1 , shapei+1 shapei−1 + shapei shapei + shapei+1 shapei−1 + shapei + shapei+1 Prev NE NEi−1 , NEi−2 + NEi−1 NEi−3 + NEi−2 + NEi−1 Prev NE + Word NEi−1 + wi Prev NE + POS NEi−1 + POSi−1 + POSi NEi−2 + NEi−1 + POSi−2 + POSi−1 + POSi Prev NE + Shape NEi−1 + shapei NEi−1 + shapei+1 NEi−1 + shapei−1 + shapei NEi−2 + NEi−1 + shapei−2 + shapei−1 + shapei Paren-Matching Signals when one parenthesis in a pair has been assigned a different tag than the other in a window of 4 words Table 1 : Local Features ( + indicates conjunction ) Many entries in gazetteers are ambiguous words , occasionally used in the sense that the gazetteer seeks to represent , but at least as frequently not .</sentence>
				<definiendum id="0">Local Features</definiendum>
				<definiens id="0">shapei+1 Prev NE NEi−1 , NEi−2 + NEi−1 NEi−3 + NEi−2 + NEi−1 Prev NE + Word NEi−1 + wi Prev NE + POS NEi−1 + POSi−1 + POSi NEi−2 + NEi−1 + POSi−2 + POSi−1 + POSi Prev NE + Shape</definiens>
			</definition>
</paper>

		<paper id="0827">
			<definition id="0">
				<sentence>A further innovation on earlier versions of memorybased WSD is the use of grammatical relation and chunk features .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">the use of grammatical relation and chunk features</definiens>
			</definition>
			<definition id="1">
				<sentence>To train the word experts , memory-based learning ( MBL ) is used , an instance of the lazy learning paradigm : all contexts in which an ambiguous word occurs in the training text are kept in memory and abstraction only occurs at classification time by extrapolating a class from the most similar item ( s ) in memory to the new test item .</sentence>
				<definiendum id="0">memory-based learning</definiendum>
				<definiendum id="1">MBL</definiendum>
				<definiens id="0">all contexts in which an ambiguous word occurs in the training text are kept in memory and abstraction only occurs at classification time by extrapolating a class from the most similar item ( s ) in memory to the new test item</definiens>
			</definition>
			<definition id="2">
				<sentence>The word expert module consists of two cascaded memory-based classifiers : the sense predicted by Association for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems the first classifier is used as a feature in the second classifier .</sentence>
				<definiendum id="0">word expert module</definiendum>
				<definiens id="0">consists of two cascaded memory-based classifiers : the sense predicted by Association for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems the first classifier is used as a feature in the second classifier</definiens>
			</definition>
			<definition id="3">
				<sentence>They determine the probability of a sense s of a focus lemma f given keyword k by dividing Ns ; kloc ( the number of occurrences of a possible local context keyword k with a particular focus word-lemma–POS-tag combination w with a particular sense s ) by Nkloc ( the number of occurrences of a possible local context keyword kloc with a particular focus word-lemma–POS-tag combination w regardless of its sense ) .</sentence>
				<definiendum id="0">kloc</definiendum>
				<definiens id="0">the probability of a sense s of a focus lemma f given keyword k by dividing Ns</definiens>
			</definition>
			<definition id="4">
				<sentence>Joint feature selection and parameter optimization is an optimization problem which involves searching the space of all possible feature subsets and parameter settings to identify the combination that is optimal or near-optimal .</sentence>
				<definiendum id="0">parameter optimization</definiendum>
				<definiens id="0">an optimization problem which involves searching the space of all possible feature subsets and parameter settings to identify the combination that is optimal or near-optimal</definiens>
			</definition>
</paper>

		<paper id="2808">
			<definition id="0">
				<sentence>The Ontology Used : The ontology used in the experiments described herein was initially designed as a general purpose component for knowledge-based NLP .</sentence>
				<definiendum id="0">Ontology Used</definiendum>
				<definiens id="0">The ontology used in the experiments described herein was initially designed as a general purpose component for knowledge-based NLP</definiens>
			</definition>
			<definition id="1">
				<sentence>The OntoScore System : The ONTOSCORE software runs as a module in the SMARTKOM multi-modal and multi-domain spoken dialogue system ( Wahlster , 2003 ) .</sentence>
				<definiendum id="0">OntoScore System</definiendum>
			</definition>
			<definition id="2">
				<sentence>The ensuing distance between two concepts , e.g. a0a2a1a4a3a6a5a8a7a9a3a11a10a6a12 is then defined as the minimum score derived between a3a6a5 and a3a11a10 .</sentence>
				<definiendum id="0">ensuing distance between two</definiendum>
			</definition>
			<definition id="3">
				<sentence>Word graphs : An efficient interface between continuousspeech recognition and language understanding .</sentence>
				<definiendum id="0">Word graphs</definiendum>
			</definition>
			<definition id="4">
				<sentence>Scoring functions for overlay and their application in discourse processing .</sentence>
				<definiendum id="0">Scoring</definiendum>
			</definition>
			<definition id="5">
				<sentence>The n-best algorithm : an efficient and exact procedure for finding the n most likely sentence hypotheses .</sentence>
				<definiendum id="0">n-best algorithm</definiendum>
			</definition>
			<definition id="6">
				<sentence>Word Sense Disambiguation : The Case for Combining Knowldge Sources .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
			</definition>
</paper>

		<paper id="1508">
</paper>

		<paper id="2612">
			<definition id="0">
				<sentence>WordNet ( Fellbaum , 1998 ) is a wonderful and free-of-charge resource designed specifically for the needs of computational linguistics ( CL ) community and the dictionary of choice for many NLP systems ( Voorhees and Buckland , 2002 ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a wonderful and free-of-charge resource designed specifically for the needs of computational linguistics</definiens>
			</definition>
			<definition id="1">
				<sentence>Step 2 For each pair ( T 1 , k , T 2 , n ) of definitions from both sources , compute qualitative relation R between each pair of properties ( P i 1 , k , P j 2 , n ) in the right handside of the definitions ; R can be one and only one of the following : EQUAL , SMALLER ( MORE-SPECIFIC ) , LARGER ( MORE GENERAL ) , PARTIAL-OVERLAP , or DISJOINT .</sentence>
				<definiendum id="0">SMALLER</definiendum>
				<definiens id="0">in the right handside of the definitions</definiens>
			</definition>
			<definition id="2">
				<sentence>This measure whose motivation is similar to ( Resnik 1999 ) is a number between 0 and 1 computed based on qualitative relations R among the properties in both definitions and on proportion of relations indicating closeness ; EQUAL corresponds to 1 , the smallest distance , SMALLER and LARGER to 0.8 , PARTIALOVERLAP to 0.6 , and DISJOINT to 0 , the largest distance .</sentence>
				<definiendum id="0">EQUAL</definiendum>
				<definiens id="0">a number between 0 and 1 computed based on qualitative relations R among the properties in both definitions and on proportion of relations indicating closeness</definiens>
			</definition>
			<definition id="3">
				<sentence>Information provided by the sources is translated into the following terms D = date ( month = &gt; [ April , May ] , 1 year = &gt; 1992 ) D = date ( month = &gt; not May ( part = &gt; early ) ) = 2 date ( month = &gt; [ not May , May ( part = &gt; not early ) ] ) If both sources are considered reliable , we use the meet operation to compute integrated piece of information or knowledge .</sentence>
				<definiendum id="0">Information</definiendum>
			</definition>
			<definition id="4">
				<sentence>As shown in Table 4 , SourceD3 defines `` virus '' as `` a very small organism , smaller than a bacterium , which causes disease in humans , animals and plants '' , and SourceC1 as `` extremely small infectious substances ( much smaller than bacteria ) '' .</sentence>
				<definiendum id="0">SourceD3 defines `` virus</definiendum>
				<definiendum id="1">SourceC1</definiendum>
				<definiens id="0">causes disease in humans , animals and plants '' , and</definiens>
			</definition>
			<definition id="5">
				<sentence>Natural Language is a Powerful Knowledge Representation System : The UNO Model .</sentence>
				<definiendum id="0">Natural Language</definiendum>
			</definition>
			<definition id="6">
				<sentence>Contextual Vocabulary Acquisition : A Computational Theory and Educational Curriculum .</sentence>
				<definiendum id="0">Contextual Vocabulary Acquisition</definiendum>
				<definiens id="0">A Computational Theory and Educational Curriculum</definiens>
			</definition>
			<definition id="7">
				<sentence>Semantic Similarity in a Taxonomy : An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language .</sentence>
				<definiendum id="0">Semantic Similarity</definiendum>
				<definiens id="0">An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language</definiens>
			</definition>
</paper>

		<paper id="0500">
</paper>

		<paper id="2203">
			<definition id="0">
				<sentence>Jeminie is a software system that helps building interlingual databases .</sentence>
				<definiendum id="0">Jeminie</definiendum>
				<definiens id="0">a software system that helps building interlingual databases</definiens>
			</definition>
			<definition id="1">
				<sentence>Recall ( coverage ) is the number of axies that are defined in both the generated database and in the golden standard database , divided by the number of axies in the golden standard .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the number of axies that are defined in both the generated database and in the golden standard database , divided by the number of axies in the golden standard</definiens>
			</definition>
			<definition id="2">
				<sentence>Precision is the number of axies that are defined in both the generated database and in the golden standard database , divided by the number of axies in the generated database .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the number of axies that are defined in both the generated database and in the golden standard database , divided by the number of axies in the generated database</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , we define one criterion module to calculate the following value : Qi = 1 vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle1 − nblexiessummationtext k = 1 nblinkedaxiesk nblexies vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle where nblexies is the total number of lexies in the database , and nblinkedaxiesk is the number of axies linked to a lexie k. Qi is comprised between 0 and 100 .</sentence>
				<definiendum id="0">nblinkedaxiesk</definiendum>
				<definiens id="0">the total number of lexies in the database</definiens>
			</definition>
			<definition id="4">
				<sentence>The set of axies produced by process A consists of axie1 to axie7 .</sentence>
				<definiendum id="0">axies</definiendum>
				<definiens id="0">produced by process A consists of axie1 to axie7</definiens>
			</definition>
			<definition id="5">
				<sentence>Process B consists of the execution of the same module Mbidict as in process A , then of a module Mvect that implements a conceptual vector comparison algorithm for filtering some bad links .</sentence>
				<definiendum id="0">Process B</definiendum>
				<definiens id="0">consists of the execution of the same module Mbidict as in process A , then of a module Mvect that implements a conceptual vector comparison algorithm for filtering some bad links</definiens>
			</definition>
			<definition id="6">
				<sentence>Jeminie : A flexible system for the automatic creation of interlingual database .</sentence>
				<definiendum id="0">Jeminie</definiendum>
				<definiens id="0">A flexible system for the automatic creation of interlingual database</definiens>
			</definition>
</paper>

		<paper id="0858">
			<definition id="0">
				<sentence>This paper describes the National Research Council ( NRC ) Word Sense Disambiguation ( WSD ) system , as applied to the English Lexical Sample ( ELS ) task in Senseval-3 .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
				<definiens id="0">applied to the English Lexical Sample ( ELS ) task in Senseval-3</definiens>
			</definition>
			<definition id="1">
				<sentence>The NRC system approaches WSD as a classical supervised machine learning problem , using familiar tools such as the Weka machine learning software and Brill’s rule-based part-of-speech tagger .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">a classical supervised machine learning problem</definiens>
			</definition>
			<definition id="2">
				<sentence>A ptag match is a partial tag match , which counts similar part-ofspeech tags , such as NN ( singular noun ) , NNS ( plural noun ) , NNP ( singular proper noun ) , and NNPS ( plural proper noun ) , as equivalent .</sentence>
				<definiendum id="0">ptag match</definiendum>
				<definiendum id="1">NNS</definiendum>
				<definiendum id="2">NNP</definiendum>
				<definiens id="0">a partial tag match , which counts similar part-ofspeech tags , such as NN ( singular noun )</definiens>
				<definiens id="1">plural noun )</definiens>
			</definition>
			<definition id="3">
				<sentence>Laplace smoothing is applied to the PMI estimates , to avoid division by zero .</sentence>
				<definiendum id="0">Laplace smoothing</definiendum>
				<definiens id="0">applied to the PMI estimates , to avoid division by zero</definiens>
			</definition>
			<definition id="4">
				<sentence>Past work demonstrates that PMI is a good estimator of semantic similarity ( Turney , 2001 ; Terra and Clarke , 2003 ) and that features based on PMI can be useful for supervised learning ( Turney , 2003 ) .</sentence>
				<definiendum id="0">PMI</definiendum>
				<definiens id="0">a good estimator of semantic similarity ( Turney , 2001 ; Terra and Clarke , 2003 ) and that features based on PMI can be useful for supervised learning</definiens>
			</definition>
</paper>

		<paper id="1210">
</paper>

		<paper id="2414">
			<definition id="0">
				<sentence>Apart from the provided words and the predicted PoS tags , chunk labels , clause labels , and named-entity labels , provided beforehand , we have considered an additional set of automatically derived features : occurring below a frequency threshold ( of 10 ) are converted to a string capturing some of the original word form’s features ( capitalization , whether it contains numbers or a hyphen , or suffix letters ) ; verb , measured in intervening words , chunks , NP chunks or VP chunks ( negative if the word is to the left , positive if it is to the right of the verb ) ; word of the previous chunk if that was labeled as preposition ; the main verb is used in a passive construction ; current word is in the same clause as the main verb ; tern of the main verb in the training data ( contains the order of V and A0-A5 ) .</sentence>
				<definiendum id="0">verb</definiendum>
				<definiens id="0">the predicted PoS tags , chunk labels , clause labels , and named-entity labels</definiens>
			</definition>
			<definition id="1">
				<sentence>Memory-based learning is a supervised inductive algorithm for learning classification tasks based on the knn algorithm ( Cover and Hart , 1967 ; Aha et al. , 1991 ) with various extensions for dealing with nominal features and feature relevance weighting .</sentence>
				<definiendum id="0">Memory-based learning</definiendum>
				<definiens id="0">a supervised inductive algorithm for learning classification tasks based on the knn algorithm ( Cover and Hart , 1967 ; Aha et al. , 1991 ) with various extensions for dealing with nominal features and feature relevance weighting</definiens>
			</definition>
			<definition id="2">
				<sentence>Memory-based learning stores feature representations of training instances in memory without abstraction and classifies new ( test ) instances by matching their feature representation to all instances in memory , finding the most similar instances .</sentence>
				<definiendum id="0">Memory-based learning stores</definiendum>
				<definiens id="0">representations of training instances in memory without abstraction and classifies new ( test ) instances by matching their feature representation to all instances in memory</definiens>
			</definition>
			<definition id="3">
				<sentence>To generate the training material , we copy these windowed ( unigram ) class labels into the input , excluding the focus class label ( which is a perfect predictor of the output class ) .</sentence>
				<definiendum id="0">focus class label</definiendum>
				<definiens id="0">a perfect predictor of the output class )</definiens>
			</definition>
			<definition id="4">
				<sentence>Distances are measured in chunks , NP chunks , VP chunks and words .</sentence>
				<definiendum id="0">Distances</definiendum>
				<definiens id="0">measured in chunks , NP chunks , VP chunks and words</definiens>
			</definition>
</paper>

		<paper id="2302">
			<definition id="0">
				<sentence>HALogen accepts a feature-value structure ranging from high-level semantics to shallow syntax .</sentence>
				<definiendum id="0">HALogen</definiendum>
				<definiens id="0">accepts a feature-value structure ranging from high-level semantics to shallow syntax</definiens>
			</definition>
			<definition id="1">
				<sentence>The TRIPS Logical Form uses many more roles than HALogen recognizes , but we converted them to the smaller set .</sentence>
				<definiendum id="0">TRIPS Logical Form</definiendum>
				<definiens id="0">uses many more roles than HALogen recognizes</definiens>
			</definition>
			<definition id="2">
				<sentence>The LF ontology consists of a single-inheritance hierarchy of frame-like LF types that classify entities according to their semantics and argument structure .</sentence>
				<definiendum id="0">LF ontology</definiendum>
				<definiens id="0">consists of a single-inheritance hierarchy of frame-like LF types that classify entities according to their semantics and argument structure</definiens>
			</definition>
			<definition id="3">
				<sentence>This is a flat and unscoped representation of the semantics of the sentence that serves as input to the TRIPS discourse interpretation modules ( which perform reference resolution , disambiguation , intention recognition to produce the final intended meaning ) .</sentence>
				<definiendum id="0">TRIPS discourse interpretation modules</definiendum>
				<definiens id="0">perform reference resolution , disambiguation , intention recognition to produce the final intended meaning )</definiens>
			</definition>
			<definition id="4">
				<sentence>V123 is pronominal form of type LF PERSON and pro-type HE , and V433 is an indefinitely specified object that is of type LF DRUG ( more specifically ”aspirin” ) .</sentence>
				<definiendum id="0">V123</definiendum>
				<definiendum id="1">V433</definiendum>
				<definiens id="0">pronominal form of type LF PERSON and pro-type HE , and</definiens>
				<definiens id="1">an indefinitely specified object that is of type LF DRUG ( more specifically ”aspirin” )</definiens>
			</definition>
			<definition id="5">
				<sentence>The LF type triple is reduced to just the lexical item and appropriate determiners are attached when the LF provides enough information to warrant it .</sentence>
				<definiendum id="0">LF type triple</definiendum>
			</definition>
			<definition id="6">
				<sentence>It is best illustrated by example using our example LF in figure comes : ( V11 / TAKE : TENSE PAST : AGENT ( V123 / HE ) : THEME ( V433 / ASPIRIN ) ) This resulting AMR is the input to HALogen where it is converted into a word forest using our modified dialoguebased HALogen grammar .</sentence>
				<definiendum id="0">AMR</definiendum>
			</definition>
</paper>

		<paper id="0108">
			<definition id="0">
				<sentence>Both systems have been independently designed as separate modules in the context of the FLaVoR project , which aims to develop a modular architecture for automatic speech recognition .</sentence>
				<definiendum id="0">FLaVoR project</definiendum>
				<definiens id="0">aims to develop a modular architecture for automatic speech recognition</definiens>
			</definition>
			<definition id="1">
				<sentence>The systems are trained and tested on the same Dutch morphological database ( CELEX ) , and can thus be objectively compared as morphological analyzers in their own right .</sentence>
				<definiendum id="0">CELEX</definiendum>
				<definiens id="0">morphological analyzers in their own right</definiens>
			</definition>
			<definition id="2">
				<sentence>The FLaVoR project investigates the feasibility of using powerful linguistic information in the recognition process .</sentence>
				<definiendum id="0">FLaVoR project</definiendum>
				<definiens id="0">investigates the feasibility of using powerful linguistic information in the recognition process</definiens>
			</definition>
			<definition id="3">
				<sentence>Obviously this results in a very low 5MBM : the memory-based morphological analyzer , FSM : the finite state morphological analyzer full word score ( which shows us that 18.64 % of the words in the test set are actually monomorphemic ) .</sentence>
				<definiendum id="0">FSM</definiendum>
				<definiens id="0">the memory-based morphological analyzer ,</definiens>
			</definition>
			<definition id="4">
				<sentence>The finite state method often seems to generate more morpheme boundaries than necessary , while the reverse is the case for the memory-based system , which seems too eager to revert to monomorphemic analyses when in doubt .</sentence>
				<definiendum id="0">memory-based system</definiendum>
				<definiens id="0">seems too eager to revert to monomorphemic analyses when in doubt</definiens>
			</definition>
</paper>

		<paper id="0911">
			<definition id="0">
				<sentence>The chal1The DIALOG project is a collaboration between the Computer Science and Computational Linguistics departments of University of the Saarland , and is a part of the Collaborative Research Center on Resource-Adaptive Cognitive Processes , SFB 378 ( www.coli.uni-sb.de/sfb378 ) .</sentence>
				<definiendum id="0">chal1The DIALOG project</definiendum>
				<definiens id="0">a collaboration between the Computer Science and Computational Linguistics departments of University of the Saarland , and is a part of the Collaborative Research Center on Resource-Adaptive Cognitive Processes</definiens>
			</definition>
			<definition id="1">
				<sentence>Mathematical Proof Assistant ( MPA ) : Checks the appropriateness of user specified inference steps with respect to the problem-solving goal ; based on MEGA .</sentence>
				<definiendum id="0">Mathematical Proof Assistant ( MPA )</definiendum>
				<definiens id="0">Checks the appropriateness of user specified inference steps with respect to the problem-solving goal</definiens>
			</definition>
			<definition id="2">
				<sentence>The collected corpus consists of 66 dialog logfiles , containing on average 12 turns .</sentence>
				<definiendum id="0">collected corpus</definiendum>
			</definition>
			<definition id="3">
				<sentence>A auch K ( B ) [ Aalso K ( B ) ] A\B ist 2 von C [ ( A\B ) [ ... is 2 of ... ] ( da ja A\B= ; ) [ ( because A\B= ; ) ] B enthaelt kein x2A [ B contains no x2A ] The mixture affects the way parsing needs to be conducted : mathematical content has to be identified before it is interpreted within the utterance .</sentence>
				<definiendum id="0">auch K</definiendum>
				<definiendum id="1">A\B</definiendum>
				<definiens id="0">because A\B= ; ) ] B enthaelt kein x2A [ B contains no x2A ] The mixture affects the way parsing needs to be conducted : mathematical content has to be identified before it is interpreted within the utterance</definiens>
			</definition>
			<definition id="4">
				<sentence>In particular , mathematical objects ( or parts thereof ) may lie within the scope of quantifiers or negation expressed in natural language ( as in the last example above ) .</sentence>
				<definiendum id="0">mathematical objects</definiendum>
				<definiens id="0">lie within the scope of quantifiers or negation expressed in natural language</definiens>
			</definition>
			<definition id="5">
				<sentence>DeMorgan-Regel-2 besagt : K ( Ai \ Bj ) = K ( Ai ) [ K ( Bj ) In diesem Fall : z.B. K ( Ai ) = dem Begriff K ( Ak [ Bl ) K ( Bj ) = dem Begriff K ( C [ D ) [ DeMorgan-Regel-2 means : K ( Ai \ Bj ) = K ( Ai ) [ K ( Bj ) In this case : e.g. K ( Ai ) = the term K ( Ak [ Bl ) K ( Bj ) = the term K ( C [ D ) ] Co-reference phenomena specific to informal mathematical discourse involve ( parts of ) mathematical expressions within text .</sentence>
				<definiendum id="0">e.g. K</definiendum>
				<definiendum id="1">K</definiendum>
				<definiens id="0">Co-reference phenomena specific to informal mathematical discourse involve ( parts of ) mathematical expressions within text</definiens>
			</definition>
			<definition id="6">
				<sentence>By linguistic meaning ( LM ) , we understand the dependency-based deep semantics in the sense of the Prague School sentence meaning as employed in the Functional Generative Description ( FGD ) ( Sgall et al. , 1986 ; Kruijff , 2001 ) .</sentence>
				<definiendum id="0">LM</definiendum>
				<definiendum id="1">Generative Description</definiendum>
				<definiens id="0">the dependency-based deep semantics in the sense of the Prague School sentence meaning as employed in the Functional</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , the expression K ( ( A [ B ) \ ( C [ D ) ) = ( K ( A [ B ) \K ( C [ D ) ) given its top node operator , = , is of type formula , its “left side” is the expression K ( ( A [ B ) \ ( C [ D ) ) , the list of bracketed sub-expressions includes : A [ B , C [ D , ( A [ B ) \ ( C [ D ) , etc .</sentence>
				<definiendum id="0">expression K</definiendum>
				<definiendum id="1">K</definiendum>
			</definition>
			<definition id="8">
				<sentence>2 ( FORMULA represents the default lexical entry for the identified mathematical expressions categorized as formulas ) .</sentence>
				<definiendum id="0">FORMULA</definiendum>
				<definiens id="0">the default lexical entry for the identified mathematical expressions categorized as formulas )</definiens>
			</definition>
			<definition id="9">
				<sentence>Lexical semantics in combination with the knowledge encoded in the ontology allows us to identify those parts of utterances that have an interpretation in the given domain .</sentence>
				<definiendum id="0">Lexical semantics</definiendum>
				<definiens id="0">in combination with the knowledge encoded in the ontology allows us to identify those parts of utterances that have an interpretation in the given domain</definiens>
			</definition>
			<definition id="10">
				<sentence>The tectogrammatical frame of “enthalten” involves the roles of Actor ( ACT ) and Patient ( PAT ) : contain ( ACTtype : FORMULA , PATtype : FORMULA ) ( SUBFORMULAP AT , embeddingACT ) contain ( ACTtype : OBJECT , PATtype : OBJECT ) CONTAINMENT ( containerACT , containeePAT ) Location The Location relation , realized linguistically by the prepositional phrase introduced by “in” , involves the tectogrammatical relations HasProperty-Location ( LOC ) and the Actor of the predicate “sein” .</sentence>
				<definiendum id="0">PATtype</definiendum>
			</definition>
</paper>

		<paper id="1407">
			<definition id="0">
				<sentence>When structuring the material into modules , it can also be defined which modules are prerequisite for what other modules and which can be taken as stand alone modules , like in the following matrix : Module sessions Knowledge required Sessions on Translator 's Workbench Session 1 ( basics ) Session 2 ( batch processes ) basics Session 3 ( administration ) basics and batch processes Session 4 ( TagEditor ) basics and batch processes Session on Conversion of DTP files Session 1 ( S-Tagger FrameMaker ) basics , TagEditor Session 2 ( S-Tagger Interleaf ) basics , TagEditor Table 3 : Knowledge required per session Each participant needs a computer with access to the internet ( a 56k-modem works OK but faster connections like ISDN or DSL are to be preferred ) .</sentence>
				<definiendum id="0">S-Tagger FrameMaker ) basics</definiendum>
				<definiens id="0">a 56k-modem works OK but faster connections like ISDN or DSL are to be preferred )</definiens>
			</definition>
</paper>

		<paper id="2106">
			<definition id="0">
				<sentence>A stroke is a graphical element that can be drawn e.g. with a brush or a pencil without interruptions .</sentence>
				<definiendum id="0">stroke</definiendum>
				<definiens id="0">a graphical element that can be drawn e.g. with a brush or a pencil without interruptions</definiens>
			</definition>
			<definition id="1">
				<sentence>SVG is an application of XML proposed by the World Wide Web Consortium .</sentence>
				<definiendum id="0">SVG</definiendum>
			</definition>
			<definition id="2">
				<sentence>For instance , the first stroke of the kanji ( kan , “Han-China” ) is : &lt; path d= '' M21.38 , 19.75 , c3.31 , The d attribute of the path element contains the path data in a compact form. This data is a list of drawing commands that an SVG renderer will execute to draw the path. The path data for every stroke will consist of a sequence of Bézier curves , which are parametric curves defined by four control points. Several paths can be grouped together under a group element , which allows the association of groups of paths ( i.e. , lists of strokes ) with every grapheme element of a kanji. It is then possible to deal directly with grapheme elements in the graphic representation of the kanji , in order to highlight such elements ( as in figure 2 ) or to link them to other SVG files—e.g. clicking on the left component of would link it to the kanji ( mizu , “water” ) , which is this component’s standard form. The SVG data available so far is static. Our goal is to present it in a dynamic fashion , showing strokes one by one , in the order and the direction in which they should be drawn. We will add an animated child element to every path in the static SVG file to create its animated counterpart. The animate element controls the moment at which the path is drawn , and the shape it should take. Unfortunately there is no special command in SVG to draw a path progressively. A solution is to divide every path in several smaller ones , and to draw each segment one after another , giving the impression of an invisible pen drawing the kanji. Our division strategy is to segment every curve in a path into a fixed number of elements. That number of element is set to a power of two , because dividing Bézier curves into two is very easy to do. Longer strokes will consist of more curves than shorter ones , and it will take more to time to draw them ; the distribution of the control points along the curves makes the animation look quite natural. At the end , an animation is controlled by two parameters : the number of segments into which a curve is split and the time between the drawing of two strokes. Modifying these values will make the drawing slower or faster , and more or less smooth. The first stroke of our example kanji will now look like shown below. The animation will start at time 0 ; it lasts for 0.45 seconds and it will iterate over the values given by the value’s attribute. The d attribute in the path parent element will take these successive values over time. &lt; path d= '' '' &gt; &lt; animate attributeName= '' d '' begin= '' 0 '' dur= '' 0.45s '' values= '' M21.38 19.75 C21.79 19.93 22.23 20.16 22.69 20.43 ; M21.38 19.75 C21.79 19.93 22.23 20.16 22.69 20.43 C23.16 20.7 23.63 21.01 24.12 21.35 ; … '' / &gt; &lt; /path &gt; Based on the existing data , it is easy to develop further data concerning variations in stroke order or kanji form .</sentence>
				<definiendum id="0">“Han-China” )</definiendum>
				<definiens id="0">: &lt; path d= '' M21.38 , 19.75 , c3.31 , The d attribute of the path element contains the path data in a compact form. This data is a list of drawing commands that an SVG renderer will execute to draw the path. The path data for every stroke will consist of a sequence of Bézier curves , which are parametric curves defined by four control points. Several paths can be grouped together under a group element , which allows the association of groups of paths ( i.e. , lists of strokes ) with every grapheme element of a kanji. It is then possible to deal directly with grapheme elements in the graphic representation of the kanji , in order to highlight such elements ( as in figure 2 ) or to link them to other SVG files—e.g. clicking on the left component of would link it to the kanji ( mizu , “water” ) , which is this component’s standard form. The SVG data available so far is static. Our goal is to present it in a dynamic fashion , showing strokes one by one , in the order and the direction in which they should be drawn. We will add an animated child element to every path in the static SVG file to create its animated counterpart. The animate element controls the moment at which the path is drawn , and the shape it should take. Unfortunately there is no special command in SVG to draw a path progressively. A solution is to divide every path in several smaller ones , and to draw each segment one after another , giving the impression of an invisible pen drawing the kanji. Our division strategy is to segment every curve in a path into a fixed number of elements. That number of element is set to a power of two , because dividing Bézier curves into two is very easy to do. Longer strokes will consist of more curves than shorter ones , and it will take more to time to draw them ; the distribution of the control points along the curves makes the animation look quite natural. At the end , an animation is controlled by two parameters : the number of segments into which a curve is split and the time between the drawing of two strokes. Modifying these values will make the drawing slower or faster , and more or less smooth. The first stroke of our example kanji will now look like shown below. The animation will start at time 0 ; it lasts for 0.45 seconds and it will iterate over the values given by the value’s attribute. The d attribute in the path parent element will take these successive values over time. &lt; path d= '' '' &gt; &lt; animate attributeName= '' d '' begin= '' 0 '' dur= '' 0.45s '' values= '' M21.38 19.75 C21.79 19.93 22.23 20.16 22.69 20.43 ; M21.38 19.75 C21.79 19.93 22.23 20.16 22.69 20.43 C23.16 20.7 23.63 21.01 24.12 21.35 ; … '' / &gt; &lt; /path &gt; Based on the existing data , it is easy to develop further data concerning variations in stroke order or kanji form</definiens>
			</definition>
</paper>

		<paper id="1117">
			<definition id="0">
				<sentence>A semantic representation is a feature that allows one word in the sentence to point at some other word to which it is related .</sentence>
				<definiendum id="0">semantic representation</definiendum>
				<definiens id="0">a feature that allows one word in the sentence to point at some other word to which it is related</definiens>
			</definition>
			<definition id="1">
				<sentence>he tall two meters In the above framework , ‘tall’ is the semantic feature describing staturs of the agent ‘he’ , and ‘two meters’ express the value of the feature .</sentence>
				<definiendum id="0">‘tall’</definiendum>
				<definiens id="0">the semantic feature describing staturs of the agent ‘he’</definiens>
			</definition>
</paper>

		<paper id="3205">
			<definition id="0">
				<sentence>These extremely useful resources have very high precision entries but have important limitations when used in real-world NLP tasks due to their limited coverage and prescriptive nature ( i.e. they do not include semantic relations that are plausible but not guaranteed ) .</sentence>
				<definiendum id="0">prescriptive nature</definiendum>
				<definiens id="0">do not include semantic relations that are plausible but not guaranteed )</definiens>
			</definition>
			<definition id="1">
				<sentence>+Temporal Inclusion Entailment -Temporal Inclusion +Troponymy ( coextensiveness ) march-walk -Troponymy ( proper inclusion ) walk-step Backward Presupposition forget-know Cause show-see of strongly associated verb pairs .</sentence>
				<definiendum id="0">+Temporal Inclusion Entailment -Temporal Inclusion +Troponymy</definiendum>
			</definition>
			<definition id="2">
				<sentence>N is the number of words indexed by the search engine ( N ≈ 7.2 × 10 11 ) , C v is a correction factor to obtain the frequency of the verb V in all tenses from the frequency of the pattern �to V� .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of words indexed by the search engine</definiens>
				<definiens id="1">a correction factor to obtain the frequency of the verb V in all tenses from the frequency of the pattern �to V�</definiens>
			</definition>
			<definition id="3">
				<sentence>The Tags Correct column represents the percentage of verb pairs whose system output relations were deemed correct .</sentence>
				<definiendum id="0">Tags Correct column</definiendum>
				<definiens id="0">represents the percentage of verb pairs whose system output relations were deemed correct</definiens>
			</definition>
			<definition id="4">
				<sentence>The Preferred Tags Correct column gives the percentage of verb pairs whose system output relations matched exactly the human�s preferred relations .</sentence>
				<definiendum id="0">Preferred Tags Correct column</definiendum>
				<definiens id="0">gives the percentage of verb pairs whose system output relations matched exactly the human�s preferred relations</definiens>
			</definition>
			<definition id="5">
				<sentence>The stronger-than relation is a subset of the similarity relation .</sentence>
				<definiendum id="0">stronger-than relation</definiendum>
				<definiens id="0">a subset of the similarity relation</definiens>
			</definition>
			<definition id="6">
				<sentence>CORRECT PREFERRED SEMANTIC RELATION PAIRS WITH SYSTEM TAG ( IN BOLD ) JUDGE 1 JUDGE 2 JUDGE 1 JUDGE 2 X absolve Y is similar to X vindicate Y Yes Yes is similar to is similar to X bottom Y has no relation with X abate Y Yes Yes has no relation with has no relation with X outrage Y happens-after / is stronger than X shock Y Yes Yes happens-before / is stronger than happens-before/ is stronger than X pool Y has no relation with X increase Y Yes No has no relation with can result in X insure Y is similar to X expedite Y No No has no relation with has no relation with Table 4 .</sentence>
				<definiendum id="0">CORRECT PREFERRED SEMANTIC RELATION PAIRS WITH SYSTEM TAG</definiendum>
				<definiens id="0">no relation with X abate Y Yes Yes has no relation with has no relation with X</definiens>
			</definition>
</paper>

		<paper id="0909">
</paper>

		<paper id="2605">
			<definition id="0">
				<sentence>tactic positions ( or slots ) that alternate—such as snow occurring as intransitive subject and transitive object in the causative alternation in ( 1 ) ( Merlo and Stevenson , 2001 ; McCarthy , 2000 ) .</sentence>
				<definiendum id="0">tactic positions</definiendum>
			</definition>
			<definition id="1">
				<sentence>Formally , we define SPD as : a55a44a56a50a57a59a58 a22a24a23a28a25a28a27a50a29a32a31a26a60a62a61a10a63a64a42a28a22a65a23a26a25a28a27a30a29a32a31a14a66a6a67 a60a62a68a28a69 a34 a70 a71a14a72a21a73 a61a75a74a16a76a43a77 a67a10a78a80a79a32a81 a82 a72a21a73 a61a75a74a16a76a83a77 a67a85a84a62a86 a78a80a87 a88a21a89a90a25a21a91a44a92a65a93 a58a28a94 a42a21a95 a69a2a96 a95a18a97 a94 a93a85a88a21a92a99a98a19a31 a58a28a94 a42a21a95 a69 ( 1 ) where a100a43a101a102a3a43a103a99a104a106a105a21a107a26a108a40a109a83a110a112a111 is the portion of the profile score at node a113 in a0a13a1a14a3a6a5a15a7a16a9a64a114a116a115a28a117 that travels to node a118 in a0a2a1a4a3a6a5a8a7a10a9a21a119a121a120a28a114a28a122 , and a110a44a123a75a108a64a105a26a100a43a104a13a124a64a9a125a107a6a108a40a109a12a110a106a111 is the semantic distance between node a113 and node a118 in the hierarchy .</sentence>
				<definiendum id="0">a100a43a101a102a3a43a103a99a104a106a105a21a107a26a108a40a109a83a110a112a111</definiendum>
				<definiendum id="1">a110a44a123a75a108a64a105a26a100a43a104a13a124a64a9a125a107a6a108a40a109a12a110a106a111</definiendum>
				<definiens id="0">the portion of the profile score at node a113 in a0a13a1a14a3a6a5a15a7a16a9a64a114a116a115a28a117 that travels to node a118 in a0a2a1a4a3a6a5a8a7a10a9a21a119a121a120a28a114a28a122</definiens>
				<definiens id="1">the semantic distance between node a113</definiens>
			</definition>
			<definition id="2">
				<sentence>We take this into account in the a100a44a101 a3a44a103a99a104a106a105 function , by including a weight component : a13a15a14a17a16a19a18a21a20a23a22 a58a25a24 a42a7a26 a69 a34a28a27a30a29a32a31a34a33a36a35a36a22 a58 a26 a69a106a96a38a37 a16a40a39a40a22a6a31a25a16a40a20 a58a25a24 a69 ( 2 ) where a41a15a9a20a123a43a42a45a44a24a105a18a107a4a110a112a111 is the weight of the destination node a118 and a0a106a3a43a1a121a105a116a123a85a3a43a104 a107a26a108a12a111 is the portion of a108a18a124a4a3a44a1a14a9a65a107a26a108a12a111 that we are moving .</sentence>
				<definiendum id="0">a41a15a9a20a123a43a42a45a44a24a105a18a107a4a110a112a111</definiendum>
				<definiens id="0">the weight of the destination</definiens>
			</definition>
			<definition id="3">
				<sentence>SPD refers to SPD without entropy , using either a110a1a0a3a2 or a110a40a120a28a119a5a4a20a120 .</sentence>
				<definiendum id="0">SPD</definiendum>
				<definiens id="0">refers to SPD without entropy , using either a110a1a0a3a2 or a110a40a120a28a119a5a4a20a120</definiens>
			</definition>
			<definition id="4">
				<sentence>Given any pair of probability distributions over WordNet ( which we call a selectional profile ) , SPD captures in a single measure the aggregate semantic distance of the component nodes , weighted by their probability .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="5">
				<sentence>SPD achieves a best performance of 70 % accuracy ( baseline 50 % ) on unseen test verbs , and no other measure we tested performed consistently as well as it did , achieving best performance ( alone or tied ) in 9 of 12 development experiments , and best or second best in all three test scenarios .</sentence>
				<definiendum id="0">SPD</definiendum>
				<definiens id="0">achieves a best performance of 70 % accuracy ( baseline 50 % ) on unseen test verbs</definiens>
			</definition>
</paper>

		<paper id="1506">
			<definition id="0">
				<sentence>1This work is part of a general project ( http : //www.dlsi.ua.es/projectes/3lb ) which objective is to build three linguistically annotated corpora with linguistic annotation at syntactic , semantic and pragmatic levels : Cat3LB ( for Catalan ) , Cast3LB ( for Spanish ) ( Civit &amp; Martí , 2002 ) and Eus3LB ( for Basque ) .</sentence>
				<definiendum id="0">Cat3LB</definiendum>
				<definiens id="0">part of a general project ( http : //www.dlsi.ua.es/projectes/3lb ) which objective is to build three linguistically annotated corpora with linguistic annotation at syntactic , semantic and pragmatic levels</definiens>
			</definition>
			<definition id="1">
				<sentence>The Constraint Grammar ( CG ) formalism has been chosen in most cases because , on the one hand , it is suitable for treating unrestricted texts and , on the other hand , it provides a useful methodology and the tools to tackle morphosyntax as well as free order phrase components in a direct way .</sentence>
				<definiendum id="0">Constraint Grammar</definiendum>
				<definiens id="0">a useful methodology and the tools to tackle morphosyntax as well as free order phrase components in a direct way</definiens>
			</definition>
			<definition id="2">
				<sentence>Each tuple represents one relation in the dependency tree .</sentence>
				<definiendum id="0">tuple</definiendum>
				<definiens id="0">one relation in the dependency tree</definiens>
			</definition>
</paper>

		<paper id="0313">
			<definition id="0">
				<sentence>architecture ACT-R ACT-R is a theory of the human cognitive architecture .</sentence>
				<definiendum id="0">architecture ACT-R ACT-R</definiendum>
			</definition>
			<definition id="1">
				<sentence>“Environment” is the outside world that ACT-R is programmed to interact with .</sentence>
				<definiendum id="0">“Environment”</definiendum>
				<definiens id="0">the outside world that ACT-R is programmed to interact with</definiens>
			</definition>
			<definition id="2">
				<sentence>− Adv PP RC Data Reading times ( msec ) 0 200 400 600 800 1000 − Adv PP RC Model Reading times ( msec ) 0 200 400 600 800 1000 Figure 5 : Reading times from data versus model , at the first verb .</sentence>
				<definiendum id="0">Adv PP RC Model Reading times</definiendum>
				<definiens id="0">Reading times from data versus model</definiens>
			</definition>
			<definition id="3">
				<sentence>( 4 ) a1 a2a1a0 a2a4a3a6a5a8a7a9 a10a12a11a14a13a16a15 a10a18a17a20a19a22a21 Here , a23 is the number of times the chunk a0 was successfully retrieved , a15 a10 is the time elapsed since the a24 -th retrieval , and a25 is a decay rate that defaults to a26a28a27a30a29 in ACT-R .</sentence>
				<definiendum id="0">a23</definiendum>
				<definiendum id="1">a25</definiendum>
				<definiens id="0">the number of times the chunk a0 was successfully retrieved</definiens>
			</definition>
			<definition id="4">
				<sentence>Distance here is quantified in terms of the number of words in a constituent ( EIC ) or the number of new discourse referents introduced between the arguments and head ( DLT ) .</sentence>
				<definiendum id="0">Distance</definiendum>
				<definiens id="0">quantified in terms of the number of words in a constituent ( EIC ) or the number of new discourse referents introduced between the arguments and head ( DLT )</definiens>
			</definition>
</paper>

		<paper id="3256">
			<definition id="0">
				<sentence>Classification is defined as a task of classifying examples into one of a discrete set of possible categories ( Mitchell , 1997 ) .</sentence>
				<definiendum id="0">Classification</definiendum>
			</definition>
			<definition id="1">
				<sentence>Support Vector Machine Support Vector Machines ( SVMs ) have been shown to be an effective classifier in text categorization .</sentence>
				<definiendum id="0">Support Vector Machine Support Vector Machines ( SVMs</definiendum>
				<definiens id="0">an effective classifier in text categorization</definiens>
			</definition>
			<definition id="2">
				<sentence>Decision Tree ( 4.5 ) In addition to SVM , we also used a decision-tree algorithm , C4.5 ( Quinlan , 1993 ) , with the same training and testing data as SVM .</sentence>
				<definiendum id="0">Decision Tree</definiendum>
			</definition>
			<definition id="3">
				<sentence>The overall informativeness of each word w is : € C w = d itf w W itf w where d itf is the document set ITF of word w and W itf is the world ITF of w. A word that occurs frequently bears a lower C w score compared to a rarely used word ( bearing high information value ) with a higher C w score .</sentence>
				<definiendum id="0">W itf</definiendum>
				<definiens id="0">the world ITF of w. A word that occurs frequently bears a lower C w score compared to a rarely used word ( bearing high information value</definiens>
			</definition>
</paper>

		<paper id="0309">
			<definition id="0">
				<sentence>The ERH is the proposal that fluctuations in this value be taken as psycholinguistic predictions .</sentence>
				<definiendum id="0">ERH</definiendum>
				<definiens id="0">the proposal that fluctuations in this value be taken as psycholinguistic predictions</definiens>
			</definition>
			<definition id="1">
				<sentence>Grenander’s theorem is a recurrence relation that gives the entropy of each nonterminal in a PCFG G as the sum of two terms .</sentence>
				<definiendum id="0">Grenander’s theorem</definiendum>
				<definiens id="0">a recurrence relation that gives the entropy of each nonterminal in a PCFG G as the sum of two terms</definiens>
			</definition>
			<definition id="2">
				<sentence>For PCFGs that define a probability distribution , the solution to this recurrence can be written as a matrix equation where I is the identity matrix , vectorh the vector of the h ( ξi ) and A is a matrix whose ( i , j ) th component gives the expected number of nonterminals of type j resulting from nonterminals of type i. H = ( I −A ) −1vectorh ( 2 ) Grenander’s theorem supplies the entropy for any PCFG nonterminal in one step by inverting a matrix .</sentence>
				<definiendum id="0">A</definiendum>
				<definiendum id="1">2 ) Grenander’s theorem</definiendum>
				<definiens id="0">supplies the entropy for any PCFG nonterminal in one step by inverting a matrix</definiens>
			</definition>
			<definition id="3">
				<sentence>If L ( G ) is the language of the grammar G , parsing an initial substring w is the intersection depicted in 3 where the period denotes any terminal symbol of G and the Kleene star indicates any number of repetitions .</sentence>
				<definiendum id="0">period</definiendum>
				<definiens id="0">the language of the grammar G , parsing an initial substring w is the intersection depicted in 3 where the</definiens>
				<definiens id="1">any terminal symbol of G and the Kleene star indicates any number of repetitions</definiens>
			</definition>
			<definition id="4">
				<sentence>The AH is an implicational markedness hierarchy of grammatical relations discovered by Keenan and Comrie in ( 1977 ) .</sentence>
				<definiendum id="0">AH</definiendum>
				<definiens id="0">an implicational markedness hierarchy of grammatical relations discovered by Keenan and Comrie in ( 1977 )</definiens>
			</definition>
			<definition id="5">
				<sentence>The hierarchy also figures in LexicalFunctional Grammar ( Bresnan , 1982 ) where it is known as Syntactic Rank .</sentence>
				<definiendum id="0">hierarchy also</definiendum>
				<definiens id="0">figures in LexicalFunctional Grammar ( Bresnan , 1982 ) where it is known as Syntactic Rank</definiens>
			</definition>
			<definition id="6">
				<sentence>An ERH account that avoids predicting these outliers on the Keenan and Hawkins ( 1987 ) stimuli seems to require a grammar where the probability of 2nd and subsequent stacked relative clause modifiers is closer to 0 ( its value on the trained promotion grammar ) than to 0.31 ( its value on the trained adjunction grammar ) .</sentence>
				<definiendum id="0">ERH account</definiendum>
				<definiens id="0">the probability of 2nd and subsequent stacked relative clause modifiers is closer to 0 ( its value on the trained promotion grammar ) than to 0.31 ( its value on the trained adjunction grammar )</definiens>
			</definition>
</paper>

		<paper id="0837">
</paper>

		<paper id="2105">
			<definition id="0">
				<sentence>Word access is an obligatory step in language production .</sentence>
				<definiendum id="0">Word access</definiendum>
			</definition>
			<definition id="1">
				<sentence>A Figure 1 : Search based on propagation in a network ( internal representation ) word amounts thus to entering the network and following the links leading from the source node ( the first word that comes to your mind ) to the target word ( the one you are looking for ) .</sentence>
				<definiendum id="0">node</definiendum>
				<definiens id="0">Search based on propagation in a network ( internal representation ) word amounts thus to entering the network and following the links leading from the source</definiens>
			</definition>
			<definition id="2">
				<sentence>Readability is hampered by at least two factors : high connectivity ( the great number of links or associations emanating from each word ) , and distribution : conceptually related nodes , that is , nodes activated by the same kind of assocation are scattered around , that is , they do not necessarily occur next to each other , which is quite confusing for the user .</sentence>
				<definiendum id="0">Readability</definiendum>
				<definiendum id="1">high connectivity</definiendum>
				<definiens id="0">the great number of links or associations emanating from each word )</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , Mel’cuk’s lexical functions ( Mel’cuk , 1992 ) , Fillmore’s FRAMENET13 , work on ontologies ( CYC ) , thesaurus ( Roget ) , WordNets ( the original version from Princeton , divers EuroWordNets , BalkaNet ) , HowNet14 , the work done by MICRA , the FACTOTUM project15 or the Wordsmyth dictionary/thesaurus combination16 .</sentence>
				<definiendum id="0">CYC</definiendum>
				<definiens id="0">the original version from Princeton</definiens>
			</definition>
			<definition id="4">
				<sentence>Introduction to WordNet : An On-line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="2611">
			<definition id="0">
				<sentence>The Metathesaurus is at the core and contains more than 900,000 concepts compiled from more than sixty controlled vocabularies .</sentence>
				<definiendum id="0">Metathesaurus</definiendum>
				<definiens id="0">at the core and contains more than 900,000 concepts compiled from more than sixty controlled vocabularies</definiens>
			</definition>
			<definition id="1">
				<sentence>Editors combine terms in the constituent vocabularies into a set of synonyms ( cf. WordNet’s synsets ) , which constitutes a concept .</sentence>
				<definiendum id="0">Editors</definiendum>
				<definiens id="0">combine terms in the constituent vocabularies into a set of synonyms ( cf. WordNet’s synsets ) , which constitutes a concept</definiens>
			</definition>
			<definition id="2">
				<sentence>Indicator rules map between syntactic phenomena ( such as verbs , nominalizations , and prepositions ) and predicates in the Semantic Network .</sentence>
				<definiendum id="0">Indicator rules</definiendum>
			</definition>
			<definition id="3">
				<sentence>( 4 ) Mycoplasma pneumonia is an infection of the lung caused by Mycoplasma pneumoniae ( 5 ) [ [ Mycoplasma pneumonia ] [ is ] [ an infection ] [ of the lung ] [ caused ] [ by Mycoplasma pneumoniae ] ] ( 6 ) “Mycoplasma pneumonia”–‘Disease or Syndrome’ ”Infection”–‘Disease or Syndrome’ ”Lung”–‘Body Part , Organ , or Organ Component’ ”Mycoplasma pneumoniae”–‘Bacterium’ ( 7 ) Mycoplasma Pneumonia ISA Infection Lung LOCATION_OF Infection Lung LOCATION_OF Mycoplasma Pneumonia Mycoplasma pneumoniae CAUSES Infection Mycoplasma pneumoniae CAUSES Mycoplasma Pneumonia 3 Automatic Summarization Automatic summarization is “a reductive transformation of source text to summary text through content reduction , selection , and/or generalization on what is important in the source” ( Sparck Jones , 1999 ) .</sentence>
				<definiendum id="0">Organ Component’ ”Mycoplasma pneumoniae”–‘Bacterium’</definiendum>
				<definiendum id="1">Mycoplasma Pneumonia ISA Infection Lung LOCATION_OF Infection Lung LOCATION_OF Mycoplasma Pneumonia Mycoplasma pneumoniae CAUSES Infection</definiendum>
				<definiens id="0">Mycoplasma pneumoniae CAUSES Mycoplasma Pneumonia 3 Automatic Summarization Automatic summarization is “a reductive transformation of source text to summary text through content reduction , selection , and/or generalization on what is important in the source”</definiens>
			</definition>
			<definition id="4">
				<sentence>A recent study ( Kan et al. , 2001 ) uses topic composition from text headers , but other studies in the extraction paradigm ( Goldstein et al. , 1999 ) , extraction coupled with rhetorical structural identification ( Teufel and Moens , 2002 ) , and syntactic abstraction paradigms use different methodologies ( Barzilay et al. , 1999 ; McKeown et al. , 1999 ) .</sentence>
				<definiendum id="0">recent study</definiendum>
				<definiens id="0">uses topic composition from text headers</definiens>
			</definition>
			<definition id="5">
				<sentence>In Table 1 , “Base” is the number of predications SemRep produced from eac of 300 citations .</sentence>
				<definiendum id="0">“Base”</definiendum>
				<definiens id="0">the number of predications SemRep produced from eac of 300 citations</definiens>
			</definition>
			<definition id="6">
				<sentence>“Final” is the number of predications left after the final transformation .</sentence>
				<definiendum id="0">“Final”</definiendum>
				<definiens id="0">the number of predications left after the final transformation</definiens>
			</definition>
</paper>

		<paper id="2205">
			<definition id="0">
				<sentence>First ( 1 ) , the French interlocutor takes a turn of one or more utterances .</sentence>
				<definiendum id="0">French interlocutor</definiendum>
				<definiens id="0">takes a turn of one or more utterances</definiens>
			</definition>
			<definition id="1">
				<sentence>An ERIM-paST ( partially automated Speech Translation ) platform is in progress at CLIPS in Grenoble , originally in cooperation with Spoken Translation Inc. ( Berkeley ) .</sentence>
				<definiendum id="0">ERIM-paST</definiendum>
			</definition>
			<definition id="2">
				<sentence>Objective is to carry out comparative assessment of their results , or possibly contrastive evaluation with the human production of an interpreter `` warm body '' .</sentence>
				<definiendum id="0">Objective</definiendum>
				<definiens id="0">to carry out comparative assessment of their results</definiens>
			</definition>
			<definition id="3">
				<sentence>Experiments ( Grades from 0 to 5 ) text voice : record then send voice : record &amp; send ( streaming ) voice : same with overlapping Streaming — — + + Connexion : Internet 100 Mbit = = = Reception quality 5 5 3 1 Speed of exchange 5 2 4 5 Reliability 5 5 4 1 Special problems / phenomena None User wary ( too slow ) Some micro-cuts , but good overall quality Unusable , bandwidth too large Figure 5 : Oral communication over the web speech corpora The system has been used in the ChinFaDial project for collecting bilingual French-Chinese interpreted spontaneous spoken dialogues , in the hotel reservation domain .</sentence>
				<definiendum id="0">Experiments</definiendum>
				<definiens id="0">Oral communication over the web speech corpora The system has been used in the ChinFaDial project for collecting bilingual French-Chinese interpreted spontaneous spoken dialogues , in the hotel reservation domain</definiens>
			</definition>
			<definition id="4">
				<sentence>ERIM-Collect is a deliberate development of the latter , dedicated to multilingual `` raw '' speech corpus building , and intended to alleviate the current scarcity of data —particularly open data— , and which can also support the construction of speech translation systems .</sentence>
				<definiendum id="0">ERIM-Collect</definiendum>
				<definiens id="0">a deliberate development of the latter , dedicated to multilingual `` raw '' speech corpus building , and intended to alleviate the current scarcity of data —particularly open data—</definiens>
			</definition>
</paper>

		<paper id="2902">
</paper>

		<paper id="0829">
</paper>

		<paper id="3247">
			<definition id="0">
				<sentence>Text summarization is the process of automatically creating a compressed version of a given text that provides useful information for the user .</sentence>
				<definiendum id="0">Text summarization</definiendum>
				<definiens id="0">the process of automatically creating a compressed version of a given text that provides useful information for the user</definiens>
			</definition>
			<definition id="1">
				<sentence>The centroid of a cluster is a pseudodocument which consists of words that have frequency*IDF scores above a predefined threshold .</sentence>
				<definiendum id="0">centroid of a cluster</definiendum>
				<definiens id="0">a pseudodocument which consists of words that have frequency*IDF scores above a predefined threshold</definiens>
			</definition>
			<definition id="2">
				<sentence>We define degree centrality as the degree of each node in the similarity graph .</sentence>
				<definiendum id="0">degree centrality</definiendum>
				<definiens id="0">the degree of each node in the similarity graph</definiens>
			</definition>
			<definition id="3">
				<sentence>More formally , the PageRank of a page a14 is given as follows : PRa15a16a14a18a17a20a19a21a15a22a5a24a23a26a25a27a17a29a28a30a25a31a15 PRa15a33a32 a0 a17 Ca15a33a32 a0 a17 a28a34a3a35a3a35a3a36a28 PRa15a33a32a24a37a31a17 Ca15a33a32 a37 a17 a17 ( 1 ) where a32 a0 a3a35a3a35a3a32 a37 are pages that link to a14 , Ca15a33a32a39a38a40a17 is the number of outgoing links from page a32a41a38 , and a25 is the damping factor which can be set between a2 and a5 .</sentence>
				<definiendum id="0">Ca15a33a32a39a38a40a17</definiendum>
				<definiendum id="1">a25</definiendum>
				<definiens id="0">the number of outgoing links from page a32a41a38 , and</definiens>
			</definition>
			<definition id="4">
				<sentence>ROUGE is a recallbased metric for fixed-length summaries which is based on n-gram co-occurence .</sentence>
				<definiendum id="0">ROUGE</definiendum>
				<definiens id="0">a recallbased metric for fixed-length summaries which is based on n-gram co-occurence</definiens>
			</definition>
			<definition id="5">
				<sentence>Position is the normalized value of the position of a sentence in the document such that the first sentence of a document gets the maximum Position value of 1 , and the last sentence gets the value 0 .</sentence>
				<definiendum id="0">Position</definiendum>
				<definiens id="0">the normalized value of the position of a sentence in the document such that the first sentence of a document gets the maximum Position value of 1</definiens>
			</definition>
			<definition id="6">
				<sentence>Policy ROUGE-1 ROUGE-2 ROUGE-W Code ( unigram ) ( bigram ) ( LCS ) degree0.5T0.1 0.38304 0.09204 0.13275 degree1T0.1 0.38188 0.09430 0.13284 lpr2T0.1 0.38079 0.08971 0.12984 lpr1.5T0.1 0.37873 0.09068 0.13032 lpr0.5T0.1 0.37842 0.08972 0.13121 lpr1T0.1 0.37700 0.09174 0.13096 C0.5 0.37672 0.09233 0.13230 lpr1T0.2 0.37667 0.09115 0.13234 lpr0.5T0.2 0.37482 0.09160 0.13220 C1 0.37464 0.09210 0.13071 lpr1T0.3 0.37448 0.08767 0.13302 degree0.5T0.2 0.37432 0.09124 0.13185 lpr0.5T0.3 0.37362 0.08981 0.13173 degree2T0.1 0.37338 0.08799 0.12980 degree1.5T0.1 0.37324 0.08803 0.12983 degree0.5T0.3 0.37096 0.09197 0.13236 lpr1.5T0.2 0.37058 0.08658 0.12965 C1.5 0.36885 0.08765 0.12747 lead-based 0.36859 0.08669 0.13196 lpr1.5T0.3 0.36849 0.08455 0.13111 lpr2T0.3 0.36737 0.08182 0.13040 lpr2T0.2 0.36737 0.08264 0.12891 C2 0.36710 0.08696 0.12682 degree1T0.2 0.36653 0.08572 0.13011 degree1T0.3 0.36517 0.08870 0.13046 degree1.5T0.3 0.35500 0.08014 0.12828 degree1.5T0.2 0.35200 0.07572 0.12484 degree2T0.3 0.34337 0.07576 0.12523 degree2T0.2 0.34333 0.07167 0.12302 random 0.32381 0.05285 0.11623 Table 2 : Results for Task 2 Policy ROUGE-1 ROUGE-2 ROUGE-W Code ( unigram ) ( bigram ) ( LCS ) Task 4a lpr1.5T0.1 0.39997 0.11030 0.12427 lpr1.5T0.2 0.39970 0.11508 0.12422 lpr2T0.2 0.39954 0.11417 0.12468 lpr2T0.1 0.39809 0.11033 0.12357 lpr1T0.2 0.39614 0.11266 0.12350 degree2T0.2 0.39574 0.11590 0.12410 degree1.5T0.2 0.39395 0.11360 0.12329 lpr0.5T0.1 0.39369 0.10665 0.12287 lpr1T0.1 0.39312 0.10730 0.12274 degree1T0.2 0.39241 0.11298 0.12277 degree2T0.1 0.39217 0.10977 0.12205 degree0.5T0.2 0.39076 0.11026 0.12236 degree0.5T0.1 0.39016 0.10831 0.12292 C0.5 0.39013 0.10459 0.12202 lpr0.5T0.2 0.38899 0.10891 0.12200 degree1T0.1 0.38882 0.10812 0.12286 lpr1T0.3 0.38777 0.10586 0.12157 lpr0.5T0.3 0.38667 0.10255 0.12244 degree1.5T0.1 0.38634 0.10882 0.12136 degree0.5T0.3 0.38568 0.10818 0.12088 degree1.5T0.3 0.38553 0.10683 0.12064 degree2T0.3 0.38506 0.10910 0.12075 degree1T0.3 0.38412 0.10568 0.11961 lpr1.5T0.3 0.38251 0.10610 0.12039 C1 0.38181 0.10023 0.11909 lpr2T0.3 0.38096 0.10497 0.12001 C1.5 0.38074 0.09922 0.11804 C2 0.38001 0.09901 0.11772 lead-based 0.37880 0.09942 0.12218 random 0.35929 0.08121 0.11466 Task 4b lpr1.5T0.1 0.40639 0.12419 0.13445 degree2T0.1 0.40572 0.12421 0.13293 lpr2T0.1 0.40529 0.12530 0.13346 C1.5 0.40344 0.12824 0.13023 degree1.5T0.1 0.40190 0.12407 0.13314 C2 0.39997 0.12367 0.12873 degree2T0.3 0.39911 0.11913 0.12998 lpr2T0.3 0.39859 0.11744 0.12924 lpr1.5T0.3 0.39858 0.11737 0.13044 lpr1.5T0.2 0.39819 0.12228 0.12989 lpr2T0.2 0.39763 0.12114 0.12924 degree2T0.2 0.39752 0.12352 0.12958 lpr1T0.1 0.39552 0.12045 0.13304 degree1.5T0.3 0.39538 0.11515 0.12879 lpr1T0.2 0.39492 0.12056 0.13061 C1 0.39388 0.12301 0.12805 degree1.5T0.2 0.39386 0.12018 0.12945 lpr1T0.3 0.39053 0.11500 0.13044 degree1T0.1 0.39039 0.11918 0.13113 degree1T0.2 0.38973 0.11722 0.12793 degree1T0.3 0.38658 0.11452 0.12780 lpr0.5T0.1 0.38374 0.11331 0.12954 lpr0.5T0.2 0.38201 0.11201 0.12757 degree0.5T0.2 0.38029 0.11335 0.12780 degree0.5T0.1 0.38011 0.11320 0.12921 C0.5 0.37601 0.11123 0.12605 lpr0.5T0.3 0.37525 0.11115 0.12898 degree0.5T0.3 0.37455 0.11307 0.12857 random 0.37339 0.09225 0.12205 lead-based 0.35872 0.10241 0.12496 Table 3 : Results for Task 4 We ran MEAD with several policies with different feature weights and combinations of features .</sentence>
				<definiendum id="0">Policy ROUGE-1 ROUGE-2 ROUGE-W Code ( unigram )</definiendum>
				<definiens id="0">Results for Task 2 Policy ROUGE-1 ROUGE-2 ROUGE-W Code ( unigram ) ( bigram ) ( LCS</definiens>
			</definition>
			<definition id="7">
				<sentence>Finally , ‘CX’ shows a policy with Centroid weight a0 .</sentence>
				<definiendum id="0">‘CX’</definiendum>
			</definition>
</paper>

		<paper id="2701">
</paper>

		<paper id="0819">
			<definition id="0">
				<sentence>The PropBank annotations ( www.cis.upenn.edu/ ace ) enable training for two distinct learning techniques : ( 1 ) decision trees ( Surdeanu et al. , 2003 ) and ( 2 ) Support Vector Machines ( SVMs ) ( Pradhan et al. , 2004 ) .</sentence>
				<definiendum id="0">PropBank annotations</definiendum>
			</definition>
			<definition id="1">
				<sentence>− POSITION ( pos ) − Indicates if the constituent appears before or after the the predicate in the sentence .</sentence>
				<definiendum id="0">POSITION</definiendum>
				<definiens id="0">Indicates if the constituent appears before or after the the predicate in the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Case and morphological information − HEAD WORD ( hw ) − This feature contains the head word − PARSE TREE PATH ( path ) : This feature contains the path in the parse tree between the predicate phrase and the labels linked by direction symbols ( up or down ) , e.g. − PHRASE TYPE ( pt ) : This feature indicates the syntactic noun phrases only , and it indicates if the NP is dominated by a sentence phrase ( typical for subject arguments with active−voice predicates ) , or by a verb phrase ( typical for object arguments ) .</sentence>
				<definiendum id="0">morphological information − HEAD WORD</definiendum>
				<definiendum id="1">PARSE TREE PATH</definiendum>
				<definiens id="0">dominated by a sentence phrase ( typical for subject arguments with active−voice predicates ) , or by a verb phrase ( typical for object arguments</definiens>
			</definition>
			<definition id="3">
				<sentence>− GOVERNING CATEGORY ( gov ) − This feature applies to type of the phrase labeled as a frame element , e.g. target word , expressed as a sequence of nonterminal − TARGET WORD − In our implementation this feature ( 2 ) LEMMA which represents the target normalized to lower the case and morphological information preserved ; and consists of two components : ( 1 ) WORD : the word itself with case and infinitive form for the verbs or singular for nouns .</sentence>
				<definiendum id="0">− GOVERNING CATEGORY</definiendum>
				<definiendum id="1">WORD</definiendum>
				<definiens id="0">type of the phrase labeled as a frame element</definiens>
			</definition>
			<definition id="4">
				<sentence>Similarly , if the SBAR is “that occurred yesterday” , instead of using the head “that” we select “occurred” , the head of the VP .</sentence>
				<definiendum id="0">SBAR</definiendum>
				<definiens id="0">“that occurred yesterday”</definiens>
			</definition>
			<definition id="5">
				<sentence>PART OF SPEECH OF CONTENT WORD ( cPos ) −The part of speech tag of the content word .</sentence>
				<definiendum id="0">PART OF SPEECH OF CONTENT WORD</definiendum>
				<definiens id="0">−The part of speech tag of the content word</definiens>
			</definition>
			<definition id="6">
				<sentence>Feature SUPPORT VERBS considers the usage of support expressions in FrameNet .</sentence>
				<definiendum id="0">Feature SUPPORT VERBS</definiendum>
				<definiens id="0">considers the usage of support expressions in FrameNet</definiens>
			</definition>
			<definition id="7">
				<sentence>The CORENESS feature takes advantage of a more recent implementation concept of core FEs ( vs. non-core FEs ) in FrameNet .</sentence>
				<definiendum id="0">CORENESS feature</definiendum>
				<definiens id="0">takes advantage of a more recent implementation concept of core FEs ( vs. non-core FEs ) in FrameNet</definiens>
			</definition>
			<definition id="8">
				<sentence>The values of this feature are either ( 1 ) The POS of the head of the VP containing the target word or ( 2 ) NULL if the target word does not belong to a VP or ADJECTIVE LIST_CONSTITUENT ( FEs ) : This feature represents a list of the syntactic Grammatical Function : This feature indicates whether the FE is : − an External Argument ( Ext ) − an Object ( Obj ) − a Complement ( Comp ) − a Modifier ( Mod ) − Head noun modified by attributive adjective ( Head ) − Genitive determiner ( Gen ) − Appositive ( Appos ) LIST_Grammatical_Function : This feature represents a list of the grammatical functions of the FEs recognized in the sentence .</sentence>
				<definiendum id="0">External Argument</definiendum>
				<definiendum id="1">LIST_Grammatical_Function</definiendum>
				<definiens id="0">a Complement ( Comp ) − a Modifier ( Mod ) − Head noun modified by attributive adjective ( Head ) − Genitive determiner ( Gen ) − Appositive ( Appos )</definiens>
				<definiens id="1">a list of the grammatical functions of the FEs recognized in the sentence</definiens>
			</definition>
			<definition id="9">
				<sentence>( 2 ) a hyponym of sense 1 of PERSON in WordNet ( 1 ) a personal pronoun or HUMAN : This feature indicates whether the syntactic phrase is either TARGET−TYPE : the lexical class of the target word , e.g. VERB , NOUN consituents covering each FE of the frame recognized in a sentence .</sentence>
				<definiendum id="0">HUMAN</definiendum>
				<definiens id="0">the lexical class of the target word , e.g. VERB , NOUN consituents covering each FE of the frame recognized in a sentence</definiens>
			</definition>
			<definition id="10">
				<sentence>For example , if the target word is `` clever '' in the sentence `` Smith is very clever , but he’s no Einstein '' , the the FE `` Smith '' is an argument of the support verb `` is '' ’ rather than of the CORENESS : This feature indicates whether the FE instantiates REVENGE frame , Punishment is a core element .</sentence>
				<definiendum id="0">Punishment</definiendum>
				<definiens id="0">This feature indicates whether the FE instantiates REVENGE frame</definiens>
				<definiens id="1">a core element</definiens>
			</definition>
</paper>

		<paper id="1218">
			<definition id="0">
				<sentence>f4 Probabilites of all classes if higher than zero , calculated by the second-order Markov Model .</sentence>
				<definiendum id="0">Probabilites of all classes</definiendum>
				<definiens id="0">if higher than zero , calculated by the second-order Markov Model</definiens>
			</definition>
			<definition id="1">
				<sentence>We trained TnT ( Brants , 1998 ) , a Markov Model implemented for POS-tagging on the surface words , and used the probabilities for all classes as features for the SVMs ( feature set f4 on Table 1 ) .</sentence>
				<definiendum id="0">TnT</definiendum>
				<definiens id="0">a Markov Model implemented for POS-tagging on the surface words</definiens>
			</definition>
			<definition id="2">
				<sentence>• The discourse level describes all occurrences of a word form within a text unit and the semantic labels assigned to them .</sentence>
				<definiendum id="0">discourse level</definiendum>
				<definiens id="0">describes all occurrences of a word form within a text unit and the semantic labels assigned to them</definiens>
			</definition>
			<definition id="3">
				<sentence>Additionally , the NEs occurring within the GENIA corpus consist in average of more than two words and seem to be diverse in their appearance , even within one document .</sentence>
				<definiendum id="0">NEs occurring</definiendum>
				<definiens id="0">within the GENIA corpus consist in average of more than two words and seem to be diverse in their appearance</definiens>
			</definition>
</paper>

		<paper id="1710">
</paper>

		<paper id="0814">
			<definition id="0">
				<sentence>The LF formalism is a simple logical form language for natural language semantics with only predicates and variables ; there is no quantification or negation , and atomic predications are implicitly conjoined .</sentence>
				<definiendum id="0">LF formalism</definiendum>
			</definition>
			<definition id="1">
				<sentence>For nouns , the semantic class of a word is defined as the hypernym of the first sense of the noun in WordNet , one of 19 manually selected terms ( animal , person , social group , clothes , feeling , property , phenomenon , etc. ) For lexical adverbs and prepositions , the semantic class is one of the 6 clusters obtained automatically using the K-mean clustering algorithm on data extracted from FrameNet .</sentence>
				<definiendum id="0">semantic class of a word</definiendum>
				<definiens id="0">one of 19 manually selected terms ( animal , person , social group , clothes , feeling , property , phenomenon , etc. ) For lexical adverbs and prepositions , the semantic class is one of the 6 clusters obtained automatically using the K-mean clustering algorithm on data extracted from FrameNet</definiens>
			</definition>
			<definition id="2">
				<sentence>Our LF generator traverses the dependency structure , turning POStagged lexical items into LF predicates , creating referential variables for nouns and verbs , and using dependency labels to order the arguments for each predicate .</sentence>
				<definiendum id="0">LF generator</definiendum>
				<definiens id="0">traverses the dependency structure , turning POStagged lexical items into LF predicates , creating referential variables for nouns and verbs</definiens>
			</definition>
			<definition id="3">
				<sentence>About 50 of these 135 labels are dependencies that can be ignored in the generation of LFs ( labels involving punctuation , determiners , auxiliary verbs , etc. ) ; of the remaining 85 labels , the 45 labels handled were chosen to provide reasonable coverage over the sample corpus provided by the task organizers .</sentence>
				<definiendum id="0">LFs</definiendum>
				<definiens id="0">labels involving punctuation , determiners , auxiliary verbs</definiens>
			</definition>
</paper>

		<paper id="1708">
			<definition id="0">
				<sentence>The first part involves a test sentence selection part to achieve precise measurement with a small test set .</sentence>
				<definiendum id="0">first part</definiendum>
				<definiens id="0">involves a test sentence selection part to achieve precise measurement with a small test set</definiens>
			</definition>
			<definition id="1">
				<sentence>The first set consists of 330 sentences , each translated to English by29 subjects with varied English proficiency .</sentence>
				<definiendum id="0">first set</definiendum>
			</definition>
			<definition id="2">
				<sentence>SDP ( Wa ; Wb ) = T ¡S ¡I ¡DT ( 1 ) where T is the total number of words in Wa , S is the number of substitution words for comparing Wa to Wb , I is the number of inserted words for comparing Wa to Wb , and D is the number of deleted words for comparing Wa to Wb .</sentence>
				<definiendum id="0">SDP</definiendum>
				<definiendum id="1">T</definiendum>
				<definiendum id="2">S</definiendum>
				<definiendum id="3">D</definiendum>
				<definiens id="0">the total number of words in Wa ,</definiens>
			</definition>
			<definition id="3">
				<sentence>Using Equation1 , ( Si ( j ) ) , that is , the test sentence unit DP-score of the translation of test sentence j done by subject i , can be calculated by the following formula .</sentence>
				<definiendum id="0">Si</definiendum>
				<definiens id="0">( j ) ) , that is , the test sentence unit DP-score of the translation of test sentence j done by subject i , can be calculated by the following formula</definiens>
			</definition>
			<definition id="4">
				<sentence>SDPi ( j ) = max k=1 to Nref n SDP ( Wref ( k ) ( j ) ; Wsub ( i ) ( j ) ) ; 0 o ( 2 ) where Nref is the number of references , Wref ( k ) ( j ) is the k-th reference of the test sentence j , and Wsub ( i ) ( j ) is the translation of the test sentence j done by subject i. Finally , SDPi , which is the test set unit DPscore of subject i , can be calculated by the following formula .</sentence>
				<definiendum id="0">SDPi</definiendum>
				<definiendum id="1">Nref</definiendum>
				<definiendum id="2">Wref ( k )</definiendum>
				<definiens id="0">the number of references</definiens>
				<definiens id="1">the k-th reference of the test sentence j</definiens>
			</definition>
			<definition id="5">
				<sentence>SDPi = 1N sent NsentX j=1 SDPi ( j ) ( 3 ) where Nsent is the number of test sentences .</sentence>
				<definiendum id="0">Nsent</definiendum>
				<definiens id="0">the number of test sentences</definiens>
			</definition>
			<definition id="6">
				<sentence>Equation4 is the test sentence unit BLEU score formulation of the translation of test sentence j done by subject i. SBLEUi ( j ) = exp ( NX n=1 wn log ( pn ) ¡max ˆL⁄ ref Lsys ¡1 ; 0 ! )</sentence>
				<definiendum id="0">Equation4</definiendum>
				<definiens id="0">the test sentence unit BLEU score formulation of the translation of test sentence j done by subject i. SBLEUi ( j ) = exp ( NX n=1 wn log</definiens>
			</definition>
			<definition id="7">
				<sentence>SLTA1 SLTA1 consists of 330 sentences in 23 conversations from the ATR bilingual travel conversation database ( Takezawa , 1999 ) .</sentence>
				<definiendum id="0">SLTA1 SLTA1</definiendum>
			</definition>
			<definition id="8">
				<sentence>Comparing BTEC and SLTA1 , BTEC contains more cumbersome test sentences .</sentence>
				<definiendum id="0">BTEC</definiendum>
			</definition>
			<definition id="9">
				<sentence>E = vu ut 1 Nuser NuserX i=1 ( Ti ¡Ai ) 2 ( 8 ) where Nuser is the number of users , Ti is the actual TOEIC score of user i , and Ai is user i’s estimated TOEIC score by using the proposed method .</sentence>
				<definiendum id="0">Nuser</definiendum>
				<definiendum id="1">Ti</definiendum>
				<definiendum id="2">Ai</definiendum>
				<definiens id="0">the number of users</definiens>
				<definiens id="1">the actual TOEIC score of user i , and</definiens>
			</definition>
			<definition id="10">
				<sentence>In these figures , the abscissa represents the number of test sentences , and the ordinate represents the standard error .</sentence>
				<definiendum id="0">ordinate</definiendum>
				<definiens id="0">the number of test sentences , and the</definiens>
			</definition>
			<definition id="11">
				<sentence>In the experiments , we used TOEIC as an objective measure of English language proficiency .</sentence>
				<definiendum id="0">TOEIC</definiendum>
				<definiens id="0">an objective measure of English language proficiency</definiens>
			</definition>
</paper>

		<paper id="2424">
			<definition id="0">
				<sentence>For example , John is the Agent or Arg0 of John broke the window , IBM is the Theme or Arg1 of IBM rose 1.2 points .</sentence>
				<definiendum id="0">IBM</definiendum>
				<definiens id="0">the Agent or Arg0 of John broke the window</definiens>
			</definition>
			<definition id="1">
				<sentence>There is a complementary lexicography project at Berkeley , Chuck Fillmore’s FRAMENET , which provides representative annotated samples rather than broad-coverage annotation , and there are current plans to combine these resources and train automatic labelers for English and Chinese .</sentence>
				<definiendum id="0">Chuck Fillmore’s FRAMENET</definiendum>
				<definiens id="0">provides representative annotated samples rather than broad-coverage annotation</definiens>
			</definition>
</paper>

		<paper id="0836">
			<definition id="0">
				<sentence>MiniCors-Cat is a semantically tagged corpus according to the Senseval lexical sample setting , so one single target word per example is semantically labeled with the MiniDir-Cat sense repository .</sentence>
				<definiendum id="0">MiniCors-Cat</definiendum>
				<definiens id="0">a semantically tagged corpus according to the Senseval lexical sample setting</definiens>
			</definition>
			<definition id="1">
				<sentence>For instance , Duluth-CLSS applies a bagging–based ensemble of Decision Trees .</sentence>
				<definiendum id="0">Duluth-CLSS</definiendum>
				<definiens id="0">applies a bagging–based ensemble of Decision Trees</definiens>
			</definition>
			<definition id="2">
				<sentence>The Duluth-CLSS system is a replica of the one presented at the Senseval-2 English lexical sample task .</sentence>
				<definiendum id="0">Duluth-CLSS system</definiendum>
				<definiens id="0">a replica of the one presented at the Senseval-2 English lexical sample task</definiens>
			</definition>
			<definition id="3">
				<sentence>Interestingly , IRST is the best system addressing the words with few examples per sense , suggesting that SVM is a good algorithm for training on small datasets , but loses this advantage for the words with more examples .</sentence>
				<definiendum id="0">IRST</definiendum>
				<definiens id="0">the best system addressing the words with few examples per sense , suggesting that SVM is a good algorithm for training on small datasets</definiens>
			</definition>
</paper>

		<paper id="1910">
			<definition id="0">
				<sentence>A treebank is a collection of syntactically annotated sentences in which the annotation has been manually checked so that the treebank can serve as training corpus for natural language parsers , as repository for linguistic research , or as evaluation corpus for NLP systems .</sentence>
				<definiendum id="0">treebank</definiendum>
				<definiens id="0">a collection of syntactically annotated sentences in which the annotation has been manually checked so that the treebank can serve as training corpus for natural language parsers</definiens>
			</definition>
			<definition id="1">
				<sentence>First there is SUC ( the StockholmUme”a-Corpus ) , a 1 million word corpus of written Swedish designed as a representative corpus along the lines of the Brown corpus .</sentence>
				<definiendum id="0">SUC</definiendum>
			</definition>
			<definition id="2">
				<sentence>Therefore , the most serious attempt at training a 4Annotate is a treebank editor developed at the University of Saarbr˜ucken .</sentence>
				<definiendum id="0">4Annotate</definiendum>
				<definiens id="0">a treebank editor developed at the University of Saarbr˜ucken</definiens>
			</definition>
			<definition id="3">
				<sentence>possessive PPOS ( stand-alone ) possessive pronoun Table 1 : Mapping of SUC tags to STTS dative object ( DO ) .</sentence>
				<definiendum id="0">possessive PPOS</definiendum>
				<definiens id="0">Mapping of SUC tags to STTS dative object ( DO )</definiens>
			</definition>
</paper>

		<paper id="3111">
</paper>

		<paper id="0214">
			<definition id="0">
				<sentence>The Monroe domain is a series of task-oriented dialogs between human participants ( Stent , 2001 ) designed to encourage collaborative problem-solving and mixed-initiative interaction .</sentence>
				<definiendum id="0">Monroe domain</definiendum>
				<definiens id="0">a series of task-oriented dialogs between human participants ( Stent , 2001 ) designed to encourage collaborative problem-solving and mixed-initiative interaction</definiens>
			</definition>
			<definition id="1">
				<sentence>Examples of the logical form representation for the sentence So the heart attack person can’t go 1The 5 Monroe dialogs are : s2 , s4 , s12 , s16 , s17 ( TERM : VAR V3283471 : LF ( LF : :THE V3283471 ( : * LF : :PERSON PERSON ) : ASSOC-WITH ( V3283440 ) ) : SEM ( $ F : :PHYS-OBJ ( F : :SPATIAL-ABSTRACTION F : :SPATIAL-POINT ) ( F : :GROUP - ) ( F : :MOBILITY F : :NON-SELF-MOVING ) ( F : :FORM F : :SOLID-OBJECT ) ( F : :ORIGIN F : :HUMAN ) ( F : :OBJECT-FUNCTION F : :OCCUPATION ) ( F : :INTENTIONAL + ) ( F : :INFORMATION - ) ( F : :CONTAINER - ) ( F : :KR-TYPE KR : :PERSON ) ( F : :TRAJECTORY - ) ) : INPUT ( THE HEART ATTACK PERSON ) ) Figure 1 : Excerpt from full logical form for dialog s2 utterance 173 ( UTT : TYPE UTT : SPEAKER : USER : ROOT V3286907 : TERMS ( ( LF : :SPEECHACT V3286907 SA TELL : CONTENT V3283686 : MODS ( V3283247 ) ) ( LF : :F V3283247 ( : * LF : :CONJUNCT SO ) : OF V3286907 ) ( LF : :F V3283686 ( : * LF : :MOVE GO ) : THEME V3283471 : MODS ( V3284278 ) : TMA ( ( TENSE PRES ) ( MODALITY ( : * LF : :ABILITY CAN ) ) ( NEGATION + ) ) ) ( LF : :THE V3283471 ( : * LF : :PERSON PERSON ) : ASSOC-WITH ( V3283440 ) ) ( LF : :KIND V3283440 ( : * LF : :MEDICAL-CONDITION HEART-ATTACK ) ) ( LF : :F V3284278 ( : * LF : :TO-LOC THERE ) : OF V3283686 : VAL V3286383 ) ( LF : :IMPRO V3286383 ( OR LF : :PHYS-OBJECT LF : :REFERENTIAL-SEM ) : CONTEXT-REL THERE ) ) Figure 2 : Abbreviated LF representation for So the heart attack person can’t go there Figure 3 : CorpusTool Abbreviated LF View there ( dialog s2 , utterance 173 ) is shown in Figures 1 and 2 .</sentence>
				<definiendum id="0">:SPATIAL-POINT )</definiendum>
				<definiendum id="1">:MOBILITY F</definiendum>
				<definiendum id="2">:NON-SELF-MOVING )</definiendum>
				<definiendum id="3">:ORIGIN F</definiendum>
				<definiendum id="4">:PERSON )</definiendum>
				<definiendum id="5">TERMS ( ( LF</definiendum>
				<definiendum id="6">:PHYS-OBJECT LF</definiendum>
				<definiendum id="7">:REFERENTIAL-SEM )</definiendum>
				<definiens id="0">VAR V3283471 : LF ( LF : :THE V3283471 ( : * LF : :PERSON PERSON</definiens>
				<definiens id="1">:SPEECHACT V3286907 SA TELL : CONTENT V3283686 : MODS ( V3283247 ) ) ( LF : :F V3283247 ( : * LF : :CONJUNCT SO ) : OF V3286907 ) ( LF : :F V3283686 ( : * LF : :MOVE GO ) : THEME V3283471 : MODS ( V3284278 ) : TMA ( ( TENSE PRES ) ( MODALITY ( : * LF : :ABILITY CAN ) ) ( NEGATION + ) ) ) ( LF : :THE V3283471 ( : * LF : :PERSON PERSON ) : ASSOC-WITH ( V3283440 ) ) ( LF : :KIND V3283440 ( : * LF : :MEDICAL-CONDITION HEART-ATTACK</definiens>
			</definition>
			<definition id="2">
				<sentence>There is a domain-independent term for the discourse adverbial So2 , and the term for the main event , ( LF : :Move GO ) , which contains the tense and modal information in the : TMA field .</sentence>
				<definiendum id="0">LF</definiendum>
				<definiens id="0">a domain-independent term for the discourse adverbial So2</definiens>
				<definiens id="1">:Move GO ) , which contains the tense and modal information in the : TMA field</definiens>
			</definition>
			<definition id="3">
				<sentence>The corpus-building process consists of three stages : initial annotation , parsing and handchecking .</sentence>
				<definiendum id="0">corpus-building process</definiendum>
				<definiens id="0">consists of three stages : initial annotation , parsing and handchecking</definiens>
			</definition>
			<definition id="4">
				<sentence>The CorpusTool allows annotators to view the syntactic and semantic representations at different levels of granularity .</sentence>
				<definiendum id="0">CorpusTool</definiendum>
				<definiens id="0">allows annotators to view the syntactic and semantic representations at different levels of granularity</definiens>
			</definition>
			<definition id="5">
				<sentence>The standoff file for pronouns consists of two fields for each pronoun to handle the reference information : relation , which specifies how the entities are related ; and refers-to , which specifies the id of the term the referential entity in question points to .</sentence>
				<definiendum id="0">standoff file</definiendum>
				<definiendum id="1">relation</definiendum>
				<definiendum id="2">refers-to</definiendum>
				<definiens id="0">specifies how the entities are related</definiens>
				<definiens id="1">specifies the id of the term the referential entity in question points to</definiens>
			</definition>
			<definition id="6">
				<sentence>The “Relation” box is a drop down menu consisting of the relations listed above .</sentence>
				<definiendum id="0">“Relation” box</definiendum>
				<definiens id="0">a drop down menu consisting of the relations listed above</definiens>
			</definition>
</paper>

		<paper id="0848">
			<definition id="0">
				<sentence>Wordnet : a lexical database .</sentence>
				<definiendum id="0">Wordnet</definiendum>
				<definiens id="0">a lexical database</definiens>
			</definition>
</paper>

		<paper id="1116">
			<definition id="0">
				<sentence>Position : Shows whether target word appears before or after head word .</sentence>
				<definiendum id="0">Position</definiendum>
				<definiens id="0">Shows whether target word appears before or after head word</definiens>
			</definition>
			<definition id="1">
				<sentence>if # of ( h , h_pos , t_pos , pt , position ) &gt; threshold P ( r|constituent ) =P ( r|h , h_pos , t_pos , pt , position ) Else if # of ( h_pos , t_pos , pt , position ) &gt; threshold P ( r|constituent ) =P ( r|h_pos , t_pos , pt , position ) Else Baseline model : P ( r|constituent ) =P ( r| t , t_pos , pt ) We adopt the Sinica Treebank as both training and testing data .</sentence>
				<definiendum id="0">t_pos</definiendum>
				<definiens id="0">r| t ,</definiens>
			</definition>
			<definition id="2">
				<sentence>The refinements of features extractions focus on two different cases , one is the features extractions of case-marked structures , such as PP and GP ( postpositional phrases ) , and the other is the general semantic class identifications of synonyms .</sentence>
				<definiendum id="0">GP</definiendum>
				<definiens id="0">the general semantic class identifications of synonyms</definiens>
			</definition>
			<definition id="3">
				<sentence>Some type of words are very productive , such as numbers , DM ( determinative measurement ) , proper names .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiens id="0">determinative measurement ) , proper names</definiens>
			</definition>
</paper>

		<paper id="2108">
			<definition id="0">
				<sentence>QA softwares , which are particularly demanding about data from the dictionary , have a similar mode of working : they process an utterance ( generally the query ) in order to provide the largest number of way to express the same meaning .</sentence>
				<definiendum id="0">QA softwares</definiendum>
				<definiens id="0">a similar mode of working : they process an utterance ( generally the query ) in order to provide the largest number of way to express the same meaning</definiens>
			</definition>
			<definition id="1">
				<sentence>The Falcon system ( Moldovan et al. , 2000 ) uses some semantic relations from WordNet when it expands the question .</sentence>
				<definiendum id="0">Falcon system</definiendum>
				<definiens id="0">uses some semantic relations from WordNet when it expands the question</definiens>
			</definition>
			<definition id="2">
				<sentence>My semantic disambiguator ( Jacquemin et al. , 2002 ) is an evolution of a tool previously developed for both French and English at XRCE ( Brun , 2000 ; Brun et al. , 2001 ) .</sentence>
				<definiendum id="0">semantic disambiguator</definiendum>
				<definiens id="0">an evolution of a tool previously developed for both</definiens>
			</definition>
			<definition id="3">
				<sentence>The stemming , which considers two words with the same stem nearly synonyms , is too unpredictable to be used in a methodology that tries to avoid noise .</sentence>
				<definiendum id="0">stemming</definiendum>
				<definiens id="0">considers two words with the same stem nearly synonyms , is too unpredictable to be used in a methodology that tries to avoid noise</definiens>
			</definition>
			<definition id="4">
				<sentence>For each considered sense for a word , Dubois’ provides semantic features : a semantic class and an application domain .</sentence>
				<definiendum id="0">Dubois’</definiendum>
				<definiens id="0">provides semantic features : a semantic class</definiens>
			</definition>
</paper>

		<paper id="1706">
			<definition id="0">
				<sentence>Latent Semantic Analysis ( LSA ) is a statistical Natural Language Processing ( NLP ) technique for inferring meaning from a text .</sentence>
				<definiendum id="0">LSA )</definiendum>
			</definition>
			<definition id="1">
				<sentence>“Latent Semantic Analysis is a theory and method for extracting and representing the contextual-usage meaning of words by statistical computations applied to a large corpus of text” ( Landauer , Foltz &amp; Laham , 1998 ) .</sentence>
				<definiendum id="0">“Latent Semantic Analysis</definiendum>
				<definiens id="0">a theory</definiens>
			</definition>
			<definition id="2">
				<sentence>The information retrieval community continues to use the term LSI .</sentence>
				<definiendum id="0">information retrieval community</definiendum>
				<definiens id="0">continues to use the term LSI</definiens>
			</definition>
			<definition id="3">
				<sentence>A term is a subdivision of a document ; it can be a word , phrase , or some other unit .</sentence>
				<definiendum id="0">term</definiendum>
				<definiens id="0">a subdivision of a document ; it can be a word , phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>LSA exploits what can be named the transitive property of semantic relationships : If A→B and B→C , then A→C ( where → stands for is semantically related to ) .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">exploits what can be named the transitive property of semantic relationships</definiens>
			</definition>
			<definition id="5">
				<sentence>• Construct a t x d term frequency matrix M , where t is the number of terms in the corpus and d is the number of documents – 17 in this experiment .</sentence>
				<definiendum id="0">t</definiendum>
				<definiens id="0">the number of terms in the corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>Local weighting is defined as tf ij ( the number of times term i is found in document j ) dampened by the log function : local weighting = 1 + log ( tf ij ) .</sentence>
				<definiendum id="0">Local weighting</definiendum>
				<definiendum id="1">tf ij</definiendum>
				<definiens id="0">the number of times term i is found in document j ) dampened by the log function : local weighting = 1 + log ( tf ij )</definiens>
			</definition>
			<definition id="7">
				<sentence>Global weighting is defined as 1 – the entropy or noise .</sentence>
				<definiendum id="0">Global weighting</definiendum>
				<definiens id="0">1 – the entropy or noise</definiens>
			</definition>
			<definition id="8">
				<sentence>Ljungstrand and Johansson ( 1998 ) define the following similarity measures : Inner product ( dot ) measure : M ( X , Y ) = ∑ = n i ii yx 1 Cosine measure : M ( X , Y ) = ∑∑ ∑ == = n i i n i i n i ii yx yx 11 1 Manhattan distance measure : M ( X , Y ) = ∑ = − n i ii yx 1 Euclidean distance measure ( 2-norm ) : M ( X , Y ) = ( ) ∑ = − n i ii yx 1 2 m-norm measure : M ( X , Y ) = ( ) m n i m ii yx 1 1 ⎟ ⎠ ⎞ ⎜ ⎝ ⎛ ∑ − = , m ∈ N Where X = ( x 1 , x 2 , ... , x n ) and Y = ( y 1 , y 2 , ... , y n ) are two n-dimensional vectors .</sentence>
				<definiendum id="0">M</definiendum>
			</definition>
</paper>

		<paper id="2211">
			<definition id="0">
				<sentence>A verb pattern is a subcategorization frame of a predicate extended by translation information .</sentence>
				<definiendum id="0">verb pattern</definiendum>
				<definiens id="0">a subcategorization frame of a predicate extended by translation information</definiens>
			</definition>
			<definition id="1">
				<sentence>Korean-Chinese verb patterns are invaluable linguistic resources that a0a2a1a4a3a6a5a8a7a10a9 only used for Korean-Chinese transfer but also for Korean parsing .</sentence>
				<definiendum id="0">Korean-Chinese verb patterns</definiendum>
				<definiens id="0">invaluable linguistic resources that a0a2a1a4a3a6a5a8a7a10a9 only used for Korean-Chinese transfer but also for Korean parsing</definiens>
			</definition>
</paper>

		<paper id="1106">
			<definition id="0">
				<sentence>For example , G71G14 is a V-V compound meaning ‘to kill by beating’ .</sentence>
				<definiendum id="0">G71G14</definiendum>
				<definiens id="0">a V-V compound meaning ‘to kill by beating’</definiens>
			</definition>
			<definition id="1">
				<sentence>Module-B ( &lt; S-tag Determiner &gt; ) is to obtain the most likely several synonymous words are given as explanation to the meaning of a word , especially when it is a compound verb .</sentence>
				<definiendum id="0">Module-B</definiendum>
				<definiens id="0">to obtain the most likely several synonymous words are given as explanation to the meaning of a word</definiens>
			</definition>
			<definition id="2">
				<sentence>( Mei et al. , 1984 ) The idealized dictionary , denoted as dico , is actually a formatted MRD defined as follows : A dico is a set of &lt; W-S &gt; correspondence pairs , where W is a word , and S is a sense tag .</sentence>
				<definiendum id="0">dico</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">a set of &lt; W-S &gt; correspondence pairs , where W is a word , and</definiens>
				<definiens id="1">a sense tag</definiens>
			</definition>
			<definition id="3">
				<sentence>2 Z-diagram of C-S links The directed association measure from a character to a sense , denoted as CS-asso ( Ci , Sj ) , can be defined as follows : α ( Ci , Sj ) = [ freq ( Ci , Sj ) G45/ ( freq ( Ci ) +freq ( Sj ) ) ] ^ 0.5 CS-asso ( Ci , Sj ) = α ( Ci , Sj ) / Max k { α ( Ci , Sk ) } ( 2 ) where freq ( Ci , Sj ) is the number of the words in the MRD that contain character Ci and is tagged with sense Sj , while freq ( Ci ) is the number of words containing character Ci , and freq ( Sj ) the number of words tagged with sense Sj.8Likewise , the directed association measure from a sense to a character , denoted as SC-asso ( Si , Cj ) , can be defined as follows9 : α ( Si , Cj ) = [ freq ( Si , Cj ) G45/ ( freq ( Si ) +freq ( Cj ) ) ] ^0.5 SC-asso ( Si , Cj ) = α ( Si , Cj ) / Max k { α ( Si , Ck ) } , ( 3 ) Consequently , by link of a Ci-Sj-Ck chain ( a latent synonymy ) , the directed association measure for a character Ci to another character Ck is defined as a combination of two types of directed association measures , the maximal association measure CC-asso1 ( Ci , Ck ) and the over-all association measure CC-asso2 ( Ci , Ck ) , with respective weights of 1-ω and ω ( the value ω is by default set at 0.5 ) .</sentence>
				<definiendum id="0">Z-diagram of C-S</definiendum>
				<definiendum id="1">freq ( Ci , Sj )</definiendum>
				<definiendum id="2">Ci )</definiendum>
				<definiendum id="3">Cj )</definiendum>
				<definiens id="0">links The directed association measure from a character to a sense</definiens>
				<definiens id="1">the number of the words in the MRD that contain character Ci and is tagged with sense Sj , while freq (</definiens>
				<definiens id="2">the number of words containing character Ci , and freq ( Sj ) the number of words tagged with sense Sj.8Likewise , the directed association measure from a sense to a character , denoted as SC-asso ( Si ,</definiens>
				<definiens id="3">follows9 : α ( Si , Cj ) = [ freq ( Si , Cj ) G45/ ( freq ( Si ) +freq ( Cj ) ) ] ^0.5 SC-asso ( Si , Cj ) = α ( Si , Cj ) / Max k { α ( Si , Ck ) } , ( 3 ) Consequently , by link of a Ci-Sj-Ck chain ( a latent synonymy ) , the directed association measure for a character Ci to another character Ck is defined as a combination of two types of directed association measures</definiens>
			</definition>
			<definition id="4">
				<sentence>λ ( V-Vi , S-tagj ) = Σ j WW-asso ( V-Vi , SWk ) ( 6 ) , where SWk is a known word in dicox and S-tagj is one of the S-tages to SWk Λ ( V-Vi , S-tagj ) =λ ( V-Vi , S-tagj ) /Max n { λ ( V-Vi , S-tagn ) } Based on the model proposed , a system of semantic classification can be implemented for two-character V-V compound verbs by using dico2 as the dicox in the Module-B ( the S-tag now is the semantic class in CILIN ) .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiendum id="1">SWk</definiendum>
				<definiendum id="2">S-tagj</definiendum>
				<definiens id="0">a known word in dicox and</definiens>
			</definition>
			<definition id="5">
				<sentence>In this paper I have proposed a character-based model of sense determination for Chinese 10 VC ( transitive action/activity ) and VA ( intransitive action/activity ) are the two most dominant types of two-character verbs in the corpus , occupying respectively 44 % and 27 % around .</sentence>
				<definiendum id="0">VA</definiendum>
				<definiens id="0">intransitive action/activity ) are the two most dominant types of two-character verbs in the corpus</definiens>
			</definition>
</paper>

		<paper id="0213">
			<definition id="0">
				<sentence>While RST ( Mann , Thompson 1988 ) proposed that a single relation hold between adjacent text segments , SDRT ( Asher , Lascarides 2003 ) maintains that multiple relations may hold simultaneously .</sentence>
				<definiendum id="0">SDRT</definiendum>
				<definiens id="0">a single relation hold between adjacent text segments</definiens>
			</definition>
</paper>

		<paper id="2608">
			<definition id="0">
				<sentence>At the same time , it is likely to be identified from the semantic features of the Complement noun phrase , which denotes a definite period of time in discourse during which an event takes place .</sentence>
				<definiendum id="0">Complement noun phrase</definiendum>
				<definiens id="0">a definite period of time in discourse during which an event takes place</definiens>
			</definition>
			<definition id="1">
				<sentence>The Complement denotes a place in many cases , but sometimes a physical object , and this use of over is always preceded by all .</sentence>
				<definiendum id="0">Complement</definiendum>
				<definiens id="0">a place in many cases , but sometimes a physical object</definiens>
			</definition>
			<definition id="2">
				<sentence>Uses identifiable by the Complements The following is a list of the features identifying the uses of over by the Complements .</sentence>
				<definiendum id="0">Uses identifiable</definiendum>
				<definiens id="0">a list of the features identifying the uses of over by the Complements</definiens>
			</definition>
			<definition id="3">
				<sentence>When the Head of over denotes movement and the Complement a place or a physical object , the overprepositional phrase indicates a place above which and across which an object moves , as given below : ( 7 ) a. The bullet goes flying over my head and lands in the field behind me .</sentence>
				<definiendum id="0">overprepositional phrase</definiendum>
			</definition>
			<definition id="4">
				<sentence>The prepositional phrase indicates a path over which an object moves , and therefore it is termed over_path .</sentence>
				<definiendum id="0">prepositional phrase</definiendum>
				<definiens id="0">indicates a path over which an object moves , and therefore it is termed over_path</definiens>
			</definition>
			<definition id="5">
				<sentence>The prepositional phrase implies a place on which or above which an object sits .</sentence>
				<definiendum id="0">prepositional phrase</definiendum>
			</definition>
			<definition id="6">
				<sentence>The Head denotes an act of control or having more power .</sentence>
				<definiendum id="0">Head</definiendum>
				<definiens id="0">an act of control or having more power</definiens>
			</definition>
			<definition id="7">
				<sentence>The Head is a verb or noun denoting selection .</sentence>
				<definiendum id="0">Head</definiendum>
				<definiens id="0">a verb</definiens>
			</definition>
			<definition id="8">
				<sentence>The Head component of over can be a verb governing the over-prepositional phrase ( as in I would PREFER coffee over tea ) , a verb phrase modified by the over-prepositional phrase ( as in A BIG EARTHQUAKE OCCURED over the weekend ) or a noun ( as in He has considerable CONTROL over her activities ) .</sentence>
				<definiendum id="0">Head component of over</definiendum>
				<definiendum id="1">over-prepositional phrase</definiendum>
				<definiens id="0">a verb governing the over-prepositional phrase ( as in I would PREFER coffee over tea ) , a verb phrase modified by the</definiens>
				<definiens id="1">considerable CONTROL over her activities )</definiens>
			</definition>
</paper>

		<paper id="1609">
			<definition id="0">
				<sentence>In this paper we present and evaluate a novel unsupervised approach , SALAAM , which exploits translational correspondences between words in a parallel Arabic English corpus to annotate Arabic text using an English WordNet taxonomy .</sentence>
				<definiendum id="0">SALAAM</definiendum>
				<definiens id="0">exploits translational correspondences between words in a parallel Arabic English corpus to annotate Arabic text using an English WordNet taxonomy</definiens>
			</definition>
			<definition id="1">
				<sentence>Word Sense Disambiguation ( WSD ) is the process of resolving the meaning of a word unambiguously in a given natural language context .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
				<definiendum id="1">WSD )</definiendum>
				<definiens id="0">the process of resolving the meaning of a word unambiguously in a given natural language context</definiens>
			</definition>
			<definition id="2">
				<sentence>Arabic is a Semitic language with rich templatic morphology .</sentence>
				<definiendum id="0">Arabic</definiendum>
				<definiens id="0">a Semitic language with rich templatic morphology</definiens>
			</definition>
			<definition id="3">
				<sentence>( Diab , 2003 ) SALAAM uses cross-linguistic correspondences for characterizing word meanings in natural language .</sentence>
				<definiendum id="0">SALAAM</definiendum>
				<definiens id="0">uses cross-linguistic correspondences for characterizing word meanings in natural language</definiens>
			</definition>
			<definition id="4">
				<sentence>SALAAM’s algorithm is as follows : a5 SALAAM expects a word aligned parallel corpus as input ; a5 L1 words that translate into the same L2 word are grouped into clusters ; a5 SALAAM identifies the appropriate senses for the words in those clusters based on the words senses’ proximity in WordNet .</sentence>
				<definiendum id="0">SALAAM’s algorithm</definiendum>
				<definiendum id="1">a5 SALAAM</definiendum>
				<definiens id="0">identifies the appropriate senses for the words in those clusters based on the words senses’ proximity in WordNet</definiens>
			</definition>
			<definition id="5">
				<sentence>Simultaneously , SALAAM projects the propagated sense tags for L1 words onto their L2 corresponding translations .</sentence>
				<definiendum id="0">SALAAM</definiendum>
				<definiens id="0">projects the propagated sense tags for L1 words onto their L2 corresponding translations</definiens>
			</definition>
			<definition id="6">
				<sentence>Fortunately , the SENSEVAL2 exercises afford such sets.2 SENSEVAL is a series of community-wide exercises that create a platform for researchers to evaluate their WSD systems on a myriad of languages using different techiques by constantly defining consistent standards and robust measures for WSD .</sentence>
				<definiendum id="0">SENSEVAL</definiendum>
				<definiens id="0">a series of community-wide exercises that create a platform for researchers to evaluate their WSD systems on a myriad of languages using different techiques by constantly defining consistent standards and robust measures for WSD</definiens>
			</definition>
			<definition id="7">
				<sentence>SALAAM ranks as the best unsupervised system when compared to state-of-the-art WSD systems on the same English task .</sentence>
				<definiendum id="0">SALAAM</definiendum>
				<definiens id="0">ranks as the best unsupervised system when compared to state-of-the-art WSD systems on the same English task</definiens>
			</definition>
			<definition id="8">
				<sentence>Therefore the test set corpus is the SENSEVAL2 English All Words test corpus which comprises three articles from the Wall Street Journal discussing religious practice , medicine and education .</sentence>
				<definiendum id="0">test set corpus</definiendum>
				<definiens id="0">the SENSEVAL2 English All Words test corpus which comprises three articles from the Wall Street Journal discussing religious practice , medicine and education</definiens>
			</definition>
			<definition id="9">
				<sentence>BC-SV1 is the Brown Corpus and SENSEVAL1 trial , training and test data .</sentence>
				<definiendum id="0">BC-SV1</definiendum>
			</definition>
			<definition id="10">
				<sentence>SV2-LS is the SENSEVAL2 English Lexical Sample trial , training and test data .</sentence>
				<definiendum id="0">SV2-LS</definiendum>
			</definition>
			<definition id="11">
				<sentence>WSJ is the Wall Street Journal .</sentence>
				<definiendum id="0">WSJ</definiendum>
				<definiens id="0">the Wall Street Journal</definiens>
			</definition>
			<definition id="12">
				<sentence>Like previous WordNet editions ( Fellbaum , 1998 ) , WN17pre is a computational semantic lexicon for English .</sentence>
				<definiendum id="0">WN17pre</definiendum>
			</definition>
			<definition id="13">
				<sentence>The nouns database consists of 69K concepts and has a depth of 15 nodes .</sentence>
				<definiendum id="0">nouns database</definiendum>
			</definition>
</paper>

		<paper id="2212">
</paper>

		<paper id="3109">
</paper>

		<paper id="1302">
			<definition id="0">
				<sentence>EVAL consumes a set of SDs and selects the set of best SDs to be added to the knowledge base .</sentence>
				<definiendum id="0">EVAL</definiendum>
				<definiens id="0">consumes a set of SDs and selects the set of best SDs to be added to the knowledge base</definiens>
			</definition>
			<definition id="1">
				<sentence>The knowledge base is a component that not only stores SDs but also organizes them into optimal representations , here morphology grammars .</sentence>
				<definiendum id="0">knowledge base</definiendum>
			</definition>
			<definition id="2">
				<sentence>The concept of substitutability generally applies to central part of the induction procedure itself , i.e. substitutable elements ( e.g. substrings , words , structures ) are assumed to be of the same type ( represented e.g. with the same symbol ) .</sentence>
				<definiendum id="0">substitutability</definiendum>
				<definiens id="0">central part of the induction procedure itself , i.e. substitutable elements ( e.g. substrings , words , structures</definiens>
			</definition>
			<definition id="3">
				<sentence>A hypothesis is defined as a tuple : H = &lt; w , f , g &gt; , with w the input word , f its frequency in C , and g a list of substrings that represent a linear list of morphemes in w , g = [ m 1 , m 2 , ... m n ] .</sentence>
				<definiendum id="0">hypothesis</definiendum>
				<definiens id="0">a tuple : H = &lt; w , f , g &gt; , with w the input word , f its frequency in C , and g a list of substrings that represent a linear list of morphemes in w</definiens>
			</definition>
			<definition id="4">
				<sentence>EVAL is a voting based algorithm that subsumes a set of independent algorithms that judge the list of SDs from the GEN component , using statistical and information theoretic criteria .</sentence>
				<definiendum id="0">EVAL</definiendum>
				<definiendum id="1">SDs</definiendum>
				<definiens id="0">a voting based algorithm that subsumes a set of independent algorithms that judge the list of</definiens>
			</definition>
			<definition id="5">
				<sentence>Note that p ( &lt; xy &gt; ) is the probability of the bigram &lt; xy &gt; occurring and is not equal to p ( &lt; yx &gt; ) which is the probability of the bigram &lt; yx &gt; occurring .</sentence>
				<definiendum id="0">&gt; )</definiendum>
				<definiens id="0">the probability of the bigram</definiens>
				<definiens id="1">the probability of the bigram &lt; yx &gt; occurring</definiens>
			</definition>
			<definition id="6">
				<sentence>The entropy equation is as follows : p ( x ) lg 1 p ( x ) x∈G ∑ The second equation does n't give variable pointer lengths , but it is preferred since it does n't carry the heavy computational burden of calculating the frequency rank .</sentence>
				<definiendum id="0">entropy equation</definiendum>
				<definiens id="0">give variable pointer lengths , but it is preferred since it does n't carry the heavy computational burden of calculating the frequency rank</definiens>
			</definition>
			<definition id="7">
				<sentence>Relative Entropy ( RE ) We are using RE as a measure for the cost of adding a hypothesis to the existing grammar .</sentence>
				<definiendum id="0">Relative Entropy</definiendum>
				<definiens id="0">a measure for the cost of adding a hypothesis to the existing grammar</definiens>
			</definition>
			<definition id="8">
				<sentence>The hypothesis space is defined as a list of hypotheses : Hypotheses space : S = [ H 1 , H 2 , ... H n ] Further , each morpheme that occurred in the SDs of words in the hypothesis space is kept with its frequency information , as well as bigrams that consist of morpheme pairs in the SDs and their frequency .</sentence>
				<definiendum id="0">hypothesis space</definiendum>
			</definition>
			<definition id="9">
				<sentence>A grammar rule consists of a stem and the suffixes and prefixes that can be attached to it , similar to the signatures used in Goldsmith ( 2001 ) .</sentence>
				<definiendum id="0">grammar rule</definiendum>
			</definition>
</paper>

		<paper id="3224">
			<definition id="0">
				<sentence>For example , in an ngram language model , p ( wijwi 1 ) is a parameter class , whereas the estimated distribution ˆp ( jthe ) is a particular parameter from this class , consisting of estimates of every word that can follow the word “the” .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">a parameter class</definiens>
			</definition>
			<definition id="1">
				<sentence>A partially-lexicalized nonterminal is a nonterminal label and its head word’s part of speech ( such asNP ( NN ) ) .</sentence>
				<definiendum id="0">partially-lexicalized nonterminal</definiendum>
			</definition>
			<definition id="2">
				<sentence>We can then compute the total entropy of word-generation decisions for the entire training corpus via HPMw = X c2PMw f ( c ) H ( c ) ( 1 ) where f ( c ) is the frequency of some history context c and H ( c ) is that context’s entropy .</sentence>
				<definiendum id="0">f ( c )</definiendum>
				<definiendum id="1">H ( c )</definiendum>
				<definiens id="0">the frequency of some history context c</definiens>
			</definition>
			<definition id="3">
				<sentence>A useful metric for measuring distributional similarity , as explored by ( Lee , 1999 ) , is the JensenShannon divergence ( Lin , 1991 ) : JS ( p kq ) = 12 h D p avgp ; q +D q avgp ; q i ( 2 ) where D is the Kullback-Leibler divergence ( Cover and Thomas , 1991 ) and where avgp ; q = 1 2 ( p ( A ) +q ( A ) ) for an event A in the event spaceof at least one of the two distributions .</sentence>
				<definiendum id="0">D</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">useful metric for measuring distributional similarity</definiens>
				<definiens id="1">the Kullback-Leibler divergence ( Cover and Thomas , 1991 ) and where avgp</definiens>
			</definition>
			<definition id="4">
				<sentence>In our case , we have p = p ( yjx1 ; x2 ) and q = p ( yjx1 ) , where y is a possible future and x1 ; x2 are elements of a history context , with q representing a back-o distribution using less context .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">a possible future and x1 ; x2 are elements of a history context</definiens>
			</definition>
</paper>

		<paper id="1501">
			<definition id="0">
				<sentence>Then it presents a system for the annotation of the Relational Structure in treebanks , called Augmented Relational Structure , which allows for a systematic annotation of various components of linguistic knowledge crucial in several tasks .</sentence>
				<definiendum id="0">Augmented Relational Structure</definiendum>
				<definiens id="0">presents a system for the annotation of the Relational Structure in treebanks</definiens>
			</definition>
			<definition id="1">
				<sentence>Diﬀerent treebanks use diﬀerent annotation schemes which make explicit two distinct but interrelated aspects of the structure of the sentence , i.e. the function of the syntactic units and their organization according to a part-whole paradigm .</sentence>
				<definiendum id="0">Diﬀerent treebanks</definiendum>
				<definiens id="0">use diﬀerent annotation schemes which make explicit two distinct but interrelated aspects of the structure of the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , Lexical Functional Grammar ( LFG ) ( Bresnan , 1982 ) collocates relations at the interface between lexicon and syntax , Relational Grammar ( RG ) ( Perlmutter , 1983 ) provides a description of the sentence structure exclusively based on relations and syntactic units not structured beyond the string level .</sentence>
				<definiendum id="0">Relational Grammar ( RG )</definiendum>
				<definiens id="0">provides a description of the sentence structure exclusively based on relations and syntactic units not structured beyond the string level</definiens>
			</definition>
			<definition id="3">
				<sentence>Then the paper shows how a dependency-based annotation can descend on ARS , and describes the ARS-based annotation of a dependency treebank for Italian , the Turin University Treebank ( TUT ) , which is the first available treebank for Italian , with a few quantitative results .</sentence>
				<definiendum id="0">Turin University Treebank</definiendum>
				<definiendum id="1">TUT )</definiendum>
				<definiens id="0">a dependency-based annotation can descend on ARS , and describes the ARS-based annotation of a dependency treebank for Italian , the</definiens>
			</definition>
			<definition id="4">
				<sentence>The Prague Dependency Treebank ( ( Hajiˇcov´a and Ceplov´a , 2000 ) , ( B¨ohmov´a et al. , 2003 ) ) implements a three level annotation scheme where both the analytical ( surface syntactic ) and tectogrammatical level ( deep syntactic and topic-focus articulation ) are dependency-based ; the English Dependency Treebank ( Rambow et al. , 2002 ) implements a dependency-based mono-stratal analysis which encompasses surface and deep syntax and directly represents the predicate-argument structure .</sentence>
				<definiendum id="0">Prague Dependency Treebank</definiendum>
				<definiendum id="1">tectogrammatical level</definiendum>
				<definiens id="0">implements a dependency-based mono-stratal analysis which encompasses surface and deep syntax and directly represents the predicate-argument structure</definiens>
			</definition>
			<definition id="5">
				<sentence>Structure A RS consists of syntactic units linked by relations .</sentence>
				<definiendum id="0">RS</definiendum>
				<definiens id="0">consists of syntactic units linked by relations</definiens>
			</definition>
			<definition id="6">
				<sentence>An Augmented Relational Structure ( ARS ) organizes and systematizes the information usually associated in existing annotations to the RS , and includes not only syntactic , but also linguistic information that can be represented according to a dependency paradigm and that is proximate to semantics and underlies syntax and morphology .</sentence>
				<definiendum id="0">Augmented Relational Structure</definiendum>
				<definiendum id="1">ARS</definiendum>
				<definiens id="0">proximate to semantics and underlies syntax and morphology</definiens>
			</definition>
			<definition id="7">
				<sentence>The functional-syntactic component identifies the subcategorized elements , that is it keeps apart arguments and modifiers in the predicative structures .</sentence>
				<definiendum id="0">functional-syntactic component</definiendum>
				<definiens id="0">identifies the subcategorized elements , that is it keeps apart arguments and modifiers in the predicative structures</definiens>
			</definition>
			<definition id="8">
				<sentence>By following this strategy , the annotation process can be easier , and the result is a direct representation of a complete predicate argument structure , that is a RS where all the information ( morpho-syntactic , functional-syntactic and semantic ) are immediately available .</sentence>
				<definiendum id="0">annotation process</definiendum>
				<definiens id="0">a RS where all the information ( morpho-syntactic , functional-syntactic and semantic ) are immediately available</definiens>
			</definition>
			<definition id="9">
				<sentence>Furthermore , the ARS allows for forms of annotation of relations where not all the features are specified too .</sentence>
				<definiendum id="0">ARS</definiendum>
				<definiens id="0">allows for forms of annotation of relations where not all the features are specified too</definiens>
			</definition>
			<definition id="10">
				<sentence>Some relation involves a morpho-syntactic component where morphological categories are composed by more elements , e.g. DET+DEF ( in DET+DEF , NOUN ) for the relation linking quei with giorni .</sentence>
				<definiendum id="0">DET+DEF</definiendum>
				<definiens id="0">a morpho-syntactic component where morphological categories are composed by more elements</definiens>
			</definition>
			<definition id="11">
				<sentence>The elements of the morphosyntactic component of TUT includes , in fact , 10 ”primary” tags that represent morphological categories of words ( e.g. DET for Determiner , NOUN for Noun , and VERB for Verb ) , and that can be augmented with 20 ”secondary” tags ( specific of the primary tags ) which further describe them by showing specific features , e.g. DEF which specifies the definiteness of the Determiner or INF which specifies infiniteness of Verb .</sentence>
				<definiendum id="0">e.g. DEF</definiendum>
				<definiens id="0">in fact , 10 ”primary” tags that represent morphological categories of words</definiens>
				<definiens id="1">specific of the primary tags ) which further describe them by showing specific features</definiens>
			</definition>
			<definition id="12">
				<sentence>In the hierarchy of relations , Arguments ( ARG ) include Subject ( SUBJ ) , Object ( OBJ ) , Indirect Object ( INDOBJ ) , Indirect Complement ( INDCOMPL ) , Predicative Complements ( of the Subject ( PREDCOMPL+SUBJ ) and of the Object ( PREDCOMPL+OBJ ) ) .</sentence>
				<definiendum id="0">ARG</definiendum>
				<definiendum id="1">Object ( OBJ</definiendum>
				<definiendum id="2">Indirect Object</definiendum>
				<definiendum id="3">Indirect Complement</definiendum>
			</definition>
</paper>

		<paper id="1812">
			<definition id="0">
				<sentence>The main goal of literature mining is to retrieve knowledge that is “buried” in a text and to present the distilled knowledge to users in a concise form .</sentence>
				<definiendum id="0">literature mining</definiendum>
				<definiens id="0">to retrieve knowledge that is “buried” in a text and to present the distilled knowledge to users in a concise form</definiens>
			</definition>
			<definition id="1">
				<sentence>In this paper , we introduce a knowledge integration and structuring system ( KISS ) we designed , in which terminology-driven knowledge acquisition ( KA ) , knowledge retrieval ( KR ) and knowledge visualization ( KV ) are combined using automatic term recognition , automatic term clustering and terminology-based similarity calculation is explained .</sentence>
				<definiendum id="0">knowledge retrieval</definiendum>
				<definiendum id="1">knowledge visualization</definiendum>
				<definiens id="0">combined using automatic term recognition , automatic term clustering and terminology-based similarity calculation is explained</definiens>
			</definition>
			<definition id="2">
				<sentence>Term variants ( i.e. synonymous terms ) are dealt with in the initial phase of ATR when term candidates are singled out , as opposed to other approaches ( e.g. FASTR handles variants subsequently by applying transformation rules to extracted terms ) .</sentence>
				<definiendum id="0">Term variants</definiendum>
				<definiens id="0">i.e. synonymous terms ) are dealt with in the initial phase of ATR when term candidates are singled out</definiens>
			</definition>
</paper>

		<paper id="0607">
			<definition id="0">
				<sentence>Digital Pathology is the cover term for a number of efforts to introduce digital processing into the work-flow of the pathologist .</sentence>
				<definiendum id="0">Digital Pathology</definiendum>
				<definiens id="0">the cover term for a number of efforts to introduce digital processing into the work-flow of the pathologist</definiens>
			</definition>
			<definition id="1">
				<sentence>The system uses the case reports produced by experts ( the pathologists ) to extract information about the accompanying images ( of the tissue samples ) , and thus produces semantic annotation both for the report and for those images .</sentence>
				<definiendum id="0">system</definiendum>
			</definition>
			<definition id="2">
				<sentence>The ontology we use is compiled out of several medical sources ( such as UMLS ( The UMLS Consortium , 2003 ) and SNOMED ( SNOMED International , 2004 ) ) , but since these sources often were not intended for machine reasoning ( i.e. , are not necessarily consistent , and use rather loosely defined relations ) , considerable effort has been spent ( and is being spent ) on cleaning them up.3 At the moment , about 1,000 domain-level concepts and ca .</sentence>
				<definiendum id="0">SNOMED</definiendum>
				<definiens id="0">but since these sources often were not intended for machine reasoning ( i.e. , are not necessarily consistent , and use rather loosely defined relations ) , considerable effort has been spent ( and is being spent ) on cleaning them up.3 At the moment , about 1,000 domain-level concepts and ca</definiens>
			</definition>
			<definition id="3">
				<sentence>⇓ Intermediate Representation ( excerpt ) : [ 2 ] unspec det ( x2 ) ∧ punch biopsat ( x2 ) [ 3 ] unspec plur det ( x3 ) ∧ infiltrate ( x3 , x4 ) ∧ indef det ( x4 ) ∧solid ( x4 ) ∧malign ( x4 ) ∧epithelial ( x4 ) ∧neoplasia ( x4 ) [ 4 ] def plur det ( x5 ) ∧tumorcell ( x5 ) ∧with rel ( x5 , x6 ) ∧unspec plur det ( x6 ) ∧distinctive ( x6 ) ∧ cell borders ( x6 ) [ 7 ] spec det ( x9 ) ∧ low degree ( d1 ) ∧ basophile ( x9 , d1 ) ∧ partially ( d2 ) ∧ broad ( x9 , d2 ) ∧eosinphile ( x9 , d2 ) ∧cytoplasm ( x9 ) [ 8 ] def plur det ( x10 ) ∧ high degree ( d3 ) ∧ polymorpheous ( x10 , d3 ) ∧ nucleus ( x10 ) ∧ with rel ( x10 , x11 ) ∧unspec plur det ( x11 ) ∧partially ( d4 ) ∧multiple ( x11 , d4 ) ∧basophile ( x11 ) ∧ nucleoli ( x11 ) ⇓ Target Representation ( excerpt ) : &lt; Malignant Epithelial Neoplasm C0432650 rdf : ID=”neoplasia x4” &gt; &lt; solidity rdf : datatype=”http : //www.w3.org/2001/XMLSchema # float” &gt; 1.0 &lt; /solidity &gt; &lt; /Malignant Epithelial Neoplasm &gt; &lt; Cell Border C0032743 rdf : ID=”cell border x61”/ &gt; &lt; Tumor cells C0431085 rdf : ID=”tumor cell x52” &gt; &lt; hasBoundary rdf : resource=”file : ... # cell boundary x61”/ &gt; &lt; /Tumor cells C0431085 &gt; &lt; cytoplasm C0326583 rdf : ID=”cytoplasm1” &gt; &lt; broad rdf : datatype=”http : //www.w3.org/2001/XMLSchema # float” &gt; 1.0 &lt; /broad &gt; &lt; eosinphil rdf : datatype=”http : //www.w3.org/2001/XMLSchema # float” &gt; 1.0 &lt; /eosinphil &gt; &lt; basophil rdf : datatype=”http : //www.w3.org/2001/XMLSchema # float” &gt; 0.5 &lt; /basophil &gt; &lt; /cytoplasm &gt; Figure 1 : Input , Intermediate and Target Representation Figure 2 : Flowchart Using OWL DL as a representation format for natural language content means certain limitations have to be accepted .</sentence>
				<definiendum id="0">⇓ Intermediate Representation ( excerpt )</definiendum>
				<definiendum id="1">spec det</definiendum>
				<definiendum id="2">⇓ Target Representation</definiendum>
				<definiens id="0">ID=”neoplasia x4” &gt; &lt; solidity rdf : datatype=”http : //www.w3.org/2001/XMLSchema # float” &gt; 1.0 &lt; /solidity &gt; &lt; /Malignant Epithelial Neoplasm &gt; &lt; Cell Border C0032743 rdf : ID=”cell border x61”/ &gt; &lt; Tumor cells C0431085 rdf : ID=”tumor cell x52” &gt; &lt; hasBoundary rdf : resource=”file : ... # cell boundary</definiens>
				<definiens id="1">a representation format for natural language content means certain limitations have to be accepted</definiens>
			</definition>
			<definition id="4">
				<sentence>At the next stage , certain sequences of tokens are grouped together , namely multi-word expression that denote a single concept in our ontology ( e.g. , “anthrakotische Lymphknoten” denotes a single concept , and hence is marked as one token of type NN at this step ) , and certain other phrases ( e.g. specifications of spatial dimensions ) which can be recognised easily but would require very specialised grammar rules later on.6 Then , the domain-specific lexicon is accessed , which maps “concept names” ( nouns , or phrases as recognised in the previous step ) to the concept IDs used in the ontology.7 Tokens for which there is no entry in that lexicon , and which are hence deemed ‘irrelevant’ for the domain , are assigned a ‘dummy’ semantics appropriate for their part of speech , so that they do not confuse the later parsing stage .</sentence>
				<definiendum id="0">“anthrakotische Lymphknoten”</definiendum>
				<definiens id="0">maps “concept names” ( nouns , or phrases as recognised in the previous step</definiens>
			</definition>
</paper>

		<paper id="0207">
			<definition id="0">
				<sentence>An annotation level is an abstract level of information ( such as the morphology and syntax levels in linguistics ) , originally independent of any annotation scheme .</sentence>
				<definiendum id="0">annotation level</definiendum>
				<definiens id="0">an abstract level of information ( such as the morphology and syntax levels in linguistics ) , originally independent of any annotation scheme</definiens>
			</definition>
			<definition id="1">
				<sentence>• POS tags ( pos ) : the distribution of part-ofspeech tags of the segment taken from the THMCNX layer ( cf. section 3.2 ) .</sentence>
				<definiendum id="0">POS tags ( pos )</definiendum>
			</definition>
</paper>

		<paper id="3012">
			<definition id="0">
				<sentence>The hierarchically structured ontology consists of ca .</sentence>
				<definiendum id="0">hierarchically structured ontology</definiendum>
			</definition>
			<definition id="1">
				<sentence>A domain model is a two-dimensional matrix DM with the dimensions ( # d # c ) , where # d and # c denote the overall number of domain categories and ontological concepts , respectively .</sentence>
				<definiendum id="0">domain model</definiendum>
			</definition>
			<definition id="2">
				<sentence>P ( A ) P ( E ) Kappa Electr .</sentence>
				<definiendum id="0">P (</definiendum>
				<definiens id="0">A ) P ( E ) Kappa Electr</definiens>
			</definition>
			<definition id="3">
				<sentence>Absolute agreement ( CONCabs , SRHabs ) means that annotators agreed on all domains .</sentence>
				<definiendum id="0">Absolute agreement</definiendum>
				<definiendum id="1">SRHabs )</definiendum>
			</definition>
			<definition id="4">
				<sentence>SRH is a set of words W = fw1 ; : : : ; wng .</sentence>
				<definiendum id="0">SRH</definiendum>
				<definiens id="0">a set of words W = fw1 ; : : : ; wng</definiens>
			</definition>
			<definition id="5">
				<sentence>CR is a set of ontological concepts CR = fc1 ; : : : ; cng .</sentence>
				<definiendum id="0">CR</definiendum>
			</definition>
			<definition id="6">
				<sentence>For a given domain model DM , this formally means : SCR ( d ) = 1n nX i=1 Sd ; i where n is the number of concepts in the respective CR .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
</paper>

		<paper id="3252">
			<definition id="0">
				<sentence>Formally , let a2a4a3a6a5a8a7a10a9a12a11a14a13 be a directed graph with the set of vertices a7 and set of edges a11 , where a11 is a subset of a7a16a15a17a7 .</sentence>
				<definiendum id="0">a11</definiendum>
				<definiens id="0">a subset of a7a16a15a17a7</definiens>
			</definition>
			<definition id="1">
				<sentence>The score of a vertex a7 a18 is defined as follows ( Brin and Page , 1998 ) : a31a33a32a35a34a37a36a35a38a24a39a40a32a42a41a44a43a14a45a46a38a22a47a48a45a50a49 a51 a52a54a53a56a55a8a57a46a58a60a59a12a61a63a62 a64 a65a66a68a67a70a69 a58a71a59a73a72a74a62 a65 a31a75a32a35a34 a52 a38 where a76 is a damping factor that can be set between 0 and 1 , which has the role of integrating into the model the probability of jumping from a given vertex to another random vertex in the graph .</sentence>
				<definiendum id="0">score of a vertex a7 a18</definiendum>
			</definition>
			<definition id="2">
				<sentence>The error rate of a vertex a34 a36 is defined as the difference between the “real” score of the vertex a31a75a32a35a34a37a36a63a38 and the score computed at iteration a3 , a31a5a4 a32a35a34a37a36a35a38 .</sentence>
				<definiendum id="0">error rate of a vertex a34 a36</definiendum>
			</definition>
			<definition id="3">
				<sentence>Shortly , her system consists of a supervised learning scheme that attempts to learn how to best extract keywords from a document , by looking at a set of four features that are determined for each “candidate” keyword : ( 1 ) within-document frequency , ( 2 ) collection frequency , ( 3 ) relative position of the first occurrence , ( 4 ) sequence of part of speech tags .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of a supervised learning scheme that attempts to learn how to best extract keywords from a document</definiens>
			</definition>
			<definition id="4">
				<sentence>Instead , we are defining a different relation , which determines a connection between two sentences if there is a “similarity” relation between them , where “similarity” is measured as a function of their content overlap .</sentence>
				<definiendum id="0">“similarity”</definiendum>
				<definiens id="0">a function of their content overlap</definiens>
			</definition>
			<definition id="5">
				<sentence>TextRank extractive summary Hurricane Gilbert is moving toward the Dominican Republic , where the residents of the south coast , especially the Barahona Province , have been alerted to prepare for Carribean and became a hurricane on Saturday night .</sentence>
				<definiendum id="0">TextRank extractive summary Hurricane Gilbert</definiendum>
				<definiendum id="1">Barahona Province</definiendum>
				<definiens id="0">moving toward the Dominican Republic , where the residents of the south coast</definiens>
			</definition>
			<definition id="6">
				<sentence>Intuitively , TextRank works well because it does not only rely on the local context of a text unit ( vertex ) , but rather it takes into account information recursively drawn from the entire text ( graph ) .</sentence>
				<definiendum id="0">TextRank</definiendum>
				<definiens id="0">works well because it does not only rely on the local context of a text unit ( vertex ) , but rather it takes into account information recursively drawn from the entire text ( graph )</definiens>
			</definition>
			<definition id="7">
				<sentence>Through its iterative mechanism , TextRank goes beyond simple graph connectivity , and it is able to score text units based also on the “importance” of other text units they link to .</sentence>
				<definiendum id="0">TextRank</definiendum>
				<definiens id="0">goes beyond simple graph connectivity</definiens>
			</definition>
</paper>

		<paper id="2704">
			<definition id="0">
				<sentence>PropBank ( Kingsbury &amp; Palmer , 2002 ) is an annotation of the Wall Street Journal portion of the Penn Treebank II ( Marcus , 1994 ) with `predicate-argument ' structures , using sense tags for highly polysemous words and semantic role labels for each argument .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">an annotation of the Wall Street Journal portion of the Penn</definiens>
			</definition>
			<definition id="1">
				<sentence>Verbs can take any of a set of general , adjunct-like arguments ( ARGMs ) , such as LOC ( location ) , TMP ( time ) , DIS ( discourse connectives ) , PRP ( purpose ) or DIR ( direction ) .</sentence>
				<definiendum id="0">PRP</definiendum>
				<definiens id="0">take any of a set of general , adjunct-like arguments ( ARGMs ) , such as LOC ( location ) , TMP ( time ) , DIS ( discourse connectives ) ,</definiens>
			</definition>
			<definition id="2">
				<sentence>PropBank I annotations can be translated straightforwardly into logical representations with event variables , as illustrated in ( 5 ) , with relations being defined as predicates of events , and Args and ArgMs representing relations between event variables and corresponding phrases .</sentence>
				<definiendum id="0">PropBank I</definiendum>
				<definiens id="0">annotations can be translated straightforwardly into logical representations with event variables</definiens>
				<definiens id="1">predicates of events , and Args and ArgMs representing relations between event variables and corresponding phrases</definiens>
			</definition>
			<definition id="3">
				<sentence>b. ∃e’ TMP ( e’ , ‘for the past five years’ ) &amp; ∃¬e ( e &lt; e’ &amp; managing ( e ) &amp; Arg0 ( e , unions ) &amp; Arg1 ( e , ‘win wage increases’ ) ) Further annotation involves linking empty categories in PropBank to event variables in cases of control , as illustrated in ( 9 ) , where event variables can be viewed as the appropriate antecedents for PRO , marked as ‘*’ below : ( 9 ) The car collided with a lorry , * killing both drivers .</sentence>
				<definiendum id="0">event variables</definiendum>
				<definiens id="0">involves linking empty categories in PropBank to event variables in cases of control</definiens>
			</definition>
			<definition id="4">
				<sentence>( 16 ) Larry is a university lecturer .</sentence>
				<definiendum id="0">Larry</definiendum>
				<definiens id="0">a university lecturer</definiens>
			</definition>
			<definition id="5">
				<sentence>( PDTB ) The Penn Discourse Treebank ( PDTB ) is currently being built by the PDTB team at the University of Pennsylvania , providing the next appropriate level of annotation : the annotation of the predicate argument structure of connectives ( Miltsakaki et al 2004a/b ) .</sentence>
				<definiendum id="0">PDTB</definiendum>
				<definiens id="0">currently being built by the PDTB team at the University of Pennsylvania , providing the next appropriate level of annotation : the annotation of the predicate argument structure of connectives</definiens>
			</definition>
			<definition id="6">
				<sentence>The PropBank Frames Files for the verbs include coarse-grained sense distinctions based primarily on usages of a verb that have different numbers of predicate-arguments .</sentence>
				<definiendum id="0">PropBank Frames Files for</definiendum>
				<definiens id="0">the verbs include coarse-grained sense distinctions based primarily on usages of a verb that have different numbers of predicate-arguments</definiens>
			</definition>
</paper>

		<paper id="2213">
			<definition id="0">
				<sentence>INTERA ( Integrated European language data Repository Area , Contract 22076Y2C2DMAL2 ) is an EU-funded project within the eContent framework , aiming at � building an integrated European Language Resources ( LRs ) area by connecting existing data centers at regional , national and international level , and � at proposing `` ways and techniques for LRs packaging to make it a profitable and attractive task to eContent professionals '' ; as an application of this task , the production of multilingual resources , namely parallel corpora and multilingual terminologies extracted from these , is undertaken ( INTERA Technical Annex ) .</sentence>
				<definiendum id="0">INTERA</definiendum>
				<definiens id="0">an EU-funded project within the eContent framework , aiming at � building an integrated European Language Resources ( LRs ) area by connecting existing data centers at regional , national and international level</definiens>
			</definition>
			<definition id="1">
				<sentence>Given that INTERA is an eContent project , the target user group defined by the Technical Annex of the project was eContent professionals and users ; furthermore , it was decided that the LRs to be produced ( which would be of interest to this group ) would be parallel corpora and multilingual terminological lists .</sentence>
				<definiendum id="0">INTERA</definiendum>
				<definiens id="0">an eContent project , the target user group defined by the Technical Annex of the project was eContent professionals and users ; furthermore , it was decided that the LRs to be produced ( which would be of interest to this group ) would be parallel corpora and multilingual terminological lists</definiens>
			</definition>
			<definition id="2">
				<sentence>Previous surveys ( see section 2 ) that identify existing LRs as well as a search over the Internet attested the scarcity of available resources in the selected languages and domains , and so , the idea of re-using existing corpora was abandoned in favour of the construction of a new corpus from scratch .</sentence>
				<definiendum id="0">Previous surveys</definiendum>
				<definiens id="0">a search over the Internet attested the scarcity of available resources in the selected languages and domains</definiens>
			</definition>
</paper>

		<paper id="0300">
</paper>

		<paper id="0709">
</paper>

		<paper id="0502">
			<definition id="0">
				<sentence>Question-Answering ( QA ) evaluation efforts have largely been tailored to open-domain systems .</sentence>
				<definiendum id="0">Question-Answering</definiendum>
				<definiens id="0">tailored to open-domain systems</definiens>
			</definition>
			<definition id="1">
				<sentence>The TREC QA test collections contain newswire articles and the accompanying queries cover a wide variety of topics .</sentence>
				<definiendum id="0">TREC QA test collections</definiendum>
				<definiens id="0">contain newswire articles and the accompanying queries cover a wide variety of topics</definiens>
			</definition>
			<definition id="2">
				<sentence>The KAAS system uses a two-stage retrieval model to find answers in relevant passages .</sentence>
				<definiendum id="0">KAAS system</definiendum>
				<definiens id="0">uses a two-stage retrieval model to find answers in relevant passages</definiens>
			</definition>
			<definition id="3">
				<sentence>System Performance is the category that deals with system speed and system availability .</sentence>
				<definiendum id="0">System Performance</definiendum>
				<definiens id="0">the category that deals with system speed and system availability</definiens>
			</definition>
</paper>

		<paper id="1701">
			<definition id="0">
				<sentence>The formal specification of the concepts and relations between them takes usually advantage of the new XML-family standards , RDF ( Beckett , 2003 ) and OWL ( van Harmelen et al. , 2003 ) .</sentence>
				<definiendum id="0">RDF</definiendum>
				<definiens id="0">The formal specification of the concepts and relations between them takes usually advantage of the new XML-family standards</definiens>
			</definition>
			<definition id="1">
				<sentence>The sketch engine is a corpus tool developed by our team which takes as input a corpus of any language and a corresponding grammar patterns and generates word sketches for the words of that language as its outputs .</sentence>
				<definiendum id="0">sketch engine</definiendum>
				<definiens id="0">a corpus tool developed by our team which takes as input a corpus of any language and a corresponding grammar patterns and generates word sketches for the words of that language as its outputs</definiens>
			</definition>
			<definition id="2">
				<sentence>The above-mentioned word sketch engine needs several hours to compute the necessary statistics on a 100,000-word corpus ( BNC ) .</sentence>
				<definiendum id="0">BNC</definiendum>
				<definiens id="0">The above-mentioned word sketch engine needs several hours to compute the necessary statistics on a 100,000-word corpus</definiens>
			</definition>
</paper>

		<paper id="1201">
			<definition id="0">
				<sentence>All of our experiments are done on the GENIA corpus , which is the largest annotated corpus in the molecular biology domain available to public ( Ohta et al. 2002 ) .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">the largest annotated corpus in the molecular biology domain available to public</definiens>
			</definition>
			<definition id="1">
				<sentence>Here , the observation o , where is the word and is the feature set of the word w , and the state is structural and s n n ooo ... 211 = &gt; = &lt; iii wf , &gt; i s ii FEATURE_ n n sss ... 211 = i HEAD i POS FF , , i i BOUNDARY _ ) | ( 11 nn OSP = &lt; i i Ff i w F , i ALIAS i MPWFP F , i ENTITY= , where denotes the position of the current word in the entity ; ENTITY indicates the class of the entity ; and FEATURE is the feature set used to model the ngram more precisely .</sentence>
				<definiendum id="0">ENTITY</definiendum>
				<definiendum id="1">FEATURE</definiendum>
				<definiens id="0">the word and is the feature set of the word w</definiens>
				<definiens id="1">the class of the entity ; and</definiens>
				<definiens id="2">the feature set used to model the ngram more precisely</definiens>
			</definition>
			<definition id="2">
				<sentence>For efficiency , we apply the one vs. others strategy , which builds K classifiers so as to separate one class from all others , instead of the pairwise strategy , which builds K* ( K-1 ) /2 classifiers considering all pairs of classes .</sentence>
				<definiendum id="0">pairwise strategy</definiendum>
				<definiens id="0">builds K classifiers so as to separate one class from all others</definiens>
			</definition>
			<definition id="3">
				<sentence>We also find that the GENIA corpus annotates some general noun phrases as biomedical entity names , e.g. “protein” in “the protein” and “cofactor” in “a cofactor” .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">annotates some general noun phrases as biomedical entity names</definiens>
			</definition>
			<definition id="4">
				<sentence>The main contributions of our work are the novel name alias feature in the biomedical domain , the SVM plus sigmoid approach in the effective resolution of the data sparseness problem in our system and its integration with the Hidden Markov Model .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">Hidden Markov Model</definiens>
			</definition>
</paper>

		<paper id="2509">
			<definition id="0">
				<sentence>This restriction reflects the fact that QACIAD is a simulation of interactive use of question answering systems in dialogues .</sentence>
				<definiendum id="0">QACIAD</definiendum>
				<definiens id="0">a simulation of interactive use of question answering systems in dialogues</definiens>
			</definition>
			<definition id="1">
				<sentence>1It is a special case that the number of answers is just one for all questions shown in Figure 1 .</sentence>
				<definiendum id="0">1It</definiendum>
				<definiens id="0">a special case that the number of answers is just one for all questions shown in Figure 1</definiens>
			</definition>
			<definition id="2">
				<sentence>The first reference test set consists of isolated questions , that is , not in series , obtained from questions of the original test set by manually resolving all anaphoric expressions including zero anaphora .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of isolated questions , that is , not in series , obtained from questions of the original test set by manually resolving all anaphoric expressions including zero anaphora</definiens>
			</definition>
			<definition id="3">
				<sentence>The second reference test set consists of isolated questions obtained from questions of the original test set by mechanically removing anaphoric expressions .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of isolated questions obtained from questions of the original test set by mechanically removing anaphoric expressions</definiens>
			</definition>
</paper>

		<paper id="0706">
			<definition id="0">
				<sentence>Coreference has been defined by ( van Deemter and Kibble , 2000 ) as the relation holding between linguistic expressions that refer to the same extralinguistic entity .</sentence>
				<definiendum id="0">Coreference</definiendum>
				<definiens id="0">the relation holding between linguistic expressions that refer to the same extralinguistic entity</definiens>
			</definition>
			<definition id="1">
				<sentence>Finally , ( Bunescu , 2003 ) deals with another class of anaphoric descriptions , which is also included in the bridging class , called as associative anaphora , following ( Hawkins , 1978 ) , where associative anaphora is an anaphoric relation between non-coreferent entities .</sentence>
				<definiendum id="0">associative anaphora</definiendum>
				<definiens id="0">an anaphoric relation between non-coreferent entities</definiens>
			</definition>
			<definition id="2">
				<sentence>Our lexical resource consists on lists of semantically related words .</sentence>
				<definiendum id="0">lexical resource</definiendum>
			</definition>
			<definition id="3">
				<sentence>Consider : • Hana is the head-noun of the anaphor • Hcani is the head-noun of the antecedent candidate i • Lana is the anaphor’s list of similar nouns • Lcani is the list of similar nouns for the candidate i • So , Hcani is considered the antecedent ofHana if ( 1 ) Hcani ∈ Lana or ( 2 ) Hana ∈ Lcani 1See http : //visl.hum.sdu.dk/visl/pt/ or ( 3 ) Lana owner Hj ∈ Lcani We call ( 1 ) ’right direction’ , ( 2 ) ’opposite direction’ , and ( 3 ) ’indirect way’ .</sentence>
				<definiendum id="0">Hana</definiendum>
				<definiendum id="1">Hcani</definiendum>
				<definiendum id="2">Hcani</definiendum>
				<definiens id="0">the head-noun of the anaphor •</definiens>
				<definiens id="1">the anaphor’s list of similar nouns • Lcani is the list of similar nouns for the candidate i • So ,</definiens>
			</definition>
			<definition id="4">
				<sentence>For the annotation task , we adopted the MMAX annotation tool ( Müller and Strube , 2001 ) , that requires all data to be encoded in XML format .</sentence>
				<definiendum id="0">MMAX annotation tool</definiendum>
				<definiens id="0">requires all data to be encoded in XML format</definiens>
			</definition>
			<definition id="5">
				<sentence>This evaluation considers 204 bridging descriptions , distributed as follows , where NPj is the anaphora and NPi is antecedent .</sentence>
				<definiendum id="0">NPj</definiendum>
				<definiendum id="1">NPi</definiendum>
				<definiens id="0">the anaphora</definiens>
			</definition>
			<definition id="6">
				<sentence>Bunescu ( Bunescu , 2003 ) reports for his method on resolving associative anaphora ( anaphoric relation between non-coreferent entities ) a precision of 53 % when his recall is 22.7 % .</sentence>
				<definiendum id="0">Bunescu</definiendum>
				<definiens id="0">anaphoric relation between non-coreferent entities</definiens>
			</definition>
</paper>

		<paper id="2409">
			<definition id="0">
				<sentence>The mutual information C5C1B4CFBNBVCPD8B5 between a word CF , and a category BVCPD8is defined as : C5C1B4CFBNBVCPD8B5 BP CG CFBECUDBBNAMDBCV CG BVCPD8BECUCRBNAMCRCV C8B4CFBNBVCPD8B5D0D3CV C8B4CFBNBVCPD8B5 C8B4CFB5C8B4BVCPD8B5 ( 1 ) Each CR CXCY ( 1 AKCXAKD2 ) is the value of mutual information between DB CX and CR CY .</sentence>
				<definiendum id="0">BP CG CFBECUDBBNAMDBCV CG BVCPD8BECUCRBNAMCRCV C8B4CFBNBVCPD8B5D0D3CV C8B4CFBNBVCPD8B5 C8B4CFB5C8B4BVCPD8B5</definiendum>
				<definiendum id="1">1 ) Each CR CXCY</definiendum>
				<definiens id="0">mutual information C5C1B4CFBNBVCPD8B5 between a word CF</definiens>
			</definition>
			<definition id="1">
				<sentence>C8B4CR CY CY CS CX BN CM AIB5 BP C8B4CR CY CY CM AIB5A5 CYCS CX CY CZBPBD C8B4DB CS CXCZ CY CR CY BN CM AIB5 C8 CYBVCY D6BPBD C8B4CR D6 CY CM AIB5A5 CYCS CX CY CZBPBD C8B4DB CS CXCZ CY CR D6 BN CM AIB5 DBCWCTD6CT CM AI D8CY AH C8B4DB D8 CY CR CY BN CM AIB5 BP BDB7 C8 CYBWCY CXBPBD C6B4DB D8 BNCS CX B5C8B4CR CY CY CS CX B5 CYCECY B7 C8 CYCE CY D7BPBD C8 CYBWCY CXBPBD C6B4DB D7 BNCS CX B5C8B4CR CY CY CS CX B5 CM AI BCCY AH C8B4CR CY CY CM AIB5BP CYBWCY CG CXBPBD C8B4CR CY CY CS CX B5BPCYBWCY ( 2 ) CYCECY refers to the size of vocabulary , CYBWCY denotes the number of labeled training documents , and CYBVCY shows the number of categories .</sentence>
				<definiendum id="0">CYBWCY</definiendum>
				<definiendum id="1">CYBVCY</definiendum>
				<definiens id="0">C8B4CR CY CY CS CX BN CM AIB5 BP C8B4CR CY CY CM AIB5A5 CYCS CX CY CZBPBD C8B4DB CS CXCZ CY CR CY BN CM AIB5 C8 CYBVCY D6BPBD C8B4CR D6 CY CM AIB5A5 CYCS CX CY CZBPBD C8B4DB CS CXCZ CY CR D6 BN CM AIB5 DBCWCTD6CT CM AI D8CY AH C8B4DB D8 CY CR CY BN CM AIB5 BP BDB7 C8 CYBWCY CXBPBD C6B4DB D8 BNCS CX B5C8B4CR CY CY CS CX B5 CYCECY B7 C8 CYCE CY D7BPBD C8 CYBWCY CXBPBD C6B4DB D7 BNCS CX B5C8B4CR CY CY CS CX B5 CM AI BCCY AH C8B4CR CY CY CM AIB5BP CYBWCY CG CXBPBD C8B4CR CY CY CS CX B5BPCYBWCY ( 2 ) CYCECY refers to the size of vocabulary ,</definiens>
				<definiens id="1">the number of labeled training documents</definiens>
			</definition>
			<definition id="2">
				<sentence>CYCS CX CY denotes document length .</sentence>
				<definiendum id="0">CYCS CX CY</definiendum>
			</definition>
			<definition id="3">
				<sentence>DB CS CXCZ is the word in position CZ of document CS CX , where the subscript of DB , CS CXCZ indicates an index into the vocabulary .</sentence>
				<definiendum id="0">DB CS CXCZ</definiendum>
				<definiens id="0">the word in position CZ of document CS CX , where the subscript of DB , CS CXCZ indicates an index into the vocabulary</definiens>
			</definition>
			<definition id="4">
				<sentence>C6B4DB D8 BNCS CX B5 denotes the number of times word DB D8 occurs in document CS CX , and C8B4CR CY CY CS CX B5 is defined by C8B4CR CY CY CS CX B5 BECU0,1CV .</sentence>
				<definiendum id="0">C6B4DB D8 BNCS CX B5</definiendum>
				<definiendum id="1">C8B4CR CY CY CS CX B5</definiendum>
				<definiendum id="2">C8B4CR CY CY CS CX B5 BECU0,1CV</definiendum>
				<definiens id="0">the number of times word DB D8 occurs in document CS CX , and</definiens>
			</definition>
			<definition id="5">
				<sentence>Let C8B4DD CY DCB5 be an unknown conditional distribution over inputs , DC , and output classes , DD BECUDD BD , DD BE , A1A1A1 , DD D2 CV , and let C8B4DCB5 be the marginal ‘input’ distribution .</sentence>
				<definiendum id="0">C8B4DD CY DCB5</definiendum>
				<definiendum id="1">DD BECUDD BD</definiendum>
				<definiens id="0">an unknown conditional distribution over inputs , DC , and output classes</definiens>
			</definition>
			<definition id="6">
				<sentence>The expected error of the learner can be defined as follows : BX CM C8 BW BP CI DC C4B4C8B4DD CY DCB5BN CM C8 BW B4DD CY DCB5B5C8B4DCB5 ( 3 ) where C4 is some loss function that measures the degree of our disappointment in any differences between the true 1 We tested these three assignment strategies in the experiment , and obtained a better result with probability threshold than with other strategies .</sentence>
				<definiendum id="0">expected error of the learner</definiendum>
				<definiens id="0">follows : BX CM C8 BW BP CI DC C4B4C8B4DD CY DCB5BN CM C8 BW B4DD CY DCB5B5C8B4DCB5 ( 3 ) where C4 is some loss function that measures the degree of our disappointment in any differences between the true 1 We tested these three assignment strategies in the experiment</definiens>
			</definition>
			<definition id="7">
				<sentence>A log loss which is defined as follows : C4 BP CG DDBECH C8B4DD CY DCB5D0D3CVB4 CM C8 BW B4DD CY DCB5B5 ( 4 ) Suppose that we chose the optimal number of CZ in the CZ-means algorithm .</sentence>
				<definiendum id="0">log loss</definiendum>
				<definiens id="0">follows : C4 BP CG DDBECH C8B4DD CY DCB5D0D3CVB4 CM C8 BW B4DD CY DCB5B5 ( 4 ) Suppose that we chose the optimal number of CZ in the CZ-means algorithm</definiens>
			</definition>
			<definition id="8">
				<sentence>BKCZ BX CM C8 BW CX BOBX CM C8 BW CZ ( 5 ) We defined a loss function as follows : CM BX CM C8 BW CX BPA0 BD CYCH CZ CY BD CYCGCY CG DCBECG CG DDBECH CZ C8B4DD CY DCB5D0D3CVB4 CM C8 BW CX B4DD CY DCB5B5 ( 6 ) CH CZ in formula ( 6 ) denotes a set of seed points ( categories ) of BW CZ .</sentence>
				<definiendum id="0">BKCZ BX CM C8 BW CX BOBX CM C8 BW CZ</definiendum>
				<definiendum id="1">CM BX CM C8 BW CX BPA0 BD CYCH CZ CY BD CYCGCY CG DCBECG CG DDBECH CZ C8B4DD CY DCB5D0D3CVB4 CM C8 BW CX B4DD CY DCB5B5</definiendum>
				<definiens id="0">CH CZ in formula ( 6 ) denotes a set of seed points ( categories ) of BW CZ</definiens>
			</definition>
			<definition id="9">
				<sentence>D2 is the number of different categories .</sentence>
				<definiendum id="0">D2</definiendum>
				<definiens id="0">the number of different categories</definiens>
			</definition>
			<definition id="10">
				<sentence>Precision is the ratio of correct assignments by the system divided by the total number of the system’s assignments .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio of correct assignments by the system divided by the total number of the system’s assignments</definiens>
			</definition>
			<definition id="11">
				<sentence>‘Clusters’ denotes the number of clusters , and ‘Categories’ refers to the number of categories at each level .</sentence>
				<definiendum id="0">‘Clusters’</definiendum>
				<definiendum id="1">‘Categories’</definiendum>
				<definiens id="0">the number of clusters</definiens>
			</definition>
</paper>

		<paper id="0312">
			<definition id="0">
				<sentence>Anaphora resolution is a familiar case of update : pronouns are de ned to project metavariables that are substituted from context as part of the construction process .</sentence>
				<definiendum id="0">Anaphora resolution</definiendum>
				<definiens id="0">a familiar case of update : pronouns are de ned to project metavariables that are substituted from context as part of the construction process</definiens>
			</definition>
			<definition id="1">
				<sentence>In the simple case where the sentence is unambiguous ( or all ambiguity has been removed ) this set will again have been reduced to a single triple hT1 ; W1 ; A1i , corresponding to the nal interpretation of the string T1 with its sequence of words W1 and actions A1 , and this replaces hT0 ; W0 ; A0i as the new context ; in the presence of persistent ambiguity there will simply be more than one triple in the new context.9 Generation in Context A generator state is now de ned as a pair ( Tg ; X ) of a goal tree Tg and a set X of pairs ( S ; P ) , where S is a candidate partial string and P is the associated parser state ( a set of hT ; W ; Ai triples ) .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">a candidate partial string and</definiens>
			</definition>
			<definition id="2">
				<sentence>Transition from Speaker to Hearer At transition , the initial speaker B’s generator state G0t contains the pair ( St ; P0t ) , where St is the partial string output so far , and P 0t is the corresponding parser state , the transition state as far as B is concerned.12 In order for B to interpret A’s continuation , B need only use P 0t as the initial parser state which is extended as the string produced by A is consumed .</sentence>
				<definiendum id="0">St</definiendum>
				<definiendum id="1">P 0t</definiendum>
				<definiens id="0">the partial string output so far , and</definiens>
				<definiens id="1">concerned.12 In order for B to interpret A’s continuation</definiens>
				<definiens id="2">the string produced by A is consumed</definiens>
			</definition>
			<definition id="3">
				<sentence>Parsing the fragment involves constructing an un xed node , and merging it with the contextually available structure , so characterising the wellformedness/interpretation of fragment answers to questions without any additional mechanisms : the term ( ; x ; porridge0 ( x ) ) stands in a licensed growth relation from the metavariable WH provided by the lexical actions of what .</sentence>
				<definiendum id="0">Parsing the fragment involves</definiendum>
				<definiens id="0">constructing an un xed node , and merging it with the contextually available structure , so characterising the wellformedness/interpretation of fragment answers to questions without any additional mechanisms : the term ( ; x ; porridge0 ( x ) ) stands in a licensed growth relation from the metavariable WH provided by the lexical actions of what</definiens>
			</definition>
</paper>

		<paper id="3223">
			<definition id="0">
				<sentence>Also , we motivate an extension to n-best feature selection for linguistic features sets with moderate redundancy , and present experimental results showing its advantage over lscript0 , 1-best lscript1 , lscript2 regularization and over standard incremental feature selection for the task of maximum-entropy parsing.1 The maximum-entropy ( ME ) principle , which prescribes choosing the model that maximizes the entropy out of all models that satisfy given feature constraints , can be seen as a built-in regularization mechanism that avoids overfitting the training data .</sentence>
				<definiendum id="0">principle</definiendum>
				<definiens id="0">prescribes choosing the model that maximizes the entropy out of all models that satisfy given feature constraints</definiens>
				<definiens id="1">a built-in regularization mechanism that avoids overfitting the training data</definiens>
			</definition>
			<definition id="1">
				<sentence>lscript1 regularization is defined by the case where p = 1 .</sentence>
				<definiendum id="0">lscript1 regularization</definiendum>
				<definiens id="0">the case where p = 1</definiens>
			</definition>
			<definition id="2">
				<sentence>Stopping condition : Stop if for all fi in Z ( t−1 ) : vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle ∂L ( λ ( t−1 ) , S ( t−1 ) ) ∂λi vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle≤ γ Figure 1 : n-best gradient feature testing For features that meet the constraints without parameter adjustment , parameter values can be kept at zero , effectively discarding the features .</sentence>
				<definiendum id="0">vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle ∂L</definiendum>
				<definiens id="0">n-best gradient feature testing For features that meet the constraints without parameter adjustment , parameter values can be kept at zero</definiens>
			</definition>
			<definition id="3">
				<sentence>In such cases , it is beneficial to add a number of n &gt; 1 features at each step , where n is adjusted by cross-validation or on a held-out data set .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">is adjusted by cross-validation or on a held-out data set</definiens>
			</definition>
			<definition id="4">
				<sentence>parc.com/istl/groups/nltt/fsbank/ Table 1 : Feature templates name parameters activation condition Local Templates cs label label constituent label is present in parse cs adj label parent label , constituent child label is child label child of constituent parent label cs right branch constituent has right child cs conj nonpar depth non-parallel conjuncts within depth levels fs attrs attrs f-structure attribute is one of attrs fs attr value attr , value attribute attr has value value fs attr subsets attr sum of cardinalities of subsets of attr lex subcat pred , args sets verb pred has one of args sets as arguments Non-Local ( Top-Down ) Templates cs embedded label , size chain of size constituents labeled label embedded into one another cs sub label ancestor label , constituent descendant label descendant label is descendant of ancestor label fs aunt subattr aunts , parents , one of descendants is descendant of one of descendants parents which is a sister of one of aunts much larger , but sparser feature sets are employed4 .</sentence>
				<definiendum id="0">Non-Local ( Top-Down ) Templates cs</definiendum>
			</definition>
</paper>

		<paper id="0410">
			<definition id="0">
				<sentence>N and C stand for noun phrases ; N is a free tive example , and the approximate number of sentences collected so far .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">a free tive example , and the approximate number of sentences collected so far</definiens>
			</definition>
			<definition id="1">
				<sentence>and C is frozen noun phrase ; N 0 is the subject , N 1 and N 2 the first and second complement ; V is the verb and Prep a preposition .</sentence>
				<definiendum id="0">N 0</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">the verb</definiens>
			</definition>
			<definition id="2">
				<sentence>Another measure is the ratio between the lexical diversity ( LexDiv ) of DLE ( number of entries/different lemmas ) and precision ( P ) .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the ratio between the lexical diversity ( LexDiv ) of DLE ( number of entries/different lemmas</definiens>
			</definition>
			<definition id="3">
				<sentence>Sometimes , the matched string is formally ambiguous with free constructions : Como resultado , a Comunidade dá de si uma imagem de paralisia ( Has a result , the Community gives of itself an image of paralysis ) .</sentence>
				<definiendum id="0">Community</definiendum>
				<definiens id="0">gives of itself an image of paralysis )</definiens>
			</definition>
			<definition id="4">
				<sentence>Ambiguity also arises from the syntactic operations underwent by a free sentence .</sentence>
				<definiendum id="0">Ambiguity</definiendum>
				<definiens id="0">arises from the syntactic operations underwent by a free sentence</definiens>
			</definition>
</paper>

		<paper id="2215">
			<definition id="0">
				<sentence>An MPM stores one or more corpora of polyphrazes .</sentence>
				<definiendum id="0">MPM</definiendum>
				<definiens id="0">stores one or more corpora of polyphrazes</definiens>
			</definition>
			<definition id="1">
				<sentence>ß add UNL tags at sentence level to store the translations as well as UNL hypergraphs ( anglosemantic interlingual representations ) , from which raw ( or rough ! )</sentence>
				<definiendum id="0">UNL</definiendum>
				<definiens id="0">tags at sentence level to store the translations as well as UNL hypergraphs ( anglosemantic interlingual representations ) , from which raw</definiens>
			</definition>
			<definition id="2">
				<sentence>Programmed in standard Java under the Enhydra development environment used for the dynamic and multilingual Papillon web site , PolyphraZ is multi-platform ( MacOS-X/Unix/Linux , Windows ) .</sentence>
				<definiendum id="0">PolyphraZ</definiendum>
				<definiens id="0">multi-platform ( MacOS-X/Unix/Linux</definiens>
			</definition>
			<definition id="3">
				<sentence>Ø represents the exchange of a character by another , || represents the equality between two characters Ø represent the suppression of the 1st character , Figure 9 : XML representation The CXM and CPXM levels of PolyphraZ are already used .</sentence>
				<definiendum id="0">Ø</definiendum>
				<definiens id="0">the equality between two characters Ø represent the suppression of the 1st character , Figure 9 : XML representation The CXM and CPXM levels of PolyphraZ are already used</definiens>
			</definition>
</paper>

		<paper id="0406">
			<definition id="0">
				<sentence>is not : a preposition , an auxiliary verb , an adverb , an adjective , an interrogative pronoun , or a correlative conjunctions THEN Delete that word ENDIF is not : an adverb , a closing parenthesis , or a number , THEN Delete that word ENDIF UNTIL ( the words at the beginning and end of FL are not on the stopword list OR FL is a one word term that is a not a stopword or all the words in the expression are deleted by this algorithm ) This algorithm can be implemented using either a program that does part of speech tagging or a program that looks up a thesaurus .</sentence>
				<definiendum id="0">FL</definiendum>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>This paper has proposed a new summarization method , where K-medoid clustering method is applied to detect all possible partitions of thematic areas , and a novel clustering analysis method , which is based on a self-defined objective function , is applied to automatically determine K , the number of latent thematic areas in a document This method consists of three main stages : 1 ) Find out the thematic areas in the document by adopting the K-medoid clustering method ( Kaufmann and Rousseeuw , 1987as well as a novel clustering analysis method .</sentence>
				<definiendum id="0">K-medoid clustering</definiendum>
				<definiens id="0">applied to automatically determine K , the number of latent thematic areas in a document This method consists of three main stages : 1 ) Find out the thematic areas in the document by adopting the K-medoid clustering method ( Kaufmann and Rousseeuw , 1987as well as a novel clustering analysis method</definiens>
			</definition>
			<definition id="1">
				<sentence>According to this , we can set up the VSM of paragraphs , that is each paragraph Pi ( i:1~M , M is the number of all paragraphs in a document ) is represented as the vector of weights of terms , VPi , VPi = ( WPi1 , WPi2 , … , WPiN ) Where N is the total number of terms , WPij denotes the weight of the j-th term in the i-th paragraph .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">WPiN ) Where N</definiendum>
				<definiendum id="2">WPij</definiendum>
				<definiens id="0">the number of all paragraphs in a document ) is represented as the vector of weights of terms , VPi , VPi = ( WPi1 , WPi2 , … ,</definiens>
				<definiens id="1">the total number of terms ,</definiens>
				<definiens id="2">the weight of the j-th term in the i-th paragraph</definiens>
			</definition>
			<definition id="2">
				<sentence>The method adopted here ( Gong and Liu , 2001 ) is shown as follows : WPij= log ( 1+TF ( Tij ) ) *log ( M/Mj ) ( 1 ) Where TF ( Tij ) denotes the number of occurrence of the j-th term in the i-th paragraph , M/Mj denotes the inverse paragraph frequency of term j , and Mj denotes the number of paragraphs in which term j occurs .</sentence>
				<definiendum id="0">TF ( Tij )</definiendum>
				<definiendum id="1">M/Mj</definiendum>
				<definiendum id="2">Mj</definiendum>
				<definiens id="0">the number of occurrence of the j-th term in the i-th paragraph</definiens>
				<definiens id="1">the inverse paragraph frequency of term j , and</definiens>
				<definiens id="2">the number of paragraphs in which term j occurs</definiens>
			</definition>
			<definition id="3">
				<sentence>In accordance , on the basis of defining WPij , we can further define the weight of paragraph Pi , W ( P i ) , by the follwing formula : ( 2 ) In formula ( 2 ) , n represents the total number of different terms occurring in the i-th paragraph .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the total number of different terms occurring in the i-th paragraph</definiens>
			</definition>
			<definition id="4">
				<sentence>The complexity of the hierarchical clustering algorithm is O ( n2Log ( n ) ) , where n is the number of elements to be clustered , which is usually greater than that of the partitional method .</sentence>
				<definiendum id="0">O</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of elements to be clustered , which is usually greater than that of the partitional method</definiens>
			</definition>
			<definition id="5">
				<sentence>Here N is the number of terms in the document and M is the number of paragraphs .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">the number of terms in the document and</definiens>
				<definiens id="1">the number of paragraphs</definiens>
			</definition>
			<definition id="6">
				<sentence>1 ) Theme coverage ( TC ) The definition of TC is the percentage of the thematic contents covered by the selected summarization sentences .</sentence>
				<definiendum id="0">TC</definiendum>
				<definiens id="0">the percentage of the thematic contents covered by the selected summarization sentences</definiens>
			</definition>
			<definition id="7">
				<sentence>According to this , some important notations are defined as follows : N Number of terms in the original document ; Nz Number of sentences in the produced summary ; Lz Nz-by-N matrix composed by all the sentence vectors in the produced summary ; ∑ z Nz-by-Nz covariance matrix composed by all the sentence vectors in the produced summary ; λ i Eigenvalues of ∑ z i:1~Nz ; ϒi ϒi= λ i / 1 Nz i = λ ∑ i ; Theme coverage ( TC ) Representation entropy ( RE ) Genre Sample ID Number of characters Number of paragraphs Number of detected thematic areas Method1 Method2 Method1 Method2 d10000801 1461 11 5 0.6 0.56 1.44 1.25 d10000901 1192 7 5 0.64 0.6 1.36 1.35 d10100101 1936 14 9 0.66 0.64 2.14 2.06 d10100201 1778 12 6 0.8 0.5 1.62 1.54 d10100301 2472 4 3 0.64 0.4 0.81 1.05 d10100601 1553 11 7 0.9 0.64 1.79 1.83 d29600501 2400 6 4 0.7 0.56 1.33 1.01 d29800101 670 4 3 0.64 0.6 1.06 1.01 d40000301 2026 8 5 0.56 0.52 1.45 1.54 Economy d40100101 1529 7 4 0.6 0.58 1.19 1.31 e10000101 907 4 2 0.72 0.56 0.64 0.24 e10000201 845 5 3 0.9 0.6 1.06 0.89 e29600201 2035 5 4 0.72 0.5 1.36 1.21 Art e29800201 1831 7 2 0.56 0.52 0.67 0.57 f20000101 2354 12 7 0.58 0.5 1.92 1.79 Prose f20000201 1769 9 6 0.64 0.52 1.72 1.50 g00000201 1163 5 4 0.84 0.56 1.34 1.21 g00000501 790 6 4 0.64 0.54 1.31 1.26 g00001201 425 5 5 0.92 0.62 1.45 1.49 g00100101 1629 10 3 0.84 0.6 0.93 0.82 g00100301 817 6 4 0.76 0.7 1.32 1.26 g00100501 1355 4 4 0.84 0.5 1.31 1.12 g09600901 2179 7 6 0.72 0.62 1.75 1.73 Military g09601601 1271 5 3 0.7 0.52 1.03 0.98 h00000401 1224 6 6 0.72 0.54 1.75 1.60 h00000601 1331 15 7 0.6 0.5 1.88 1.80 h00000901 1507 7 3 0.64 0.68 1.05 0.83 h00001801 1604 8 6 0.68 0.64 1.73 1.66 h00100301 960 6 3 0.9 0.4 1.04 1.05 Life h00100601 1228 6 3 0.8 0.6 1.06 0.89 Table 3 : Experimental data Mean of theme coverage ( TC ) Mean of representation entropy ( RE ) Ratio of information and noise ( F ) Genre Number of samples Method 1 Method 2 Method 1 Method 2 Method 1 Method 2 Economy 10 0.68 0.56 1.42 1.40 2.81 2.27 Art 4 0.72 0.54 0.93 0.73 1.82 1.12 Prose 2 0.62 0.52 1.82 1.65 3.83 2.71 Military 8 0.78 0.58 1.31 1.23 2.89 1.98 Life 6 0.72 0.56 1.42 1.31 2.98 2.08 Table 4 : Evaluation results of parameters The value of RE ( Mitra et al. , 2002 ) is calculated as follows : RE=1 Nz i = ϒ ϒ ∑ i*ilog ( 5 ) The evaluation principles of the summarization redundancy based on RE are demonstrated in Table 2 .</sentence>
				<definiendum id="0">Theme coverage</definiendum>
				<definiendum id="1">Representation entropy</definiendum>
				<definiens id="0">some important notations are defined as follows : N Number of terms in the original document ; Nz Number of sentences in the produced summary ; Lz Nz-by-N matrix composed by all the sentence vectors in the produced summary ; ∑ z Nz-by-Nz covariance matrix composed by all the sentence vectors in the produced summary ; λ i Eigenvalues of ∑ z i:1~Nz</definiens>
				<definiens id="1">Experimental data Mean of theme coverage ( TC ) Mean of representation entropy ( RE ) Ratio of information and noise</definiens>
			</definition>
</paper>

		<paper id="2613">
			<definition id="0">
				<sentence>Text , such as a paragraph describing the weather over the past twentyfour hours , can be processed to yield a set of eventrelation combinations .</sentence>
				<definiendum id="0">Text</definiendum>
				<definiens id="0">such as a paragraph describing the weather over the past twentyfour hours</definiens>
			</definition>
			<definition id="1">
				<sentence>I.e. , A meets B Æ A before B , A starts B Æ A before B , and A ended_by B Æ A before B. In all of these cases , it is implausible that a third event would occur between events A and B in a linear order .</sentence>
				<definiendum id="0">I.e.</definiendum>
				<definiens id="0">A meets B Æ A before B , A starts B Æ A before B</definiens>
			</definition>
			<definition id="2">
				<sentence>FerryDocks is always directly before TruckArrives with no intermediate events between them .</sentence>
				<definiendum id="0">FerryDocks</definiendum>
			</definition>
</paper>

		<paper id="2904">
			<definition id="0">
				<sentence>The measurement is based on the Kolmogorov-Smirnov test statistic , which is given by KS = maxi vextendsinglevextendsingle vextendsinglevextendsingleF parenleftBigR ( i ) MparenrightBig− i N vextendsinglevextendsingle vextendsinglevextendsingle ( 6 ) where R ( i ) M are the raw scores for the false alarms in descending order .</sentence>
				<definiendum id="0">Kolmogorov-Smirnov test statistic</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">the raw scores for the false alarms in descending order</definiens>
			</definition>
			<definition id="1">
				<sentence>Toseta threshold for K false alarms per hour , then the threshold should be set to α = 1.0− KK T , ( 9 ) where KT is the range of false alarms per hour that the miss model is trained .</sentence>
				<definiendum id="0">KT</definiendum>
			</definition>
			<definition id="2">
				<sentence>By Bayes law , the conditional probability can be calculated by FB parenleftBig R ( q ) parenrightBig = Pr parenleftBig Hit|R ( q ) parenrightBig = PHp ( R ( q ) |Hit ) PHp ( R ( q ) |Hit ) + ( 1−PH ) p ( R ( q ) |Miss ) , ( 10 ) where PH is the prior probability of a hit .</sentence>
				<definiendum id="0">conditional probability</definiendum>
				<definiendum id="1">FB parenleftBig R</definiendum>
				<definiendum id="2">PH</definiendum>
				<definiens id="0">( q ) parenrightBig = Pr parenleftBig Hit|R ( q ) parenrightBig = PHp ( R ( q ) |Hit ) PHp ( R ( q ) |Hit ) + ( 1−PH ) p ( R ( q ) |Miss )</definiens>
				<definiens id="1">the prior probability of a hit</definiens>
			</definition>
</paper>

		<paper id="1901">
			<definition id="0">
				<sentence>The ranker uses a maximum entropy learner to train a PCFG over the parse derivation trees , with the current node as a conditioning feature .</sentence>
				<definiendum id="0">ranker</definiendum>
				<definiens id="0">uses a maximum entropy learner to train a PCFG over the parse derivation trees , with the current node as a conditioning feature</definiens>
			</definition>
			<definition id="1">
				<sentence>The parser uses the stochastic parse ranking model learned from the Hinoki treebank , and returns the MRS of the rst ranked parse .</sentence>
				<definiendum id="0">MRS of</definiendum>
			</definition>
</paper>

		<paper id="0801">
</paper>

		<paper id="0705">
			<definition id="0">
				<sentence>Our baseline name tagger consists of an HMM tagger augmented with a set of post-processing rules .</sentence>
				<definiendum id="0">baseline name tagger</definiendum>
				<definiens id="0">consists of an HMM tagger augmented with a set of post-processing rules</definiens>
			</definition>
			<definition id="1">
				<sentence>10 Acknowledgements This research was supported by the Defense Advanced Research Projects Agency as part of the Translingual Information Detection , Extraction and Summarization ( TIDES ) program , under Grant N66001-001-1-8917 from the Space and Naval Warfare Systems Center San Diego , and by the National Science Foundation under Grants IIS-0081962 and 0325657 .</sentence>
				<definiendum id="0">Extraction</definiendum>
				<definiens id="0">the Defense Advanced Research Projects Agency as part of the Translingual Information Detection</definiens>
			</definition>
</paper>

		<paper id="0305">
			<definition id="0">
				<sentence>Incremental interpretation is a fundamental property of the human parsing mechanism .</sentence>
				<definiendum id="0">Incremental interpretation</definiendum>
				<definiens id="0">a fundamental property of the human parsing mechanism</definiens>
			</definition>
			<definition id="1">
				<sentence>We believe the gain provided by more than one word of lookahead is the result of compensating for limitations in the family of deterministic parsers assumed here .</sentence>
				<definiendum id="0">lookahead</definiendum>
				<definiens id="0">the gain provided by more than one word of</definiens>
			</definition>
</paper>

		<paper id="2705">
			<definition id="0">
				<sentence>The fragile and inaccurate multistage parsers of a few decades were replaced by treebank-based parsers , which had better performance , but typically provided more shallow analyses.1 As the same set of data is annotated with more and more levels of annotation , a new type of multistage processing becomes possible that could reintroduce this information , 1A treebank-based parser output is de ned by the treebank on which it is based .</sentence>
				<definiendum id="0">treebank-based parsers</definiendum>
				<definiens id="0">ned by the treebank on which it is based</definiens>
			</definition>
			<definition id="1">
				<sentence>Given a pattern stating that the object ( ARG1 ) of appoint is John and the subject ( ARG0 ) is IBM , a PropBank/NomBank enlightened system could detect that IBM hired John from the following strings : IBM appointed John , John was appointed by IBM , IBM’s appointment of John , the appointment of John by IBM and John is the current IBM appointee .</sentence>
				<definiendum id="0">IBM</definiendum>
				<definiens id="0">a PropBank/NomBank enlightened system could detect that IBM hired John from the following strings : IBM appointed John , John was appointed by IBM , IBM’s appointment of John , the appointment of John by IBM and John is the current IBM appointee</definiens>
			</definition>
			<definition id="2">
				<sentence>Figure 1 lists some sample NomBank propositions along with the class of the noun predicate ( NOM stands for nominalization , DEFREL is a type of relational noun ) .</sentence>
				<definiendum id="0">NOM</definiendum>
				<definiendum id="1">DEFREL</definiendum>
				<definiens id="0">a type of relational noun )</definiens>
			</definition>
			<definition id="3">
				<sentence>A noun instance is markable if it is accompanied by one of its arguments ( ARG0 , ARG1 , ARG2 , ARG3 , ARG4 ) or if it is a nominalization ( or similar word ) and it is accompanied by one of the allowable types of adjuncts ( ARGM-TMP , ARGMLOC , ARGM-ADV , ARGM-EXT , etc. ) the same set of adjuncts used in PropBank.3 The basic idea is that each triple a0 REL , SENSE , ARGNUMa1 uniquely de nes an argument , given a particular sense of a particular REL ( or predicate ) , where ARGNUM is one of the numbered arguments ( ARG0 , ARG1 , ARG2 , ARG3 , ARG4 ) and SENSE is one of the senses of that REL .</sentence>
				<definiendum id="0">ARGNUM</definiendum>
				<definiendum id="1">SENSE</definiendum>
				<definiens id="0">markable if it is accompanied by one of its arguments ( ARG0 , ARG1 , ARG2 , ARG3 , ARG4 ) or if it is a nominalization ( or similar word ) and it is accompanied by one of the allowable types of adjuncts ( ARGM-TMP , ARGMLOC , ARGM-ADV , ARGM-EXT , etc. ) the same set of adjuncts used in PropBank.3 The basic idea is that each triple a0 REL , SENSE , ARGNUMa1 uniquely de nes an argument , given a particular sense of a particular REL ( or predicate ) , where</definiens>
				<definiens id="1">one of the numbered arguments ( ARG0 , ARG1 , ARG2 , ARG3</definiens>
				<definiens id="2">one of the senses of that REL</definiens>
			</definition>
			<definition id="4">
				<sentence>The result was NOMLEX-PLUS , a NOMLEX-style dictionary , which includes the original 1000 entries in NOMLEX plus 6000 additional entries ( Meyers et al. , 2004 ) .</sentence>
				<definiendum id="0">NOMLEX-style dictionary</definiendum>
			</definition>
			<definition id="5">
				<sentence>The phrase for a celebration is a subject-oriented adverbial , similar to adverbs like willingly , which takes the subject of the sentence as an argument .</sentence>
				<definiendum id="0">phrase for a celebration</definiendum>
			</definition>
			<definition id="6">
				<sentence>ARGM is the annotation tag used for nonarguments , also known as adjuncts .</sentence>
				<definiendum id="0">ARGM</definiendum>
				<definiens id="0">the annotation tag used for nonarguments , also known as adjuncts</definiens>
			</definition>
</paper>

		<paper id="1505">
			<definition id="0">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0600">
</paper>

		<paper id="3201">
			<definition id="0">
				<sentence>In the discriminative parsing task , we want to learn a function f : X → Y , where X is a set of sentences , and Y is a set of valid parse trees according to a fixed grammar G. G maps an input x ∈ X to a set of candidate parses G ( x ) ⊆ Y.2 We assume a loss function L : X × Y × Y → R+ .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">a set of sentences , and</definiens>
				<definiens id="1">a set of valid parse trees according to a fixed grammar G. G maps an input x ∈ X to a set of candidate parses G ( x</definiens>
			</definition>
			<definition id="1">
				<sentence>We also define sets R ( xi ) = ∪y∈G ( xi ) R ( xi , y ) for the training examples i = 1 ... n. Thus , R ( xi ) is the set of parts that is seen in at least one of the objects { ( xi , y ) : y ∈ G ( xi ) } .</sentence>
				<definiendum id="0">R ( xi )</definiendum>
				<definiens id="0">R ( xi ) = ∪y∈G ( xi ) R ( xi , y ) for the</definiens>
				<definiens id="1">the set of parts that is seen in at least one of the objects { ( xi , y ) : y ∈ G ( xi ) }</definiens>
			</definition>
			<definition id="2">
				<sentence>marginals as Qm ( µ ( α ) ) , whereµ ( α ) is thevector with components µi , r ( αi ) , and Qm ( µ ) is defined as : C summationdisplay i , r∈R ( xi ) µi , rli , r − 12 vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingleC summationdisplay i , r∈R ( xi ) ( Ii , r −µi , r ) φi , r vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle 2 where li , r = l ( xi , yi , r ) , φi , r = φ ( xi , r ) and Ii , r = I ( xi , yi , r ) .</sentence>
				<definiendum id="0">r vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle</definiendum>
				<definiendum id="1">yi</definiendum>
				<definiens id="0">C summationdisplay i , r∈R ( xi ) µi , rli , r − 12 vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingleC summationdisplay i , r∈R ( xi )</definiens>
			</definition>
			<definition id="3">
				<sentence>Our marginals track constituent parts 〈A , s , e , i〉 and CF-rule-tuple parts 〈A → B C , s , m , e , i〉 The consistency constraints are precisely the insideoutside probability relations : µi , A , s , e = summationdisplay B , Cs &lt; m &lt; e µi , A→B C , s , m , e and µi , A , s , e = summationdisplay B , C e &lt; m≤ni µi , B→AC + summationdisplay B , C 0≤m &lt; s µi , B→CA where ni is the length of the sentence .</sentence>
				<definiendum id="0">ni</definiendum>
				<definiens id="0">s , e , i〉 and CF-rule-tuple parts 〈A → B C , s , m , e</definiens>
				<definiens id="1">the length of the sentence</definiens>
			</definition>
</paper>

		<paper id="0832">
			<definition id="0">
				<sentence>We use the YASMET MEtagger ( Bender et al. 2003 ) to perform the Viterbi search for choosing the most probable tag sequence for a sentence using the probabilities computed during training .</sentence>
				<definiendum id="0">YASMET MEtagger</definiendum>
				<definiens id="0">a sentence using the probabilities computed during training</definiens>
			</definition>
			<definition id="1">
				<sentence>Frame element identification is executed for segments to classify into the classes on FE , Target , or None .</sentence>
				<definiendum id="0">Frame element identification</definiendum>
			</definition>
			<definition id="2">
				<sentence>• Position ( pos ) : The position indicates whether a constituent appears before or after the target predicate .</sentence>
				<definiendum id="0">Position ( pos )</definiendum>
				<definiens id="0">The position indicates whether a constituent appears before or after the target predicate</definiens>
			</definition>
			<definition id="3">
				<sentence>• Previous class ( c_n ) : The class information of the n th -previous constituent ( Target , FE , or None ) is used to exploit the dependency between constituents .</sentence>
				<definiendum id="0">Previous class</definiendum>
				<definiendum id="1">None</definiendum>
				<definiens id="0">The class information of the n th -previous constituent ( Target , FE , or</definiens>
				<definiens id="1">used to exploit the dependency between constituents</definiens>
			</definition>
			<definition id="4">
				<sentence>v ) = 1 f ( c , pt , pos , voice ) f ( c , NP , after , active ) = 1 f ( c , pt , lf ) f ( c , ADVP , obj ) = 1 f ( c , pt_-1 , lf_-1 ) f ( c , VBD_-1 , other_-1 ) = 1 f ( c , pt_1 , lf_1 ) f ( c , PP_1 , other_1 ) = 1 f ( c , head ) f ( c , wheel ) = 1 f ( c , head , frame ) f ( c , wheel , Attaching ) = 1 f ( c , path ) f ( c , NP↑VP↓VBD ) = 1 f ( c , path_-1 ) f ( c , VBD_-1 ) = 1 f ( c , path_1 ) f ( c , PP↑VP↓VBD_1 ) = 1 f ( c , target ) f ( c , tied ) = 1 f ( c , ppath ) f ( c , NP↑VP↓VBD ) = 1 f ( c , ppath , pos ) f ( c , NP↑VP↓VBD , after ) = 1 f ( c , ppath_-1 , pos_-1 ) f ( c , VBD_-1 , after ) = 1 f ( c , ltype , ppath ) f ( c , v , NP↑VP↓VBD ) = 1 f ( c , ltype , path ) f ( c , v , NP↑VP↓VBD ) = 1 f ( c , ltype , path_-1 ) f ( c , v , VBD_-1 ) = 1 f ( c frame ) f ( c , Attaching ) = 1 f ( c , frame , c_-1 ) f ( c , Attaching , T_-1 ) = 1 f ( c , frame , c_-2 , c_-1 ) f ( c , Attaching , NO_-2 , T_-1 ) =1 Table 2 .</sentence>
				<definiendum id="0">c , target ) f</definiendum>
				<definiens id="0">c , NP↑VP↓VBD ) = 1 f ( c , ppath , pos ) f ( c , NP↑VP↓VBD , after ) = 1 f ( c , ppath_-1 , pos_-1 ) f ( c , VBD_-1 , after ) = 1 f ( c , ltype , ppath ) f ( c , v , NP↑VP↓VBD</definiens>
			</definition>
			<definition id="5">
				<sentence>In the example sentence in Figure 2 , “He” is an external argument Noun Phrase , “tied” is a target predicate , and “the driving wheel” is an object argument Noun Phrase .</sentence>
				<definiendum id="0">“He”</definiendum>
				<definiendum id="1">“tied”</definiendum>
				<definiens id="0">a target predicate</definiens>
			</definition>
			<definition id="6">
				<sentence>We submit two sets to SensEval-3 , one ( test A ) is the output of all above processes ( identifying frame elements and tagging them given a sentence ) , and the other ( test B ) is to tag semantic roles given frame elements .</sentence>
				<definiendum id="0">test A )</definiendum>
				<definiens id="0">the output of all above processes ( identifying frame elements and tagging them given a sentence</definiens>
				<definiens id="1">to tag semantic roles given frame elements</definiens>
			</definition>
</paper>

		<paper id="0906">
			<definition id="0">
				<sentence>Our question answering system consists of four main and one auxiliary processing modules ( see Figure 1 ) .</sentence>
				<definiendum id="0">question answering system</definiendum>
			</definition>
			<definition id="1">
				<sentence>The question analysis module takes as input the text of a user’s question and produces its text meaning representation ( TMR , see below for an illustration ) that contains representations of instances of ontological concepts to which the input refers plus speaker-attitude and communicative information .</sentence>
				<definiendum id="0">TMR</definiendum>
				<definiens id="0">input the text of a user’s question and produces its text meaning representation</definiens>
			</definition>
			<definition id="2">
				<sentence>The preprocessor module deals with mark-up in the input text , finds boundaries of sentences and words , recognizes dates , numbers , named entities and acron analy generated the citation for text , the s entries in its l lexicon of sa ontological se clause-level dependency and assign gra constituents ( that is , est objects , obliq ( m the ontology carry disam dependencies in the text .</sentence>
				<definiendum id="0">obliq</definiendum>
				<definiens id="0">the ontology carry disam dependencies in the text</definiens>
			</definition>
			<definition id="3">
				<sentence>The OntoSem ontology provides a metalanguage for describing the meaning of the lexical units in a language as well as for the specification of meaning encoded in TMRs .</sentence>
				<definiendum id="0">OntoSem ontology</definiendum>
				<definiens id="0">provides a metalanguage for describing the meaning of the lexical units in a language as well as for the specification of meaning encoded in TMRs</definiens>
			</definition>
			<definition id="4">
				<sentence>MEET-WITH ( AGENT ( VALUE $ VAR1 ) ) ( THEME ( VALUE $ VAR2 ) ) ( LOCATION ( VALUE $ VAR3 ) ) ( TIME ( VALUE $ VAR4 ) ) PRECONDITIONS ( AND ( LOCATION ( DOMAIN ( VALUE $ VAR1 ) ) ( RANGE ( VALUE $ VAR3 ) ) ( TIME ( VALUE $ VAR4 ) ) ) ( LOCATION ( DOMAIN ( VALUE $ VAR2 ) ) ( RANGE ( VALUE $ VAR3 ) ) ( TIME ( VALUE $ VAR4 ) ) ) ) EFFECTS ( SPEECH-ACT ( AGENT ( VALUE $ VAR1 ) ) ( BENEFICIARY ( VALUE $ VAR2 ) ) ) ( SPEECH-ACT ( AGENT ( VALUE $ VAR2 ) ) ( BENEFICIARY ( VALUE $ VAR1 ) ) ) COME ( AGENT ( VALUE $ VAR1 ) ) ( DESTINATION ( VALUE $ VAR2 ) ) EFFECTS ( LOCATION ( DOMAIN ( VALUE $ VAR1 ) ) ( RANGE ( VALUE $ VAR2 ) ) ) LOCATION ( DOMAIN ( VALUE $ VAR1 ) ) ( RANGE ( VALUE $ VAR2 ) ) EFFECT-OF ( COME ( AGENT ( VALUE $ VAR1 ) ) ( DESTINATION ( VALUE $ VAR2 ) ) ) Figure 4 : A sample script , presented in a simplified presentation format .</sentence>
				<definiendum id="0">MEET-WITH ( AGENT</definiendum>
				<definiendum id="1">THEME</definiendum>
				<definiendum id="2">LOCATION</definiendum>
				<definiendum id="3">TIME</definiendum>
				<definiendum id="4">AND ( LOCATION ( DOMAIN</definiendum>
				<definiendum id="5">RANGE</definiendum>
				<definiendum id="6">TIME</definiendum>
				<definiendum id="7">LOCATION</definiendum>
				<definiendum id="8">DOMAIN</definiendum>
				<definiendum id="9">RANGE</definiendum>
				<definiendum id="10">TIME</definiendum>
				<definiendum id="11">BENEFICIARY</definiendum>
				<definiendum id="12">BENEFICIARY</definiendum>
				<definiendum id="13">DESTINATION</definiendum>
				<definiendum id="14">LOCATION</definiendum>
				<definiendum id="15">DOMAIN</definiendum>
				<definiendum id="16">RANGE</definiendum>
				<definiendum id="17">LOCATION</definiendum>
				<definiendum id="18">RANGE</definiendum>
				<definiendum id="19">DESTINATION</definiendum>
				<definiens id="0">A sample script , presented in a simplified presentation format</definiens>
			</definition>
			<definition id="5">
				<sentence>The English onomasticon ( lexicon of proper names ) currently contains over 350,000 entries semantically linked to ontological concepts ; it is increasing in size daily by means of semiautomated knowledge-extraction methods .</sentence>
				<definiendum id="0">English onomasticon</definiendum>
				<definiens id="0">contains over 350,000 entries semantically linked to ontological concepts</definiens>
			</definition>
			<definition id="6">
				<sentence>We illustrate the structure of the lexicon entry on the example of the first verbal sense of alert : alert-v1 cat v morph regular ex `` He alerted us to the danger '' The above says that there is a REQUEST-ACTION event whose agent is HUMAN-72 ( Colin Powell ) , whose beneficiary is ORGANIZATION-71 ( United Nations ) and whose THEME is an ACCEPT event .</sentence>
				<definiendum id="0">THEME</definiendum>
				<definiens id="0">an ACCEPT event</definiens>
			</definition>
</paper>

		<paper id="0310">
</paper>

		<paper id="2703">
			<definition id="0">
				<sentence>The Penn TreeBank ( PTB ) is an example of such a resource with worldwide impact on natural language processing ( Marcus et al. , 1993 ) .</sentence>
				<definiendum id="0">Penn TreeBank</definiendum>
				<definiendum id="1">PTB )</definiendum>
			</definition>
			<definition id="1">
				<sentence>There are two exceptions to the requirement that an argument include a verb – these are nominal phrases that express an event or a state , and discourse deictics that denote an event or state .</sentence>
				<definiendum id="0">discourse deictics</definiendum>
				<definiens id="0">the requirement that an argument include a verb – these are nominal phrases that express an event or a state</definiens>
			</definition>
			<definition id="2">
				<sentence>Dependent Clause includes tokens where one of the annotators included extra clausal material that is syntactically dependent on the clause that was selected by both , and that occurs on the left or right periphery of the common text .</sentence>
				<definiendum id="0">Dependent Clause</definiendum>
				<definiens id="0">includes tokens where one of the annotators included extra clausal material that is syntactically dependent on the clause that was selected by both</definiens>
			</definition>
</paper>

		<paper id="3005">
			<definition id="0">
				<sentence>Call routing refers to the technique of automatically relaying a customer 's telephone enquiry to one of several appropriate destinations , using computational speech and language processing techniques .</sentence>
				<definiendum id="0">Call routing</definiendum>
			</definition>
</paper>

		<paper id="0860">
			<definition id="0">
				<sentence>The supervised methods are based on Maximum Entropy ( ME ) ( Lau et al. , 1993 ; Berger et al. , 1996 ; Ratnaparkhi , 1998 ) , neural network using the Learning Vector Quantization algorithm ( Kohonen , 1995 ) and Specialized Hidden Markov Models ( Pla , 2000 ) .</sentence>
				<definiendum id="0">Specialized Hidden Markov Models</definiendum>
				<definiens id="0">neural network using the Learning Vector Quantization algorithm</definiens>
			</definition>
			<definition id="1">
				<sentence>ME probability models have been successAssociation for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems fully applied to some NLP tasks , such as POS tagging or sentence boundary detection ( Ratnaparkhi , 1998 ) .</sentence>
				<definiendum id="0">ME probability models</definiendum>
				<definiens id="0">the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems fully applied to some NLP tasks , such as POS tagging or sentence boundary detection</definiens>
			</definition>
			<definition id="2">
				<sentence>Basically , a SHMM consists of changing the topology of a Hidden Markov Model in order to get a more accurate model which includes more information .</sentence>
				<definiendum id="0">SHMM</definiendum>
				<definiens id="0">consists of changing the topology of a Hidden Markov Model</definiens>
				<definiens id="1">includes more information</definiens>
			</definition>
			<definition id="3">
				<sentence>The LVQ-JA ´EN-ELS system ( Garc´ıa-Vega et al. , 2003 ) is based on a supervised learning algorithm for WSD .</sentence>
				<definiendum id="0">LVQ-JA ´EN-ELS system</definiendum>
				<definiens id="0">based on a supervised learning algorithm for WSD</definiens>
			</definition>
			<definition id="4">
				<sentence>The method trains a neural network using the Learning Vector Quantization ( LVQ ) algorithm ( Kohonen , 1995 ) , integrating Semcor and several semantic relations of WordNet .</sentence>
				<definiendum id="0">Learning Vector Quantization</definiendum>
				<definiens id="0">several semantic relations of WordNet</definiens>
			</definition>
			<definition id="5">
				<sentence>Each sense of a word is represented as a vector in an n-dimensional space where n is the number of words in all its contexts .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="6">
				<sentence>Each weight is proportional to the frequency of such senses , and is calculated as MDW ( f ; i ) = 1=f¢1=i where f is an integer representing the frequency of the sense of the word to be disambiguated and i gives the same information for the context word .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">an integer representing the frequency of the sense of the word to be disambiguated and i gives the same information for the context word</definiens>
			</definition>
</paper>

		<paper id="1203">
			<definition id="0">
				<sentence>TheresultofLGanalysisfor a sentence is a labeled undirected simple graph , whosenodesrepresentthewordsofthesentence and whose edges and their labels express the grammatical relationships between the words .</sentence>
				<definiendum id="0">TheresultofLGanalysisfor a sentence</definiendum>
			</definition>
			<definition id="1">
				<sentence>Deflnition 1 ( Interaction subgraph ) The interaction subgraph for an interaction between two proteins A and B in a linkage L is the minimal connected subgraph of L that contains A , B , and the word or phrase that states their interaction .</sentence>
				<definiendum id="0">Deflnition 1</definiendum>
				<definiendum id="1">Interaction subgraph</definiendum>
				<definiendum id="2">interaction subgraph</definiendum>
			</definition>
</paper>

		<paper id="2903">
			<definition id="0">
				<sentence>The index-generation algorithm takes the following factors into consideration : a ) absolute word length by its utterance duration , b ) the number of syllables , c ) the recognizer’s own confidence score , and d ) the part of speech ( i.e. verb , noun ) using a POS tagger with some heuristic rules .</sentence>
				<definiendum id="0">index-generation algorithm</definiendum>
				<definiens id="0">takes the following factors into consideration : a ) absolute word length by its utterance duration , b ) the number of syllables , c ) the recognizer’s own confidence score</definiens>
			</definition>
			<definition id="1">
				<sentence>26.8 13.6 4.3 24 32.0 12.3 3.3 18 39.4 10.8 5.9 12 54.7 8.0 12.2 6 75.9 3.4 20.6 3 87.9 1.4 41.7 Table 1 Indexer SNR Performance where Index Coverage is the fraction of the words in the transcript chosen as index words and IWER is the index word error rate .</sentence>
				<definiendum id="0">Index Coverage</definiendum>
				<definiendum id="1">IWER</definiendum>
				<definiens id="0">the fraction of the words in the transcript chosen as index words</definiens>
				<definiens id="1">the index word error rate</definiens>
			</definition>
			<definition id="2">
				<sentence>Toolkit ( http : //www.nist.gov/speech/tools/ ) Combining Words and Prosody for Information Extraction from Speech .</sentence>
				<definiendum id="0">Toolkit ( http</definiendum>
			</definition>
</paper>

		<paper id="3242">
			<definition id="0">
				<sentence>The interpolated Kneser-Ney smoothing assumes the following form : a18a98a97 a37 a19a40a28 a38a32a43 a28 a38a50a49 a30 a38a69a49a12a70a72a71 a30 a23 a2a100a99a102a101a9a103 a79a81a78a104a79a81a80 a38 a38a69a49a12a70a72a71 a30 a83 a49a98a105a27a106 a107 a83 a78a36a79a81a80 a38a50a49 a30 a38a50a49a82a70a62a71 a30 a83 a75a27a108 a19a29a28 a38a50a49 a30 a38a50a49a82a70a62a71 a30 a23a69a18a98a97 a37 a19a29a28 a38a32a43 a28 a38a50a49 a30 a38a50a49a82a70a62a71a68a41 a23 ( 4 ) where a109 is a discounting constant and a110 a53 a3 a55a60a59 a5 a55a77a59a74a73a82a75 a5 a61 is the interpolation weight for the lower order probabilities ( a53 a2a111a65a112a67 a61 -gram ) .</sentence>
				<definiendum id="0">interpolated Kneser-Ney smoothing</definiendum>
				<definiendum id="1">a109</definiendum>
				<definiens id="0">a18a98a97 a37 a19a40a28 a38a32a43 a28 a38a50a49 a30 a38a69a49a12a70a72a71 a30 a23 a2a100a99a102a101a9a103 a79a81a78a104a79a81a80 a38 a38a69a49a12a70a72a71 a30 a83 a49a98a105a27a106 a107 a83 a78a36a79a81a80 a38a50a49 a30 a38a50a49a82a70a62a71 a30 a83 a75a27a108 a19a29a28 a38a50a49 a30 a38a50a49a82a70a62a71 a30 a23a69a18a98a97 a37 a19a29a28 a38a32a43 a28 a38a50a49 a30 a38a50a49a82a70a62a71a68a41 a23</definiens>
				<definiens id="1">a discounting constant and a110 a53 a3 a55a60a59 a5 a55a77a59a74a73a82a75 a5 a61 is the interpolation weight for the lower order probabilities ( a53 a2a111a65a112a67 a61 -gram )</definiens>
			</definition>
			<definition id="1">
				<sentence>The discount constant is often estimated using leave-one-out , leading to the approximation a109a95a2 a73 a30 a73 a30 a75 a10 a73 a41 , where a2a113a5 is the number of a2 -grams with count one and a2a20a10 is the number of a2 -grams with count two .</sentence>
				<definiendum id="0">a2a113a5</definiendum>
				<definiendum id="1">a2a20a10</definiendum>
			</definition>
			<definition id="2">
				<sentence>By definition , an RF is a collection of randomly constructed Decision Trees ( DTs ) ( Breiman et al. , 1984 ) .</sentence>
				<definiendum id="0">RF</definiendum>
			</definition>
			<definition id="3">
				<sentence>A DT language model uses a decision tree to classify all histories into equivalence classes and each history in the same equivalence class shares the same distribution over the predicted words .</sentence>
				<definiendum id="0">DT language model</definiendum>
				<definiens id="0">uses a decision tree to classify all histories into equivalence classes and each history in the same equivalence class shares the same distribution over the predicted words</definiens>
			</definition>
			<definition id="4">
				<sentence>A node consists of a set of histories and a node splitting splits the set of histories into two subsets based on statistics from the training data .</sentence>
				<definiendum id="0">node</definiendum>
			</definition>
			<definition id="5">
				<sentence>Pruning is done in such a way that we maximize the likelihood of the heldout data , where smoothing is applied similarly to the interpolated KN smoothing : a18 a105a10a9 a19a29a28 a38a124a43a11 a105a10a9 a19a29a28 a38a50a49 a30 a38a69a49a12a70a72a71 a30 a23a77a23 a2 a99a102a101a46a103 a79 a78a104a79a48a80 a38 a106a12 a105a13a9 a79a81a80 a38a50a49 a30 a38a50a49a82a70a62a71 a30 a83a22a83 a49a98a105a27a106 a107 a83 a78a36a79 a12 a105a10a9 a79a81a80 a38a50a49 a30 a38a69a49a12a70a72a71 a30 a83a22a83 a75a27a108 a19 a11 a105a10a9 a19a29a28 a38a50a49 a30 a38a50a49a82a70a62a71 a30 a23a26a23a69a18a98a97 a37 a19a29a28 a38a124a43 a28 a38a69a49 a30 a38a50a49a82a70a72a71a42a41 a23 ( 9 ) where a14a16a15a18a17 a53a10a9 a61 is one of the DT nodes the history can be mapped to and a52a20a19 a16 a53 a3 a55 a57 a3 a55a60a59 a5 a55a60a59a74a73a12a75 a10 a61 is from Equation 5 .</sentence>
				<definiendum id="0">Pruning</definiendum>
			</definition>
			<definition id="6">
				<sentence>An a2 -gram language model can be seen as a special DT language model and a DT language model can also be seen as a special RF language model , therefore , our RF language model is a more general representation of language models .</sentence>
				<definiendum id="0">-gram language model</definiendum>
				<definiendum id="1">RF language model</definiendum>
				<definiens id="0">a special DT language model and a DT language model can also be seen as a special RF language model</definiens>
			</definition>
			<definition id="7">
				<sentence>In order to analyze why this RF approach can improve the PPL on test data , we split the events ( an event is a predicted word with its history ) in test data into two categories : seen events and unseen events .</sentence>
				<definiendum id="0">event</definiendum>
				<definiens id="0">a predicted word with its history ) in test data into two categories : seen events and unseen events</definiens>
			</definition>
			<definition id="8">
				<sentence>However , it is the a110 =0.0 column ( a110 is the weight on the KN-trigram trained from 40M words ) that is the most interesting .</sentence>
				<definiendum id="0">a110</definiendum>
				<definiens id="0">the weight on the KN-trigram trained from 40M words</definiens>
			</definition>
</paper>

		<paper id="1711">
			<definition id="0">
				<sentence>CALL aims to develop useful learning tools with the focus on the learner .</sentence>
				<definiendum id="0">CALL</definiendum>
			</definition>
			<definition id="1">
				<sentence>The following sections outline the use of CL/NLP in CALL ( also known as Intelligent Computer-Assisted Language Learning ICALL ) for a particular target audience – primary school students in Ireland .</sentence>
				<definiendum id="0">Intelligent Computer-Assisted Language Learning ICALL ) for</definiendum>
				<definiens id="0">a particular target audience – primary school students in Ireland</definiens>
			</definition>
			<definition id="2">
				<sentence>Example technologies include speech processing , HMM taggers , probabilistic parsing and FST .</sentence>
				<definiendum id="0">HMM</definiendum>
			</definition>
</paper>

		<paper id="3105">
			<definition id="0">
				<sentence>Consequently , the goal of text mining ( also known as literature mining ) systems and algorithms is to assist users find such needles , if these exist at all in the literature “haystacks” ( Hearst 1999 ) .</sentence>
				<definiendum id="0">text mining</definiendum>
			</definition>
			<definition id="1">
				<sentence>Since a MeSH term typically occurs once in a MEDLINE record , here TFi ( term frequency ) equals the number of documents in which the MeSH term ti occurs within the retrieved document set .</sentence>
				<definiendum id="0">term frequency</definiendum>
				<definiens id="0">equals the number of documents in which the MeSH term ti occurs within the retrieved document set</definiens>
			</definition>
			<definition id="2">
				<sentence>IDFi ( inverse document frequency ) is log ( N/TFi ) .</sentence>
				<definiendum id="0">IDFi ( inverse document frequency</definiendum>
				<definiens id="0">log ( N/TFi )</definiens>
			</definition>
			<definition id="3">
				<sentence>N is the number of documents retrieved for the topic .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of documents retrieved for the topic</definiens>
			</definition>
			<definition id="4">
				<sentence>We restricted ST-C to Disease or Syndrome and Neoplastic Process4 and set M ( the parameter specifying the number of B terms to select ) to 10 .</sentence>
				<definiendum id="0">Neoplastic Process4</definiendum>
				<definiens id="0">the parameter specifying the number of B terms to select</definiens>
			</definition>
			<definition id="5">
				<sentence>Curcumin inhibits NF-kappaB ( 12714587 ) leading to the suppression of cell proliferation and the induction of apoptosis 4Neoplastic Process includes MeSH terms referring to cancers .</sentence>
				<definiendum id="0">Curcumin</definiendum>
			</definition>
			<definition id="6">
				<sentence>TGF-beta1 induced IL-6 which has been implicated in the malignant progression of prostate cancers was severely impeded by curcumin through inhibition of c-Jun ( matches with Genes , jun in the table ) JNK ( an instance of MAPK in the table ) or AP-1 ( 12853969 ) .</sentence>
				<definiendum id="0">c-Jun</definiendum>
				<definiens id="0">an instance of MAPK in the table</definiens>
			</definition>
			<definition id="7">
				<sentence>The family of mitogen-activated protein kinases ( MAPK ) is another group of genes that has an important role in retinal disease .</sentence>
				<definiendum id="0">MAPK</definiendum>
				<definiens id="0">another group of genes that has an important role in retinal disease</definiens>
			</definition>
</paper>

		<paper id="1408">
			<definition id="0">
				<sentence>The software uses the formatting information in files to carry out alignment of headings and 2 In fact , ParaConc could more properly be termed a multilingual concordancer , since it is possible to consult texts in up to four languages at once .</sentence>
				<definiendum id="0">software</definiendum>
				<definiens id="0">uses the formatting information in files to carry out alignment of headings</definiens>
			</definition>
			<definition id="1">
				<sentence>Like a BC , a TM is a tool designed to help translators identify and retrieve information from a bilingual parallel corpus .</sentence>
				<definiendum id="0">TM</definiendum>
				<definiens id="0">a tool designed to help translators identify and retrieve information from a bilingual parallel corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>Trados divides each text into small units known as segments , which usually correspond to sentences or sentencelike units ( e.g. , titles , headings , list items , table cells ) .</sentence>
				<definiendum id="0">Trados</definiendum>
				<definiens id="0">divides each text into small units known as segments , which usually correspond to sentences or sentencelike units ( e.g. , titles , headings , list items , table cells )</definiens>
			</definition>
			<definition id="3">
				<sentence>The source text segments are linked to their corresponding target text segments and the resulting aligned pair of segments is known as a translation unit ( TU ) .</sentence>
				<definiendum id="0">source text segments</definiendum>
				<definiens id="0">linked to their corresponding target text segments and the resulting aligned pair of segments is known as a translation unit ( TU )</definiens>
			</definition>
			<definition id="4">
				<sentence>FR : L'opération a été interrompue par l'application .</sentence>
				<definiendum id="0">FR</definiendum>
				<definiens id="0">L'opération a été interrompue par l'application</definiens>
			</definition>
			<definition id="5">
				<sentence>This means that , at present , most of the translators in the workforce will have received their education during a time when BCs were not part of the translator training curriculum .</sentence>
				<definiendum id="0">education</definiendum>
				<definiens id="0">during a time when BCs were not part of the translator training curriculum</definiens>
			</definition>
			<definition id="6">
				<sentence>On the surface , it may seem to be an obvious choice for a translator to select a TM over a BC since a TM includes the basic functions of a BC , as well as a number of additional features ( e.g. automated searching , segment-level matching , fuzzy matching ) .</sentence>
				<definiendum id="0">TM</definiendum>
				<definiens id="0">includes the basic functions of a BC , as well as a number of additional features ( e.g. automated searching</definiens>
			</definition>
			<definition id="7">
				<sentence>It was noted in section 2.1.1 that one of the perceived limitations of BCs is the nature of the searches that can be conducted .</sentence>
				<definiendum id="0">BCs</definiendum>
			</definition>
			<definition id="8">
				<sentence>Typically , BCs search for occurrences in the corpus that precisely match the search pattern entered by the user .</sentence>
				<definiendum id="0">BCs search</definiendum>
				<definiens id="0">for occurrences in the corpus that precisely match the search pattern entered by the user</definiens>
			</definition>
			<definition id="9">
				<sentence>Another good candidate for use with a TM is a text where the repetitive sentences are varied ( i.e. , many sentences with few occurrences of each ) and scattered throughout the document .</sentence>
				<definiendum id="0">TM</definiendum>
				<definiens id="0">a text where the repetitive sentences are varied</definiens>
			</definition>
			<definition id="10">
				<sentence>Technology : A Practical Introduction .</sentence>
				<definiendum id="0">Technology</definiendum>
				<definiens id="0">A Practical Introduction</definiens>
			</definition>
</paper>

		<paper id="0404">
			<definition id="0">
				<sentence>Constructional templates are of the form [ Na1 a10 in Na1 a9 ] ( where Na1a2 indicates that the word is a noun ( N ) in English ( a3 ) and corresponds to the a4 th-occurring noun in the original Japanese ; see Table 3 for further example templates and Kageura et al. ( 2004 ) for discussion of templates of this type ) .</sentence>
				<definiendum id="0">Constructional templates</definiendum>
				<definiens id="0">are of the form [ Na1 a10 in Na1 a9 ] ( where Na1a2 indicates that the word is a noun</definiens>
			</definition>
			<definition id="1">
				<sentence>Ignoring the effects of POS constraints for the moment , the number of generated translations is a5a7a6a9a8a11a10a13a12a15a14 where a8 and a10 are the fertility of Japanese nouns Na16 a9 and Na16 a10 , respectively , and a12 is the number of translation templates .</sentence>
				<definiendum id="0">a12</definiendum>
				<definiens id="0">a5a7a6a9a8a11a10a13a12a15a14 where a8 and a10 are the fertility of Japanese nouns Na16 a9 and Na16 a10 , respectively , and</definiens>
				<definiens id="1">the number of translation templates</definiens>
			</definition>
			<definition id="2">
				<sentence>The ALTDIC dictionary was compiled from the ALT-J/E MT system ( Ikehara et al. , 1991 ) , and has approximately 400,000 entries including more than 200,000 proper nouns ; EDICT ( Breen , 1995 ) has approximately 150,000 entries .</sentence>
				<definiendum id="0">EDICT</definiendum>
				<definiens id="0">the ALT-J/E MT system ( Ikehara et al. , 1991 ) , and has approximately 400,000 entries including more than 200,000 proper nouns</definiens>
			</definition>
			<definition id="3">
				<sentence>This is calculated as:3 a0a2a1a4a3a6a5a8a7a10a9a12a11 a13a15a14 a7a10a9a12a11 a11 a14a17a16a17a18a20a19a22a21a24a23 a5a8a7a10a9a12a11 a13a15a14 a7a10a9a12a11 a11 a14a17a16a17a18a26a25a28a27a29a23 a5a8a7a10a9a12a11 a13a30a14a17a16a17a18a31a23 a5a8a7a10a9a32a11 a11 a14a33a16a17a18 where a34a36a35 a10 a9 and a34a37a35 a10 a10 are the word-level translations of the source language Na35 a9 a9 and Na35 a9 a10 , respectively , and a12 is the translation template.4 Each probability is calculated according to a maximum likelihood estimate based on relative corpus occurrence .</sentence>
				<definiendum id="0">a12</definiendum>
				<definiens id="0">a34a36a35 a10 a9 and a34a37a35 a10 a10 are the word-level translations of the source language Na35 a9 a9 and Na35 a9 a10 , respectively , and</definiens>
				<definiens id="1">the translation template.4 Each probability is calculated according to a maximum likelihood estimate based on relative corpus occurrence</definiens>
			</definition>
			<definition id="4">
				<sentence>E.g. , in generating translations for a88a63a89 a90 a3 a42a63a91 fudousaNa3gaisha “real estate company” , we get two word-level translations for a88a47a89 a90 : real estate and real property .</sentence>
				<definiendum id="0">E.g.</definiendum>
				<definiens id="0">real estate and real property</definiens>
			</definition>
			<definition id="5">
				<sentence>We chose to use the BNC and Reuters Corpus because of their complementary nature : the BNC is a balanced corpus and hence has a rounded coverage of NN compounds ( see Table 1 ) , whereas the Reuters Corpus contains newswire data which aligns relatively well in content with the newspaper articles in the Mainichi Shimbun Corpus .</sentence>
				<definiendum id="0">complementary nature</definiendum>
				<definiendum id="1">BNC</definiendum>
				<definiens id="0">a balanced corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>RASP is a tag sequence grammar-based stochastic parser which attempts to exhaustively resolve inter-word dependencies in the input .</sentence>
				<definiendum id="0">RASP</definiendum>
				<definiens id="0">a tag sequence grammar-based stochastic parser which attempts to exhaustively resolve inter-word dependencies in the input</definiens>
			</definition>
			<definition id="7">
				<sentence>The principle reason for the English data being more forgiving is the existence of possessiveand PP-based paraphrases of NN gold-standard translations ( e.g. ammendment of rule ( s ) as an L1-recoverable paraphrase of rule ammendment ) .</sentence>
				<definiendum id="0">principle reason</definiendum>
				<definiens id="0">the existence of possessiveand PP-based paraphrases of NN gold-standard translations ( e.g. ammendment of rule ( s ) as an L1-recoverable paraphrase of rule ammendment )</definiens>
			</definition>
			<definition id="8">
				<sentence>The results based on training over data from all frequency bands are labelled All and those based on training over data from only the same frequency band are labelled Local ; G is the gold-standard accuracy and S is the silver-standard accuracy .</sentence>
				<definiendum id="0">G</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">the gold-standard accuracy and</definiens>
			</definition>
</paper>

		<paper id="2901">
			<definition id="0">
				<sentence>User needs to navigate through the calls and find relevant information in the audio .</sentence>
				<definiendum id="0">User</definiendum>
				<definiens id="0">needs to navigate through the calls and find relevant information in the audio</definiens>
			</definition>
			<definition id="1">
				<sentence>The keyword extraction component generates the most salient words found in the speech recognition output ( one-best word ) or transcript ( if available ) and can be used to determine the nature of the spoken communications .</sentence>
				<definiendum id="0">keyword extraction component</definiendum>
				<definiens id="0">generates the most salient words found in the speech recognition output ( one-best word</definiens>
			</definition>
			<definition id="2">
				<sentence>The acoustic models consist of decision tree state clustered triphones and the output distributions are mixtures of Gaussians .</sentence>
				<definiendum id="0">acoustic models</definiendum>
			</definition>
			<definition id="3">
				<sentence>A popular approach is to select keywords that frequently occur in one document but do not frequently occur in other documents based on the term frequency inverse document frequency ( TF-IDF ) feature .</sentence>
				<definiendum id="0">frequency inverse document frequency</definiendum>
				<definiens id="0">to select keywords that frequently occur in one document but do not frequently occur in other documents based on the term</definiens>
			</definition>
			<definition id="4">
				<sentence>The term probability measures the probability that a term may appear in a general document and it is a language dependent characteristic .</sentence>
				<definiendum id="0">term probability</definiendum>
				<definiens id="0">measures the probability that a term may appear in a general document and it is a language dependent characteristic</definiens>
			</definition>
			<definition id="5">
				<sentence>The lattice output is a compact representation of likely alternative hypotheses of an ASR system .</sentence>
				<definiendum id="0">lattice output</definiendum>
			</definition>
			<definition id="6">
				<sentence>The expected count for a substring can be defined as the sum of the probabilities of all paths which contain that substring .</sentence>
				<definiendum id="0">expected count for a substring</definiendum>
				<definiens id="0">the sum of the probabilities of all paths which contain that substring</definiens>
			</definition>
			<definition id="7">
				<sentence>Let C ( q ) be the number of times the query q is found correctly , M ( q ) be the number of answers to the query q , and N ( q ) be the number of times q is found in the reference .</sentence>
				<definiendum id="0">C ( q )</definiendum>
				<definiendum id="1">M ( q</definiendum>
				<definiendum id="2">N ( q</definiendum>
				<definiens id="0">the number of answers to the query q</definiens>
			</definition>
</paper>

		<paper id="1603">
			<definition id="0">
				<sentence>The Framework consists of 9 stages during which various lexical resources are collected , studied , and combined into a single combinatory lexical resource .</sentence>
				<definiendum id="0">Framework</definiendum>
				<definiens id="0">consists of 9 stages during which various lexical resources are collected</definiens>
			</definition>
			<definition id="1">
				<sentence>Cross-Language Information Retrieval ( CLIR ) systems facilitate matching between queries and documents that do not necessarily share the same language .</sentence>
				<definiendum id="0">Cross-Language Information Retrieval</definiendum>
				<definiendum id="1">CLIR ) systems</definiendum>
				<definiens id="0">facilitate matching between queries and documents that do not necessarily share the same language</definiens>
			</definition>
</paper>

		<paper id="0201">
			<definition id="0">
				<sentence>A problem for RST : the need for multi-level discourse analysis .</sentence>
				<definiendum id="0">problem for RST</definiendum>
				<definiens id="0">the need for multi-level discourse analysis</definiens>
			</definition>
</paper>

		<paper id="3239">
			<definition id="0">
				<sentence>In this paper , we propose a Boosting algorithm that captures sub-structures embedded in texts .</sentence>
				<definiendum id="0">Boosting algorithm</definiendum>
				<definiens id="0">captures sub-structures embedded in texts</definiens>
			</definition>
			<definition id="1">
				<sentence>For learning algorithms to identify these topics , a text is usually represented as a bag-of-words , where a text is regarded as a multi-set ( i.e. , a bag ) of words and the word order or syntactic relations appearing in the original text is ignored .</sentence>
				<definiendum id="0">multi-set</definiendum>
				<definiens id="0">a bag ) of words and the word order or syntactic relations appearing in the original text is ignored</definiens>
			</definition>
			<definition id="2">
				<sentence>Note that word sequence , base-phrase annotation , dependency tree and an XML document can be modeled as a labeled ordered tree .</sentence>
				<definiendum id="0">XML document</definiendum>
				<definiens id="0">a labeled ordered tree</definiens>
			</definition>
			<definition id="3">
				<sentence>f 1g , from given training examples T = fhxi ; yiigLi=1 , where xi 2X is a labeled ordered tree and yi 2f 1gis a class label associated with each training data ( we focus here on the problem of binary classification . )</sentence>
				<definiendum id="0">xi 2X</definiendum>
				<definiens id="0">a labeled ordered tree and yi 2f 1gis a class label associated with each training data</definiens>
			</definition>
			<definition id="4">
				<sentence>Decision stumps are simple classifiers , where the final decision is made by only a single hypothesis a0 a1 a2 a1 a0 a2 a3 a0 a1 a2 a0 a2 a1 a0 a4a4a6a5 a7 a8a8a10a9 a11a11a12 Figure 1 : Labeled ordered tree and subtree relation or feature .</sentence>
				<definiendum id="0">Decision stumps</definiendum>
				<definiens id="0">Labeled ordered tree and subtree relation or feature</definiens>
			</definition>
			<definition id="5">
				<sentence>The decision stumps are trained to find ruleh^t ; ^yi that minimizes the error rate for the given training data T =fhxi ; yiigLi=1 : h^t ; ^yi = argmin t2F ; y2f 1g 1 2L LX i=1 ( 1 yihht ; yi ( xi ) ) ; ( 1 ) whereF is a set of candidate trees or a feature set ( i.e. , F = SLi=1ftjt xig ) .</sentence>
				<definiendum id="0">whereF</definiendum>
				<definiendum id="1">F</definiendum>
				<definiens id="0">a set of candidate trees or a feature set ( i.e. ,</definiens>
			</definition>
			<definition id="6">
				<sentence>The gain function for ruleht ; yiis defined as gain ( ht ; yi ) def= LX i=1 yihht ; yi ( xi ) : ( 2 ) Using the gain , the search problem given in ( 1 ) becomes equivalent to the following problem : h^t ; ^yi = argmax t2F ; y2f 1g gain ( ht ; yi ) : In this paper , we will use gain instead of error rate for clarity .</sentence>
				<definiendum id="0">gain function for ruleht ; yiis</definiendum>
				<definiendum id="1">yi )</definiendum>
				<definiens id="0">gain ( ht ; yi ) def= LX i=1 yihht ; yi ( xi ) : ( 2 ) Using the gain , the search problem given in ( 1 ) becomes equivalent to the following problem : h^t ; ^yi = argmax t2F</definiens>
			</definition>
			<definition id="7">
				<sentence>Problem 1 Find Optimal Rule Let T = fhx1 ; y1 ; d1i ; : : : ; hxL ; yL ; dLig be training data , where , xi is a labeled ordered tree , yi 2 f 1g is a class label associated with xi and di ( PLi=1di = 1 ; di 0 ) is a normalized weight assigned to xi .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiens id="0">a labeled ordered tree</definiens>
				<definiens id="1">a normalized weight assigned to xi</definiens>
			</definition>
			<definition id="8">
				<sentence>Tree kernel is one of the convolution kernels , and implicitly maps the example represented in a labeled ordered tree into all subtree spaces .</sentence>
				<definiendum id="0">Tree kernel</definiendum>
				<definiens id="0">one of the convolution kernels , and implicitly maps the example represented in a labeled ordered tree into all subtree spaces</definiens>
			</definition>
			<definition id="9">
				<sentence>The implicit mapping defined by tree kernel is given as : ( x ) = ( I ( t1 x ) ; : : : ; I ( tjFj x ) ) , where tj2F , x2X and I ( ) is the indicator function 1 .</sentence>
				<definiendum id="0">tj2F</definiendum>
				<definiendum id="1">I ( )</definiendum>
				<definiens id="0">the indicator function 1</definiens>
			</definition>
			<definition id="10">
				<sentence>The complexity of SVMs with tree kernel is O ( L0jN1jjN2j ) , where N1 and N2 are trees , and L0 is the number of support vectors , which is too heavy to realize real applications .</sentence>
				<definiendum id="0">L0</definiendum>
				<definiens id="0">the number of support vectors</definiens>
			</definition>
			<definition id="11">
				<sentence>Table 1 : Results of Experiments on PHS / MOD , F-measure , precision ( % ) , and recall ( % ) PHS MOD opinion assertion description Boosting bow 76.0 ( 76.1 / 75.9 ) 59.6 ( 59.4 / 60.0 ) 70.0 ( 70.4 / 69.9 ) 82.2 ( 81.0 / 83.5 ) dep 78.7 ( 79.1 / 78.4 ) 78.7* ( 90.2 / 70.0 ) 86.7* ( 88.0 / 85.6 ) 91.7* ( 91.1 / 92.4 ) n-gram 79.3 ( 79.8 / 78.5 ) 76.7* ( 87.2 / 68.6 ) 87.2 ( 86.9 / 87.4 ) 91.6 ( 91.0 / 92.2 ) SVMs bow 76.8 ( 78.3 / 75.4 ) 57.2 ( 79.0 / 48.4 ) 71.3 ( 64.3 / 80.0 ) 82.1 ( 82.7 / 81.5 ) dep 77.0 ( 80.7 / 73.6 ) 24.2 ( 95.7 / 13.8 ) 81.7 ( 86.7 / 77.2 ) 87.6 ( 86.1 / 89.2 ) n-gram 78.9 ( 80.4 / 77.5 ) 57.5 ( 98.0 / 40.9 ) 84.1 ( 90.1 / 78.9 ) 90.1 ( 88.2 / 92.0 ) We employed a McNemar’s paired test on the labeling disagreements .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiendum id="1">90.1 / 78.9 ) 90.1</definiendum>
				<definiens id="0">employed a McNemar’s paired test on the labeling disagreements</definiens>
			</definition>
			<definition id="12">
				<sentence>Even though all subtrees are used as feature candidates , Boosting selects a small and highly relevant subset of features .</sentence>
				<definiendum id="0">Boosting</definiendum>
				<definiens id="0">selects a small and highly relevant subset of features</definiens>
			</definition>
</paper>

		<paper id="2010">
			<definition id="0">
				<sentence>The word formation building blocks define the so called inflectional classes , which represent sequential letter strings associated with word classes as well as with individual words , also known as isuffixes in Porter-like stemmers ( Porter,1980 ) .</sentence>
				<definiendum id="0">word formation building blocks</definiendum>
				<definiens id="0">the so called inflectional classes , which represent sequential letter strings associated with word classes as well as with individual words , also known as isuffixes in Porter-like stemmers ( Porter,1980 )</definiens>
			</definition>
			<definition id="1">
				<sentence>Section 3 introduces our basic resource : the Large Grammatical Dictionary of Bulgarian .</sentence>
				<definiendum id="0">basic resource</definiendum>
				<definiens id="0">the Large Grammatical Dictionary of Bulgarian</definiens>
			</definition>
			<definition id="2">
				<sentence>2 We use the following abbreviations for the ten POS : A ( adjective ) , ADV ( adverb ) , CONJ ( conjunction ) , INTJ ( interjunction ) , N ( noun ) , NU ( numeral ) , PC ( particle ) , PREP ( preposition ) , PRO ( pronoun ) and V ( verb ) .</sentence>
				<definiendum id="0">ADV ( adverb</definiendum>
				<definiendum id="1">NU ( numeral</definiendum>
				<definiendum id="2">PC</definiendum>
				<definiendum id="3">PREP</definiendum>
				<definiens id="0">A ( adjective )</definiens>
			</definition>
			<definition id="3">
				<sentence>These criteria are combined in the following formula : ) log ( 1 ) 1 ( ) 1 ( 2/ ) 1 ( l n pp t pscore n + = where : l is the rule length ; x is the number of successful rule guesses ; n is the total number of training instances compatible with the rule ; p is a smoothed version of the maximum likelihood estimation pˆ , which ensures that neither p nor ( 1–p ) could be zero : p = ( x+0.5 ) / ( n+1 ) ; n pp ) 1 ( is an estimation of the dispersion ; ) 1 ( 2/ ) 1 ( n t is a coefficient of the t-distribution with n–1 degrees of freedom and confidence level  .</sentence>
				<definiendum id="0">x</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">p</definiendum>
				<definiendum id="3">n pp ) 1 (</definiendum>
				<definiendum id="4">; ) 1</definiendum>
				<definiens id="0">l n pp t pscore n + = where : l is the rule length ;</definiens>
				<definiens id="1">the number of successful rule guesses</definiens>
				<definiens id="2">a smoothed version of the maximum likelihood estimation pˆ , which ensures that neither p</definiens>
				<definiens id="3">an estimation of the dispersion</definiens>
				<definiens id="4">a coefficient of the t-distribution with n–1 degrees of freedom and confidence level </definiens>
			</definition>
			<definition id="4">
				<sentence>defined as 2PR/ ( P+R ) , where R is the recall ( proportion of proposed instances out of all that have to be found ) .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the recall ( proportion of proposed instances out of all that have to be found )</definiens>
			</definition>
</paper>

		<paper id="3210">
			<definition id="0">
				<sentence>Sentence splitting is a necessary pre-processing step for a number of Natural Language Processing ( NLP ) tasks including part-ofspeech tagging and parsing .</sentence>
				<definiendum id="0">Sentence splitting</definiendum>
				<definiens id="0">a necessary pre-processing step for a number of Natural Language Processing ( NLP ) tasks including part-ofspeech tagging and parsing</definiens>
			</definition>
			<definition id="1">
				<sentence>We used BoosTexter ( Schapire and Singer , 2000 ) as our machine learning system .</sentence>
				<definiendum id="0">BoosTexter</definiendum>
				<definiens id="0">machine learning system</definiens>
			</definition>
			<definition id="2">
				<sentence>Relative Position ( Pos ) : The relative position of a sentence in the text is calculated by dividing the current sentence number by the number of sentences in the text .</sentence>
				<definiendum id="0">Relative Position</definiendum>
				<definiens id="0">The relative position of a sentence in the text is calculated by dividing the current sentence number by the number of sentences in the text</definiens>
			</definition>
			<definition id="3">
				<sentence>Quotes ( Quotep , Quotec , Quotei ) : These features encode whether the previous or current sentence contain a quotation ( Quotep and Quotec , respectively ) and whether the current sentence continues a quotation that started in a preceding sentence ( Quotei ) .</sentence>
				<definiendum id="0">Quotes</definiendum>
				<definiens id="0">These features encode whether the previous or current sentence contain a quotation ( Quotep and Quotec , respectively ) and whether the current sentence continues a quotation that started in a preceding sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>Words ( W1 , W2 , W3 , Wall ) : These text-valued features encode the words in the sentence .</sentence>
				<definiendum id="0">Words</definiendum>
				<definiens id="0">These text-valued features encode the words in the sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>Wall takes the complete sentence as its value .</sentence>
				<definiendum id="0">Wall</definiendum>
			</definition>
			<definition id="6">
				<sentence>Signature ( Sign , Signp ) : These text-valued features encode the sequence of part-of-speech tags in the current sentence .</sentence>
				<definiendum id="0">Signature</definiendum>
				<definiendum id="1">Signp )</definiendum>
				<definiens id="0">These text-valued features encode the sequence of part-of-speech tags in the current sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>The only exception is the German fiction corpus , which consists mainly of 19th century texts .</sentence>
				<definiendum id="0">fiction corpus</definiendum>
				<definiens id="0">consists mainly of 19th century texts</definiens>
			</definition>
			<definition id="8">
				<sentence>The word entropy rate yields the worst performance , whereas character-based models perform as well as word-based models .</sentence>
				<definiendum id="0">word entropy rate</definiendum>
				<definiens id="0">whereas character-based models perform as well as word-based models</definiens>
			</definition>
</paper>

		<paper id="3216">
			<definition id="0">
				<sentence>Here , S is the state space , and the observation sequences come from the alphabet K. j is the probability of beginning in state j. The transition probability ai ; j is the probability of transitioning from state i to state j. bi ; j ; k is the probability of emitting ( the non-empty ) observation sequence k while transitioning from state i to state j. Finally , xt denotes the state after emitting t symbols .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">j</definiendum>
				<definiendum id="2">k</definiendum>
				<definiens id="0">the state space</definiens>
				<definiens id="1">the probability of emitting</definiens>
			</definition>
			<definition id="1">
				<sentence>The prior we choose has a form such that fake counts are added as follows : word-to-word rewrites get an additional count of 2 ; identity rewrites get an additional count of 4 ; stemidentity rewrites get an additional count of 3 .</sentence>
				<definiendum id="0">stemidentity rewrites get</definiendum>
				<definiens id="0">an additional count of 3</definiens>
			</definition>
			<definition id="2">
				<sentence>Abstracts Extracts Documents 2033 Sentences 13k 41k Words 261k 1m Types 14k 26k 29k Sentences/Doc 6:28 21:51 Words/Doc 128:52 510:99 Words/Sent 20:47 23:77 Table 4 : Ziff-Davis extract corpus statistics From the Ziff-Davis corpus , we randomly selected 45 document/abstract pairs and had both annotators align them .</sentence>
				<definiendum id="0">Ziff-Davis corpus</definiendum>
				<definiens id="0">Ziff-Davis extract corpus statistics From the</definiens>
			</definition>
			<definition id="3">
				<sentence>The soft precision metric induces a new , soft F-Score , labeled SoftF .</sentence>
				<definiendum id="0">soft precision metric</definiendum>
				<definiens id="0">induces a new , soft F-Score , labeled SoftF</definiens>
			</definition>
			<definition id="4">
				<sentence>The PBHMMO system is an oracle system in which system-produced alignments are removed for summary words that should be null-aligned ( according to the hand-annotated data ) .</sentence>
				<definiendum id="0">PBHMMO system</definiendum>
			</definition>
</paper>

		<paper id="2421">
			<definition id="0">
				<sentence>SNoW learns a sparse network of linear functions , in which the targets ( phrase border predictions or argument type predictions , in this case ) are represented as linear functions over a common feature space .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiens id="0">learns a sparse network of linear functions , in which the targets ( phrase border predictions or argument type predictions , in this case ) are represented as linear functions over a common feature space</definiens>
			</definition>
			<definition id="1">
				<sentence>• Part-of-speech tag ( POS ) feature includes the POS tags of the current word , two words before and after .</sentence>
				<definiendum id="0">Part-of-speech tag</definiendum>
				<definiendum id="1">feature</definiendum>
				<definiens id="0">includes the POS tags of the current word , two words before and after</definiens>
			</definition>
			<definition id="2">
				<sentence>• Predicate lemma &amp; POS tag show the lemma form and POS tag of the active predicate .</sentence>
				<definiendum id="0">POS tag</definiendum>
				<definiens id="0">show the lemma form and POS tag of the active predicate</definiens>
			</definition>
			<definition id="3">
				<sentence>Formally ( but very briefly ) , the phrase classifier is attempting to assign labels to a set of phrases , S1 : M , indexed from 1 to M. Each phrase Si can take any label from a set of phrase labels , P , and the indexed set of phrases can take a set of labels , s1 : M ∈ PM .</sentence>
				<definiendum id="0">S1</definiendum>
				<definiens id="0">attempting to assign labels to a set of phrases</definiens>
			</definition>
</paper>

		<paper id="3212">
			<definition id="0">
				<sentence>The proposition bank : An annotated corpus of semantic roles .</sentence>
				<definiendum id="0">proposition bank</definiendum>
				<definiens id="0">An annotated corpus of semantic roles</definiens>
			</definition>
</paper>

		<paper id="1804">
			<definition id="0">
				<sentence>The Gene Ontology is an important tool for the representation and processing of information about gene products and functions .</sentence>
				<definiendum id="0">Gene Ontology</definiendum>
				<definiens id="0">an important tool for the representation and processing of information about gene products and functions</definiens>
			</definition>
			<definition id="1">
				<sentence>GO s cellular component ( cc ) vocabulary consists of terms such as flagellum , chromosome , ferritin , extracellular matrix and virion .</sentence>
				<definiendum id="0">GO</definiendum>
				<definiens id="0">s cellular component ( cc ) vocabulary consists of terms such as flagellum , chromosome , ferritin , extracellular matrix and virion</definiens>
			</definition>
			<definition id="2">
				<sentence>A biological process ( bp ) is defined in GO as : A phenomenon marked by changes that lead to a particular result , mediated by one or more gene products .</sentence>
				<definiendum id="0">biological process</definiendum>
				<definiens id="0">A phenomenon marked by changes that lead to a particular result , mediated by one or more gene products</definiens>
			</definition>
			<definition id="3">
				<sentence>TGICL is a pipeline for the analysis of large Expressed Sequence Tags ( EST ) and mRNA databases in which the sequences are first clustered on the basis of pairwise sequence similarity and then assembled by individual clusters ( Pertia et al 2003 ) .</sentence>
				<definiendum id="0">TGICL</definiendum>
			</definition>
			<definition id="4">
				<sentence>( Resnik 1995 ) has pointed out that the semantic similarity of terms as one traverses the hierarchical tree reduces by a factor of log ( p ( c ) ) where p ( c ) is the probability of finding a child for the term when seeking information .</sentence>
				<definiendum id="0">p ( c )</definiendum>
				<definiens id="0">the probability of finding a child for the term when seeking information</definiens>
			</definition>
			<definition id="5">
				<sentence>The confidence of an association rule is the fraction of cases in which it is correct relative to those in which it is applicable , that is , the ratio of the number of transactions that contain all items in the rule to the number of transactions that contain all items in the antecendent .</sentence>
				<definiendum id="0">confidence of an association rule</definiendum>
				<definiens id="0">the fraction of cases in which it is correct relative to those in which it is applicable , that is , the ratio of the number of transactions that contain all items in the rule to the number of transactions that contain all items in the antecendent</definiens>
			</definition>
			<definition id="6">
				<sentence>The numbers in parentheses at the end of each rule describe the quality of the rule as ( S % /A , C % ) , where S is the support of the rule as a percentage of gene products to which the rule is applicable , A is the absolute number of gene products to which it is applicable ( which is designed to complement the information regarding support ) , and C is the confidence of the rule .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the support of the rule as a percentage of</definiens>
				<definiens id="1">applicable ( which is designed to complement the information regarding support ) , and</definiens>
				<definiens id="2">the confidence of the rule</definiens>
			</definition>
			<definition id="7">
				<sentence>In the GO context S is the percentage of gene product IDs to which the relevant rule is applicable ( i.e. , the percentage of gene product IDs which are annotated with all the terms in the antecedent in the rule ) , A is the absolute number of gene product IDs to which the rule is applicable , and C is the percentage of gene product IDs for which the rule makes the correct prediction relative to those to which the rule is applicable .</sentence>
				<definiendum id="0">GO context S</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">applicable ( i.e. , the percentage of gene product IDs which are annotated with all the terms in the antecedent in the rule</definiens>
			</definition>
			<definition id="8">
				<sentence>Basic Foundational Ontology ( BFO ) is a framework of this type , the essentials of which can be summarized as follows .</sentence>
				<definiendum id="0">BFO )</definiendum>
			</definition>
			<definition id="9">
				<sentence>BFO consists of two complementary ontologies , called SNAP ( a snapshot ontology of continuant entities existing at a time ) and SPAN ( a fourdimensional ontology of processes unfolding themselves through time .</sentence>
				<definiendum id="0">BFO</definiendum>
				<definiendum id="1">SPAN</definiendum>
				<definiens id="0">consists of two complementary ontologies , called SNAP ( a snapshot ontology of continuant entities existing at a time</definiens>
				<definiens id="1">a fourdimensional ontology of processes unfolding themselves through time</definiens>
			</definition>
			<definition id="10">
				<sentence>SPAN entities , in contrast , have temporal parts which means that they unfold themselves in successive phases and can be segmented via segmentation of the temporal intervals which they occupy .</sentence>
				<definiendum id="0">SPAN entities</definiendum>
				<definiens id="0">temporal parts which means that they unfold themselves in successive phases and can be segmented via segmentation of the temporal intervals which they occupy</definiens>
			</definition>
</paper>

		<paper id="1219">
			<definition id="0">
				<sentence>For efficiency , we apply the one vs. others strategy , which builds K classifiers so as to separate one class from all others , instead of the pairwise strategy , which builds K* ( K-1 ) /2 classifiers considering all pairs of classes .</sentence>
				<definiendum id="0">pairwise strategy</definiendum>
				<definiens id="0">builds K classifiers so as to separate one class from all others</definiens>
			</definition>
			<definition id="1">
				<sentence>+3.1 +Abbreviation Resolution +2.1 +Small Closed Dictionary +1.5 +Large Open Dictionary +1.2 +All Deep Knowledge Resources +12.2 Table 2 : Final Detailed Performance : full correct answer ( # of correct answers ) P R F Protein ( 4015 ) 69.01 79.24 73.77 DNA ( 772 ) 66.84 73.11 69.83 RNA ( 75 ) 64.66 63.56 64.10 Cell Line ( 329 ) 53.85 65.80 59.23 Cell Type ( 1391 ) 78.06 72.41 75.13 Overall ( 6582 ) 69.42 75.99 72.55 Table 3 : Final Detailed Performance : correct left boundary with correct class information ( # of correct answers ) P R F Protein ( 4239 ) 72.86 83.66 77.89 DNA ( 798 ) 69.09 75.57 72.18 RNA ( 76 ) 65.52 64.41 64.96 Cell Line ( 346 ) 56.63 69.20 62.29 Cell Type ( 1418 ) 79.57 73.82 76.59 Overall ( 6877 ) 72.53 79.39 75.80 Table 4 : Final Detailed Performance : correct right boundary with correct class information ( # of correct answers ) P R F Protein ( 4285 ) 73.65 84.57 78.73 DNA ( 854 ) 73.94 80.87 77.25 RNA ( 83 ) 71.55 70.34 70.94 Cell Line ( 383 ) 62.68 76.60 68.95 Cell Type ( 1532 ) 85.97 79.75 82.74 Overall ( 7137 ) 75.27 82.39 78.67 In the paper , we have explored various deep knowledge resources such as the name alias phenomenon , the cascaded entity name phenomenon , the use of both a closed dictionary from the training corpus and an open dictionary from the database term list SwissProt and the alias list LocusLink , the abbreviation resolution and indomain POS using the GENIA corpus .</sentence>
				<definiendum id="0">RNA</definiendum>
				<definiens id="0">Final Detailed Performance : full correct answer ( # of correct answers</definiens>
				<definiens id="1">Final Detailed Performance : correct left boundary with correct class information ( # of correct answers ) P R F Protein</definiens>
			</definition>
</paper>

		<paper id="2408">
			<definition id="0">
				<sentence>This inequality means that minimizing D ( fˆ ) leads to reducing the generalization error R ( fˆ ) .</sentence>
				<definiendum id="0">inequality</definiendum>
			</definition>
			<definition id="1">
				<sentence>The TOP kernel consists of features which can minimize D ( fˆ ) .</sentence>
				<definiendum id="0">TOP kernel</definiendum>
			</definition>
			<definition id="2">
				<sentence>Thus , the TOP kernel is defined as K ( x1 ; x2 ) = fˆ ( x1 ) ¢ fˆ ( x2 ) : ( 10 ) A detailed discussion of the TOP kernel and its theoretical analysis have been given by Tsuda et al ( Tsuda et al. , 2002 ) .</sentence>
				<definiendum id="0">TOP kernel</definiendum>
			</definition>
			<definition id="3">
				<sentence>Suppose we have obtained the parameters wc and bc of the separating hyperplane for each category c 2 Ccategory in the original feature space , where Ccategory denotes the set of categories .</sentence>
				<definiendum id="0">Ccategory</definiendum>
			</definition>
			<definition id="4">
				<sentence>Using this probabilistic model , we compute function v ( d ; ) as described in Appendix B ( denotes fwx ; bx ; x1 ; x2jx 2 Ccategoryg and wxi denotes the ith element of the weight vector wx ) .</sentence>
				<definiendum id="0">Appendix B</definiendum>
				<definiens id="0">the ith element of the weight vector wx )</definiens>
			</definition>
			<definition id="5">
				<sentence>Thus , from the viewpoint of computational time , our kernel has an advantage over some other kernels such as the PLSI-based Fisher kernel in Section 4 , which requires the computational complexity of O ( jIj£jCclusterj ) , where Ccluster denotes the set of clusters .</sentence>
				<definiendum id="0">Ccluster</definiendum>
				<definiens id="0">the set of clusters</definiens>
			</definition>
</paper>

		<paper id="0833">
			<definition id="0">
				<sentence>Furthermore , the grammatical structures the target word takes part in can be used as a distinguishing tool : \the word ‘keep’ , can be disambiguated by determining whether its object is gerund ( He kept eating ) , adjectival phrase ( He kept calm ) , or noun phrase ( He kept a record ) '' ( Rei er , 1955 ) .</sentence>
				<definiendum id="0">adjectival phrase</definiendum>
				<definiens id="0">a distinguishing tool : \the word ‘keep’</definiens>
			</definition>
</paper>

		<paper id="1511">
			<definition id="0">
				<sentence>Ponct Algas is the C++ program responsible for connecting chunks and the elements inside them , taking as input a structure that contains information from arrow properties and also information that can limit the search space ( see section 4 from details about this ) .</sentence>
				<definiendum id="0">Ponct Algas</definiendum>
				<definiens id="0">the C++ program responsible for connecting chunks and the elements inside them , taking</definiens>
			</definition>
			<definition id="1">
				<sentence>Both the IntC and the PC chunks arrow the NC and inside them , all the elements arrow the head .</sentence>
				<definiendum id="0">PC</definiendum>
				<definiens id="0">chunks arrow the NC and inside them , all the elements arrow the head</definiens>
			</definition>
</paper>

		<paper id="1204">
			<definition id="0">
				<sentence>Define F ( i , j ) as the score of the optimal alignment between the initial segment from x 1 to x i of X and the initial segment from y 1 to y j of Y. F ( i , j ) is recursively calculated as follows : ⎪ ⎪ ⎩ ⎪ ⎪ ⎨ ⎧ −+− −+− +−− = ) , ' ( ' ) 1 , ( ) '' , ( ) ,1 ( ) , ( ) 1,1 ( ,0 max ) , ( j i ji ysjiF xsjiF yxsjiF jiF ( 1a ) ∑∈== ji yxjFiF , ,0 ) ,0 ( ,0 ) 0 , ( ( 1b ) where s ( a , b ) is defined as follows : ] ) ) ( * ) ( ( ) , ( log [ ) , ( bpapbapbas = ( 2 ) Here , p ( a ) denotes the appearance probability of character a , and p ( a , b ) denotes the probability that a and b appear at the same position in two aligned sequences .</sentence>
				<definiendum id="0">Define F ( i</definiendum>
				<definiendum id="1">1b ) where s</definiendum>
				<definiendum id="2">p ( a )</definiendum>
				<definiens id="0">the score of the optimal alignment between the initial segment from x 1 to x i of X and the initial segment from y 1 to y j of Y. F ( i , j ) is recursively calculated as follows : ⎪ ⎪ ⎩ ⎪ ⎪ ⎨ ⎧ −+− −+− +−− = ) , ' ( ' ) 1 , ( ) '' , ( ) ,1 ( ) , ( ) 1,1 ( ,0 max )</definiens>
				<definiens id="1">the appearance probability of character a , and p ( a , b ) denotes the probability that a and b appear at the same position in two aligned sequences</definiens>
			</definition>
			<definition id="1">
				<sentence>It will be referred to as mVector : ) , , , ( cVbcPtncMatchcLenmVector = ( 6 ) where cLen is the length of a pattern ; cMatch is the number of matched tags ; cPtn is the number of protein name tag ( PTN ) skipped by the alignment in the sentence ; cVb is the number of skipped verbs .</sentence>
				<definiendum id="0">cLen</definiendum>
				<definiendum id="1">cMatch</definiendum>
				<definiendum id="2">cPtn</definiendum>
				<definiendum id="3">cVb</definiendum>
				<definiens id="0">the length of a pattern ;</definiens>
				<definiens id="1">the number of matched tags ;</definiens>
				<definiens id="2">the number of protein name tag ( PTN ) skipped by the alignment in the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>A MDL-based algorithm that measures the confidence of each pattern and maintains them without human intervention is under development .</sentence>
				<definiendum id="0">MDL-based algorithm</definiendum>
				<definiens id="0">measures the confidence of each pattern and maintains them without human intervention is under development</definiens>
			</definition>
			<definition id="3">
				<sentence>Because our matching algorithm utilizes part-ofspeech tags , and our patterns do not contain any adjective ( JJ ) , interactions defined by adjectives , such as 'inducible ' and 'inhibitable ' , can not be extracted correctly by our method currently .</sentence>
				<definiendum id="0">matching algorithm</definiendum>
				<definiens id="0">utilizes part-ofspeech tags , and our patterns do not contain any adjective ( JJ ) , interactions defined by adjectives</definiens>
			</definition>
</paper>

		<paper id="2417">
			<definition id="0">
				<sentence>TBL is a general machine learning tool for assigning classes to a sequence of observations .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">a general machine learning tool for assigning classes to a sequence of observations</definiens>
			</definition>
</paper>

		<paper id="0208">
			<definition id="0">
				<sentence>More precisely , a Temporal Discourse Model for a text is a pair &lt; T , C &gt; , where T is a rooted , unordered , directed tree with nodes N = E ∪ A , where E is the set of events mentioned in the text and A is a set of abstract events , and a parent-child ordering relation , ⊆ ( temporal inclusion ) .</sentence>
				<definiendum id="0">Temporal Discourse Model</definiendum>
			</definition>
			<definition id="1">
				<sentence>C is a set of temporal ordering constraints using the ordering relation , &lt; ( temporal precedence ) as well as ( for states , clarified below ) ‘minimal restrictions’ on the above temporal inclusion relation ( expressed as a ⊆ min ) .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a set of temporal ordering constraints using the ordering relation , &lt; ( temporal precedence ) as well as ( for states , clarified below ) ‘minimal restrictions’ on the above temporal inclusion relation ( expressed as a ⊆ min )</definiens>
			</definition>
			<definition id="2">
				<sentence>A TDM is a tree-structured syntactic model of global discourse structure , where temporal relations are used as surrogates for discourse relations , and where abstract events corresponding to entire discourses are introduced as nodes in the tree .</sentence>
				<definiendum id="0">TDM</definiendum>
				<definiens id="0">a tree-structured syntactic model of global discourse structure , where temporal relations are used as surrogates for discourse relations , and where abstract events corresponding to entire discourses are introduced as nodes in the tree</definiens>
			</definition>
			<definition id="3">
				<sentence>So , E0 is an abstract node representing a top-level story , and E1 is an abstract node representing an embedded story .</sentence>
				<definiendum id="0">E0</definiendum>
				<definiendum id="1">E1</definiendum>
				<definiens id="0">an abstract node representing a top-level story , and</definiens>
				<definiens id="1">an abstract node representing an embedded story</definiens>
			</definition>
			<definition id="4">
				<sentence>However , TimeML is inadequate as a temporal model of discourse : it constructs no global representation of the narrative structure , instead annotating a complex graph that links primitive events and times .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">links primitive events and times</definiens>
			</definition>
			<definition id="5">
				<sentence>A TDM tree can be converted to a first-order temporal logic representation ( where temporal ordering and inclusion operators are added ) by expanding the properties of the nodes .</sentence>
				<definiendum id="0">TDM tree</definiendum>
				<definiens id="0">temporal ordering and inclusion operators</definiens>
			</definition>
			<definition id="6">
				<sentence>DLTAG ( Webber et al. 2004 ) is a model of discourse structure where explicit or implicit discourse markers relating only primitive discourse units .</sentence>
				<definiendum id="0">DLTAG</definiendum>
			</definition>
			<definition id="7">
				<sentence>Unlike TDMs , where the nodes in the tree can contain embedded structures , DLTAG is a local model of discourse structure ; it thus provides a set of binary relations , rather than a tree Like TDMs , however , DLTAG models discourse structure without postulating the existence of rhetorical relations in the discourse tree .</sentence>
				<definiendum id="0">DLTAG</definiendum>
				<definiens id="0">a local model of discourse structure</definiens>
			</definition>
			<definition id="8">
				<sentence>The Brandeis Reading Corpus is a collection of 100 K-8 Reading Comprehension articles , mined from the web and categorized by level of comprehension difficulty .</sentence>
				<definiendum id="0">Brandeis Reading Corpus</definiendum>
				<definiens id="0">a collection of 100 K-8 Reading Comprehension articles , mined from the web and categorized by level of comprehension difficulty</definiens>
			</definition>
</paper>

		<paper id="3235">
			<definition id="0">
				<sentence>The result is known as Bayes decision rule ( Chapter 2 in ( Duda and Hart , 1973 ) ) : y → ˆc = argminc braceleftBiggsummationdisplay ˜c Pr ( c|y ) ·L [ c , ˜c ] bracerightBigg where L [ c , ˜c ] is the so-called loss function or error measure , i.e. the loss we incur in making decision c when the true class is ˜c .</sentence>
				<definiendum id="0">Bayes decision rule</definiendum>
				<definiens id="0">y → ˆc = argminc braceleftBiggsummationdisplay ˜c Pr ( c|y ) ·L [ c , ˜c ] bracerightBigg where L [ c , ˜c ] is the so-called loss function or error measure</definiens>
			</definition>
			<definition id="1">
				<sentence>Inserting this cost function into the Bayes risk ( see Section 2.1 ) , we immediately obtain the following form of Bayes decision rule for minimum string error : wN1 → ˆgN1 = argmax gN1 braceleftBig Pr ( gN1 |wN1 ) bracerightBig = argmax gN1 braceleftBig Pr ( gN1 , wN1 ) bracerightBig This is the starting point for virtually all statistical approaches in NLP like speech recognition and machine translation .</sentence>
				<definiendum id="0">bracerightBig This</definiendum>
			</definition>
			<definition id="2">
				<sentence>The POS tagging part of The WSJ corpus ( Table 1 ) was compiled by the University of Pennsylvania and consists of about one million English words with manually annotated POS tags .</sentence>
				<definiendum id="0">POS tagging part</definiendum>
				<definiendum id="1">WSJ corpus</definiendum>
			</definition>
			<definition id="3">
				<sentence>Out-of-Vocabulary words ( OOVs ) are the words in the test data that did not not occur in the training corpus .</sentence>
				<definiendum id="0">Out-of-Vocabulary words</definiendum>
				<definiendum id="1">OOVs</definiendum>
				<definiens id="0">the words in the test data that did not not occur in the training corpus</definiens>
			</definition>
</paper>

		<paper id="2807">
			<definition id="0">
				<sentence>On the other hand , accurate Word Sense Disambiguation ( WSD ) could significantly improve the precision of Information Retrieval by ensuring that the senses of verbs in the retrieved documents match the sense of the verb in the query .</sentence>
				<definiendum id="0">Word Sense Disambiguation ( WSD</definiendum>
				<definiens id="0">the precision of Information Retrieval by ensuring that the senses of verbs in the retrieved documents match the sense of the verb in the query</definiens>
			</definition>
			<definition id="1">
				<sentence>The idea of underspecification as a solution to WSD has been proposed in Buitelaar 2000 ( among others ) , who pointed out that for some applications , such as document categorization , information retrieval , and information extraction it may be sufficient to know if a given word belongs to a certain class of WordNet senses or underspecified sense .</sentence>
				<definiendum id="0">information extraction</definiendum>
				<definiens id="0">document categorization , information retrieval</definiens>
			</definition>
			<definition id="2">
				<sentence>In addition to the annotated corpus , PropBank provides a lexicon that lists , for each broad meaning of each annotated verb , its Frameset , i.e. , the possible arguments in the predicate and their labels and all possible syntactic realizations .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">provides a lexicon that lists , for each broad meaning of each annotated verb</definiens>
			</definition>
			<definition id="3">
				<sentence>The Senseval-1 workshop ( Kilgarriff and Palmer , 2000 ) provided convincing evidence that supervised automatic systems can perform word sense disambiguation ( WSD ) satisfactorily , given clear , consistent sense distinctions and suitable training data .</sentence>
				<definiendum id="0">Senseval-1 workshop</definiendum>
				<definiens id="0">provided convincing evidence that supervised automatic systems can perform word sense disambiguation ( WSD ) satisfactorily , given clear , consistent sense distinctions and suitable training data</definiens>
			</definition>
			<definition id="4">
				<sentence>Second , given that PropBank is an annotation of the Wall Street Journal , it often distinguishes obscure financial senses of the verb as separate senses .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">an annotation of the Wall Street Journal , it often distinguishes obscure financial senses of the verb as separate senses</definiens>
			</definition>
			<definition id="5">
				<sentence>Exploiting Parallel Texts for Word Sense Disambiguation : An Empirical Study .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
			</definition>
</paper>

		<paper id="1707">
			<definition id="0">
				<sentence>Section 3 deals with Information Retrieval ( IR ) approaches for measuring document similarity , which are integrated in ITS as techniques for e.g. assessing the content of student essays or choosing the most relevant text to be shown to the learner .</sentence>
				<definiendum id="0">Information Retrieval</definiendum>
				<definiendum id="1">IR )</definiendum>
			</definition>
			<definition id="1">
				<sentence>Please note that nowadays the deductive approach can be relatively efficient , as our prover ( in Sicstus Prolog ) works on-line , integrated in a Web-based environment , in real time with several hundred meaning postulates .</sentence>
				<definiendum id="0">Please note</definiendum>
				<definiens id="0">works on-line , integrated in a Web-based environment , in real time with several hundred meaning postulates</definiens>
			</definition>
			<definition id="2">
				<sentence>Cover ( predefined maximum answer ) Primary market is a financial market that operates with newly issued debt instruments and securities and provides new investments and its goal is to raise capital .</sentence>
				<definiendum id="0">Primary market</definiendum>
				<definiens id="0">a financial market that operates with newly issued debt instruments and securities and provides new investments</definiens>
			</definition>
			<definition id="3">
				<sentence>Bond is a specialisation of security ; Missing : debt instruments .</sentence>
				<definiendum id="0">Bond</definiendum>
				<definiens id="0">a specialisation of security ; Missing : debt instruments</definiens>
			</definition>
			<definition id="4">
				<sentence>The similarity between two words , two texts , or a word and a text , is given by the cosine of the angle between their corresponding vectors ( the cosine is the most popular similarity measure ) .</sentence>
				<definiendum id="0">corresponding vectors</definiendum>
				<definiendum id="1">cosine</definiendum>
				<definiens id="0">the most popular similarity measure )</definiens>
			</definition>
			<definition id="5">
				<sentence>Select-a-Kibitzer ( WiemerHastings , 2000 ) aims at the assessment of essay composition .</sentence>
				<definiendum id="0">Select-a-Kibitzer</definiendum>
				<definiens id="0">aims at the assessment of essay composition</definiens>
			</definition>
			<definition id="6">
				<sentence>CarmelTC ( Rose , 2002 ) , a recent system which analyses essay answers to qualitative physics questions , learns to classify units of text based on features extracted from a syntactic analysis of that text .</sentence>
				<definiendum id="0">CarmelTC</definiendum>
				<definiens id="0">a recent system which analyses essay answers to qualitative physics questions , learns to classify units of text based on features extracted from a syntactic analysis of that text</definiens>
			</definition>
			<definition id="7">
				<sentence>Erroneous answers appear in terminology learning due to the following reasons : Language errors ( spelling , morphology , syntax ) ; Question misunderstanding , which causes wrong answer ; Correct question understanding , but absent knowledge of the correct term , which implies usage of paraphrases and generalisation instead of the expected answer ; Correct question understanding , but absent domain knowledge , which implies specialisation , partially correct answers , incomplete answers and wrong answers .</sentence>
				<definiendum id="0">Erroneous answers</definiendum>
				<definiens id="0">causes wrong answer ; Correct question understanding , but absent knowledge of the correct term , which implies usage of paraphrases and generalisation instead of the expected answer ; Correct question understanding , but absent domain knowledge , which implies specialisation , partially correct answers , incomplete answers and wrong answers</definiens>
			</definition>
			<definition id="8">
				<sentence>The Architecture of Why2-Atlas : A Coach for Qualitative Physics Essay Writing .</sentence>
				<definiendum id="0">Architecture of Why2-Atlas</definiendum>
				<definiens id="0">A Coach for Qualitative Physics Essay Writing</definiens>
			</definition>
			<definition id="9">
				<sentence>Selecta-kibitzer : A computer tool that gives meaningful feedback on student compositions , Interactive Learning Environments , 8 ( 2 ) , pp .</sentence>
				<definiendum id="0">Selecta-kibitzer</definiendum>
				<definiendum id="1">Interactive Learning</definiendum>
				<definiens id="0">A computer tool that gives meaningful feedback on student compositions</definiens>
			</definition>
</paper>

		<paper id="0854">
			<definition id="0">
				<sentence>The substituent word of the CX-th target word D8DB CX in a context BV is defined to be the relative of D8DB CX which has the largest co-occurrence probability with the words in the context : CBCFB4D8DB CX BNBVB5 CSCTCU BP CPD6CVD1CPDC D6 CXCY C8B4D6 AB CXCY CYBVB5 ( 1 ) where CBCF is the substituent word , D6 CXCY is the CY-th relative of D8DB CX , and D6 AB CXCY is the AB-th sense related to D8DB CX 3 .</sentence>
				<definiendum id="0">CBCF</definiendum>
				<definiendum id="1">D6 CXCY</definiendum>
				<definiendum id="2">D6 AB CXCY</definiendum>
				<definiens id="0">the relative of D8DB CX which has the largest co-occurrence probability with the words in the context : CBCFB4D8DB CX BNBVB5 CSCTCU BP CPD6CVD1CPDC D6 CXCY C8B4D6 AB CXCY CYBVB5</definiens>
				<definiens id="1">the substituent word ,</definiens>
			</definition>
			<definition id="1">
				<sentence>The right hand side of Equation 1 is calculated with logarithm as follows : CPD6CVD1CPDC D6 CXCY C8B4D6 AB CXCY CYBVB5 BP CPD6CVD1CPDC D6 CXCY C8B4BVCYD6 AB CXCY B5C8B4D6 AB CXCY B5 C8B4BVB5 BP CPD6CVD1CPDC D6 CXCY C8B4BVCYD6 AB CXCY B5C8B4D6 AB CXCY B5 BP CPD6CVD1CPDC D6 CXCY CUD0D3CVC8B4BVCYD6 AB CXCY B5B7D0D3CVC8B4D6 AB CXCY B5CV ( 2 ) 3 AB is a function with two parameters D8DB CX and D6 CXCY , but it can be written in brief without parameters .</sentence>
				<definiendum id="0">AB</definiendum>
				<definiens id="0">a function with two parameters D8DB CX and D6 CXCY , but it can be written in brief without parameters</definiens>
			</definition>
			<definition id="2">
				<sentence>Figure 2 : Example of sense disambiguation procedure for chair Then Equation 2 may be calculated under the assumption that words in BV occur independently : CPD6CVD1CPDC D6 CXCY CUD0D3CVC8B4BVCYD6 AB CXCY B5B7D0D3CVC8B4D6 AB CXCY B5CV AP CPD6CVD1CPDC D6 CXCY CU D2 CG CZBPBD D0D3CVC8B4DB CZ CYD6 AB CXCY B5B7D0D3CVC8B4D6 AB CXCY B5CV ( 3 ) where DB CZ is the CZ-th word in BV and D2 is the number of words in BV .</sentence>
				<definiendum id="0">DB CZ</definiendum>
				<definiendum id="1">D2</definiendum>
				<definiens id="0">the CZ-th word in BV and</definiens>
				<definiens id="1">the number of words in BV</definiens>
			</definition>
			<definition id="3">
				<sentence>The first probability in Equation 3 is calculated as follows : C8B4DB CZ CYD6 AB CXCY B5 AP C8B4DB CZ CYD6 CXCY B5 BP C8B4D6 CXCY CYDB CZ B5C8B4DB CZ B5 C8B4D6 CXCY B5 ( 4 ) The second probability in Equation 3 is computed as follows : C8B4D6 AB CXCY B5BPACB4D6 AB CXCY B5C8B4D6 CXCY B5 ( 5 ) where ACB4D6 AB CXCY B5 is the ratio of the frequency of D6 AB CXCY to that of D6 CXCY : ACB4D6 AB CXCY B5BP CFC6CUB4D6 AB CXCY B5B7BCBMBH D2A3 BCBMBHB7CFC6CUB4D6 CXCY B5 where CFC6CUB4D6 AB CXCY B5 is the frequency of D6 AB CXCY in WordNet , CFC6CUB4D6 CXCY B5 is the frequency of D6 CXCY in WordNet , senses of D6 CXCY .</sentence>
				<definiendum id="0">ACB4D6 AB CXCY B5</definiendum>
				<definiendum id="1">CFC6CUB4D6 AB CXCY B5</definiendum>
				<definiens id="0">calculated as follows : C8B4DB CZ CYD6 AB CXCY B5 AP C8B4DB CZ CYD6 CXCY B5 BP C8B4D6 CXCY CYDB CZ B5C8B4DB CZ B5 C8B4D6 CXCY B5</definiens>
				<definiens id="1">the ratio of the frequency of D6 AB CXCY to that of D6 CXCY : ACB4D6 AB CXCY B5BP CFC6CUB4D6 AB CXCY B5B7BCBMBH D2A3 BCBMBHB7CFC6CUB4D6 CXCY B5 where</definiens>
				<definiens id="2">the frequency of D6 AB CXCY in WordNet</definiens>
			</definition>
			<definition id="4">
				<sentence>These probabilities can be estimated based on the co-occurrence frequency between a relative and context words as follows : C8B4D6 CXCY B5BP CUD6CTD5B4D6 CXCY B5 BVCB ( 6 ) C8B4D6 CXCY CYDB CZ B5 BP C8B4D6 CXCY BNDB CZ B5 C8B4DB CZ B5 BP CUD6CTD5B4D6 CXCY BNDB CZ B5 CUD6CTD5B4DB CZ B5 ( 7 ) where CUD6CTD5B4D6 CXCY B5 is the frequency of D6 CXCY , BVCB is the corpus size , C8B4D6 CXCY BNDB CZ B5 is the probability that D6 CXCY and DB CZ co-occur , and CUD6CTD5B4D6 CXCY BNDB CZ B5 is the frequency that D6 CXCY and DB CZ co-occur .</sentence>
				<definiendum id="0">BVCB</definiendum>
				<definiendum id="1">C8B4D6 CXCY BNDB CZ B5</definiendum>
				<definiendum id="2">CUD6CTD5B4D6 CXCY BNDB CZ B5</definiendum>
				<definiens id="0">be estimated based on the co-occurrence frequency between a relative and context words as follows : C8B4D6 CXCY B5BP CUD6CTD5B4D6 CXCY B5 BVCB ( 6 ) C8B4D6 CXCY CYDB CZ B5 BP C8B4D6 CXCY BNDB CZ B5 C8B4DB CZ B5 BP CUD6CTD5B4D6 CXCY BNDB CZ B5 CUD6CTD5B4DB CZ B5 ( 7 ) where CUD6CTD5B4D6 CXCY B5 is the frequency of D6 CXCY</definiens>
				<definiens id="1">the corpus size</definiens>
				<definiens id="2">the probability that D6 CXCY and DB CZ co-occur</definiens>
			</definition>
			<definition id="5">
				<sentence>In this matrix , an element D1 CXCY represents the frequency that the i-th word and j-th word in the vocabulary cooccur in a corpus 4 .</sentence>
				<definiendum id="0">element D1 CXCY</definiendum>
				<definiens id="0">represents the frequency that the i-th word and j-th word in the vocabulary cooccur in a corpus 4</definiens>
			</definition>
			<definition id="6">
				<sentence>overall 0.500 0.500 0.496 0.510 Table 2 : Official Results ( fine grained ) : English All Words of the target word is determined , relationship types related to the POS are considered to acquire the candidate relatives of the target word .</sentence>
				<definiendum id="0">fine grained</definiendum>
				<definiens id="0">English All Words of the target word is determined</definiens>
			</definition>
</paper>

		<paper id="1211">
			<definition id="0">
				<sentence>The absolute agreement ( Abs Agr ) was calculated by dividing the total number of times all annotators agreed on a tag over the total number of tags .</sentence>
				<definiendum id="0">absolute agreement ( Abs Agr</definiendum>
				<definiens id="0">calculated by dividing the total number of times all annotators agreed on a tag over the total number of tags</definiens>
			</definition>
			<definition id="1">
				<sentence>Kappa coefficient is given in ( 1 ) ( Carletta 1996 ) ( 1 ) ) ( 1 ) ( ) ( EP EPAP Kappa − − = where P ( A ) is the proportion of times the annotators actually agree and P ( E ) is the proportion of times the annotators are expected to agree due to chance 3 .</sentence>
				<definiendum id="0">Kappa coefficient</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Treebank corpus contains over 40,000 lexical items that are not found in the corpus of clinical notes .</sentence>
				<definiendum id="0">Treebank corpus</definiendum>
				<definiens id="0">contains over 40,000 lexical items that are not found in the corpus of clinical notes</definiens>
			</definition>
</paper>

		<paper id="0912">
			<definition id="0">
				<sentence>The ‘relation’ constitutes the aspectual value : TO Relation Reading of the ipf I. synchronous , bounded TT included in ϕ dyn actual-processual II .</sentence>
				<definiendum id="0">TT</definiendum>
				<definiens id="0">the aspectual value : TO Relation Reading of the ipf I. synchronous , bounded</definiens>
			</definition>
</paper>

		<paper id="2501">
			<definition id="0">
				<sentence>BootstrappedPatterns is initialized to the empty set and is iteratively increased during the bootstrap loop .</sentence>
				<definiendum id="0">BootstrappedPatterns</definiendum>
				<definiens id="0">the empty set and is iteratively increased during the bootstrap loop</definiens>
			</definition>
			<definition id="1">
				<sentence>is “viral agent” , which does not exist in the current WordNet ontology .</sentence>
				<definiendum id="0">“viral agent”</definiendum>
			</definition>
			<definition id="2">
				<sentence>The relevant answers ( where “relevancy” can be explicitly requested from the user , or implicitly detected based on the documents visited ) are mapped back to the corresponding questions , which provides a dynamic trace in the question decomposition tree .</sentence>
				<definiendum id="0">“relevancy”</definiendum>
				<definiens id="0">provides a dynamic trace in the question decomposition tree</definiens>
			</definition>
			<definition id="3">
				<sentence>Traditionally , the user profile ( or background ) has been represented as a term vector , derived from the previously relevant document ( be it online or offline information ) .</sentence>
				<definiendum id="0">user profile</definiendum>
				<definiens id="0">a term vector , derived from the previously relevant document ( be it online or offline information )</definiens>
			</definition>
</paper>

		<paper id="0704">
</paper>

		<paper id="2313">
			<definition id="0">
				<sentence>The identification of discourse markers ( DMs ) is an essential step in dialog understanding , since there is often a prosodic , syntactic and functional distinction between DMs and the rest of an utterance .</sentence>
				<definiendum id="0">DMs )</definiendum>
				<definiens id="0">an essential step in dialog understanding</definiens>
			</definition>
</paper>

		<paper id="1303">
			<definition id="0">
				<sentence>Comprehension consists of two stages : identifying the constructions involved and how their meanings are related ( analysis ) , and matching these constructionally sanctioned meanings to the actual participants and relations present in context ( resolution ) .</sentence>
				<definiendum id="0">Comprehension</definiendum>
				<definiens id="0">consists of two stages : identifying the constructions involved and how their meanings are related ( analysis ) , and matching these constructionally sanctioned meanings to the actual participants and relations present in context ( resolution )</definiens>
			</definition>
			<definition id="1">
				<sentence>The space of possible grammars ( or sets of constructions ) is defined by Embodied Construction Grammar ( ECG ) , a computationally explicit unification-based formalism for capturing insights from the construction grammar and cognitive linguistics literature ( Bergen and Chang , in press ; Chang et al. , 2002 ) .</sentence>
				<definiendum id="0">space of possible grammars</definiendum>
			</definition>
			<definition id="2">
				<sentence>ECG is designed to support the analysis process mentioned above , which determines what constructions and schematic meanings are present in an utterance , resulting in a semantic specification ( or semspec ) .1 1ECG is intended to support a simulation-based model of language understanding , with the semspec parameterizing a We highlight a few relevant aspects of the formalism , exemplified in Figure 1 .</sentence>
				<definiendum id="0">ECG</definiendum>
				<definiens id="0">designed to support the analysis process mentioned above , which determines what constructions and schematic meanings are present in an utterance , resulting in a semantic specification</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus , the a10a12a11a14a13a16a15a18a17 construction simply links a form whose orthography role ( or feature ) is bound to the string “throw” to a meaning that is constrained to be of type Throw , a separately defined conceptual schema corresponding to throwing events ( including roles for a thrower and throwee ) .</sentence>
				<definiendum id="0">a10a12a11a14a13a16a15a18a17 construction simply</definiendum>
				<definiens id="0">links a form whose orthography role ( or feature ) is bound to the string “throw” to a meaning that is constrained to be of type Throw , a separately defined conceptual schema corresponding to throwing events ( including roles for a thrower and throwee )</definiens>
			</definition>
			<definition id="4">
				<sentence>The construction analyzer takes as input a set of ECG constructions ( linguistic knowledge ) , a set of ECG schemas ( conceptual knowledge ) and an utterance .</sentence>
				<definiendum id="0">construction analyzer</definiendum>
				<definiens id="0">linguistic knowledge ) , a set of ECG schemas ( conceptual knowledge ) and an utterance</definiens>
			</definition>
			<definition id="5">
				<sentence>The resolution procedure attempts to unify each schema and constraint appearing in the semspec with a type-compatible entity or relation in the context .</sentence>
				<definiendum id="0">resolution procedure</definiendum>
				<definiens id="0">attempts to unify each schema and constraint appearing in the semspec with a type-compatible entity or relation in the context</definiens>
			</definition>
			<definition id="6">
				<sentence>A suitable overarching computational framework for guiding the search is provided by the minimum description length ( MDL ) heuristic ( Rissanen , 1978 ) , which is used to find the optimal analysis of data in terms of ( a ) a compact representation of the data ( i.e. , a grammar ) ; and ( b ) a compact means of describing the original data in terms of the compressed representation ( i.e. , constructional analyses using the grammar ) .</sentence>
				<definiendum id="0">suitable overarching computational framework</definiendum>
				<definiendum id="1">MDL</definiendum>
				<definiens id="0">used to find the optimal analysis of data in terms of ( a ) a compact representation of the data</definiens>
			</definition>
			<definition id="7">
				<sentence>The MDL heuristic exploits a tradeoff between competing preferences for smaller grammars ( encouraging generalization ) and for simpler analyses of the data ( encouraging the retention of specific/frequent constructions ) .</sentence>
				<definiendum id="0">MDL heuristic</definiendum>
				<definiens id="0">exploits a tradeoff between competing preferences for smaller grammars ( encouraging generalization ) and for simpler analyses of the data ( encouraging the retention of specific/frequent constructions</definiens>
			</definition>
			<definition id="8">
				<sentence>The resolution process matches these schemas to the actual context , which includes a particular throwing event in which the addressee ( Naomi ) is the thrower of a particular ball .</sentence>
				<definiendum id="0">resolution process</definiendum>
				<definiendum id="1">Naomi )</definiendum>
				<definiens id="0">includes a particular throwing event in which the addressee</definiens>
				<definiens id="1">the thrower of a particular ball</definiens>
			</definition>
			<definition id="9">
				<sentence>This condition captures three common patterns of relational formmeaning mappings , i.e. , ways in which a meaning relation rela8 over Aa8 and Ba8 can be correlated with a form relation rela9 over Aa9 and Ba9 ( e.g. , word order ) ; these are illustrated in Figure 5 , where we assume a simple form relation : ( a ) strictly isomorphic : Ba8 is a role-filler of Aa8 ( or vice versa ) ( Aa10 .</sentence>
				<definiendum id="0">Ba8</definiendum>
				<definiens id="0">common patterns of relational formmeaning mappings , i.e. , ways in which a meaning relation rela8 over Aa8 and Ba8 can be correlated with a form relation rela9 over Aa9</definiens>
			</definition>
			<definition id="10">
				<sentence>r2 ) ( c ) sibling role-fillers : Aa8 and Ba8 fill roles of the same schema ( Y.r1 a11a13a12 Aa10 , Y.r2 a11a13a12 Ba10 ) 22 rel rel r rel fB A m mB mf r1 r1 r2 r2 x A mA fB fA f f f B mA Bf fA mB ( c ) ( b ) ( a ) Y B B A B A A Figure 5 : Pseudo-isomorphic relational mappings over constructs A and B : ( a ) strictly isomorphic ; ( b ) shared role-filler ; and ( c ) sibling role-fillers .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">Pseudo-isomorphic relational mappings over constructs A and</definiens>
			</definition>
			<definition id="11">
				<sentence>The size ( a55 ) is the sum over the size of each construction a80 in the grammar ( a70 a75 is the number of constituents in a80 , a84 a75 is the number of constraints in a80 , and each element reference a86 in a80 has a length , measured as slot chain length ) .</sentence>
				<definiendum id="0">a75</definiendum>
				<definiens id="0">the sum over the size of each construction a80 in the grammar ( a70 a75 is the number of constituents in a80</definiens>
			</definition>
			<definition id="12">
				<sentence>The cost ( complexity ) of the data a56 given a55 is the sum of the analysis scores of each input token a91 using a55 .</sentence>
				<definiendum id="0">a55</definiendum>
				<definiens id="0">the sum of the analysis scores of each input token a91 using a55</definiens>
			</definition>
			<definition id="13">
				<sentence>This score sums over the constructions 23 a0 in the analysis of a1 , where weight a2 reflects relative ( in ) frequency , a3typea4a5a3 denotes the number of ontology items of type a6 , summed over all the constituents in the analysis and discounted by parameter a7 .</sentence>
				<definiendum id="0">a3typea4a5a3</definiendum>
			</definition>
</paper>

		<paper id="3108">
</paper>

		<paper id="0807">
			<definition id="0">
				<sentence>The main reason motivating selection of a different sense inventory is the Association for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems Class Nr of Avg senses Avg senses words ( fine ) ( coarse ) Nouns 20 5.8 4.35 Verbs 32 6.31 4.59 Adjectives 5 10.2 9.8 Total 57 6.47 4.96 Table 1 : Summary of the sense inventory weak verb performance of systems participating in the English lexical sample in SENSEVAL-2 , which may be due to the high number of senses defined for verbs in the WordNet sense inventory .</sentence>
				<definiendum id="0">Summary of</definiendum>
				<definiens id="0">the sense inventory weak verb performance of systems participating in the English lexical sample in SENSEVAL-2</definiens>
			</definition>
			<definition id="1">
				<sentence>72.2 72.2 78.7 78.7 rlsc-comb A regularized least-square classification ( RLSC ) , using local and topical U.Bucharest ( Popescu ) features , with a term weighting scheme .</sentence>
				<definiendum id="0">RLSC</definiendum>
				<definiens id="0">with a term weighting scheme</definiens>
			</definition>
			<definition id="2">
				<sentence>Features consist of local and syntactic features .</sentence>
				<definiendum id="0">Features</definiendum>
				<definiens id="0">consist of local and syntactic features</definiens>
			</definition>
			<definition id="3">
				<sentence>67.2 67.2 74.2 74.2 CLaC1 A Naive Bayes approach using a context window around the target word , 67.2 67.2 75.1 75.1 Concordia U. ( Lamjiri ) which is dynamically adjusted SinequaLex2 A cumulative method based on scores of surrounding words .</sentence>
				<definiendum id="0">Lamjiri )</definiendum>
				<definiens id="0">dynamically adjusted SinequaLex2 A cumulative method based on scores of surrounding words</definiens>
			</definition>
</paper>

		<paper id="1309">
			<definition id="0">
				<sentence>In terms of production , children produce noises , such as discomfort noises ( 0-2 months ) , comfort noises ( 2-4 months ) , and �play� vocally with pitch and loudness variations ( 4-7 months ) ( Pinker , 1994 ) .</sentence>
				<definiendum id="0">)</definiendum>
				<definiens id="0">0-2 months ) , comfort noises ( 2-4 months ) , and �play� vocally with pitch and loudness variations ( 4-7 months</definiens>
			</definition>
			<definition id="1">
				<sentence>The learning process involves a user selecting an object in a scene and naming it .</sentence>
				<definiendum id="0">learning process</definiendum>
				<definiens id="0">involves a user selecting an object in a scene and naming it</definiens>
			</definition>
			<definition id="2">
				<sentence>The guessing game involves a user saying a phrase , and the system pointing to the object that the phrase refers to .</sentence>
				<definiendum id="0">guessing game</definiendum>
			</definition>
			<definition id="3">
				<sentence>The naming game involves a user pointing to an object and the system naming it The system is not physically grounded , so all games are simulated .</sentence>
				<definiendum id="0">naming game</definiendum>
				<definiens id="0">involves a user pointing to an object and the system naming it The system is not physically grounded , so all games are simulated</definiens>
			</definition>
			<definition id="4">
				<sentence>The learning process allows the system to acquire associations between phrases and concepts while the games test system comprehension and system production respectively .</sentence>
				<definiendum id="0">learning process</definiendum>
				<definiens id="0">allows the system to acquire associations between phrases and concepts while the games test system comprehension and system production respectively</definiens>
			</definition>
			<definition id="5">
				<sentence>The learning process takes a string and concept as input , and produces no output .</sentence>
				<definiendum id="0">learning process</definiendum>
				<definiens id="0">takes a string and concept as input , and produces no output</definiens>
			</definition>
			<definition id="6">
				<sentence>Comprehension takes a string as input , and produces a concept as output , whereas production takes a concept as input , and produces a string as output .</sentence>
				<definiendum id="0">Comprehension</definiendum>
				<definiens id="0">takes a string as input , and produces a concept as output , whereas production takes a concept as input , and produces a string as output</definiens>
			</definition>
			<definition id="7">
				<sentence>The ID acts as a unique identifier , allowing the group to be found .</sentence>
				<definiendum id="0">ID</definiendum>
			</definition>
			<definition id="8">
				<sentence>The occurrence supporter link reinforces the description pair�s association and increases the total frequency of the group .</sentence>
				<definiendum id="0">occurrence supporter link</definiendum>
				<definiens id="0">reinforces the description pair�s association and increases the total frequency of the group</definiens>
			</definition>
			<definition id="9">
				<sentence>Multi-groups form syntactic categories based on similarities between description pair usage .</sentence>
				<definiendum id="0">Multi-groups</definiendum>
				<definiens id="0">form syntactic categories based on similarities between description pair usage</definiens>
			</definition>
			<definition id="10">
				<sentence>Lexical items ( strings ) are associated with their meanings ( concepts ) .</sentence>
				<definiendum id="0">Lexical items</definiendum>
				<definiens id="0">associated with their meanings ( concepts )</definiens>
			</definition>
			<definition id="11">
				<sentence>Comprehension takes a string as input , and produces a concept as output , whereas production takes a concept as input , and produces a string as output .</sentence>
				<definiendum id="0">Comprehension</definiendum>
				<definiens id="0">takes a string as input , and produces a concept as output , whereas production takes a concept as input , and produces a string as output</definiens>
			</definition>
			<definition id="12">
				<sentence>This research can be viewed as a form of social learning with one agent ( string and concept generator ) performing the teacher role , and the other agent ( the system ) performing the learner role .</sentence>
				<definiendum id="0">other agent</definiendum>
				<definiens id="0">a form of social learning with one agent ( string and concept generator ) performing the teacher role</definiens>
				<definiens id="1">the system ) performing the learner role</definiens>
			</definition>
			<definition id="13">
				<sentence>ACCLAIM , a one-word stage simulator , demonstrates that systems can react appropriately to changes in situations .</sentence>
				<definiendum id="0">ACCLAIM</definiendum>
				<definiens id="0">a one-word stage simulator , demonstrates that systems can react appropriately to changes in situations</definiens>
			</definition>
			<definition id="14">
				<sentence>The simple syntax continues to grow in strength , ultimately being used in favour of holophrastic data in all production and comprehension tasks .</sentence>
				<definiendum id="0">simple syntax</definiendum>
				<definiens id="0">continues to grow in strength , ultimately being used in favour of holophrastic data in all production and comprehension tasks</definiens>
			</definition>
</paper>

		<paper id="3225">
			<definition id="0">
				<sentence>A cache-based language model is a language model to which is added a smaller model trained only on the history of the document being processed .</sentence>
				<definiendum id="0">cache-based language model</definiendum>
				<definiens id="0">a language model to which is added a smaller model trained only on the history of the document being processed</definiens>
			</definition>
			<definition id="1">
				<sentence>The resulting model ( named MDI2B ) is of the following form , where h is the current target text , s the source sentence being translated , s a particular word in s and w the next word to be predicted : p ( w|h , s ) = q ( w|h ) exp ( summationtext s∈s αsw + βAB ) Z ( h , s ) ( 1 ) The q distribution represents the prior knowledge that we have about the true distribution and is modeled by an interpolated trigram in this study .</sentence>
				<definiendum id="0">h</definiendum>
				<definiendum id="1">q distribution</definiendum>
				<definiens id="0">the current target text , s the source sentence being translated , s a particular word in s</definiens>
				<definiens id="1">the prior knowledge that we have about the true distribution and is modeled by an interpolated trigram in this study</definiens>
			</definition>
			<definition id="2">
				<sentence>The word pair feature functions are defined as follows : fst ( w , h , s ) = braceleftbigg 1 if s ∈ s and t = w 0 otherwise This function is on if the predicted word is t and s is in the current source sentence .</sentence>
				<definiendum id="0">word pair feature functions</definiendum>
				<definiens id="0">fst ( w , h , s ) = braceleftbigg 1 if s ∈ s and t = w 0 otherwise This function is on if the predicted word is t and s is in the current source sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>The positional feature functions are defined as follows : fA , B ( w , i , s ) = Jsummationdisplay j=1 δ [ ( i , j , J ) ∈ A ∧ ( sj , w ) ∈ B ∧j = ˆsj ] where δ [ X ] is 1 if X is true , otherwise 0 ; and ˆsj is the position of the occurrence of sj that is closest to i according to an IBM2 model .</sentence>
				<definiendum id="0">positional feature functions</definiendum>
				<definiendum id="1">ˆsj</definiendum>
				<definiens id="0">follows : fA , B ( w , i , s ) = Jsummationdisplay j=1 δ [ ( i , j , J ) ∈ A ∧ ( sj , w ) ∈ B ∧j = ˆsj ] where δ [ X ] is 1 if X is true , otherwise 0 ; and</definiens>
				<definiens id="1">the position of the occurrence of sj that is closest to i according to an IBM2 model</definiens>
			</definition>
			<definition id="4">
				<sentence>The metric used is the percentage of keystrokes saved by the use of the system instead of having to type directly all the target text .</sentence>
				<definiendum id="0">metric used</definiendum>
				<definiens id="0">the percentage of keystrokes saved by the use of the system</definiens>
			</definition>
</paper>

		<paper id="0501">
</paper>

		<paper id="0503">
			<definition id="0">
				<sentence>Restricted-domain Question-Answering ( RDQA ) works on specific domains and often uses document collections restricted in subject and volume .</sentence>
				<definiendum id="0">Restricted-domain Question-Answering</definiendum>
				<definiendum id="1">RDQA )</definiendum>
				<definiens id="0">works on specific domains and often uses document collections restricted in subject and volume</definiens>
			</definition>
			<definition id="1">
				<sentence>RDQA has a long history , beginning with systems working over databases ( e.g. , BASEBALL ( Green et al , 1961 ) and LUNAR ( Woods , 1973 ) ) .</sentence>
				<definiendum id="0">RDQA</definiendum>
				<definiendum id="1">LUNAR</definiendum>
				<definiens id="0">a long history , beginning with systems working over databases</definiens>
			</definition>
			<definition id="2">
				<sentence>For each question , Okapi returns an ordered list of answer candidates , together with a relevance score for each candidate and the name of the document containing it .</sentence>
				<definiendum id="0">Okapi</definiendum>
				<definiens id="0">returns an ordered list of answer candidates</definiens>
			</definition>
			<definition id="3">
				<sentence>An answer candidate is a paragraph which Okapi considers most relevant to the question .</sentence>
				<definiendum id="0">answer candidate</definiendum>
				<definiens id="0">a paragraph which Okapi considers most relevant to the question</definiens>
			</definition>
			<definition id="4">
				<sentence>C ( n ) is the number of candidates at rank n which are judged correct .</sentence>
				<definiendum id="0">C ( n )</definiendum>
				<definiens id="0">the number of candidates at rank n which are judged correct</definiens>
			</definition>
			<definition id="5">
				<sentence>Q ( n ) is the number of questions in the training set which have at least one correct answer among the first n ranks .</sentence>
				<definiendum id="0">Q ( n )</definiendum>
				<definiens id="0">the number of questions in the training set</definiens>
			</definition>
			<definition id="6">
				<sentence>( ii ) A Term_score that measures the importance of common occurrences of special terms , and , with less emphasis , other noun phrases and open-class words , in the question and the candidate .</sentence>
				<definiendum id="0">Term_score</definiendum>
				<definiens id="0">measures the importance of common occurrences of special terms</definiens>
			</definition>
			<definition id="7">
				<sentence>( iii ) A document coefficient DC that indicates the relative importance of a candidate i coming or not coming from a document which contains at least a special term occurring in the question .</sentence>
				<definiendum id="0">document coefficient DC</definiendum>
				<definiens id="0">indicates the relative importance of a candidate i coming or not coming from a document which contains at least a special term occurring in the question</definiens>
			</definition>
			<definition id="8">
				<sentence>See ( Doan-Nguyen and Kosseim , 2004 ) for a detailed explanation of how formula ( 1 ) was derived , and how to design the values of DC , RC , and OW .</sentence>
				<definiendum id="0">See</definiendum>
				<definiens id="0">a detailed explanation of how formula ( 1 ) was derived , and how to design the values of DC , RC , and OW</definiens>
			</definition>
			<definition id="9">
				<sentence>characterization In formula ( 1 ) , the coefficient DC represents an estimate of the relevance of a document to a question based only on special terms ; it can not help when the question and document do not contain special terms .</sentence>
				<definiendum id="0">coefficient DC</definiendum>
				<definiens id="0">an estimate of the relevance of a document to a question based only on special terms</definiens>
			</definition>
			<definition id="10">
				<sentence>RC is a coefficient representing the importance of the document rank .</sentence>
				<definiendum id="0">RC</definiendum>
			</definition>
</paper>

		<paper id="2325">
			<definition id="0">
				<sentence>It is widely accepted that it would be desirable for dialogue systems to be able to produce and understand the whole range of Clarification Requests ( CRs ) that can be found in human-human dialogue , as exemplified in the following : ( 1 ) a. A : I talked to Mary-Ann Parker-Tomlison .</sentence>
				<definiendum id="0">CRs</definiendum>
				<definiens id="0">exemplified in the following : ( 1 ) a. A : I talked to Mary-Ann Parker-Tomlison</definiens>
			</definition>
			<definition id="1">
				<sentence>Our term ‘CR’ covers what Larsson calls negative feedback as well as what he calls checking feedback , whereas Before we finally come to the description of the dimension level of understanding in the next Section , we will briefly look at an earlier analysis of CR that does not make these distinctions .</sentence>
				<definiendum id="0">term ‘CR’</definiendum>
				<definiens id="0">covers what Larsson calls negative feedback as well as what he calls checking feedback</definiens>
			</definition>
			<definition id="2">
				<sentence>; the constituent reading is a reading “whereby the content of a constituent of the previous utterance is being clarified.”</sentence>
				<definiendum id="0">constituent reading</definiendum>
			</definition>
			<definition id="3">
				<sentence>Herb Clark ( Clark , 1996 ) and Jens Allwood ( Allwood , 1995 ) independently developed a model of the ( hierarchically ordered ) tasks involved in communication , as shown schematically in Figure 1.7 ( We have also assigned the readings defined by G &amp; C to the appropriate levels in the last column . )</sentence>
				<definiendum id="0">Jens Allwood</definiendum>
				<definiens id="0">developed a model of the ( hierarchically ordered ) tasks involved in communication</definiens>
				<definiens id="1">also assigned the readings defined by G &amp; C to the appropriate levels in the last column</definiens>
			</definition>
			<definition id="4">
				<sentence>In contrast to traditional dynamic semantics , SDRT attempts to represent the pragmatically preferred interpretation of a discourse .</sentence>
				<definiendum id="0">SDRT</definiendum>
				<definiens id="0">attempts to represent the pragmatically preferred interpretation of a discourse</definiens>
			</definition>
			<definition id="5">
				<sentence>The central notion of Discourse Update is for13This is a generalisation of the approach taken for example by ( Walker et al. , 2000 ) , who use the output of the semantic and pragmatic modules of their dialogue system to dramatically improve the classifier that judges whether a SR hypothesis is correct or not , compared to a classifier that just uses SR-features .</sentence>
				<definiendum id="0">for13This</definiendum>
			</definition>
</paper>

		<paper id="2401">
			<definition id="0">
				<sentence>Learning global models trains a probabilistic model under the constraints imposed by the domain .</sentence>
				<definiendum id="0">Learning global models</definiendum>
				<definiens id="0">trains a probabilistic model under the constraints imposed by the domain</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , it may be useful to identify that Oswald and KFJ are people , and JFK is a location .</sentence>
				<definiendum id="0">JFK</definiendum>
				<definiens id="0">a location</definiens>
			</definition>
			<definition id="2">
				<sentence>min summationdisplay E∈E summationdisplay e∈LE cE ( e ) ·x { E , e } + summationdisplay R∈R summationdisplay r∈LR cR ( r ) ·x { R , r } + summationdisplay Ei , Ej∈E Einegationslash=Ej bracketleftBigg summationdisplay r∈LR summationdisplay e1∈LE d1 ( r , e1 ) ·x { Rij , r , Ei , e1 } + summationdisplay r∈LR summationdisplay e2∈LE d2 ( r , e2 ) ·x { Rij , r , Ej , e2 } bracketrightBigg subject to : summationdisplay e∈LE x { E , e } = 1 ∀E ∈ E ( 2 ) summationdisplay r∈LR x { R , r } = 1 ∀R ∈ R ( 3 ) x { E , e } = summationdisplay r∈LR x { R , r , E , e } ∀E ∈ E and ∀R ∈ { R : E = N1 ( R ) or R : E = N2 ( R ) } ( 4 ) x { R , r } = summationdisplay e∈LE x { R , r , E , e } ∀R ∈ R and ∀E = N1 ( R ) or E = N2 ( R ) ( 5 ) x { E , e } ∈ { 0,1 } ∀E ∈ E , e ∈ LE ( 6 ) x { R , r } ∈ { 0,1 } ∀R ∈ R , r ∈ LR ( 7 ) x { R , r , E , e } ∈ { 0,1 } ∀R ∈ R , r ∈ LR , E ∈ E , e ∈ LE ( 8 ) Figure 1 : Integer Linear Programming Formulation To solve an ILP problem , a natural idea is to relax the integral constraints .</sentence>
				<definiendum id="0">min summationdisplay E∈E summationdisplay e∈LE cE</definiendum>
				<definiens id="0">e } = summationdisplay r∈LR x { R , r , E , e } ∀E ∈ E and ∀R ∈ { R : E = N1 ( R ) or R : E = N2 ( R ) } ( 4 ) x { R , r } = summationdisplay e∈LE x { R , r , E , e } ∀R ∈ R and ∀E = N1 ( R ) or E = N2 ( R ) ( 5 ) x { E , e</definiens>
			</definition>
			<definition id="3">
				<sentence>SNoW learns a sparse network of linear functions , in which the targets ( entity classes or relation classes , in this case ) are represented as linear functions over a common feature space .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiens id="0">learns a sparse network of linear functions , in which the targets ( entity classes or relation classes , in this case ) are represented as linear functions over a common feature space</definiens>
			</definition>
</paper>

		<paper id="1903">
			<definition id="0">
				<sentence>The Szeged Corpus is a manually annotated natural language corpus currently comprising 1.2 million word entries , 145 thousand different word forms , and an additional 225 thousand punctuation marks .</sentence>
				<definiendum id="0">Szeged Corpus</definiendum>
				<definiens id="0">a manually annotated natural language corpus currently comprising 1.2 million word entries , 145 thousand different word forms</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>In HOLXML , a House of Lords Judgment is defined as a J element whose BODY element is composed of a number of LORD elements ( usually five ) .</sentence>
				<definiendum id="0">House of Lords Judgment</definiendum>
			</definition>
			<definition id="1">
				<sentence>The automatic processing is divided into two stages , tokenisation , which also includes partof-speech ( POS ) tagging and sentence boundary disambiguation , followed by linguistic annotation ( described in detail in Section 2.3 below ) .</sentence>
				<definiendum id="0">tokenisation</definiendum>
				<definiens id="0">also includes partof-speech ( POS ) tagging and sentence boundary disambiguation , followed by linguistic annotation ( described in detail in Section 2.3 below )</definiens>
			</definition>
			<definition id="2">
				<sentence>This showed that the human annotators distinguish the seven categories with a reproducibility of K=.83 ( N=1,955 , k=2 ; where K is the kappa co-efficient , N is the number of sentences and k is the number of annotators ) .</sentence>
				<definiendum id="0">K</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">k</definiendum>
				<definiens id="0">the kappa co-efficient</definiens>
				<definiens id="1">the number of sentences</definiens>
				<definiens id="2">the number of annotators</definiens>
			</definition>
			<definition id="3">
				<sentence>Once the word tokens have been identified , the next step uses ltpos to mark up the senHOLXML Conversion to document HTML Automatically annotated HOLXML document Recognition Named Entity Identification Chunking &amp; Clause Verb &amp; subject featuressation Lemmati− Tokenisation POS Tagging &amp; Sentence Identification TOKENISATION MODULE LINGUISTIC ANALYSIS MODULE Figure 1 : HOLJ processing stages tences as SENT elements and to add part of speech attributes to word tokens .</sentence>
				<definiendum id="0">senHOLXML Conversion</definiendum>
				<definiens id="0">to document HTML Automatically annotated HOLXML document Recognition Named Entity Identification Chunking &amp; Clause Verb &amp; subject featuressation Lemmati− Tokenisation POS Tagging &amp; Sentence Identification TOKENISATION MODULE LINGUISTIC ANALYSIS MODULE Figure 1 : HOLJ processing stages tences as SENT elements and to add part of speech attributes to word tokens</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>The third baseline , COMP is the document compression system developed by Daum´e III and Marcu ( 2002 ) , which compresses documents by cutting out constituents in a combined syntax and discourse tree .</sentence>
				<definiendum id="0">COMP</definiendum>
				<definiens id="0">the document compression system developed by Daum´e III and Marcu ( 2002 ) , which compresses documents by cutting out constituents in a combined syntax and discourse tree</definiens>
			</definition>
</paper>

		<paper id="2505">
			<definition id="0">
				<sentence>Qi6 asks about the source of information that enables the answers of question Q1 .</sentence>
				<definiendum id="0">Qi6</definiendum>
				<definiens id="0">asks about the source of information that enables the answers of question Q1</definiens>
			</definition>
			<definition id="1">
				<sentence>When intended questions are generated , their sequential processing ( a ) represents a decomposition of the complex question and ( b ) generates a scenario for finding information ; thus questions like Q1 are also known as scenario questions .</sentence>
				<definiendum id="0">sequential processing ( a )</definiendum>
			</definition>
			<definition id="2">
				<sentence>Qm31 : Is it the transfer of complete missile systems , licensing agreements , components , materials , or plans ?</sentence>
				<definiendum id="0">Qm31</definiendum>
				<definiens id="0">Is it the transfer of complete missile systems</definiens>
			</definition>
			<definition id="3">
				<sentence>Qm34 : Does transfer include data , and , if so , what kind of data ?</sentence>
				<definiendum id="0">Qm34</definiendum>
			</definition>
			<definition id="4">
				<sentence>Qm35 : Does transfer include financial assistance , and , if so , what kind of financial assistance ?</sentence>
				<definiendum id="0">Qm35</definiendum>
			</definition>
			<definition id="5">
				<sentence>Therefore , Q/A is modeled by the distribution P ( C—A , Q ) where C measures the “correctness” of A to question Q. By using a hidden variable E that represents the expected answer type , P ( C—A , Q ) = ΣE p ( C , E—Q , A ) = ΣE p ( C—E , Q , A ) * p ( E—Q , A ) .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">measures the “correctness” of A to question Q. By using a hidden variable E that represents the expected answer type</definiens>
			</definition>
			<definition id="6">
				<sentence>The Documents Processing module implements a search engine that returns passages that are likely to contain the expected answer type in the case of factoid questions or the definition pattern in the case of definition questions .</sentence>
				<definiendum id="0">Documents Processing module</definiendum>
			</definition>
			<definition id="7">
				<sentence>One such pattern is recognized in an apposition , by [ QP , a AP ] where AP represents the answer phrase .</sentence>
				<definiendum id="0">AP</definiendum>
				<definiens id="0">the answer phrase</definiens>
			</definition>
			<definition id="8">
				<sentence>In this paper , by considering the intentional information and the implied information that can be derived when processing questions , we introduce a novel model of Q/A , which has access to rich semantic structures and enables the retrieval of more accurate answers as well as inference processes that explain the validity and contextual coverage of answers .</sentence>
				<definiendum id="0">Q/A</definiendum>
				<definiens id="0">the intentional information and the implied information that can be derived when processing questions</definiens>
				<definiens id="1">has access to rich semantic structures and enables the retrieval of more accurate answers as well as inference processes that explain the validity and contextual coverage of answers</definiens>
			</definition>
			<definition id="9">
				<sentence>Generally , Arg 0 stands for agent , Arg 1 for direct object or theme or patient , Arg 2 for indirect object or benefactive or instrument or attribute or end state , Arg 3 for start point or benefactive or attribute and Arg4 for end point .</sentence>
				<definiendum id="0">Arg 0</definiendum>
				<definiens id="0">stands for agent , Arg 1 for direct object or theme or patient</definiens>
			</definition>
			<definition id="10">
				<sentence>PHRASE TYPE ( pt ) : This feature indicates the syntactic type of the phrase labeled as a predicate argument .</sentence>
				<definiendum id="0">PHRASE TYPE</definiendum>
				<definiens id="0">the syntactic type of the phrase labeled as a predicate argument</definiens>
			</definition>
			<definition id="11">
				<sentence>PARSE TREE PATH ( path ) : This feature contains the path in the parse tree between the predicate phrase and the argument phrase , expressed as a sequence of nonterminal labels linked by direction ( up or down ) .</sentence>
				<definiendum id="0">PARSE TREE PATH ( path )</definiendum>
			</definition>
			<definition id="12">
				<sentence>VOICE ( voice ) This feature distinguishes between active or passive voice for the predicate phrase .</sentence>
				<definiendum id="0">VOICE ( voice</definiendum>
				<definiens id="0">active or passive voice for the predicate phrase</definiens>
			</definition>
			<definition id="13">
				<sentence>HEAD WORD ( hw ) This feature contains the head word of the evaluated phrase .</sentence>
				<definiendum id="0">HEAD WORD</definiendum>
				<definiens id="0">the head word of the evaluated phrase</definiens>
			</definition>
			<definition id="14">
				<sentence>GOVERNING CATEGORY ( gov ) This feature applies to noun phrases only , and it indicates if the NP is dominated by a sentence phrase ( typical for subject arguments with active voice predicates ) , or by a verb phrase ( typical for object arguments ) .</sentence>
				<definiendum id="0">GOVERNING CATEGORY</definiendum>
				<definiens id="0">dominated by a sentence phrase ( typical for subject arguments with active voice predicates ) , or by a verb phrase ( typical for object arguments )</definiens>
			</definition>
			<definition id="15">
				<sentence>PREDICATE WORD In our implementation this feature consists of two components : ( 1 ) VERB : the word itself with the case and morphological information preserved ; and ( 2 ) LEMMA which represents the verb normalized to lower case and infinitive form .</sentence>
				<definiendum id="0">VERB</definiendum>
				<definiens id="0">the word itself with the case and morphological information preserved ; and ( 2 ) LEMMA which represents the verb normalized to lower case and infinitive form</definiens>
			</definition>
			<definition id="16">
				<sentence>DANGER ( Prime Minister Mori continues in Position ) Figure 9 : Intentional Structure derived from Lexico-Semantic Knowledge .</sentence>
				<definiendum id="0">DANGER</definiendum>
			</definition>
</paper>

		<paper id="1814">
			<definition id="0">
				<sentence>In The balancing act : combining symbolic and statistica application to language .</sentence>
				<definiendum id="0">balancing act</definiendum>
				<definiens id="0">combining symbolic and statistica application to language</definiens>
			</definition>
</paper>

		<paper id="3008">
</paper>

		<paper id="2415">
			<definition id="0">
				<sentence>For a fragment from s to e the algorithm is as follows : r : = arg maxs r &lt; e A [ s ; r ] + A [ r+1 ; e ] ( a ) K : = F ( ( s ; e ) ; v ) ( b ) Compute k0 such that k0 : = arg maxk2K k-score ( ( s ; e ) ; v ; x ) Set to the score of category k0. ( c ) Set Av as the arguments in A linked to v. ( d ) If ( Av ) &lt; then A : = AnAv [ f ( s ; e ) k0v g Note that an argument is visited once , and that its score can be stored to efficiently compute the global score. The function F determines which categories in K are plausible for an argument ( s ; e ) to relate to a verb v. This is done via start-end filters ( FkS and FkE ) , one for each type in K1. They operate on words , independently of verbs , deciding whether a word is likely to start or end some argument of role type k. The selection of categories is conditional to the relative level of the verb and the clause , and to the relative position of the verb and the argument. The conditions are : v is local to the clause , and ( v=s ) and FVE ( xe ) : K : = fVg v is local , and ( e &lt; v _ v &lt; s ) : K : = fk 2 K j FkS ( xs ) ^ FkE ( xe ) g 1Actually , we share start-end filters for A0-A5 arguments. v is at deeper level , and ( e &lt; v ) : K : = fk 2 K j k62K ( v ) ^ FkS ( xs ) ^ FkE ( xe ) g where K ( v ) is the set of categories already assigned to the verb in deeper clauses. Otherwise , K is set to empty. Note that setting K to empty has the effect of filtering out the argument for the proposition. Note also that Start-End classifications do not depend on the verb , thus they can be performed once per candidate word , before entering the exploration of clauses. Then , when visiting a clause , the Start-End filtering can be performed with stored predictions. In this section we describe the learning components of the system , namely start , end and score functions , and the Perceptron-based algorithm to train them together online. Each function is implemented using a linear separator , hw : Rn ! R , operating in a feature space defined by a feature extraction function , : X ! Rn , for some instance space X. The start-end functions ( FkS and FkE ) are formed by a prediction vector for each type , noted as wkS or wkE , and a shared representation function w which maps a word in context to a feature vector. A prediction is computed as FkS ( x ) = wkS w ( x ) , and similarly for the FkE , and the sign is taken as the binary classification. The score functions compute real-valued scores for arguments ( s ; e ) v. We implement these functions with a prediction vector wk for each type k 2 K , and a shared representation function a which maps an argument-verb pair to a feature vector. The score prediction for a type k is then given by the expression : k-score ( ( s ; e ) ; v ; x ) = wk a ( ( s ; e ) ; v ; x ) . We describe a mistake-driven online algorithm to train prediction vectors together. The algorithm is essentially the same as the one introduced in ( Collins , 2002 ) . Let W be the set of prediction vectors : Initialize : 8w2W w : = 0 For each epoch t : = 1 : : : T , for each sentence-solution pair ( x ; y ) in training : Return W We now describe the learning feedback rule , introduced in earlier works ( Carreras and M`arquez , 2004b ) . We differentiate two kinds of global errors in order to give feedback to the functions being learned : missed arguments and over-predicted arguments. In each case , we identify the prediction vectors responsible for producing the incorrect argument and update them additively : vectors are moved towards instances predicted too low , and moved away from instances predicted too high. Let y be the gold set of arguments for a sentence x , and ^y those predicted by the SRL function. Let goldS ( xi ; k ) and goldE ( xi ; k ) be , respectively , the perfect indicator functions for start and end boundaries of arguments of type k. That is , they return 1 if word xi starts/ends some k-argument in y and -1 otherwise. The feedback is as follows : Missed arguments : 8 ( s ; e ) kv 2 y n^y : if ( wkS w ( xs ) 0 ) then wkS = wkS + w ( xs ) if ( wkE w ( xe ) 0 ) then wkE = wkE + w ( xe ) if ( k 2 F ( ( s ; e ) ; v ) then wk = wk + a ( ( s ; e ) ; v ; x ) Over-predicted arguments : 8 ( s ; e ) kp 2 ^yny : wk = wk a ( ( s ; e ) ; v ; x ) if ( goldS ( xs ; k ) = 1 ) then wkS = wkS w ( xs ) if ( goldE ( xe ; k ) = 1 ) then wkE =wkE w ( xe ) Our final architecture makes use of Voted Perceptrons ( Freund and Schapire , 1999 ) , which compute a prediction as an average of all vectors generated during training. Roughly , each vector contributes to the average proportionally to the number of correct positive training predictions the vector has made. Furthermore , a prediction vector can be expressed in dual form as a combination of training instances , which allows the use of kernel functions. We use standard polynomial kernels of degree 2. The features of the system are extracted from three types of elements : words , target verbs , and arguments. They are formed making use of PoS tags , chunks and clauses of the sentence. The functions w and a are defined in terms of a collection of feature extraction patterns , which are binarized in the functions : each extracted pattern forms a binary dimension indicating the existence of the pattern in a learning instance. Extraction on Words. The list of features extracted from a word xi is the following : PoS tag. Form , if the PoS tag does not match with the Perl regexp /ˆ ( CD|FW|J|LS|N|POS|SYM|V ) /. Chunk type , of the chunk containing the word. Binary-valued flags : ( a ) Its chunk is one-word or multi-word ; ( b ) Starts and/or ends , or is strictly within a chunk ( 3 flags ) ; ( c ) Starts and/or ends clauses ( 2 flags ) ; ( d ) Aligned with a target verb ; and ( e ) First and/or last word of the sentence ( 2 flags ) . Given a word xi , the w function implements a 3 window , that is , it returns the features of the words xi+r , with 3 r +3 , each with its relative position r. Extraction on Target Verbs. Given a target verb v , we extract the following features from the word xv : Form , PoS tag , and target verb infinitive form. Voice : passive , if xv has PoS tag VBN , and either its chunk is not VP or xv is preceded by a form of “to be” or “to get” within its chunk ; otherwise active. Chunk type. Binary-valued flags : ( a ) Its chunk is multi-word or not ; and ( b ) Starts and/or ends clauses ( 2 flags ) . Extraction on Arguments. The a function performs the following feature extraction for an argument ( s ; e ) linked to a verb v : Target verb features , of verb v. Word features , of words s 1 , s , e , and e+1 , each anchored with its relative position. Distance of v to s and to e : for both pairs , a flag indicating if distance is f0 ; 1 ; 1 ; &gt; 1 ; &lt; 1g .</sentence>
				<definiendum id="0">x ) Set to</definiendum>
				<definiens id="0">follows : r : = arg maxs r &lt; e A [ s ; r ] + A [ r+1 ; e ] ( a ) K : = F ( ( s ; e ) ; v ) ( b ) Compute k0 such that k0 : = arg maxk2K k-score ( ( s ; e ) ; v ;</definiens>
				<definiens id="1">the score of category k0. ( c ) Set Av as the arguments in A linked to v. ( d ) If ( Av ) &lt; then A : = AnAv [ f ( s ; e ) k0v g Note that an argument is visited once , and that its score can be stored to efficiently compute the global score. The function F determines which categories in K are plausible for an argument ( s ; e ) to relate to a verb</definiens>
				<definiens id="2">conditional to the relative level of the verb and the clause , and to the relative position of the verb and the argument. The conditions are : v is local to the clause , and ( v=s ) and FVE ( xe ) : K : = fVg v is local , and ( e &lt; v _ v &lt; s ) : K : = fk 2 K j FkS ( xs ) ^ FkE ( xe ) g 1Actually , we share start-end filters for A0-A5 arguments. v is at deeper level , and ( e &lt; v ) : K : = fk 2 K j k62K ( v ) ^ FkS ( xs ) ^ FkE ( xe ) g where K ( v ) is the set of categories already assigned to the verb in deeper clauses. Otherwise , K is set to empty. Note that setting K to empty has the effect of filtering out the argument for the proposition. Note also that Start-End classifications do not depend on the verb , thus they can be performed once per candidate word , before entering the exploration of clauses. Then , when visiting a clause , the Start-End filtering can be performed with stored predictions. In this section we describe the learning components of the system , namely start , end and score functions , and the Perceptron-based algorithm to train them together online. Each function is implemented using a linear separator , hw : Rn ! R , operating in a feature space defined by a feature extraction function , : X ! Rn , for some instance space X. The start-end functions ( FkS and FkE ) are formed by a prediction vector for each type , noted as wkS or wkE , and a shared representation function w which maps a word in context to a feature vector. A prediction is computed as FkS ( x ) = wkS w ( x ) , and similarly for the FkE , and the sign is taken as the binary classification. The score functions compute real-valued scores for arguments ( s ; e ) v. We implement these functions with a prediction vector wk for each type k 2 K , and a shared representation function a which maps an argument-verb pair to a feature vector. The score prediction for a type k is then given by the expression : k-score ( ( s ; e ) ; v ; x ) = wk a ( ( s ; e ) ; v ; x ) . We describe a mistake-driven online algorithm to train prediction vectors together. The algorithm is essentially the same as the one introduced in ( Collins , 2002 ) . Let W be the set of prediction vectors : Initialize : 8w2W w : = 0 For each epoch t : = 1 : : : T , for each sentence-solution pair ( x ; y ) in training : Return W We now describe the learning feedback rule , introduced in earlier works ( Carreras and M`arquez , 2004b ) . We differentiate two kinds of global errors in order to give feedback to the functions being learned : missed arguments</definiens>
				<definiens id="3">responsible for producing the incorrect argument and update them additively : vectors are moved towards instances predicted too low , and moved away from instances predicted too high. Let y be the gold set of arguments for a sentence x , and ^y those predicted by the SRL function. Let goldS ( xi ; k ) and goldE ( xi ; k ) be , respectively , the perfect indicator functions for start and end boundaries of arguments of type k. That is , they return 1 if word xi starts/ends some k-argument in y and -1 otherwise. The feedback is as follows : Missed arguments : 8 ( s ; e ) kv 2 y n^y : if ( wkS w ( xs ) 0 ) then wkS = wkS + w ( xs ) if ( wkE w ( xe ) 0 ) then wkE = wkE + w ( xe ) if ( k 2 F ( ( s ; e ) ; v ) then wk = wk + a ( ( s ; e ) ; v ; x ) Over-predicted arguments : 8 ( s ; e ) kp 2 ^yny : wk = wk a ( ( s ; e ) ; v ; x ) if ( goldS ( xs ; k ) = 1 ) then wkS = wkS w ( xs ) if ( goldE ( xe ; k ) = 1 ) then wkE =wkE w ( xe ) Our final architecture makes use of Voted Perceptrons ( Freund and Schapire , 1999 ) , which compute a prediction as an average of all vectors generated during training. Roughly , each vector contributes to the average proportionally to the number of correct positive training predictions the vector has made. Furthermore , a prediction vector can be expressed in dual form as a combination of training instances , which allows the use of kernel functions. We use standard polynomial kernels of degree 2. The features of the system are extracted from three types of elements : words , target verbs , and arguments. They are formed making use of PoS tags , chunks and clauses of the sentence. The functions w and a are defined in terms of a collection of feature extraction patterns , which are binarized in the functions : each extracted pattern forms a binary dimension indicating the existence of the pattern in a learning instance. Extraction on Words. The list of features extracted from a word xi is the following : PoS tag. Form , if the PoS tag does not match with the Perl regexp /ˆ ( CD|FW|J|LS|N|POS|SYM|V ) /. Chunk type , of the chunk containing the word. Binary-valued flags : ( a ) Its chunk is one-word or multi-word ; ( b ) Starts and/or ends , or is strictly within a chunk ( 3 flags ) ; ( c ) Starts and/or ends clauses ( 2 flags ) ; ( d ) Aligned with a target verb ; and ( e ) First and/or last word of the sentence ( 2 flags ) . Given a word xi , the w function implements a 3 window , that is , it returns the features of the words xi+r , with 3 r +3 , each with its relative position r. Extraction on Target Verbs. Given a target verb v</definiens>
				<definiens id="4">Form , PoS tag , and target verb infinitive form. Voice : passive , if xv has PoS tag VBN , and either its chunk is not VP or xv is preceded by a form of “to be” or “to get” within its chunk ; otherwise active. Chunk type. Binary-valued flags : ( a ) Its chunk is multi-word or not</definiens>
				<definiens id="5">s ; e ) linked to a verb v : Target verb features , of verb v. Word features , of words s 1 , s , e , and e+1 , each anchored with its relative position. Distance of v to s and to e</definiens>
			</definition>
			<definition id="1">
				<sentence>The vertical part is the list of tags of the phrases which contain the verb , from the phrase at the level of the argument to the verb .</sentence>
				<definiendum id="0">vertical part</definiendum>
				<definiens id="0">the list of tags of the phrases which contain the verb , from the phrase at the level of the argument to the verb</definiens>
			</definition>
</paper>

		<paper id="3006">
			<definition id="0">
				<sentence>Spoken dialogue systems are emerging as an intuitive interface for providing conversational access to online information sources ( Eckert et al. , 1997 ; Gorin et al. , 1997 ; Dahlback et al. , 1999 ; Zue et al. , 2000 ; Walker et al. , 2001 ; Glass and Seneff , 2003 ; Pieraccini et al. , 1997 ; Quast et al. , 2003 ; J. Gustafson , 1999 ; Polifroni and Chung , 2002 ; Denecke , 2002 ; Seneff , 2002 ; Zue and Glass , 2000 ) .</sentence>
				<definiendum id="0">Spoken dialogue systems</definiendum>
				<definiens id="0">an intuitive interface for providing conversational access to online information sources ( Eckert et al. , 1997 ; Gorin et al. , 1997</definiens>
			</definition>
			<definition id="1">
				<sentence>A similar process takes place for dates .</sentence>
				<definiendum id="0">similar process</definiendum>
				<definiens id="0">takes place for dates</definiens>
			</definition>
</paper>

		<paper id="1612">
			<definition id="0">
				<sentence>The Arabic alphabet consists of twenty-eight letters , twentyve of which represent consonants and three of which represent the long vowels ( /i : / , /a : / , /u : / ) .</sentence>
				<definiendum id="0">Arabic alphabet</definiendum>
				<definiens id="0">consists of twenty-eight letters , twentyve of which represent consonants and three of which represent the long vowels ( /i : / , /a : / , /u : / )</definiens>
			</definition>
			<definition id="1">
				<sentence>Several knowledge sources are available for determining the most appropriate diacritization of a script form : analysis of the morphological structure of the word ( including segmentation into stems , pre xes , roots and patterns ) , consideration of the syntactic context in which the word form appears , and , in the context of speech recognition , the acoustic data that accompanies the transcription .</sentence>
				<definiendum id="0">Several knowledge sources</definiendum>
				<definiens id="0">xes , roots and patterns ) , consideration of the syntactic context in which the word form appears , and , in the context of speech recognition , the acoustic data that accompanies the transcription</definiens>
			</definition>
			<definition id="2">
				<sentence>The FBIS corpus is a collection of radio newscasts from various radio stations in the Arabic speaking world ( Cairo , Damascus , Baghdad ) totaling approximately 40 hours of speech ( roughly 240K words ) .</sentence>
				<definiendum id="0">FBIS corpus</definiendum>
				<definiens id="0">a collection of radio newscasts from various radio stations in the Arabic speaking world ( Cairo , Damascus , Baghdad ) totaling approximately 40 hours of speech ( roughly 240K words )</definiens>
			</definition>
			<definition id="3">
				<sentence>The CallHome corpus , made available by LDC , consists of informal telephone conversations between native speakers ( friends and family members ) of Egyptian Arabic , mostly from the Cairene dialect region .</sentence>
				<definiendum id="0">CallHome corpus</definiendum>
				<definiens id="0">consists of informal telephone conversations between native speakers ( friends and family members ) of Egyptian Arabic</definiens>
			</definition>
			<definition id="4">
				<sentence>We adopted a standard statistical trigram tagging model : P ( t0 ; : : : ; tnjw0 ; : : : ; wn ) = nY i=0 P ( wijti ) P ( tijti 1 ; ti 2 ) ( 1 ) where t is a tag , w is a word , and n is the total number of words in the sentence .</sentence>
				<definiendum id="0">t</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the total number of words in the sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>Instead , all possible assignments are initially considered and the ExpectationMaximization ( EM ) training procedure iteratively trains the probability distributions in the above model ( the probability of word given tag , P ( wijti ) , and the tag sequence probability , P ( tijti 1 ; ti 2 ) ) until convergence .</sentence>
				<definiendum id="0">ExpectationMaximization</definiendum>
				<definiens id="0">the probability of word given tag</definiens>
			</definition>
</paper>

		<paper id="0818">
			<definition id="0">
				<sentence>The Link Grammar formalism consists of labeled , undirected links among pairs of words .</sentence>
				<definiendum id="0">Link Grammar formalism</definiendum>
			</definition>
			<definition id="1">
				<sentence>Association for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems input sentence Chris loves Sam link parser 1 Chris Ss 2 loves Ss output 2 loves O 3 Sam Os rules ( 1 ) LINK ( S SF SX ) role [ left ] : arg : S role [ right ] : head ( 2 ) LINK O role [ left ] : head role [ right ] : arg : O ( 3 ) FEAT ( SSX ) category : v dependency [ v [ Chris 1 : H ] : S loves 2 : H,3singular , present [ Sam 3 : H ] : O ] object logic form Chris ( x1 ) loves : v ( e1 , x1 , x2 ) Sam ( x2 ) Figure 1 : Processing “Chris loves Sam” Link parses contain a great deal of detail , but because the link parser is a general-purpose tool , extracting this detail for a particular task may require further processing .</sentence>
				<definiendum id="0">LINK ( S SF SX</definiendum>
				<definiens id="0">H ] : O ] object logic form Chris ( x1 ) loves : v ( e1 , x1 , x2 ) Sam ( x2 ) Figure 1 : Processing “Chris loves Sam” Link parses contain a great deal of detail , but because the link parser is a general-purpose tool</definiens>
			</definition>
			<definition id="2">
				<sentence>The LINK rules can assign a range of roles , including : a2 head a2 argument of a particular type ( e.g. , S or O ) a2 modifier of a particular type ( e.g. , DET ) a2 merge , which promotes all dependents of the merged element and constructs a complex lexical head ( e.g. , for idioms or multi-word proper names ) 1S links are simple subject-verb relations , SF is used for the special case where the subject is it or there ( e.g .</sentence>
				<definiendum id="0">LINK rules</definiendum>
				<definiendum id="1">merge</definiendum>
				<definiendum id="2">SF</definiendum>
				<definiens id="0">promotes all dependents of the merged element and constructs a complex lexical head</definiens>
			</definition>
			<definition id="3">
				<sentence>, and SX is used whent he subject is the first person pronoun I. a2 filler and hole , which establish relationships related to unbounded dependencies In addition , LINK and FEAT rules can assign roles , properties and categories to the parents of the left and right elements when necessary , and the processor postpones these assignments until the appropriate parent relationships are established .</sentence>
				<definiendum id="0">SX</definiendum>
				<definiens id="0">establish relationships related to unbounded dependencies In addition , LINK and FEAT rules can assign roles , properties and categories to the parents of the left and right elements when necessary , and the processor postpones these assignments until the appropriate parent relationships are established</definiens>
			</definition>
			<definition id="4">
				<sentence>SentArgPred indicates the percentage of sentences for which all arguments were identified correctly out of sentences that had all predicates identified correctly .</sentence>
				<definiendum id="0">SentArgPred</definiendum>
				<definiens id="0">indicates the percentage of sentences for which all arguments were identified correctly out of sentences that had all predicates identified correctly</definiens>
			</definition>
			<definition id="5">
				<sentence>SentArgPredSent is the percentage of sentences for which all arguments and all predicates were identified correctly ( SentArgPredSent ) .</sentence>
				<definiendum id="0">SentArgPredSent</definiendum>
				<definiens id="0">the percentage of sentences for which all arguments and all predicates were identified correctly</definiens>
			</definition>
			<definition id="6">
				<sentence>In the single example of this construction in the sample data ( Sunshine makes me very happy ) the modifier very is predicated of me , because happy is predicated of me .</sentence>
				<definiendum id="0">Sunshine</definiendum>
				<definiens id="0">makes me very happy ) the modifier very is predicated of me</definiens>
			</definition>
</paper>

		<paper id="1001">
</paper>

		<paper id="3250">
			<definition id="0">
				<sentence>Europarl : A multilingual corpus for evaluation of machine translation .</sentence>
				<definiendum id="0">Europarl</definiendum>
			</definition>
			<definition id="1">
				<sentence>Pharaoh : a beam search decoder for phrase-based statistical machine translation models .</sentence>
				<definiendum id="0">Pharaoh</definiendum>
				<definiens id="0">a beam search decoder for phrase-based statistical machine translation models</definiens>
			</definition>
</paper>

		<paper id="1613">
			<definition id="0">
				<sentence>Nastaleeq is a cursive , context-sensitive and highly complex writing system ( Hussain 2003 ) .</sentence>
				<definiendum id="0">Nastaleeq</definiendum>
			</definition>
			<definition id="1">
				<sentence>( a ) p b p b m m t d t d n n     k  k    t d t d q  f v s z   x  h r r   j l l ( b ) i e  æ u o      i e æ u o   Table 2 : Urdu ( a ) Consonantal and ( b ) Vocalic phonemic inventory As discussed earlier , to enable text-to-speech system for any language , a Natural Language Processing component is required .</sentence>
				<definiendum id="0">Urdu</definiendum>
				<definiens id="0">a ) Consonantal and ( b ) Vocalic phonemic inventory As discussed earlier , to enable text-to-speech system for any language , a Natural Language Processing component is required</definiens>
			</definition>
			<definition id="2">
				<sentence>Tokenizer Semantic Tagger String Generator Letter to Sound Converter Sound Change Manager Syllabifier Stress Marker Intonation Marker Urdu Raw Text Input Normalized Urdu Text Annotated Phonetic Output The Text Normalization component takes a character string as input and converts it into a string of letters .</sentence>
				<definiendum id="0">Text Normalization component</definiendum>
				<definiens id="0">takes a character string as input and converts it into a string of letters</definiens>
			</definition>
			<definition id="3">
				<sentence>Within it , the Tokenizer uses the punctuation marks and space between words to mark token boundaries which are then stamped as words , punctuation , date , time and other relevant categories by the Semantic Tagger .</sentence>
				<definiendum id="0">Tokenizer</definiendum>
				<definiens id="0">uses the punctuation marks and space between words to mark token boundaries which are then stamped as words , punctuation , date , time and other relevant categories by the Semantic Tagger</definiens>
			</definition>
			<definition id="4">
				<sentence>The String Generator takes any non-letter based input ( e.g. a number or a date containing digits ) and converts it into a letter string .</sentence>
				<definiendum id="0">String Generator</definiendum>
				<definiens id="0">takes any non-letter based input ( e.g. a number or a date containing digits</definiens>
			</definition>
			<definition id="5">
				<sentence>Following these modules , Stress Marker and Intonation Marker modules add stress and intonation to the string being processed .</sentence>
				<definiendum id="0">Intonation Marker</definiendum>
			</definition>
			<definition id="6">
				<sentence>Shad geminates the consonant on which it occurs , which is normally word medially and inter-vocalically .</sentence>
				<definiendum id="0">Shad</definiendum>
				<definiens id="0">geminates the consonant on which it occurs , which is normally word medially and inter-vocalically</definiens>
			</definition>
			<definition id="7">
				<sentence>Urdu shows regular behavior and thus the phonemic forms are predictable from the textual input .</sentence>
				<definiendum id="0">Urdu</definiendum>
				<definiens id="0">shows regular behavior and thus the phonemic forms are predictable from the textual input</definiens>
			</definition>
</paper>

		<paper id="0901">
			<definition id="0">
				<sentence>Soar : An architecture for general intelligence .</sentence>
				<definiendum id="0">Soar</definiendum>
				<definiens id="0">An architecture for general intelligence</definiens>
			</definition>
			<definition id="1">
				<sentence>EPILOG : The computational system for episodic logic .</sentence>
				<definiendum id="0">EPILOG</definiendum>
				<definiens id="0">The computational system for episodic logic</definiens>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>Sentence ranking is a crucial part of generating text summaries .</sentence>
				<definiendum id="0">Sentence ranking</definiendum>
				<definiens id="0">a crucial part of generating text summaries</definiens>
			</definition>
</paper>

		<paper id="0707">
			<definition id="0">
				<sentence>• The second group of 11 ( mostly boolean ) features specifies the type of NP : e.g. , pronoun is Y if the anaphoric expression is a pronoun , else N. • The third group of 7 features specifies syntactic properties of the anaphoric expression , including number , whether NPj is the first of two NPs in an appositive or predicative construction , whether NPj is preor post-modified , whether it contains a proper noun , and whether it is modified by a superlative .</sentence>
				<definiendum id="0">NPj</definiendum>
				<definiens id="0">the first of two NPs in an appositive or predicative construction</definiens>
			</definition>
			<definition id="1">
				<sentence>GUITAR ( Poesio and Alexandrov-Kabadjov , 2004 ) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkov’s algorithm for pronoun resolution ( Mitkov , 1998 ) .</sentence>
				<definiendum id="0">GUITAR ( Poesio</definiendum>
			</definition>
			<definition id="2">
				<sentence>Total Res Corr NM WM SM R P F 180 182 121 43 16 45 67.2 66.5 66.8 Table 6 : Evaluation of the GUITAR system without DN detection over a hand-annotated treebank GUITAR without a DN recognizer takes 182 DDs ( Res ) as anaphoric , resolving 121 of them correctly ( Corr ) ; of the 182 DDs it attempts to resolve , only 16 are incorrectly resolved ( WM ) ; almost three times that number ( 45 ) are Spurious Matches ( SM ) , i.e. , discourse-new DDs incorrectly interpreted as anaphoric .</sentence>
				<definiendum id="0">GUITAR</definiendum>
				<definiens id="0">Evaluation of the GUITAR system without DN detection over a hand-annotated treebank</definiens>
			</definition>
			<definition id="3">
				<sentence>The GNOME corpus includes pharmaceutical leaflets and museum ’labels’ ( i.e. , descriptions of museum objects and of the artists that realized them ) .</sentence>
				<definiendum id="0">GNOME corpus</definiendum>
				<definiens id="0">includes pharmaceutical leaflets and museum ’labels’ ( i.e. , descriptions of museum objects and of the artists that realized them )</definiens>
			</definition>
</paper>

		<paper id="0710">
			<definition id="0">
				<sentence>Task ( 1 ) , which amounts more or less to automated speech recognition , is of course a standard one , for which the performance level , as measured by the word error rate ( WER ) , depends on the microphone used , the environment , the type of the meeting , etc .</sentence>
				<definiendum id="0">WER</definiendum>
				<definiens id="0">amounts more or less to automated speech recognition</definiens>
				<definiens id="1">measured by the word error rate</definiens>
			</definition>
			<definition id="1">
				<sentence>The form of a document , i.e. its layout and its logical structure , carries important ( and often underestimated ) clues about the content , in particular for newspaper pages , Newspaper - &gt; Date , Name , MasterArticle , Highlight* , Article+ , Other* , Filename MasterArticle - &gt; Title , Subheading ?</sentence>
				<definiendum id="0">form of a document</definiendum>
				<definiens id="0">carries important ( and often underestimated ) clues about the content , in particular for newspaper pages , Newspaper - &gt; Date , Name , MasterArticle , Highlight* , Article+ , Other* , Filename MasterArticle - &gt;</definiens>
			</definition>
			<definition id="2">
				<sentence>Words in capital letters represent classes of occurring words : NEWSP are newspaper names , SPEC is a specifier ( one or more words , e.g. , an adjective or a relative sentence ) , DATE and TITLE are obvious .</sentence>
				<definiendum id="0">SPEC</definiendum>
				<definiens id="0">a specifier ( one or more words , e.g. , an adjective or a relative sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>If the RE is anaphoric , then it is associated to the current article or document element—a very simple implementation of a focus stack ( Grosz et al. , 1995 ) —except if the RE is the first one in the meeting , which is never considered to be anaphoric .</sentence>
				<definiendum id="0">RE</definiendum>
				<definiens id="0">anaphoric , then it is associated to the current article or document element—a very simple implementation of a focus stack ( Grosz et al.</definiens>
			</definition>
			<definition id="4">
				<sentence>Acknowledgements This work is part of ( IM ) 2 , Interactive Multimodal Information Management , a NCCR supported by the FNS / Swiss Government ( www.im2.ch ) .</sentence>
				<definiendum id="0">Multimodal Information Management</definiendum>
			</definition>
			<definition id="5">
				<sentence>and Reality : an Introduction to the Philosophy of Language .</sentence>
				<definiendum id="0">Reality</definiendum>
				<definiens id="0">an Introduction to the Philosophy of Language</definiens>
			</definition>
			<definition id="6">
				<sentence>Xed : a new tool for extracting hidden structures from electronic documents .</sentence>
				<definiendum id="0">Xed</definiendum>
				<definiens id="0">a new tool for extracting hidden structures from electronic documents</definiens>
			</definition>
</paper>

		<paper id="2418">
			<definition id="0">
				<sentence>The concept of Memory-Based Learning ( MBL ) ( Lin and Vitter , 1994 ) is to classify unseen ( test ) instances based on their similarity to known ( training ) instances .</sentence>
				<definiendum id="0">Memory-Based Learning ( MBL )</definiendum>
				<definiens id="0">to classify unseen ( test ) instances based on their similarity to known ( training ) instances</definiens>
			</definition>
			<definition id="1">
				<sentence>For this task we use the IOB2 format , where B marks an element at the beginning of an argument , I an element inside an argument and O an element that does not belong to an argument .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">marks an element at the beginning of an argument , I an element inside an argument</definiens>
			</definition>
			<definition id="2">
				<sentence>Length : the length in chunks of the argument .</sentence>
				<definiendum id="0">Length</definiendum>
			</definition>
</paper>

		<paper id="0852">
			<definition id="0">
				<sentence>Word sense disambigution : the case for combining knowledge sources .</sentence>
				<definiendum id="0">Word sense disambigution</definiendum>
			</definition>
</paper>

		<paper id="1809">
			<definition id="0">
				<sentence>Each Hangul character is a combination of more than one consonant .</sentence>
				<definiendum id="0">Hangul character</definiendum>
				<definiens id="0">a combination of more than one consonant</definiens>
			</definition>
			<definition id="1">
				<sentence>1 − 2 · ( α · dc + dv ) α · c + v ( 1 ) Here , dc and dv denote the numbers of diﬀerences in consonants and vowels , respectively , and α is a 1 http : //www.omronsoft.com/ parametric constant used to control the importance of the consonants .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">1 ) Here , dc and dv denote the numbers of diﬀerences in consonants and vowels , respectively , and</definiens>
				<definiens id="1">a 1 http : //www.omronsoft.com/ parametric constant used to control the importance of the consonants</definiens>
			</definition>
			<definition id="2">
				<sentence>This document set consists of 66,146 newspaper articles of Korean Economic Daily published in 1994 .</sentence>
				<definiendum id="0">document set</definiendum>
				<definiens id="0">consists of 66,146 newspaper articles of Korean Economic Daily published in 1994</definiens>
			</definition>
</paper>

		<paper id="0102">
			<definition id="0">
				<sentence>Barcelona , July 2004 Association for Computations Linguistics ACL Special Interest Group on Computational Phonology ( SIGPHON ) Proceedings of the Workshop of the Lazy learning methods such as the nearest neighbour algorithm ( van den Bosch et al. , 1996 ) or the analogy-based approach ( Pirrelli and Federici , 1994 ; Pirrelli and Yvon , 1999 ) require full storage of supervised data , and make on-line use of them with no prior or posterior lexical structuring .</sentence>
				<definiendum id="0">nearest neighbour algorithm</definiendum>
			</definition>
			<definition id="1">
				<sentence>More formally : { } ixbx vvvv −≡− min , where is also known as the quantization error scored by v b relative to v x .</sentence>
				<definiendum id="0">ixbx vvvv −≡− min</definiendum>
				<definiens id="0">the quantization error scored by v b relative to v x</definiens>
			</definition>
			<definition id="2">
				<sentence>( ) , ( ) ( ttllhth ibbi α⋅−= , where l b and l i are , respectively , the position of b and its kernel neurons on the map grid , and α ( t ) is the learning rate at time t , a monotonically decreasing function of t. Interaction of these functions simulates effects of memory entrenchment and proto-typicality of early input data .</sentence>
				<definiendum id="0">α ( t )</definiendum>
				<definiens id="0">the learning rate at time t</definiens>
			</definition>
			<definition id="3">
				<sentence>Traditional descriptive grammars ( e.g. Serianni , 1988 ) identify three main conjugation classes ( or more simply conjugations ) , characterised by a distinct thematic vowel ( TV ) , which appears between the verb root and the inflectional endings .</sentence>
				<definiendum id="0">Traditional descriptive grammars</definiendum>
				<definiens id="0">or more simply conjugations ) , characterised by a distinct thematic vowel ( TV ) , which appears between the verb root and the inflectional endings</definiens>
			</definition>
			<definition id="4">
				<sentence>The present experiments were carried out using the SOM toolbox ( Vesanto et al. , 2000 ) , developed at the Neural Networks Research Centre of Helsinki University of Technology .</sentence>
				<definiendum id="0">SOM toolbox</definiendum>
				<definiens id="0">developed at the Neural Networks Research Centre of Helsinki University of Technology</definiens>
			</definition>
			<definition id="5">
				<sentence>Column vectors represent characters , and rows give the random encoding of each character , ensuring maximum independence of character vector representations .</sentence>
				<definiendum id="0">Column vectors</definiendum>
				<definiens id="0">represent characters , and rows give the random encoding of each character , ensuring maximum independence of character vector representations</definiens>
			</definition>
			<definition id="6">
				<sentence>A SOM projects n-dimensional data points onto grid units of reduced dimensionality ( usually 2 ) .</sentence>
				<definiendum id="0">SOM</definiendum>
				<definiens id="0">projects n-dimensional data points onto grid units of reduced dimensionality ( usually 2 )</definiens>
			</definition>
			<definition id="7">
				<sentence>The newly trained SOM is a second level projection of the original data points .</sentence>
				<definiendum id="0">SOM</definiendum>
			</definition>
			<definition id="8">
				<sentence>To test the consistency of the paradigm-based organisation of the map in Figure 2 , we trained a 2 While Italian regular 1st and 3rd conjugation verbs present a thematic vowel in their past participle endings ( -ato and -ito respectively ) , regular 2 conjugation past participles ( TV -e- ) end , somewhat unexpectedly , in -uto .</sentence>
				<definiendum id="0">TV -e-</definiendum>
				<definiens id="0">Italian regular 1st and 3rd conjugation verbs present a thematic vowel in their past participle endings ( -ato and -ito respectively</definiens>
			</definition>
</paper>

		<paper id="0914">
			<definition id="0">
				<sentence>ONSE contains several modules , with an ontology at the center ; the other important modules are lexicons of languages and a fact repository , in which information about the world is stored , and , of course , the analyzer and generator .</sentence>
				<definiendum id="0">ONSE</definiendum>
				<definiens id="0">contains several modules , with an ontology at the center ; the other important modules are lexicons of languages and a fact repository , in which information about the world is stored , and , of course , the analyzer and generator</definiens>
			</definition>
			<definition id="1">
				<sentence>PAY definitionvalue“to compensate somebody for goods or services rendered” is-avalueEVERYDAYFINANCIAL-EVENT subclassesvaluePAY-TAX SUBSCRIBE-TO agentsemHUMAN relaxable-toORGANIZATION themedefaultMONEY semCOMMODITY relaxable-toEVENT patientsemHUMAN relaxable-toORGANIZATION Figure 2 : Ontological Concept PAY The ontology is a tangled hierarchy ( lattice ) of concepts , beginning at the root ALL , branching into OBJECT , EVENT , and PROPERTY , and so forth .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">a tangled hierarchy ( lattice ) of concepts , beginning at the root ALL , branching into OBJECT , EVENT , and PROPERTY , and so forth</definiens>
			</definition>
			<definition id="2">
				<sentence>VALUE , SEM , RELAXABLE-TO and DEFAULT are all facets of their slots .</sentence>
				<definiendum id="0">DEFAULT</definiendum>
				<definiens id="0">all facets of their slots</definiens>
			</definition>
			<definition id="3">
				<sentence>A script captures the entities of such an event and their temporal and causal sequences , as shown for the complex event BANKRUPTCY in figure 7 .</sentence>
				<definiendum id="0">script</definiendum>
				<definiens id="0">captures the entities of such an event and their temporal and causal sequences</definiens>
			</definition>
			<definition id="4">
				<sentence>This can be established since CONCEALMENT is defined as part of the script BANKRUPTCY , which is instantiated for the TMR of the text .</sentence>
				<definiendum id="0">CONCEALMENT</definiendum>
			</definition>
			<definition id="5">
				<sentence>As resources permit , we have been moving consistently to enrich our ONSE resources with IAS capabilities and functionalities , and SF is the latest but , very probably , not the last of those .</sentence>
				<definiendum id="0">SF</definiendum>
				<definiens id="0">the latest but</definiens>
			</definition>
			<definition id="6">
				<sentence>Natural Language Processing for Information Assurance and Security : An Overview and Implementations .</sentence>
				<definiendum id="0">Security</definiendum>
				<definiens id="0">An Overview and Implementations</definiens>
			</definition>
</paper>

		<paper id="3010">
</paper>

		<paper id="3007">
			<definition id="0">
				<sentence>Robustness is a key requirement in spoken language understanding ( SLU ) systems .</sentence>
				<definiendum id="0">Robustness</definiendum>
				<definiens id="0">a key requirement in spoken language understanding ( SLU ) systems</definiens>
			</definition>
			<definition id="1">
				<sentence>Traditionally , most semantic parser systems have been built using hand-crafted semantic grammar rules and so-called robust parsing ( Ward and Issar , 1996 ; Seneff , 1992 ; Dowding et al. , 1994 ) is used to handle the ill-formed user input in which word patterns corresponding to semantic tokens are used to fill slots in different semantic frames in parallel .</sentence>
				<definiendum id="0">semantic parser systems</definiendum>
				<definiens id="0">used to handle the ill-formed user input in which word patterns corresponding to semantic tokens are used to fill slots in different semantic frames in parallel</definiens>
			</definition>
			<definition id="2">
				<sentence>For the latter , the SLU system should be readily adaptable to a different application using a relatively small set ( e.g. less than 100 ) of adaptation utterances .</sentence>
				<definiendum id="0">SLU system</definiendum>
				<definiens id="0">a different application using a relatively small set ( e.g. less than 100 ) of adaptation utterances</definiens>
			</definition>
			<definition id="3">
				<sentence>Spoken language understanding ( SLU ) aims to interpret the meanings of users’ utterances and respond reasonably to what users have said .</sentence>
				<definiendum id="0">Spoken language understanding</definiendum>
				<definiendum id="1">SLU )</definiendum>
				<definiens id="0">aims to interpret the meanings of users’ utterances and respond reasonably to what users have said</definiens>
			</definition>
			<definition id="4">
				<sentence>^C ; ^W argmax C ; W2LN P ( AjW ) P ( W ) P ( CjW ) argmax C ; W2LN P ( AjW ) P ( W ) P ( CjW ) ( 4 ) where P ( AjW ) is the acoustic probability from the first pass , P ( W ) is the language modelling likelihood , P ( CjW ) is the semantic parse score , LN denotes the Nbest list , is a semantic parse scale factor , and is a grammar scale factor .</sentence>
				<definiendum id="0">P ( AjW )</definiendum>
				<definiendum id="1">P ( CjW</definiendum>
				<definiendum id="2">LN</definiendum>
				<definiens id="0">the acoustic probability from the first pass</definiens>
				<definiens id="1">the language modelling likelihood</definiens>
				<definiens id="2">the semantic parse score</definiens>
				<definiens id="3">a semantic parse scale factor , and is a grammar scale factor</definiens>
			</definition>
			<definition id="5">
				<sentence>The Hidden Vector State ( HVS ) model ( He and Young , 2003b ) is a hierarchical semantic parser which associates each state of a push-down automata with the state of a HMM .</sentence>
				<definiendum id="0">Hidden Vector State ( HVS ) model</definiendum>
				<definiens id="0">a hierarchical semantic parser which associates each state of a push-down automata with the state of a HMM</definiens>
			</definition>
			<definition id="6">
				<sentence>Given a word sequence W , concept vector sequence C and a sequence of stack pop operations N , the joint probability of P ( W ; C ; N ) can be decomposed as P ( W ; C ; N ) = TY t=1 P ( ntjct 1 ) P ( ct [ 1 ] jct [ 2 Dt ] ) P ( wtjct ) ( 5 ) where ct at word position t is a vector of Dt semantic concept labels ( tags ) , nt is the vector stack shift operation and takes values in the range 0 ; ; Dt 1 where Dt 1 is the stack size at word position t 1 , and ct [ 1 ] = cwt is the new preterminal semantic tag assigned to word wt at word position t. Thus , the HVS model consists of three types of probabilistic move : The dialog act decoder was implemented using the Tree-Augmented Naive Bayes ( TAN ) algorithm ( Friedman et al. , 1997 ) , which is an extension of Naive Bayes Networks .</sentence>
				<definiendum id="0">Dt 1</definiendum>
				<definiens id="0">the joint probability of P ( W ; C ; N ) can be decomposed as P ( W ; C ; N ) = TY t=1 P ( ntjct 1 ) P ( ct [ 1 ] jct [ 2 Dt ] ) P ( wtjct ) ( 5 ) where ct at word position t is a vector of Dt semantic concept labels ( tags ) , nt is the vector stack shift operation and takes values in the range 0 ;</definiens>
				<definiens id="1">the stack size at word position t 1</definiens>
			</definition>
			<definition id="7">
				<sentence>TAN networks relax this independence assumption by adding dependencies between concepts based on the conditional mutual information ( CMI ) between concepts given the goal .</sentence>
				<definiendum id="0">TAN networks</definiendum>
				<definiens id="0">relax this independence assumption by adding dependencies between concepts based on the conditional mutual information ( CMI ) between concepts given the goal</definiens>
			</definition>
			<definition id="8">
				<sentence>As mentioned in section 2 , the SLU system consists of three main components , a standard HTK-based HMM recognizer , the HVS semantic parser , and the TAN dialogue act ( DA ) decoder .</sentence>
				<definiendum id="0">SLU system</definiendum>
			</definition>
			<definition id="9">
				<sentence>The WER increases by 3.1 times relative to clean but the query answer error rate increases by only test set .</sentence>
				<definiendum id="0">WER</definiendum>
				<definiens id="0">increases by 3.1 times relative to clean but the query answer error rate increases by only test set</definiens>
			</definition>
			<definition id="10">
				<sentence>Assume a parser model P ( W ; C ) for a word sequence W and semantic concept sequence C exists with J component distributions Pj each of dimension K , then given some adaptation data Wl , the MAP estimate of the kth component of Pj , ^Pj ( k ) , is ^Pj ( k ) = j j + ~Pj ( k ) + j + Pj ( k ) ( 7 ) where j = PKk=1 j ( k ) in which j ( k ) is defined as the total count of the events associated with the kth component of Pj summed across the decoding of all adaptation utterances Wl , is the prior weighting parameter , Pj ( k ) is the probability of the original unadapted model , and ~Pj ( k ) is the empirical distribution of the adaptation data , which is defined as ~Pj ( k ) = j ( k ) PK i=1 j ( i ) ( 8 ) As discussed in section 2 , the HVS model consists of three types of probabilistic move .</sentence>
				<definiendum id="0">Assume a parser model P</definiendum>
				<definiendum id="1">, Pj ( k )</definiendum>
				<definiendum id="2">~Pj ( k )</definiendum>
				<definiens id="0">( W ; C ) for a word sequence W and semantic concept sequence C exists with J component distributions Pj each of dimension K , then given some adaptation data Wl , the MAP estimate of the kth component of Pj , ^Pj ( k ) , is ^Pj ( k ) = j j + ~Pj ( k ) + j + Pj ( k ) ( 7 ) where j = PKk=1 j ( k ) in which j ( k ) is defined as the total count of the events associated with the kth component of Pj summed across the decoding of all adaptation utterances Wl , is the prior weighting parameter</definiens>
				<definiens id="1">the probability of the original unadapted model , and</definiens>
			</definition>
			<definition id="11">
				<sentence>Following the notation introduced in section 4.1 , where Pj ( k ) is the probability of the original unadapted model , and ~Pj ( k ) is the empirical distribution of the adaptation obtained using MAP adaptation or log-linear interpolation .</sentence>
				<definiendum id="0">Pj ( k )</definiendum>
				<definiendum id="1">~Pj ( k )</definiendum>
				<definiens id="0">the probability of the original unadapted model</definiens>
			</definition>
</paper>

		<paper id="1308">
			<definition id="0">
				<sentence>MOSAIC is a computational model that analyses the distributional characteristics present in the input .</sentence>
				<definiendum id="0">MOSAIC</definiendum>
				<definiens id="0">a computational model that analyses the distributional characteristics present in the input</definiens>
			</definition>
			<definition id="1">
				<sentence>The node creation probability ( NCP ) is computed as follows : NCP = ( N / M ) L where M is a parameter arbitrarily set to 70,000 in the English and Spanish simulations , N = number of nodes in the net ( N  M ) , and L = length of the phrase being encoded .</sentence>
				<definiendum id="0">node creation probability</definiendum>
				<definiendum id="1">NCP</definiendum>
				<definiendum id="2">M</definiendum>
				<definiens id="0">a parameter arbitrarily set to 70,000 in the English and Spanish simulations</definiens>
				<definiens id="1">= length of the phrase being encoded</definiens>
			</definition>
			<definition id="2">
				<sentence>The production of actual utterances ( as opposed to abstract output ) by the model makes it possible to analyse the output with respect to several ( seemingly ) unrelated phenomena , so that the nontrivial predictions of the learning mechanisms can be assessed .</sentence>
				<definiendum id="0">actual utterances</definiendum>
				<definiens id="0">opposed to abstract output</definiens>
			</definition>
</paper>

		<paper id="0806">
			<definition id="0">
				<sentence>MiniCors is a semantically tagged corpus according to the Senseval lexical sample setting , labeled with the MiniDir-2.1 sense repository .</sentence>
				<definiendum id="0">MiniCors</definiendum>
				<definiens id="0">a semantically tagged corpus according to the Senseval lexical sample setting , labeled with the MiniDir-2.1 sense repository</definiens>
			</definition>
			<definition id="1">
				<sentence>The annotation process has been assisted by a graphical Perl-Tk interface specifically designed for this task , and a 2We have used corpora from newspapers , El Peri´odico ( 3.5 million words ) , La Vanguardia ( 12.5 million words ) , and the Lexesp corpus ( Sebasti´an et al. , 2000 ) , a balanced corpus of Association for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems word .</sentence>
				<definiendum id="0">Lexesp corpus</definiendum>
				<definiens id="0">a balanced corpus of Association for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems word</definiens>
			</definition>
			<definition id="2">
				<sentence>Interestingly , IRST is the best system addressing the words with less examples per sense , suggesting that SVM is a good learning algorithm for training on small datasets , but loses this advantage for the words with more ble 3 shows a non-regular behavior with abnormal low results on some groups of words .</sentence>
				<definiendum id="0">IRST</definiendum>
				<definiens id="0">the best system addressing the words with less examples per sense , suggesting that SVM is a good learning algorithm for training on small datasets</definiens>
			</definition>
			<definition id="3">
				<sentence>Authors want to thank the linguists of CLiC and UNED who collaborated in the annotation task .</sentence>
				<definiendum id="0">Authors</definiendum>
				<definiens id="0">want to thank the linguists of CLiC and UNED who collaborated in the annotation task</definiens>
			</definition>
</paper>

		<paper id="3221">
			<definition id="0">
				<sentence>Pattern Web BNC `` the * of the * '' 23,100,000 208,155 `` the * of the * is '' 10,900,000 3,627 `` the * of the car is '' 26,400 5 Attribute `` the * of the hat is '' 2,770 1 `` the fast * is '' 38,100 3 `` an electronic * is '' 120,000 5 `` the * car is '' 84,500 24 Value `` the * hat is '' 17,100 1 Table 1 : Comparison of frequencies of some patterns in BNC and the Web .</sentence>
				<definiendum id="0">electronic *</definiendum>
			</definition>
			<definition id="1">
				<sentence>CLUTO is a general-purpose clustering tool that implements three different clustering algorithms : partitional , agglomerative , and graph partitioning algorithms .</sentence>
				<definiendum id="0">CLUTO</definiendum>
				<definiens id="0">a general-purpose clustering tool that implements three different clustering algorithms : partitional , agglomerative , and graph partitioning algorithms</definiens>
			</definition>
			<definition id="2">
				<sentence>The t test formula we used for attributes is shown below : 2 ji 2 jiji j , i N ) attribute , concept ( C N ) attribute ( C ) concept ( C N ) attribute , concept ( C t ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ × − ≈ ( 1 ) where N is the total number of relations , and C is a count function .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the total number of relations , and</definiens>
			</definition>
			<definition id="3">
				<sentence>The Qualia Structure of the Generative Lexicon ( Pustejovsky , 1991 ) is another attempt at identifying `` the essential attributes of an object as defined by the lexical item '' .</sentence>
				<definiendum id="0">Qualia Structure of the Generative Lexicon</definiendum>
				<definiens id="0">another attempt at identifying `` the essential attributes of an object as defined by the lexical item ''</definiens>
			</definition>
			<definition id="4">
				<sentence>Pustejovsky identifies four roles : Constitutive Role ( Guarino 's parts ) , Formal Role ( Guarino 's qualities ) , Agentive Role ( Guarino 's relational roles ) , and Telic Role ( not included in Guarino 's classification ) .</sentence>
				<definiendum id="0">Telic Role</definiendum>
				<definiens id="0">identifies four roles : Constitutive Role ( Guarino 's parts ) , Formal Role ( Guarino 's qualities ) , Agentive Role ( Guarino 's relational roles ) , and</definiens>
			</definition>
</paper>

		<paper id="1801">
			<definition id="0">
				<sentence>For example , the Unified Medical Language System ( UMLS ) ( National Library of Medicine , 2004 ) makes a clear separation between a Semantic Network and a Lexicon .</sentence>
				<definiendum id="0">Unified Medical Language System</definiendum>
				<definiens id="0">makes a clear separation between a Semantic Network and a Lexicon</definiens>
			</definition>
</paper>

		<paper id="3013">
			<definition id="0">
				<sentence>3 GISTER GISTER is a system that infers the most likely topics under discussion in a conversation stream by using a commonsense semantic network called OMCSNet .</sentence>
				<definiendum id="0">GISTER GISTER</definiendum>
				<definiens id="0">a system that infers the most likely topics under discussion in a conversation stream by using a commonsense semantic network called OMCSNet</definiens>
			</definition>
			<definition id="1">
				<sentence>Semantic relations currently in OMCSNet Prior research in text summarization has recognized the need for general world knowledge—in SUMMARIST ( 1997 ) , Hovy &amp; Lin describe how the words “gun” , “mask” , “money” , “caught” , and “stole” together would indicate the topic of “robbery” , but they note that that WordNet and other dictionary-like resources did not contain enough such knowledge .</sentence>
				<definiendum id="0">“stole”</definiendum>
				<definiens id="0">the need for general world knowledge—in SUMMARIST ( 1997 ) , Hovy &amp; Lin describe how the words “gun” , “mask” , “money” , “caught” , and</definiens>
			</definition>
			<definition id="2">
				<sentence>The probability of a specific gist can be modeled as proportional to the gist’s links to the selected words : 1 ( ) i i G i i i k Pgk k GistScore k = = = ∑ where is the number of links between a gist , ik ig , and the observed transcript , and G is the number of potential gists ( approximately 700 ) .</sentence>
				<definiendum id="0">G</definiendum>
				<definiens id="0">the number of potential gists ( approximately 700 )</definiens>
			</definition>
			<definition id="3">
				<sentence>LifeNet was built as a probabilistic graphical model because stochastic methods can be more tolerant than traditional logical reasoning methods to the uncertainty in our knowledge of the situation , as well as to the uncertainty in the reliability of the rules themselves .</sentence>
				<definiendum id="0">LifeNet</definiendum>
				<definiens id="0">a probabilistic graphical model because stochastic methods</definiens>
			</definition>
			<definition id="4">
				<sentence>We use the following belief updating rules , as described in ( Yedidia et al. , 2000 ) : ( ) \ ( ) ( , ) ( ) ( ) iji iji j ii kii xkN i mx xx x m xαψ ψ ∈ ← ∑ ∏ j ( 1 ) 4.1 LifeNet LifeNet is a probabilistic graphical model that captures a first-person model of human experience .</sentence>
				<definiendum id="0">LifeNet LifeNet</definiendum>
				<definiens id="0">a probabilistic graphical model that captures a first-person model of human experience</definiens>
			</definition>
			<definition id="5">
				<sentence>We extended GISTER to infer the average tense of the text within the observation by detecting verb tenses , auxiliary verbs like did and will , and also specific temporal expressions like yesterday and tomorrow .</sentence>
				<definiendum id="0">GISTER</definiendum>
				<definiens id="0">to infer the average tense of the text within the observation by detecting verb tenses , auxiliary verbs like did and will , and also specific temporal expressions like yesterday and tomorrow</definiens>
			</definition>
</paper>

		<paper id="1313">
			<definition id="0">
				<sentence>In the most general case , the input of the algorithm is an utterance of length l , that is a sequence of l phonemes u : = s1 : : : sl ( where si denotes the i-th phoneme of u ) .</sentence>
				<definiendum id="0">si</definiendum>
				<definiens id="0">an utterance of length l</definiens>
				<definiens id="1">the i-th phoneme of u )</definiens>
			</definition>
			<definition id="1">
				<sentence>The word precision is the probability for a word isolated by the segmentation procedure to be present in the reference segmentation , and the word recall is the probability for a word occurring in the true segmentation to be correctly isolated .</sentence>
				<definiendum id="0">word precision</definiendum>
				<definiendum id="1">word recall</definiendum>
				<definiens id="0">the probability for a word isolated by the segmentation procedure to be present in the reference segmentation</definiens>
			</definition>
			<definition id="2">
				<sentence>Similarly , the segmentation precision is the probability that an inferred boundary actually occurs in the true segmentation , and the segmentation recall is the probability for a true boundary to be detected .</sentence>
				<definiendum id="0">segmentation precision</definiendum>
				<definiendum id="1">segmentation recall</definiendum>
				<definiens id="0">the probability that an inferred boundary actually occurs in the true segmentation</definiens>
				<definiens id="1">the probability for a true boundary to be detected</definiens>
			</definition>
			<definition id="3">
				<sentence>Let U S be the set of possible utterances in the language under examination .</sentence>
				<definiendum id="0">U S</definiendum>
				<definiens id="0">the set of possible utterances in the language under examination</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , using maximumlikelihood estimates , we may de ne the typical2Note that in general , P ~w2Sn n ( ~wjF ) =P ~w2Sn n ( ~wjI ) = ~T , where ~T T is the number of utterances in C that have a length greater than or equal to n. 95 ity of w in utterancenal position as : t ( wjF ) : = f ( wjF ) f ( w ) ( 1 ) This measure is higher than 1 i w is more likely to occur in utterancenal position ( than in any position ) , lower i it is less likely to occur there , and equal to 1 i its probability is independent of its position .</sentence>
				<definiendum id="0">P ~w2Sn n</definiendum>
				<definiendum id="1">~T T</definiendum>
				<definiens id="0">the number of utterances</definiens>
			</definition>
			<definition id="5">
				<sentence>Regarding the decision variable , if we were dealing with an utterance u of in nite length , we could simply set the order r 1 of the typicality computation and de ne d ( u ; i ) as t ( si ( r 1 ) : : : sijF ) ( where si denotes the ith phoneme of u ) .</sentence>
				<definiendum id="0">si</definiendum>
				<definiens id="0">the ith phoneme of u )</definiens>
			</definition>
			<definition id="6">
				<sentence>The diversity of transitions following an ngram w 2 Sn is evaluated by the successor count ( or successor variety ) , simply de ned as the number of di erent phonemes that can occur after it : succ ( w ) : = jfs 2 Sjn ( ws ) &gt; 0gj ( 3 ) Transposing the indications of Harris in the terms of section 2.1 , for an utterance u : = s1 : : : sl , we de ne D ( u ; i ) as succ ( w ) where w : = s1 : : : si , and T ( u ; i ) as max [ D ( u ; i 1 ) ; D ( u ; i + 1 ) ] .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">succ ( w ) where w : = s1 : : : si , and</definiens>
			</definition>
</paper>

		<paper id="1712">
</paper>

		<paper id="0604">
			<definition id="0">
				<sentence>Machine-readable structured linguistic documents ( comparative word lists , lexicons , annotated texts , audio and audio-video recordings aligned with transcriptions ( possibly annotated ) , grammatical descriptions , etc. ) are being made available in a wide variety of formats on the Web .</sentence>
				<definiendum id="0">Machine-readable structured linguistic documents</definiendum>
				<definiens id="0">comparative word lists , lexicons , annotated texts , audio and audio-video recordings aligned with transcriptions ( possibly annotated ) , grammatical descriptions , etc. ) are being made available in a wide variety of formats on the Web</definiens>
			</definition>
			<definition id="1">
				<sentence>We devise metaschemas for lexicons that use distinct XML markup schemas : one of the lexicons that Simons ( 2003 ) originally used , for Sikaiana ( Solomon Islands ) with about 3000 entries ; a Hopi ( Arizona ) dictionary with about 30,000 entries , for which Kenneth Hill’s original encoding using a proprietary and no longer supported database program was converted to XML by Lewis and Gonzalez ; and a Potawatomi ( Great Lakes region , US and Canada ) lexicon being created by Laura BuszardWelcher using the EMELD FIELD tool .</sentence>
				<definiendum id="0">Hopi</definiendum>
				<definiens id="0">for which Kenneth Hill’s original encoding using a proprietary and no longer supported database program was converted to XML by Lewis and Gonzalez ; and a Potawatomi ( Great Lakes region</definiens>
			</definition>
			<definition id="2">
				<sentence>First is the knowledge brought in from the document interpretation process itself , i.e. by the linguist , not necessarily the one who performed the original analysis .</sentence>
				<definiendum id="0">First</definiendum>
				<definiens id="0">the knowledge brought in from the document interpretation process itself</definiens>
			</definition>
			<definition id="3">
				<sentence>Linguistic data content includes linguistic expressions , the physical manifestations of language , also known as ‘morphs’ , or simply ‘forms’ , which may be written , spoken or signed .</sentence>
				<definiendum id="0">Linguistic data content</definiendum>
				<definiens id="0">includes linguistic expressions , the physical manifestations of language , also known as ‘morphs’ , or simply ‘forms’ , which may be written , spoken or signed</definiens>
			</definition>
			<definition id="4">
				<sentence>The abstract units are the main objects of interest in formal linguistics .</sentence>
				<definiendum id="0">abstract units</definiendum>
				<definiens id="0">the main objects of interest in formal linguistics</definiens>
			</definition>
			<definition id="5">
				<sentence>A FEATURESPECIFICATION is a data structure that contains a subclass and an instance of MORPHOSYNTACTICATTRIBUTE ( i.e. an ordered pair ) , for example , [ TENSE : PASTTENSE ] .</sentence>
				<definiendum id="0">FEATURESPECIFICATION</definiendum>
				<definiens id="0">a data structure that contains a subclass and an instance of MORPHOSYNTACTICATTRIBUTE ( i.e. an ordered pair</definiens>
			</definition>
			<definition id="6">
				<sentence>The Semantic Interpretation Language ( SIL ) was originally created to define the meaning of the elements and attributes declared in an XML markup schema , as well as the relationships between them .</sentence>
				<definiendum id="0">Semantic Interpretation Language</definiendum>
				<definiens id="0">SIL ) was originally created to define the meaning of the elements and attributes declared in an XML markup schema</definiens>
			</definition>
			<definition id="7">
				<sentence>An SIL metaschema is an XML document that formally maps the elements and attributes of an XML encoded resource to concepts in an OWL ontology or an RDF Schema .</sentence>
				<definiendum id="0">SIL metaschema</definiendum>
				<definiens id="0">an XML document that formally maps the elements and attributes of an XML encoded resource to concepts in an OWL ontology or an RDF Schema</definiens>
			</definition>
			<definition id="8">
				<sentence>An SIL metaschema , as described in detail in Simons ( 2004 ) , is an XML document built from metaschema directives , which are essentially processing instructions expressed as XML elements .</sentence>
				<definiendum id="0">SIL metaschema</definiendum>
			</definition>
			<definition id="9">
				<sentence>Input document : &lt; form &gt; ahali &lt; /form &gt; Metaschema directive : &lt; interpret markup= '' form '' &gt; &lt; property concept = `` gold : form '' &gt; &lt; resource concept = `` gold : LinguisticForm '' &gt; &lt; literal concept = `` gold : orthographicRepre sentation '' / &gt; &lt; /resource &gt; &lt; /property &gt; &lt; /interpret &gt; Interpretation ( output ) : &lt; gold : form &gt; &lt; gold : LinguisticForm &gt; &lt; gold : orthographicRepresen tation &gt; ahali &lt; /gold : orthographicRepresen tation &gt; &lt; /gold : LinguisticForm &gt; &lt; /gold : form &gt; Figure 3 .</sentence>
				<definiendum id="0">Interpretation</definiendum>
				<definiens id="0">orthographicRepre sentation '' / &gt; &lt; /resource &gt; &lt; /property &gt; &lt; /interpret &gt;</definiens>
			</definition>
			<definition id="10">
				<sentence>Indirect search goes beyond direct search by making use of inferences based on the structuring of the concepts in an ontology .</sentence>
				<definiendum id="0">Indirect search</definiendum>
				<definiens id="0">goes beyond direct search by making use of inferences based on the structuring of the concepts in an ontology</definiens>
			</definition>
</paper>

		<paper id="0403">
			<definition id="0">
				<sentence>The task of the current study is defined by the ongoing development of the Russian Reference Corpus ( Sharoff , 2004 ) , a general-purpose corpus of Russian that is comparable to the British National Corpus ( BNC ) in its size and coverage .</sentence>
				<definiendum id="0">Russian Reference Corpus</definiendum>
				<definiens id="0">a general-purpose corpus of Russian that is comparable to the British National Corpus ( BNC ) in its size and coverage</definiens>
			</definition>
			<definition id="1">
				<sentence>Information on the frequency of prepositions ( Table 2 ) is taken from the pilot version of the Russian Reference Corpus , which currently consists of about 55 million words ( Table 2 lists the relative frequency of prepositions in terms of the number of their instances per million words , ipm ) .</sentence>
				<definiendum id="0">Reference Corpus</definiendum>
				<definiens id="0">the relative frequency of prepositions in terms of the number of their instances per million words</definiens>
			</definition>
			<definition id="2">
				<sentence>Other prepositions that are less frequent regularly produce non-compositional patterns , e.g. pod rukami ( ‘at hand’ , which expresses the specific meaning of availability , not literally ‘under hands’ ) , pod konec ( ‘at the end’ ) .</sentence>
				<definiendum id="0">‘at hand’</definiendum>
				<definiens id="0">expresses the specific meaning of availability , not literally ‘under hands’ )</definiens>
			</definition>
			<definition id="3">
				<sentence>Even in cases when the hypothesis does not hold , as in the case of the reflexive MWE drug druga , which can be translated in many different ways depending on the main predicate in a clause , the combination of the two words in an MWE saves from the possibility of their separate translation as companion , friend , mate , pal , comrade , colleague , fellow , etc .</sentence>
				<definiendum id="0">MWE drug druga</definiendum>
			</definition>
			<definition id="4">
				<sentence>DEFI , a tool for automatic multi-word unit recognition , meaning assignment and translation selection .</sentence>
				<definiendum id="0">DEFI</definiendum>
				<definiens id="0">a tool for automatic multi-word unit recognition , meaning assignment and translation selection</definiens>
			</definition>
			<definition id="5">
				<sentence>Multiword expressions : A pain in the neck for NLP .</sentence>
				<definiendum id="0">Multiword expressions</definiendum>
				<definiens id="0">A pain in the neck for NLP</definiens>
			</definition>
</paper>

		<paper id="1212">
			<definition id="0">
				<sentence>The PubMed search tool allows a user to specify desired search fields , of which Raychaudhuri et al. used title ( TI ) , Major MeSH Heading ( MAJR ) , MeSH Heading ( MH ) and date of publication ( DP ) .</sentence>
				<definiendum id="0">PubMed search tool</definiendum>
				<definiendum id="1">MeSH Heading ( MH</definiendum>
				<definiens id="0">allows a user to specify desired search fields , of which Raychaudhuri et al. used title ( TI )</definiens>
			</definition>
			<definition id="1">
				<sentence>BMC , like PubMed Central , contains full text from many journals as well as having many of its own online journals .</sentence>
				<definiendum id="0">BMC</definiendum>
				<definiens id="0">contains full text from many journals as well as having many of its own online journals</definiens>
			</definition>
</paper>

		<paper id="2007">
			<definition id="0">
				<sentence>The UNL project ( Universal Networking Language ) proposes a standard for encoding the meaning of natural language utterances as semantic hypergraphs , intended to be used as pivot in multilingual information and communication systems .</sentence>
				<definiendum id="0">UNL project</definiendum>
				<definiens id="0">Universal Networking Language ) proposes a standard for encoding the meaning of natural language utterances as semantic hypergraphs , intended to be used as pivot in multilingual information and communication systems</definiens>
			</definition>
			<definition id="1">
				<sentence>UNL is a project of multilingual personal networking communication initiated by the University of United Nations based in Tokyo .</sentence>
				<definiendum id="0">UNL</definiendum>
				<definiens id="0">a project of multilingual personal networking communication initiated by the University of United Nations based in Tokyo</definiens>
			</definition>
			<definition id="2">
				<sentence>The representation of an utterance in the UNL interlingua is a hypergraph where nodes bear universal words ( interlingual acceptions ) with semantic attributes and arcs denote semantic relations .</sentence>
				<definiendum id="0">representation of an utterance</definiendum>
				<definiendum id="1">UNL interlingua</definiendum>
				<definiens id="0">a hypergraph where nodes bear universal words ( interlingual acceptions ) with semantic attributes and arcs denote semantic relations</definiens>
			</definition>
			<definition id="3">
				<sentence>Language ( UNL ) UNL is an artificial language that describes semantic networks .</sentence>
				<definiendum id="0">Language ( UNL ) UNL</definiendum>
				<definiens id="0">an artificial language that describes semantic networks</definiens>
			</definition>
			<definition id="4">
				<sentence>@ def session ( icl &gt; meeting ) this general ( mod &lt; thing ) mod mod mod mod objman timagt mod qua mod Figure 3 : UNL Hypergraph. UNL hypergraphs must contain one special node , called the entry of the graph ( usually the finite verb ) . This information is encoded with the label entry in the list of UNL relations representing the corresponding hypergraph. XIP ( Ait-Mokhtar et al. , 2002 ; Hagege and Roux , 2002 ) is a rule-based platform for building robust incremental parsers. It is developped at the Xerox Research Centre Europe ( XRCE ) and shares the same computationnal paradigm as the PNLPL approach ( Jensen , 1992 ) and the FDGP approach ( Tapanainen and Jarvinen , 1997 ) . At present , various grammars for XIP have been built for English and French. The diﬀerent phases of linguistic processing are organized incrementally : syntactic analysis is done by first chunking ( Abney , 1991 ) a morphosyntactic annotated input text and then extracting functionnal dependencies ( links between the words ) . The aim of the system is to produce a list of syntactic dependencies which may be later used in applications such as information retrieval , semantic disambiguation , coreference resolution , etc. A XIP parser , like the French parser ( that we will call XIPF hereafter ) , is composed of diﬀerent modules that transform and process incrementally the linguistic information given as input. XIPF contains three main modules : one for morphological disambiguation ( disambiguation of POS tags depending on contextual information ) , another one for chunking ( marking structural groups ) and a last one for dependency calculus ( identifying links between words ) . Each module may have a number of grammars which are applied one after the other depending on the linguistic complexity of the phenomena present. For example , for French , the identification of verbal phrases comes after the identification of nominal phrases. The different rules in the grammars also apply incrementally. They are organized in levels so that they apply sequentially to enrich stepwise the linguistic analysis. This strategy favors linguistic precision over recall. Within the XIP formalism , information is represented by means of syntactic trees with terminal nodes or sequences of constituant nodes ( such as nominal phrases ( NPs ) , finite verbal phrases ( FVs ) , etc. ) . The maximal node for each tree ( sentence ) is a virtual node called GROUPE. All nodes , lexical ( membre ) ornot ( NP ) , have a list of features associated with them and describing precise features : typographical ( capital letter [ maj : + ] ) , lexical ( proper noun [ proper : + ] ) , morphological ( number [ plu : + ] ) , syntactic ( subcategorization with the preposition “a” [ sfa : + ] ) or semantic ( time [ tim : + ] ) . Since the complete linguistic information of anodeisalwayspresent , evenifitisnotdisplayed in the output , it is simple to manipulate at any time during the analysis. Therefore , the possibility of taking into account diﬀerent kinds of features at any step of the analysis is a considerable advantage when building a semantic application ( the enconversion into UNL expressions ) . Indeed , semantic information can be enriched by adding new particular features when necessary ( a feature title has been added to be applied in titles ) . The final result of the parser ( a list of syntactic dependencies ) is obtained from the linguistic processing done by the diﬀerent modules. Figure 4 shows the XIPF analysis for the French sentence given as example in section 2.3. SUBJ NOUN ( ratifi´e , Etats ) VARG NOUN DIR ( ratifi´e , projet ) VMOD LEFT NOUN INDIR ( ratifi´e , Lors de , session ) VMOD POSIT1 ADV ( ratifi´e , `a , l’unanimit´e ) NMOD POSIT1 RIGHT ADJ ( Conf´erence , g´en´erale ) NMOD POSIT1 LEFT ADJ NOUN ( session,29e ) NMOD POSIT1 NOUN ( session , de , Conf´erence ) NMOD POSIT1 NOUN ( Conf´erence , de , Unesco ) NN ( Etats , membres ) DETERM DEF NOUN DET ( la , session ) DETERM DEF NOUN DET ( la , Conf´erence ) DETERM DEF NOUN DET ( l’ , Unesco ) DETERM DEF NOUN DET ( les , Etats ) DETERM DEM NOUN DET ( ce , projet ) DETERM NUM NOUN ( 186 , Etats ) AUXIL ( ratifi´e , ont ) 0 &gt; GROUPE { SC { PP { Lors de NP { la AP { 29e } session } } PP { de NP { la Conf´erence } } AP { g´en´erale } PP { de NP { l’ Unesco } } , NP { les 186 Etats } NP { membres } FV { ont ratifi´e } } `a l’unanimit´eNP { ce projet } . }</sentence>
				<definiendum id="0">UNL Hypergraph. UNL hypergraphs</definiendum>
				<definiens id="0">must contain one special node , called the entry of the graph ( usually the finite verb ) . This information is encoded with the label entry in the</definiens>
				<definiens id="1">a rule-based platform for building robust incremental parsers. It is developped at the Xerox Research Centre Europe ( XRCE</definiens>
				<definiens id="2">a morphosyntactic annotated input text and then extracting functionnal dependencies ( links between the words ) . The aim of the system is to produce a list of syntactic dependencies which may be later used in applications such as information retrieval , semantic disambiguation , coreference resolution , etc. A XIP parser</definiens>
				<definiens id="3">one for morphological disambiguation ( disambiguation of POS tags depending on contextual information</definiens>
				<definiens id="4">the identification of verbal phrases comes after the identification of nominal phrases. The different rules in the grammars also apply incrementally. They are organized in levels so that they apply sequentially to enrich stepwise the linguistic</definiens>
				<definiens id="5">a virtual node called GROUPE. All nodes , lexical ( membre</definiens>
			</definition>
</paper>

		<paper id="2012">
			<definition id="0">
				<sentence>Answer validation is a component of question answering system , which selects reliable answer from answer candidates extracted by certain methods .</sentence>
				<definiendum id="0">Answer validation</definiendum>
				<definiens id="0">a component of question answering system , which selects reliable answer from answer candidates extracted by certain methods</definiens>
			</definition>
			<definition id="1">
				<sentence>FA ( X , Y ) =hits ( X ∪ { Y } ) /hits ( X ) BA ( X , Y ) =hits ( X ∪ { Y } ) /hits ( { Y } ) Note that when X is fixed , FA ( X , Y ) is proportional to hits ( X ∪ { Y } ) .</sentence>
				<definiendum id="0">FA</definiendum>
				<definiens id="0">proportional to hits ( X ∪ { Y } )</definiens>
			</definition>
			<definition id="2">
				<sentence>The set ˆ k of keywords and the choice ˆc to be selected by FA ratio are expressed as below : ˆ k = argmin k∈2 N FA ( k , c FA 2 ( k ) ) FA ( k , c FA 1 ( k ) ) ˆc = c FA 1 ( ˆ k ) c FA 2 ( k ) =arg-secondmax c FA ( k , c ) where arg-secondmax c is defined as a function which selects c with second maximum value .</sentence>
				<definiendum id="0">c FA</definiendum>
				<definiendum id="1">arg-secondmax c</definiendum>
				<definiens id="0">The set ˆ k of keywords and the choice ˆc to be selected by FA ratio are expressed as below : ˆ k = argmin k∈2 N FA ( k , c FA 2 ( k ) ) FA ( k , c FA 1 ( k ) ) ˆc = c FA 1 ( ˆ k ) c FA 2 ( k ) =arg-secondmax</definiens>
				<definiens id="1">a function which selects c with second maximum value</definiens>
			</definition>
			<definition id="3">
				<sentence>FA 1 ( k ) =c BA 1 ( k ) thenc FA 1 ( k ) FA ( k , c BA 1 ( k ) ) FA ( k , c FA 1 ( k ) ) ≥ 0.8thenc BA 1 ( k ) FA ( k , c BA 1 ( k ) ) FA ( k , c FA 1 ( k ) ) ≤ 0.2thenc FA 1 ( k ) BA ( k , c FA 1 ( k ) ) BA ( k , c BA 1 ( k ) ) ≥ 0.53 then c FA 1 ( k ) BA 1 ( k ) FA ( k , c BA 1 ( k ) ) FA ( k , c FA 1 ( k ) ) ≥ 0.6thenc BA 1 ( k ) FA 1 ( k ) Table 7 shows the results of evaluating precision of answer selection methods against the development set , when the keywords are selected based on word weights in Section 3.1 .</sentence>
				<definiendum id="0">k ) BA</definiendum>
			</definition>
			<definition id="4">
				<sentence>In the development set 4 , there are 541 questions ( about 60 % ) where 4 Four questions are excluded because hits of the conjunct query hits ( X ∪ { Y } ) were0 Table 7 : Precision of Answer Selection ( with keyword selection by word weights ) method precision max FA 70.8 % max BA 67.6 % selection rule 77.3 % Table 8 : Evaluation of Each Answer Selection Rule ( with keyword selection by word weights ) rule answer precision 1 c FA 1 ( k ) =c BA 1 ( k ) 88.5 % ( 479/541 ) 2 ∼ 6 60.3 % ( 207/343 ) total 77.6 % ( 686/884 ) 2 c BA 1 ( k ) 65.3 % ( 32/49 ) 3 c FA 1 ( k ) 61.8 % ( 68/110 ) 4 c FA 1 ( k ) 53.6 % ( 37/69 ) 5 c BA 1 ( k ) 60.3 % ( 35/58 ) 6 c BA 1 ( k ) 66.7 % ( 12/18 ) 7 c FA 1 ( k ) 59.0 % ( 23/39 ) c FA 1 ( k ) andc BA 1 ( k ) are identical , and the 88.5 % of the selected choices are correct .</sentence>
				<definiendum id="0">c BA 1</definiendum>
				<definiens id="0">Precision of Answer Selection ( with keyword selection by word weights</definiens>
				<definiens id="1">k ) 59.0 % ( 23/39 ) c FA 1 ( k ) andc BA 1 ( k ) are identical</definiens>
			</definition>
			<definition id="5">
				<sentence>A.�������� ( Atlantis ) B.���� ( Argo ) C.������� ( Santa Maria ) D.������ ( Nautilus ) [ Correct Answer : ������� ] 10,000,000 yen level [ O4 ] F8������ Gqp�C : U s�o  ���Qh Gqxr �� ( In which summer Olympics did the number of participating countries first exceed 100 ? )</sentence>
				<definiendum id="0">A.��������</definiendum>
				<definiens id="0">Santa Maria ) D.������ ( Nautilus ) [ Correct Answer : ������� ] 10,000,000 yen level [ O4 ] F8������ Gqp�C : U s�o  ���Qh Gqxr �� ( In which summer Olympics did the number of participating countries</definiens>
			</definition>
			<definition id="6">
				<sentence>A bunsetsu consists of one content word possibly followed by one or more function words .</sentence>
				<definiendum id="0">bunsetsu</definiendum>
			</definition>
			<definition id="7">
				<sentence>Table 10 : Total Evaluation Results ( precision/coverage ) ( % ) method dev test K.A.R. ( r ≤ 1 ) 75.8/93.2 74.6/93.6 word weights 77.3/100 73.4/100 + answer selection Integration 78.6/100 75.9/100 K.A.R. ( r ≤ 0.25 ) 86.9/60.4 86.0/61.5 word weights ( r &gt; 0.25 ) 65.9/39.6 59.9/38.5 + answer selection K.A.R. : keyword association ratio : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : � : w : � : � : � : � : � : w : � : � : � : � : � : � : w :  : � : � : � : � : � : � : � : � : � : � : � : � : � : w :  : | : � Figure 1 : Precision classified by prize money amount i.e. , keyword association ratio presented in Section 3.2.2 , and word weights of Section 3.1 + answer selection of Section 4 .</sentence>
				<definiendum id="0">Total Evaluation Results</definiendum>
				<definiens id="0">Precision classified by prize money amount i.e. , keyword association ratio presented in Section 3.2.2 , and word weights of Section 3.1 + answer selection of Section 4</definiens>
			</definition>
			<definition id="8">
				<sentence>Magnini et al. ( 2002 ) proposed an answer validation method which uses the number of search engine hits .</sentence>
				<definiendum id="0">answer validation method</definiendum>
				<definiens id="0">uses the number of search engine hits</definiens>
			</definition>
</paper>

		<paper id="0825">
			<definition id="0">
				<sentence>It is defined as : ( ) 2/1 ) ( ˛ -= Ss XsPXG where P ( s/X ) is the likelihood of sense s given the population X. At the first step of the tree building process , the Gini impurity is computed for each possible questions .</sentence>
				<definiendum id="0">P ( s/X )</definiendum>
				<definiens id="0">the likelihood of sense s given the population X. At the first step of the tree building process , the Gini impurity is computed for each possible questions</definiens>
			</definition>
			<definition id="1">
				<sentence>Introduction to WordNet : An online lexical database , International Journal of Lexicography , vol .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An online lexical database</definiens>
			</definition>
</paper>

		<paper id="0800">
</paper>

		<paper id="3206">
			<definition id="0">
				<sentence>Paraphrase recognition is a critical step for natural language interpretation .</sentence>
				<definiendum id="0">Paraphrase recognition</definiendum>
				<definiens id="0">a critical step for natural language interpretation</definiens>
			</definition>
			<definition id="1">
				<sentence>ASE ALGORITHM STEPS : For each pivot ( a lexicon entry ) ( a ) Retrieve an initial sample from the Web ( b ) Identify associated phrases for the pivot ( c ) Extend S using the associated phrases ( a ) Extract slot anchors ( b ) Extract context anchors ( a ) by absolute frequency ( b ) by conditional pivot probability Figure 1 : Outline of the ASE algorithm .</sentence>
				<definiendum id="0">ASE ALGORITHM STEPS</definiendum>
				<definiendum id="1">Retrieve</definiendum>
				<definiens id="0">an initial sample from the Web ( b ) Identify associated phrases for the pivot ( c ) Extend S using the associated phrases ( a ) Extract slot anchors ( b ) Extract context anchors ( a ) by absolute frequency</definiens>
			</definition>
			<definition id="2">
				<sentence>Fi1Here , tf·idf = freqS ( X ) · log parenleftBig N freqW ( X ) parenrightBig where freqS ( X ) is the number of occurrences in S containing X , N is the total number of Web documents , and freqW ( X ) is the number of Web documents containing X. nally , STEP ( 2 .</sentence>
				<definiendum id="0">freqS</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">freqW ( X )</definiendum>
				<definiens id="0">the number of occurrences in S containing X</definiens>
				<definiens id="1">the total number of Web documents</definiens>
				<definiens id="2">the number of Web documents containing X. nally</definiens>
			</definition>
			<definition id="3">
				<sentence>Then , TE generates a set of syntactic templates which are supposed to maintain an entailment relationship with the initial pivot template .</sentence>
				<definiendum id="0">TE</definiendum>
				<definiens id="0">generates a set of syntactic templates which are supposed to maintain an entailment relationship with the initial pivot template</definiens>
			</definition>
			<definition id="4">
				<sentence>All of the sample sentences are then parsed with MINIPAR ( Lin , 1998 ) , which generates from each sentence a syntactic directed acyclic graph ( DAG ) representing the dependency structure of the sentence .</sentence>
				<definiendum id="0">MINIPAR</definiendum>
				<definiens id="0">generates from each sentence a syntactic directed acyclic graph ( DAG ) representing the dependency structure of the sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>templates The core of TE is a General Structure Learning algorithm ( GSL ) that is applied to the set of parse graphs S resulting from the previous step .</sentence>
				<definiendum id="0">GSL</definiendum>
				<definiens id="0">a General Structure Learning algorithm (</definiens>
			</definition>
			<definition id="6">
				<sentence>GSL extracts single-rooted syntactic DAGs , which are named spanning templates since they must span at least over Na slot variables , and should also appear in at least Nr sentences from S ( In our experiments we set Na=2 and Nr=2 ) .</sentence>
				<definiendum id="0">GSL</definiendum>
				<definiens id="0">extracts single-rooted syntactic DAGs , which are named spanning templates since they must span at least over Na slot variables</definiens>
			</definition>
			<definition id="7">
				<sentence>GSL learns maximal most general templates : they are spanning templates which , at the same time , ( a ) can not be generalized by further reduction and ( b ) can not be further extended keeping the same generality level .</sentence>
				<definiendum id="0">GSL</definiendum>
				<definiens id="0">learns maximal most general templates : they are spanning templates which , at the same time</definiens>
			</definition>
			<definition id="8">
				<sentence>We define T ( S ) as the set of all spanning templates in the sample S. DEFINITION : A spanning template t ∈ T ( S ) is maximal most general if and only if both of the following conditions hold : CONDITION A : For∀tprime∈T ( S ) , tprimeprecedesequalt , it holds that σ ( t ) = σ ( tprime ) .</sentence>
				<definiendum id="0">T ( S )</definiendum>
				<definiens id="0">the set of all spanning templates in the sample S. DEFINITION : A spanning template t ∈ T ( S</definiens>
			</definition>
			<definition id="9">
				<sentence>CONDITION B : For∀tprime∈T ( S ) , t≺tprime , it holds that σ ( t ) ⊃σ ( tprime ) .</sentence>
				<definiendum id="0">CONDITION B</definiendum>
				<definiens id="0">For∀tprime∈T ( S ) , t≺tprime , it holds that σ ( t ) ⊃σ ( tprime )</definiens>
			</definition>
			<definition id="10">
				<sentence>A compact graph representation is an aggregate graph which joins all the sentence graphs from S ensuring that all identical spanning sub-structures from different sentences are merged into a single one .</sentence>
				<definiendum id="0">compact graph representation</definiendum>
				<definiens id="0">an aggregate graph which joins all the sentence graphs from S ensuring that all identical spanning sub-structures from different sentences</definiens>
			</definition>
			<definition id="11">
				<sentence>Therefore , each vertex v ( respectively , edge e ) in the aggregate graph is either a copy of a corresponding vertex ( edge ) from a sentence graph Pi or it represents the merging of several identically labeled vertices ( edges ) from different sentences in S. The set of such sentences is defined as the sentence set of v ( e ) , and is represented through the set of index numbers of related sentences ( e.g. “ ( 1,2 ) ” in the third tree of Figure 2 ) .</sentence>
				<definiendum id="0">vertex v</definiendum>
				<definiendum id="1">edge e</definiendum>
				<definiens id="0">either a copy of a corresponding vertex ( edge ) from a sentence graph Pi or it represents the merging of several identically labeled vertices ( edges ) from different sentences in S. The set of such sentences is defined as the sentence set of v ( e ) , and is represented through the set of index numbers of related sentences ( e.g. “ ( 1,2 ) ” in the third tree of Figure 2 )</definiens>
			</definition>
			<definition id="12">
				<sentence>Moreover , TE removes those templates which are very long or which appear with just one anchor set and in less than four sentences .</sentence>
				<definiendum id="0">TE</definiendum>
				<definiens id="0">removes those templates which are very long or which appear with just one anchor set and in less than four sentences</definiens>
			</definition>
			<definition id="13">
				<sentence>P1 : stop subjd122 d122d122 d124d124d122d122d122d122 obj d65d65d65 d32d32d65d65d65d65 P2 : stop subjd122 d122d122 d124d124d122d122d122d122 obj d15d15 byd74 d74d74d74 d37d37d74d74d74d74 G2 : stop ( 1,2 ) subj ( 1,2 ) d114d114 d114d114 d120d120d114d114d114d114 obj ( 1,2 ) d15d15 by ( 2 ) d79d79d79d79 d39d39d79d79d79d79 X Y X Y absorbing X ( 1,2 ) Y ( 1,2 ) absorbing ( 2 ) Figure 2 : Two parse trees and their compact representation ( sentence sets are shown in parentheses ) .</sentence>
				<definiendum id="0">P1</definiendum>
				<definiens id="0">Two parse trees and their compact representation ( sentence sets are shown in parentheses</definiens>
			</definition>
			<definition id="14">
				<sentence>For each verb , we calculate Yield as the absolute number of Correct templates found and Precision as the percentage of good templates out of all extracted templates .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the absolute number of Correct templates found and</definiens>
			</definition>
</paper>

		<paper id="0846">
			<definition id="0">
				<sentence>Word Sense Disambiguation ( WSD ) is one of the central problems in Natural Language Processing .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
				<definiendum id="1">WSD</definiendum>
				<definiens id="0">one of the central problems in Natural Language Processing</definiens>
			</definition>
			<definition id="1">
				<sentence>The WSD task is defined as the hard clustering of multiple contexts of the key word .</sentence>
				<definiendum id="0">WSD task</definiendum>
				<definiens id="0">the hard clustering of multiple contexts of the key word</definiens>
			</definition>
			<definition id="2">
				<sentence>Now the maximum entropy modeling can be formulated as follows : given a pairwise context similarity } { α f , the generative probability of } { α f in Corpus I or Corpus II is given as ( ) { } ∏ ∈ = α α ff f w Z f 1 } { Pr maxEnt ( 4 ) where Z is the normalization factor , f w is the weight associated with feature f .</sentence>
				<definiendum id="0">maximum entropy modeling</definiendum>
				<definiendum id="1">Z</definiendum>
				<definiendum id="2">f w</definiendum>
				<definiens id="0">formulated as follows : given a pairwise context similarity } { α f , the generative probability of } { α f in Corpus I or Corpus II is given as</definiens>
				<definiens id="1">the normalization factor ,</definiens>
			</definition>
			<definition id="3">
				<sentence>The optimization process consists of two steps .</sentence>
				<definiendum id="0">optimization process</definiendum>
			</definition>
</paper>

		<paper id="2305">
</paper>

		<paper id="3217">
			<definition id="0">
				<sentence>StoryStation is an intelligent tutoring system created to provide personalized attention and detailed feedback to children ages 10-12 on their writing ( Roberston and Wiemar-Hastings , 2002 ) .</sentence>
				<definiendum id="0">StoryStation</definiendum>
				<definiens id="0">an intelligent tutoring system created to provide personalized attention</definiens>
			</definition>
			<definition id="1">
				<sentence>The most similar discourse analysis program to the one needed by StoryStation is the essay-grading component of “Criterion” by ETS technologies ( Burstein et al. , 2003 ) , which is designed to annotate parts of an essay according to categories such as “Thesis , “Main Points , ” “Support , ” and “Conclusion.”</sentence>
				<definiendum id="0">StoryStation</definiendum>
				<definiens id="0">the essay-grading component of “Criterion” by ETS technologies ( Burstein et al. , 2003 ) , which is designed to annotate parts of an essay according to categories such as “Thesis , “Main Points</definiens>
			</definition>
			<definition id="2">
				<sentence>Each event consists of an event name , a time variable t , and a set of entities arranged in an ordered set n1 : : : na .</sentence>
				<definiendum id="0">event</definiendum>
			</definition>
			<definition id="3">
				<sentence>The story rewriting task involves the students choosing their own diction and expressing their own unique mastery of language , so variation in how the fundamental elements of the story are rewritten is to be expected .</sentence>
				<definiendum id="0">story rewriting task</definiendum>
				<definiens id="0">involves the students choosing their own diction and expressing their own unique mastery of language , so variation in how the fundamental elements of the story are rewritten is to be expected</definiens>
			</definition>
			<definition id="4">
				<sentence>WordNet ( x ) denotes the synset of x. The “now point” of the rewritten story is t , and feature set is f , which has an index of i. The index i is incremented every time f is assigned a value .</sentence>
				<definiendum id="0">WordNet ( x )</definiendum>
				<definiens id="0">the synset of x. The “now point” of the rewritten story is t</definiens>
			</definition>
			<definition id="5">
				<sentence>K-NN makes no parametric assumptions about the data and uses no formal symbolic features other than an LSA similarity score .</sentence>
				<definiendum id="0">K-NN</definiendum>
				<definiens id="0">makes no parametric assumptions about the data and uses no formal symbolic features other than an LSA similarity score</definiens>
			</definition>
			<definition id="6">
				<sentence>In hybrid modClass Precision Recall F-score 1 ( Excellent ) 0.11 0.17 0.13 2 ( Good ) 0.42 0.46 0.44 3 ( Fair ) 0.30 0.16 0.21 4 ( Poor ) 0.83 0.76 0.79 Table 2 : K-Nearest Neighbors Precision and Recall Class 1 2 3 4 1 ( Excellent ) 3 10 4 1 2 ( Good ) 13 15 2 3 3 ( Fair ) 9 6 3 1 4 ( Poor ) 2 5 1 25 Table 3 : K-Nearest Neighbors : Confusion Matrix els a formal symbolic model ( the event calculusbased results of a Plot Comparison Algorithm ) enters a mutually beneficial relationship with a statistical model of the data ( LSA ) , mediated by a machine learner ( Naive Bayes ) .</sentence>
				<definiendum id="0">K-Nearest Neighbors</definiendum>
				<definiendum id="1">Confusion Matrix</definiendum>
				<definiens id="0">els a formal symbolic model ( the event calculusbased results of a Plot Comparison Algorithm ) enters a mutually beneficial relationship with a statistical model of the data ( LSA ) , mediated by a machine learner ( Naive Bayes )</definiens>
			</definition>
			<definition id="7">
				<sentence>NB makes the assumptions of both parametrization and Conditional Independence .</sentence>
				<definiendum id="0">NB</definiendum>
				<definiens id="0">makes the assumptions of both parametrization</definiens>
			</definition>
			<definition id="8">
				<sentence>Poor stories have “definite problems with the recall of events , ” and so are also easily identified .</sentence>
				<definiendum id="0">Poor stories</definiendum>
				<definiens id="0">have “definite problems with the recall of events , ” and so are also easily identified</definiens>
			</definition>
</paper>

		<paper id="0400">
</paper>

		<paper id="1113">
			<definition id="0">
				<sentence>A Chinese collocation is a recurrent and conventional expression of words which holds syntactic and semantic relations .</sentence>
				<definiendum id="0">Chinese collocation</definiendum>
				<definiens id="0">a recurrent and conventional expression of words which holds syntactic and semantic relations</definiens>
			</definition>
			<definition id="1">
				<sentence>Dagan ( Dagan 1997 ) applied similaritybased smoothing method to solve the problem of data sparseness in statistical natural language processing .</sentence>
				<definiendum id="0">Dagan</definiendum>
				<definiens id="0">applied similaritybased smoothing method to solve the problem of data sparseness in statistical natural language processing</definiens>
			</definition>
			<definition id="2">
				<sentence>The following lists for the word , one of its corresponding concepts In the above record , DEF is where the primitives are specified .</sentence>
				<definiendum id="0">DEF</definiendum>
				<definiens id="0">where the primitives are specified</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus , HowNet can be described by W , a collection of n words , as : W = { w 1 , w 2 , … w n } Each word w i is , in turn , described by a set of concepts S as : W i = { S i1 , S i2 , … S ix } , And , each concept S i is , in turn , described by a set of primitives : S i = { p i1 , p i2 …p iy } For each word pair , w 1 and w 2 , the similarity function is defined by ) 1 ( ) , ( max ) , ( 21 ... 1 , .</sentence>
				<definiendum id="0">1 ( ) , ( max</definiendum>
				<definiens id="0">in turn , described by a set of primitives</definiens>
			</definition>
			<definition id="4">
				<sentence>As any concept S i is presented by its primitives , the similarity of primitives for any p 1 , and p 2 of the same type , can be expressed by the following formula : α α + = ) , ( ) , ( 21 21 ppDis ppSim ( 2 ) where α is an adjustable parameter set to 1.6 , and ) , ( 21 ppDis is the path length between p 1 and p 2 based on the semantic tree structure .</sentence>
				<definiendum id="0">ppDis</definiendum>
				<definiens id="0">an adjustable parameter set to 1.6 , and )</definiens>
			</definition>
			<definition id="5">
				<sentence>The above formula where α is a constant does not indicate explicitly the fact that the depth of a pair of nodes in the tree affects their similarity .</sentence>
				<definiendum id="0">α</definiendum>
			</definition>
			<definition id="6">
				<sentence>The average frequency of f i , denoted by i f , is given by 10/ 5 5 , ∑ −= = j jii ff ( 5 ) Then , the average frequency f , and the standard deviation σ are defined by ∑ = = n i i f n f 1 1 ; 2 1 ) ( 1 ∑ = −= n i i ff n σ ( 6 ) The Strength of the co-occurrence for the pair ( w h , w i , ) , denoted by k i , is defined by σ ff k i i − = ， ( 7 ) Furthermore , the Spread of ( w h , w i , ) , , denoted as U i , which characterizes the distribution of w i around w h is define as : 10 ) ( 2 , ∑ − = iji i ff U ; ( 8 ) To eliminate the bi-grams with unlikely cooccurrence , the following sets of threshold values is defined : 0 :1 K ff kC i i ≥ − = σ ( 9 ) 0 :2 UUC i ≥ ( 10 ) ) ( :3 1 , iiji UKffC ⋅+≥ ( 11 ) However , the above statistical model given by Smadja fails to extract the bi-grams with a much higher frequency of w h but a relatively low frequency word of w i , , For example , in the bigram , freq ( ) is much lower than the freq ( ) .</sentence>
				<definiendum id="0">average frequency of f i</definiendum>
				<definiendum id="1">freq ( )</definiendum>
				<definiens id="0">1 ∑ = −= n i i ff n σ ( 6 ) The Strength of the co-occurrence for the pair ( w h , w i</definiens>
				<definiens id="1">characterizes the distribution of w i around w h is define as : 10 ) ( 2 , ∑ − = iji i ff U ; ( 8 ) To eliminate the bi-grams with unlikely cooccurrence , the following sets of threshold values is defined : 0 :1 K ff kC i i ≥ − = σ ( 9 ) 0 :2 UUC i ≥ ( 10 ) ) ( :3 1 , iiji UKffC ⋅+≥ ( 11 ) However , the above statistical model given by Smadja fails to extract the bi-grams with a much higher frequency of w h but a relatively low frequency word of w i</definiens>
			</definition>
			<definition id="7">
				<sentence>The remainder bi-grams is the total number of bi-grams extracted by the algorithm .</sentence>
				<definiendum id="0">remainder bi-grams</definiendum>
				<definiens id="0">the total number of bi-grams extracted by the algorithm</definiens>
			</definition>
			<definition id="8">
				<sentence>Precision Rate vs. Value of U 0 based on formula ( 2 ) and ( 2ª ) Table 6 shows the similarity value given by formula ( 2 ) where α is a constant given the value function of the depths of the nodes .</sentence>
				<definiendum id="0">α</definiendum>
			</definition>
			<definition id="9">
				<sentence>Type 2 Collocation : Strong collocation which allows very limited substitution of the components , for example , “ ” , “ ” , “ ” and so on .</sentence>
				<definiendum id="0">Strong collocation</definiendum>
				<definiens id="0">for example , “ ” , “ ” , “ ”</definiens>
			</definition>
</paper>

		<paper id="0902">
			<definition id="0">
				<sentence>This paper presents intial work on a system that bridges from robust , broad-coverage natural language processing to precise semantics and automated reasoning , focusing on solving logic puzzles drawn from sources such as the Law School Admission Test ( LSAT ) and the analytic section of the Graduate Record Exam ( GRE ) .</sentence>
				<definiendum id="0">LSAT</definiendum>
				<definiens id="0">intial work on a system that bridges from robust , broad-coverage natural language processing to precise semantics and automated reasoning , focusing on solving logic puzzles drawn from sources such as the Law School Admission Test (</definiens>
			</definition>
			<definition id="1">
				<sentence>The chosen task is solving logic puzzles of the sort found in the Law School Admission Test ( LSAT ) and the old analytic section of the Graduate Record Exam ( GRE ) ( see Figure 1 for a typical example ) .</sentence>
				<definiendum id="0">Record Exam</definiendum>
				<definiens id="0">solving logic puzzles of the sort found in the Law School Admission Test ( LSAT ) and the old analytic section of the Graduate</definiens>
			</definition>
			<definition id="2">
				<sentence>Presuppositions are pieces of information assumed in a sentence .</sentence>
				<definiendum id="0">Presuppositions</definiendum>
				<definiens id="0">pieces of information assumed in a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Anaphoric expressions bear presuppositions about the existence of entities in the context ; the answer choice “Sculptures C and E” conveys the meaning { C , E } , but has the presupposition sculpture ( C ) ∧ sculpture ( E ) ; and a question of the form A → B , such as question 1 in Figure 1 , presupposes that A is consistent with the preamble .</sentence>
				<definiendum id="0">Anaphoric expressions</definiendum>
				<definiendum id="1">E”</definiendum>
				<definiens id="0">conveys the meaning { C , E } , but has the presupposition sculpture ( C ) ∧ sculpture ( E ) ; and a question of the form A → B</definiens>
			</definition>
</paper>

		<paper id="1606">
</paper>

		<paper id="2006">
			<definition id="0">
				<sentence>AsdeCopas is based on hierarchically organised semantic rules , that output formulas in a flat language .</sentence>
				<definiendum id="0">AsdeCopas</definiendum>
				<definiens id="0">based on hierarchically organised semantic rules</definiens>
			</definition>
			<definition id="1">
				<sentence>In this paper we show how AsdeCopas can be used to choose between several semantic values of some quantifiers and also how it can generate underspecified formulas in Minimal Recursion Semantics ( MRS ) ( Copestake et al. , 2001 ) .</sentence>
				<definiendum id="0">AsdeCopas</definiendum>
			</definition>
			<definition id="2">
				<sentence>A¨ıt-Mokhtar ( A¨ıt-Mokhtar et al. , 2002 ) defines an incremental rule as “a self-contained operation , whose result depends on the set of contextual restrictions stated in the rule itself .</sentence>
				<definiendum id="0">A¨ıt-Mokhtar</definiendum>
				<definiens id="0">an incremental rule as “a self-contained operation , whose result depends on the set of contextual restrictions stated in the rule itself</definiens>
			</definition>
			<definition id="3">
				<sentence>Element : elem ( w , c ) is an element , where : • w ∈ { } ∪ W ; • c ∈ { } ∪ C. Arrow : arrow ( c1 , c2 , d , l ) is a dependency , and no arrow ( c1 , c2 , d , l ) a non existing dependency where : • c1 , c2 ∈ C ( c1 and c2 are , respectively , the source and the target ) ; • d ∈ { } ∪ { L , R } ( d is the dependency orientation : L if it goes from right to left , R from left to right ) ; • l ∈ { } ∪ D ( l is a possibly undefined dependency label ) .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiens id="0">a dependency</definiens>
				<definiens id="1">l ) a non existing dependency where : • c1 , c2 ∈ C ( c1 and c2 are , respectively , the source and the target ) ; • d ∈ { } ∪ { L , R } ( d is the dependency orientation : L if it goes from right to left</definiens>
				<definiens id="2">a possibly undefined dependency label )</definiens>
			</definition>
			<definition id="4">
				<sentence>Semantic Rule : [ Ri ] Σ : Θ mapsto→ Γ is a semantic rule where : • Σ is a possibly empty set of elements ( the elements to operate on ) ; • Θ is a possible empty set of existing and non existing dependencies ( the rule’s context ) ; • Γ is a set of functions , that vary according to the chosen representation language .</sentence>
				<definiendum id="0">Semantic Rule</definiendum>
				<definiendum id="1">Θ</definiendum>
				<definiendum id="2">Γ</definiendum>
				<definiens id="0">a semantic rule where : • Σ is a possibly empty set of elements ( the elements to operate on ) ; •</definiens>
				<definiens id="1">a possible empty set of existing and non existing dependencies ( the rule’s context</definiens>
				<definiens id="2">a set of functions , that vary according to the chosen representation language</definiens>
			</definition>
			<definition id="5">
				<sentence>Element subsumption : Given e1 = elem ( w1 , c1 ) and e2 = elem ( w2 , c2 ) from Σ , e1 subsumes e2 ( e1 subsetsqequale e2 ) iff : • c1 subsetsqequal c2 ; • ( w1 negationslash= ) ⇒ ( w2 = w1 ) .</sentence>
				<definiendum id="0">Element subsumption</definiendum>
			</definition>
			<definition id="6">
				<sentence>MRS ( Copestake et al. , 2001 ) uses a flat representation with explicit pointers ( called handles ) to encode scope effects , corresponding to recursive structures in more conventional formal semantic representations .</sentence>
				<definiendum id="0">MRS</definiendum>
				<definiens id="0">Copestake et al. , 2001 ) uses a flat representation with explicit pointers ( called handles ) to encode scope effects , corresponding to recursive structures in more conventional formal semantic representations</definiens>
			</definition>
			<definition id="7">
				<sentence>As an example , MRS represents Qualquer menino adora algum c˜ao ( Every boy adores some dog ) in the following underspecified structure ( the =q constraint stands for the equality modulo quantifiers and relates a handle in an argument position to a label ( Copestake et al. , 2001 ) ) : top p4 h1 : every ( x , r1 , n ) , h3 : menino ( x ) , r1 =q h3 , h7 : c~ao ( y ) , h5 : some ( y , r5 , m ) , r5 =q h7 , h4 : adora ( e , x , y ) where h1 outscopes h3 and h5 outscopes h7 .</sentence>
				<definiendum id="0">MRS</definiendum>
				<definiendum id="1">h5</definiendum>
				<definiens id="0">every ( x , r1 , n ) , h3 : menino ( x ) , r1 =q h3 , h7 : c~ao ( y ) ,</definiens>
			</definition>
			<definition id="8">
				<sentence>Then , by means of a set of constraints , such that an MRS structure must be a tree , there should be a unique top-level handle , etc. , the following readings are obtained : p=h1 ( wide scope “every” ) h1 : every ( x , h3 , h5 ) , h3 : menino ( x ) , h5 : some ( y , h7 , h4 ) , h7 : c~ao ( y ) , h4 : adora ( e , x , y ) p=h5 ( wide scope “some” ) , h5 : some ( y , h7 , h1 ) , h7 : c~ao ( y ) , h1 : every ( x , h3 , h4 ) , h3 : menino ( x ) , h4 : adora ( e , x , y ) In the next section we will show how to reach these formulas .</sentence>
				<definiendum id="0">h5</definiendum>
				<definiens id="0">wide scope “some” ) ,</definiens>
			</definition>
			<definition id="9">
				<sentence>We presented AsdeCopas , a syntax-semantics interface based on hierarchically organized semantic rules .</sentence>
				<definiendum id="0">AsdeCopas</definiendum>
				<definiens id="0">a syntax-semantics interface based on hierarchically organized semantic rules</definiens>
			</definition>
</paper>

		<paper id="1215">
			<definition id="0">
				<sentence>Yapex ( Olsson et al. , 2002 ) implemented some heuristic steps described by Fukuda , et al. , and applied filters and knowledge bases to remove false alarms .</sentence>
				<definiendum id="0">Yapex</definiendum>
				<definiens id="0">some heuristic steps described by Fukuda , et al. , and applied filters and knowledge bases to remove false alarms</definiens>
			</definition>
			<definition id="1">
				<sentence>( | , ) iiwtypewtype ii fims =−≠ ∑ , where f is the pdf of normal distribution , type is one of the five types , wi denotes the surrounding words , , ˆ itypew m and , ˆ itypew s are the maximum likelihood estimates of mean and standard deviation for wi given the type .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">type</definiendum>
				<definiens id="0">the surrounding words , , ˆ itypew m and , ˆ itypew s are the maximum likelihood estimates of mean and standard deviation for wi given the type</definiens>
			</definition>
			<definition id="2">
				<sentence>3 3 Prob ( | ) wi p ipP itype =−∈ ∑∑ , where type is one of the six types including ‘O’ , iw P is the set of patterns matching wi , Prob p denotes the pmf for pattern p. Finally , the type of the previous word is added to the feature vector , mimicking the concept of a stochastic model .</sentence>
				<definiendum id="0">type</definiendum>
				<definiendum id="1">Prob p</definiendum>
				<definiens id="0">the set of patterns matching wi</definiens>
				<definiens id="1">the pmf for pattern p. Finally , the type of the previous word is added to the feature vector , mimicking the concept of a stochastic model</definiens>
			</definition>
</paper>

		<paper id="2809">
			<definition id="0">
				<sentence>We are able to do so mainly because , as mentioned in 3.1 , the DM is responsible for content determination in our system .</sentence>
				<definiendum id="0">DM</definiendum>
			</definition>
</paper>

		<paper id="1200">
			<definition id="0">
				<sentence>This year NLPBA ( http : //www.genisis.ch/~natlang/NLPBA02/ ) and BioNLP ( http : //www-tsujii.is.s.utokyo.ac.jp/ACL03/bionlp.htm ) have merged to form a joint workshop with the aim of bringing together researchers from natural language processing , bio-informatics , medicine and ontologies who are concerned with developing methods and resources for solving these problems .</sentence>
				<definiendum id="0">BioNLP ( http</definiendum>
				<definiens id="0">a joint workshop with the aim of bringing together researchers from natural language processing</definiens>
			</definition>
			<definition id="1">
				<sentence>Over the last five years we have seen significant steps forward in the development of language technology and large-scale resources for the Bio-Medical domain such as linguistically annotated corpora ( e.g. GENIA POS and NE corpora ) , ontologies ( e.g. Gene Ontology ) , thesauri ( e.g. UMLS Metathesaurus ) , lexicons and term lists ( e.g. UMLS SPECIALIST ) as well as information retrieval collections ( e.g. TREC Genomics track ) .</sentence>
				<definiendum id="0">significant steps</definiendum>
			</definition>
			<definition id="2">
				<sentence>Nigel Collier Patrick Ruch Adeline Nazarenko iv JNLPBA Committees Workshop Co-Chairs • Nigel Collier ( National Institute of Informatics , Japan ) • Patrick Ruch ( University Hospital of Geneva and EPFL , Switzerland ) • Adeline Nazarenko ( LIPN , France ) Steering Committee • Alfonso Valencia ( Centro Nacional de Biotecnologia , Spain ) • Carol Friedman ( CUNY/Columbia University , USA ) • Donia Scott ( University of Brighton , UK ) • Udo Hahn ( Albert-Ludwigs University , Freiburg , Germany ) • Junichi Tsujii ( University of Tokyo , Japan ) ii JNLPBA Committees ( continued ) Program Committee • Sophia Ananiadou ( University of Salford , UK ) • Alan Aronson ( National Library of Medicine , USA ) • Robert Baud ( University Hospital of Geneva , Switzerland ) • Christian Blaschke ( CNB , Spain ) • Oliver Bodenreider ( National Library of Medicine , USA ) • Berry de Bruijn ( National Research Center , Canada ) • Marc Craven ( University of Wisconsin , USA ) • Robert Gaizauskas ( University of Sheffield , UK ) • Eric Gaussier ( Xerox , XRCE , France ) • Vasileios Hatzivassiloglou ( Columbia University , USA ) • Lynette Hirschman ( MITRE , USA ) • Dimitar Hristovski ( University of Ljubljana , Slovenia ) • Jerry Hobbs ( USC/ISI , USA ) • Aravind Joshi ( University of Pennsylvania , USA ) • Su Jian ( Institute for Infocomm Research , Singapore ) • Asao Fujiyama ( National Institute of Informatics , Japan ) • Arne Jönsson ( University of Linköping , Sweden ) • Frédérique Lisacek ( GeneBio SA , Switzerland ) • Yuji Matsumoto ( NAIST , Japan ) • Claire Nédellec ( INRA , France ) • Kousaku Okubo ( Kyushu University , Japan ) • Jong C. Park ( KAIST , Korea ) • Thierry Poibeau ( LIPN , France ) • Denys Proux ( Xerox , XRCE , France ) • James Pustejovsky ( Brandeis University , USA ) • Dietrich Rebholz-Schuhmann ( European Bioinformatics Institute , EU ) • Irena Spasic ( UMIST , UK ) • Ben Stapley ( UMIST , UK ) • Padmini Srinivasan ( University of Iowa , USA ) • Hirotoshi Taira ( NTT Communication Science , Japan ) • Toshihisa Takagi ( University of Tokyo , Japan ) • Yuka Tateishi ( University of Tokyo , Japan ) • Anne-Lise Veuthey ( SIB , Switzerland ) • Limsoon Wong ( Institute for Infocomm Research , Singapore ) • Pierre Zweigenbaum ( AP-HP , INSERM &amp; INaLCO , France ) iii Conference Program Saturday , August 28th , 2004 8:30-9:15 On site Registration 9:15-9:30 Introduction Regular session 1 9:30-10:00 Recognizing Names in Biomedical Texts using Hidden Markov Model and SVM plus Sigmoid GuoDong Zhou 10:00-10:30 Using Argumentation to Retrieve Articles with Similar Citations from MEDLINE Imad Tbahriti , Christine Chichester , Frédérique Lisacek and Patrick Ruch 10:30-11:00 Analysis of Link Grammar on Biomedical Dependency Corpus Targeted at Protein-Protein Interactions Sampo Pyysalo , Filip Ginter , Tapio Pahikkala , Jorma Boberg , Jouni Järvinen , Tapio Salakoski and Jeppe Koivula 11:00-11:30 BREAK Regular session 2 11:30-12:00 Discovering Patterns to Extract Protein-Protein Interactions from Full Biomedical Texts Minlie Huang , Xiaoyan Zhu , Donald G. Payan , Kunbin Qu and Ming Li 12:00-12:30 Zone Identification in Biology Articles as a Basis for Information Extraction Yoko Mizuta and Nigel Collier 12:30-14:00 LUNCH 14:00-15:00 Invited talk 15:00-16:15 Poster session Distributed Modules for Text Annotation and IE Applied to the Biomedical Domain Harald Kirsch and Dietrich Rebholz-Schuhmann Regular session 3 16:15-16:45 Assessing the Correlation between Contextual Patterns and Biological Entity Tagging M. Krallinger , M. Padr ?</sentence>
				<definiendum id="0">Japan</definiendum>
				<definiens id="0">Regular session 1 9:30-10:00 Recognizing Names in Biomedical Texts using Hidden Markov Model and SVM</definiens>
			</definition>
			<definition id="3">
				<sentence>n , C. Blaschke and A. Valencia 16:45-17:15 Event-Based Information Extraction for the Biomedical Domain : the Caderige Project Erick Alphonse , Sophie Aubin , Philippe Bessières , Gilles Bisson , Thierry Hamon , Sandrine Lagarrigue , Adeline Nazarenko , Alaine-Pierre Manine , Claire Nédellec , Mohamed Ould Abdel Vetah , Thierry Poibeau and Davy Weissenbacher 17:15-17:45 Round table and closing Sunday , August 29th , 2004 8:30-9:30 On site registration 9:30-10:00 Introduction to the Bio-entity Recognition Task at JNLPBA Nigel Collier and Jin-Dong Kim Shared task session 1 10:00-10:15 Incorporating Lexical Knowledge into Biomedical NE Recognition Kyung-Mi Park , Seon-Ho Kim , Ki-Joong Lee , Do-Gil Lee and Hae-Chang Rim 10:15-10:30 Annotating Multiple Types of Biomedical Entities : A Single Word Classification Approach Chih Lee , Wen-Juan Hou and Hsin-Hsi Chen 10:30-10:45 Named Entity Recognition in Biomedical Texts using an HMM Model Shaojun Zhao 10:45-11:00 Exploiting Context for Biomedical Entity Recognition : From Syntax to the Web Jenny Finkel , Shipra Dingare , Huy Nguyen , Malvina Nissim , Christopher Manning , and Gail Sinclair 11:00-11:30 BREAK ix Shared task session 2 11:30-11:45 Adapting an NER-System for German to the Biomedical Domain Marc Rössler 11:45-12:00 Exploring Deep Knowledge Resources in Biomedical Name Recognition Zhou GuoDong and Su Jian 12:00-12:15 POSBIOTM-NER in the Shared Task of BioNLP/NLPBA2004 Yu Song , Eunju Kim , Gary Geunbae Lee and Byoung-kee Yi 12:15-12:30 Biomedical Named Entity Recognition using Conditional Random Fields and Rich Feature Sets Burr Settles 12:30-13:00 Discussion and closing x Table of Contents PREFACE ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ………………………… ... ... ... ... ... ... ... ... ... ... .</sentence>
				<definiendum id="0">Single Word Classification Approach Chih Lee</definiendum>
				<definiens id="0">using an HMM Model Shaojun Zhao 10:45-11:00 Exploiting Context for Biomedical Entity Recognition : From Syntax to the Web Jenny Finkel</definiens>
			</definition>
</paper>

		<paper id="3003">
			<definition id="0">
				<sentence>The Reporting component of the Web Interface can automatically create the annotation guide from the Processed Data in the XML database at any time using the Annotation Guide Generation Tool .</sentence>
				<definiendum id="0">Reporting component of the Web Interface</definiendum>
				<definiens id="0">the annotation guide from the Processed Data in the XML database at any time using the Annotation Guide Generation Tool</definiens>
			</definition>
			<definition id="1">
				<sentence>Clustering is grouping data based on their intrinsic similarities .</sentence>
				<definiendum id="0">Clustering</definiendum>
				<definiens id="0">grouping data based on their intrinsic similarities</definiens>
			</definition>
			<definition id="2">
				<sentence>Relevance feedback serves as an advanced searching option .</sentence>
				<definiendum id="0">Relevance feedback</definiendum>
				<definiens id="0">an advanced searching option</definiens>
			</definition>
			<definition id="3">
				<sentence>The SLU metric is calculated as follows and it is averaged over the utterances : • if the call type is the truth , the score is the difference ( positive ) between the truth probability and the next highest probability • if the call type is not the truth , the score is the difference ( negative ) between the truth probability and the highest probability This metric allows the UE expert to easily spot problem call types or those that might give potential problems in the field .</sentence>
				<definiendum id="0">SLU metric</definiendum>
				<definiens id="0">calculated as follows and it is averaged over the utterances</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , the SLU Toolset is critical for creating the call types defined in the annotation guide which in turn is needed to label the data for creating the final SLU .</sentence>
				<definiendum id="0">SLU Toolset</definiendum>
				<definiens id="0">critical for creating the call types defined in the annotation guide which in turn is needed to label the data for creating the final SLU</definiens>
			</definition>
			<definition id="5">
				<sentence>The Redundancy R is given by N UR −= 1 where U is the number of unique utterances after feature extraction and N is the number of original utterances .</sentence>
				<definiendum id="0">Redundancy R</definiendum>
				<definiendum id="1">U</definiendum>
				<definiendum id="2">N</definiendum>
				<definiens id="0">the number of unique utterances after feature extraction</definiens>
				<definiens id="1">the number of original utterances</definiens>
			</definition>
			<definition id="6">
				<sentence>Spoken language understanding is a critical component of automated customer service applications .</sentence>
				<definiendum id="0">Spoken language understanding</definiendum>
			</definition>
</paper>

		<paper id="0908">
			<definition id="0">
				<sentence>The text-to-scene conversion process consists of two stages .</sentence>
				<definiendum id="0">text-to-scene conversion process</definiendum>
			</definition>
			<definition id="1">
				<sentence>WordsEye ( Coyne and Sproat , 2001 ) is an impressive system that recreates 3D animated scenes from short descriptions .</sentence>
				<definiendum id="0">WordsEye</definiendum>
				<definiens id="0">an impressive system that recreates 3D animated scenes from short descriptions</definiens>
			</definition>
			<definition id="2">
				<sentence>Carsim ( Egges et al. , 2001 ; Dupuy et al. , 2001 ) is a program that analyzes texts describing car accidents and visualizes them in a 3D environment .</sentence>
				<definiendum id="0">Carsim</definiendum>
				<definiens id="0">a program that analyzes texts describing car accidents and visualizes them in a 3D environment</definiens>
			</definition>
			<definition id="3">
				<sentence>The Carsim language processing module reduces the text content to a formal representation that outlines what happened and enables a conversion to a symbolic scene .</sentence>
				<definiendum id="0">Carsim language processing module</definiendum>
				<definiens id="0">reduces the text content to a formal representation that outlines what happened and enables a conversion to a symbolic scene</definiens>
			</definition>
			<definition id="4">
				<sentence>It uses information extraction techniques to map a text onto a structure that consists of three main elements : A scene object , which describes the static parameters of the environment , such as weather , light , and road configuration .</sentence>
				<definiendum id="0">scene object</definiendum>
				<definiens id="0">describes the static parameters of the environment , such as weather , light , and road configuration</definiens>
			</definition>
			<definition id="5">
				<sentence>The information extraction subsystem uses the literal content of certain phrases it finds in the text or infers the environment and the actions .</sentence>
				<definiendum id="0">information extraction subsystem</definiendum>
				<definiens id="0">uses the literal content of certain phrases it finds in the text or infers the environment and the actions</definiens>
			</definition>
			<definition id="6">
				<sentence>Carsim uses a domain-specific named entity recognition module , which detects names of persons , places , roads , and car makes ( Persson and Danielsson , 2004 ) .</sentence>
				<definiendum id="0">Carsim</definiendum>
				<definiens id="0">uses a domain-specific named entity recognition module , which detects names of persons</definiens>
			</definition>
			<definition id="7">
				<sentence>TimeML has tags for time expressions ( today ) , “signals” indicating the polarity ( not ) , the modality ( could ) , temporal prepositions and connectives such as for , during , before , after , events ( crashed , accident ) , and tags that indicate relations between entities .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">has tags for time expressions ( today ) , “signals” indicating the polarity ( not ) , the modality ( could ) , temporal prepositions and connectives such as for , during , before , after , events ( crashed , accident ) , and tags that indicate relations between entities</definiens>
			</definition>
			<definition id="8">
				<sentence>We extended the TimeML attributes to store the events’ syntactic features .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">attributes to store the events’ syntactic features</definiens>
			</definition>
			<definition id="9">
				<sentence>We first apply the PS rules to detect the time expressions , signals , and events .</sentence>
				<definiendum id="0">PS rules</definiendum>
			</definition>
			<definition id="10">
				<sentence>Heuristics represent common-sense knowledge and are encoded as nine production rules .</sentence>
				<definiendum id="0">Heuristics</definiendum>
				<definiens id="0">represent common-sense knowledge and are encoded as nine production rules</definiens>
			</definition>
			<definition id="11">
				<sentence>The current aim of the Carsim project is to visualize the content of a text as accurately as possible , with no external knowledge .</sentence>
				<definiendum id="0">Carsim project</definiendum>
				<definiens id="0">to visualize the content of a text as accurately as possible , with no external knowledge</definiens>
			</definition>
</paper>

		<paper id="1702">
			<definition id="0">
				<sentence>The system , Exills ( www.exills.com ) represents an innovative way of integrating Natural Language technologies and multimedia technologies in order to provide a visionary e-learning tool for learning foreign languages .</sentence>
				<definiendum id="0">www.exills.com )</definiendum>
				<definiens id="0">an innovative way of integrating Natural Language technologies and multimedia technologies in order to provide a visionary e-learning tool for learning foreign languages</definiens>
			</definition>
			<definition id="1">
				<sentence>2 Competence and performance as defined by Chomsky ( Chomsky , 1965 ) : Competence is the speaker-hearer 's knowledge of his language .</sentence>
				<definiendum id="0">Competence</definiendum>
			</definition>
			<definition id="2">
				<sentence>Performance is the speakerhearer 's actual use of his language in concrete situations In what follows , after presenting our view of elearning , we describe Exills and its different technical components .</sentence>
				<definiendum id="0">Performance</definiendum>
				<definiens id="0">the speakerhearer 's actual use of his language in concrete situations In what follows</definiens>
			</definition>
			<definition id="3">
				<sentence>Exills is a true e-learning solution , that on the technological part , integrates virtual reality with linguistic and collaborative technologies as well as with a smart search engine .</sentence>
				<definiendum id="0">Exills</definiendum>
			</definition>
			<definition id="4">
				<sentence>Personalization , because when they are in virtual reality , learners can choose a representation of themselves , also known as an avatar , and can move around the virtual places like in the real world .</sentence>
				<definiendum id="0">Personalization</definiendum>
				<definiens id="0">in virtual reality , learners can choose a representation of themselves , also known as an avatar , and can move around the virtual places like in the real world</definiens>
			</definition>
			<definition id="5">
				<sentence>Within the chat , Exills offers a comprehension help service which uses the context to first retrieve the most appropriate translation of a word ( syntactic and semantic disambiguation ) .</sentence>
				<definiendum id="0">Exills</definiendum>
				<definiens id="0">offers a comprehension help service which uses the context to first retrieve the most appropriate translation of a word ( syntactic and semantic disambiguation )</definiens>
			</definition>
			<definition id="6">
				<sentence>In fact , Exills permits the construction of an infinite number of scenarios .</sentence>
				<definiendum id="0">Exills</definiendum>
				<definiens id="0">permits the construction of an infinite number of scenarios</definiens>
			</definition>
			<definition id="7">
				<sentence>Exills is a true e-learning solution created to take advantage of the web .</sentence>
				<definiendum id="0">Exills</definiendum>
				<definiens id="0">a true e-learning solution created to take advantage of the web</definiens>
			</definition>
			<definition id="8">
				<sentence>• Linguistic tools provide autonomy to students by showing them concepts , give them assistance to understand word meanings or different senses within a particular context by presenting various examples , to provide feedback for their production ( in the chat as well as during exercises or even free activities ) .</sentence>
				<definiendum id="0">Linguistic</definiendum>
				<definiens id="0">tools provide autonomy to students by showing them concepts , give them assistance to understand word meanings or different senses within a particular context by presenting various examples , to provide feedback for their production ( in the chat as well as during exercises or even free activities</definiens>
			</definition>
</paper>

		<paper id="2119">
			<definition id="0">
				<sentence>XML and SGML data representation languages ( Boitet et al. , cf. ) have been a successful approach to facilitate the export of electronic dictionaries to different applications though many dictionaries use their own internal data representation formats ( Fedder , 1992 ) .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiendum id="1">SGML data representation languages</definiendum>
				<definiens id="0">Boitet et al. , cf. ) have been a successful approach to facilitate the export of electronic dictionaries to different applications though many dictionaries use their own internal data representation formats</definiens>
			</definition>
			<definition id="1">
				<sentence>TransDict includes cross-referenced monolingual lexicons for every language .</sentence>
				<definiendum id="0">TransDict</definiendum>
				<definiens id="0">includes cross-referenced monolingual lexicons for every language</definiens>
			</definition>
			<definition id="2">
				<sentence>A monolingual dictionary consists of a set of entries .</sentence>
				<definiendum id="0">monolingual dictionary</definiendum>
			</definition>
			<definition id="3">
				<sentence>the morphological zone displays an entry in the selected language equivalent to a highlighted word in the left column .</sentence>
				<definiendum id="0">morphological zone</definiendum>
				<definiens id="0">displays an entry in the selected language equivalent to a highlighted word in the left column</definiens>
			</definition>
</paper>

		<paper id="0302">
			<definition id="0">
				<sentence>The difference between ITAG and TAG is the form of elementary trees .</sentence>
				<definiendum id="0">TAG</definiendum>
			</definition>
			<definition id="1">
				<sentence>The probability that fl is adjoined is calculated as follows : P ( afl ) = C ( afl ) C ( X ) ( 3 ) where C ( X ) is the count of the number of occurrences of symbol X. The probability that adjunction is not applied is calculated as follows : P ( nilX ) = 1¡ X fl2A ( X ) P ( afl ) ( 4 ) where nilX means that the adjunction is not applied to a node labeled with X , and A ( X ) is the set of all auxiliary trees whose root is labeled X. In this PITAG formalism , the probability that elementary trees are combined at each node depends only on the nonterminal symbol of that node 2 .</sentence>
				<definiendum id="0">C ( X )</definiendum>
				<definiendum id="1">nilX</definiendum>
				<definiendum id="2">A ( X</definiendum>
				<definiens id="0">the count of the number of occurrences of symbol X. The probability that adjunction is not applied is calculated as follows : P ( nilX</definiens>
				<definiens id="1">the set of all auxiliary trees whose root is labeled X.</definiens>
			</definition>
			<definition id="2">
				<sentence>When the j-th word wj is scanned , our incremental parser returns the following partial parse : argmaxf : V ( ; w1¢¢¢wj ) ‚ gl ( ) ( 6 ) where is a threshold between [ 0 ; 1 ] and l ( ) is the length of the initial fragment which is yielded by .</sentence>
				<definiendum id="0">l ( )</definiendum>
				<definiens id="0">the length of the initial fragment which is yielded by</definiens>
			</definition>
			<definition id="3">
				<sentence>We define the degree of delay when j-th word is scanned as follows : D ( j ; s ) = j ¡l ( oj ( s ) ) ( 7 ) We define maximum delay Dmax ( s ) and average delay Dave ( s ) as follows : Dmax ( s ) = max1•j•nD ( j ; s ) ( 8 ) Dave ( s ) = 1n nX j=1 D ( j ; s ) ( 9 ) The precision is defined as the percentage of valid partial parse trees in the output .</sentence>
				<definiendum id="0">s )</definiendum>
				<definiendum id="1">s )</definiendum>
				<definiens id="0">the degree of delay when j-th word is scanned as follows : D ( j ; s ) = j ¡l ( oj ( s ) ) ( 7 ) We define maximum delay Dmax ( s ) and average delay Dave ( s ) as follows : Dmax ( s ) = max1•j•nD ( j ;</definiens>
				<definiens id="1">the percentage of valid partial parse trees in the output</definiens>
			</definition>
</paper>

		<paper id="0202">
			<definition id="0">
				<sentence>Grice ( Grice , 1975 ) proposed a number of maxims that describe various ways in which speakers are engaged in a cooperative conversation .</sentence>
				<definiendum id="0">Grice</definiendum>
				<definiens id="0">a number of maxims that describe various ways in which speakers are engaged in a cooperative conversation</definiens>
			</definition>
			<definition id="1">
				<sentence>Direct responses ( DR ) : are MUs corresponding to statements whose contents can be directly elaborated from texts , web pages , databases , etc. , possibly via deduction , but not involving any reformulation of the original query .</sentence>
				<definiendum id="0">Direct responses</definiendum>
				<definiens id="0">DR ) : are MUs corresponding to statements whose contents can be directly elaborated from texts , web pages , databases , etc. , possibly via deduction , but not involving any reformulation of the original query</definiens>
			</definition>
			<definition id="2">
				<sentence>• Hypothetical responses ( CSFH ) : include responses based on an hypothesis .</sentence>
				<definiendum id="0">CSFH</definiendum>
				<definiens id="0">include responses based on an hypothesis</definiens>
			</definition>
			<definition id="3">
				<sentence>Our ontology is a synthesis of two existing French ontologies , that we customized : TourinFrance ( www.tourinfrance.net ) and the bilingual ( French and English ) thesaurus of tourism and leisure activities ( www.iztzg.hr/indokibiblioteka/THESAUR.PDF ) which includes 2800 French terms .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">a synthesis of two existing French ontologies , that we customized : TourinFrance ( www.tourinfrance.net ) and the bilingual ( French and English ) thesaurus of tourism and leisure activities ( www.iztzg.hr/indokibiblioteka/THESAUR.PDF ) which includes 2800 French terms</definiens>
			</definition>
			<definition id="4">
				<sentence>We consider here the MU : DS , AJ , AR , AA , as characterized above : Unit A B C Total correct annotation DS 102 6 0 108 88 % AJ 27 6 3 36 75 % AR 36 4 2 42 86 % AA 24 0 0 24 100 % A : number of MU annotated correctly for that category , B : MU not annotated ( no decision made ) , C : incorrect annotation .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">MU not annotated ( no decision made ) ,</definiens>
			</definition>
</paper>

		<paper id="0851">
			<definition id="0">
				<sentence>Let S = ( x1 , y1 ) , ... , ( xn , yn ) be a training sample with xi ∈ Rd and yi ∈ { −1,1 } for all i. The hypothesis space H of RLSC is the set of functions f : Rd → R of the form : f ( x ) = nsummationdisplay i=1 cik ( x , xi ) with ci ∈ R for all i and k : Rd × Rd → R a kernel function ( a symmetric positive definite function ) that measures the similarity between two instances .</sentence>
				<definiendum id="0">RLSC</definiendum>
				<definiens id="0">the set of functions f : Rd → R of the form : f ( x ) = nsummationdisplay i=1 cik ( x , xi ) with ci ∈ R for all i and k</definiens>
			</definition>
			<definition id="1">
				<sentence>First , RLSC produces a binary classifier and word sense disambiguation is a multi-class classification problem .</sentence>
				<definiendum id="0">RLSC</definiendum>
				<definiens id="0">produces a binary classifier</definiens>
			</definition>
			<definition id="2">
				<sentence>To solve this problem we split the kernel in two parts : k ( x , y ) = 12kl ( x , y ) + 12kb ( x , y ) where kl is a linear normalized kernel that uses only the components of the feature vectors that encode local information ( and have 0/1 values ) and kb is a normalized kernel that uses only the components of the feature vectors that encode broad context .</sentence>
				<definiendum id="0">kl</definiendum>
				<definiendum id="1">kb</definiendum>
				<definiens id="0">a linear normalized kernel that uses only the components of the feature vectors that encode local information</definiens>
				<definiens id="1">a normalized kernel that uses only the components of the feature vectors that encode broad context</definiens>
			</definition>
</paper>

		<paper id="2315">
			<definition id="0">
				<sentence>By standardizing user input , Speech Graffiti aims to reduce the negative effects of variability on system complexity and recognition performance .</sentence>
				<definiendum id="0">Speech Graffiti</definiendum>
				<definiens id="0">aims to reduce the negative effects of variability on system complexity and recognition performance</definiens>
			</definition>
			<definition id="1">
				<sentence>The user study generated 4062 Speech Graffiti MovieLine utterances , where an utterance is defined as one chunk of speech input sent to our Sphinx II speech recognizer ( Huang et al. , 1993 ) .</sentence>
				<definiendum id="0">an utterance</definiendum>
			</definition>
</paper>

		<paper id="2110">
</paper>

		<paper id="2111">
			<definition id="0">
				<sentence>Excellent concordances can be produced by tools mounted on regular web search engines but these tools are not suitable for quick lookups on the web because it takes time to collect ad-hoc corpora with occurrences of a queried word or phrase .</sentence>
				<definiendum id="0">Excellent concordances</definiendum>
				<definiens id="0">the web because it takes time to collect ad-hoc corpora with occurrences of a queried word or phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>KWiCFinder is used in its own client application which needs to be downloaded .</sentence>
				<definiendum id="0">KWiCFinder</definiendum>
				<definiens id="0">used in its own client application which needs to be downloaded</definiens>
			</definition>
			<definition id="2">
				<sentence>WebCorp is an excellent example of how useful search engines can be made for linguists when their power is enhanced with natural language processing .</sentence>
				<definiendum id="0">WebCorp</definiendum>
				<definiens id="0">an excellent example of how useful search engines</definiens>
			</definition>
			<definition id="3">
				<sentence>If the search is not limited to a specific country excerpts thus obtained are hard to find elsewhere side by side : Many people in Japan think that Moomin is a hippopotamus , however , it is actually a forest fairy or Moomin is a Finnish cartoon/storybook character likened to Finland 's version of Mickey Mouse , Moomins are WHITE , dammit !</sentence>
				<definiendum id="0">Moomin</definiendum>
				<definiens id="0">a Finnish cartoon/storybook character likened to Finland 's version of Mickey Mouse</definiens>
			</definition>
</paper>

		<paper id="0601">
			<definition id="0">
				<sentence>COMIC produces a variety of output , using its full range of modalities .</sentence>
				<definiendum id="0">COMIC</definiendum>
				<definiens id="0">produces a variety of output</definiens>
			</definition>
			<definition id="1">
				<sentence>( a ) Avatar ( b ) Bathroom-design application Figure 1 : Components of the COMIC demonstrator decorating the user’s bathroom , as in the following description of a set of tiles : ( 1 ) Here is a country design .</sentence>
				<definiendum id="0">user’s bathroom</definiendum>
				<definiens id="0">a country design</definiens>
			</definition>
			<definition id="2">
				<sentence>The tasks described here take little time to perform ( i.e. , hundreds of milliseconds ) ; 2http : //xml.apache.org/xalan-j/ &lt; rdf : Description rdf : about= '' # Tileset9 '' &gt; &lt; rdf : type &gt; &lt; daml : Class rdf : about= '' # Tileset '' / &gt; &lt; /rdf : type &gt; &lt; comic : has_id &gt; &lt; xsd : string xsd : value= '' 9 '' / &gt; &lt; /comic : has_id &gt; &lt; comic : has_commentary rdf : resource= '' # Commentary9 '' / &gt; &lt; comic : has_decoration &gt; &lt; xsd : string xsd : value= '' floral-motifs '' / &gt; &lt; /comic : has_decoration &gt; &lt; comic : has_series &gt; &lt; xsd : string xsd : value= '' Armonie '' / &gt; &lt; /comic : has_series &gt; &lt; comic : has_manufacturer &gt; &lt; xsd : string xsd : value= '' Coem '' / &gt; &lt; /comic : has_manufacturer &gt; &lt; comic : has_colour rdf : resource= '' # Terracotta '' / &gt; &lt; comic : has_colour rdf : resource= '' # Beige '' / &gt; &lt; comic : has_style rdf : resource= '' # Country '' / &gt; &lt; /rdf : Description &gt; Figure 2 : Ontology properties of tileset 9 &lt; object type= '' describe '' &gt; &lt; slot name= '' has_object '' &gt; &lt; object type= '' Tileset '' &gt; &lt; slot name= '' has_id '' &gt; &lt; value type= '' String '' &gt; 9 &lt; /value &gt; &lt; /slot &gt; &lt; /object &gt; &lt; /slot &gt; &lt; slot name= '' has_feature '' &gt; &lt; value type= '' String '' &gt; has_colour &lt; /value &gt; &lt; /slot &gt; &lt; /object &gt; Figure 3 : Dialogue-manager specification most of the module’s time is spent communicating with other modules in the system .</sentence>
				<definiendum id="0">Class rdf</definiendum>
				<definiens id="0">hundreds of milliseconds</definiens>
			</definition>
			<definition id="3">
				<sentence>Other systems that fall into this category include EXEMPLARS ( White and Caldwell , 1998 ) , D2S ( van Deemter et al. , 1999 ) , Interact &lt; xsl : template match= '' one-of '' &gt; &lt; ! -Recursive pruning step -- &gt; &lt; xsl : variable name= '' pruned-alts '' &gt; &lt; xsl : for-each select= '' * '' &gt; &lt; xsl : variable name= '' pruned-alt '' &gt; &lt; xsl : apply-templates select= '' . '' / &gt; &lt; /xsl : variable &gt; &lt; xsl : if test= '' not ( xalan : nodeset ( $ pruned-alt ) //fail ) '' &gt; &lt; xsl : copy-of select= '' $ pruned-alt '' / &gt; &lt; /xsl : if &gt; &lt; /xsl : for-each &gt; &lt; /xsl : variable &gt; &lt; xsl : variable name= '' num-remaining '' select= '' count ( xalan : nodeset ( $ pruned-alts ) /* ) '' / &gt; &lt; ! -Propagation step -- &gt; &lt; xsl : choose &gt; &lt; ! -keep one-of when multiple alts succeed -- &gt; &lt; xsl : when test= '' $ num-remaining &amp; gt ; 1 '' &gt; &lt; one-of &gt; &lt; xsl : copy-of select= '' $ pruned-alts '' / &gt; &lt; /one-of &gt; &lt; /xsl : when &gt; &lt; ! -filter out one-of when just one choice remains -- &gt; &lt; xsl : when test= '' $ num-remaining = 1 '' &gt; &lt; xsl : copy-of select= '' $ pruned-alts '' / &gt; &lt; /xsl : when &gt; &lt; ! -fail if none remain -- &gt; &lt; xsl : otherwise &gt; &lt; fail/ &gt; &lt; /xsl : otherwise &gt; &lt; /xsl : choose &gt; &lt; /xsl : template &gt; Figure 10 : Failure-pruning template ( Wilcock , 2001 ; Wilcock , 2003 ) , and SmartKom ( Becker , 2002 ) .</sentence>
				<definiendum id="0">SmartKom</definiendum>
				<definiens id="0">for-each select= '' * '' &gt; &lt; xsl : variable name= '' pruned-alt '' &gt; &lt; xsl : apply-templates select= ''</definiens>
			</definition>
</paper>

		<paper id="0409">
			<definition id="0">
				<sentence>Multi-word expression extraction is an important component in language processing that aims to identify segments of input text where the syntactic structure and the semantics of a sequence of words ( possibly not contiguous ) are usually not compositional .</sentence>
				<definiendum id="0">Multi-word expression extraction</definiendum>
				<definiens id="0">an important component in language processing that aims to identify segments of input text where the syntactic structure and the semantics of a sequence of words ( possibly not contiguous ) are usually not compositional</definiens>
			</definition>
			<definition id="1">
				<sentence>Turkish is an Ural-Altaic language , having agglutinative word structures with productive in ectional and derivational processes .</sentence>
				<definiendum id="0">Turkish</definiendum>
				<definiens id="0">an Ural-Altaic language , having agglutinative word structures with productive in ectional and derivational processes</definiens>
			</definition>
			<definition id="2">
				<sentence>Turkish word forms consist of morphemes concatenated to a root morpheme or to other morphemes , much like beads on a string .</sentence>
				<definiendum id="0">Turkish word forms</definiendum>
				<definiens id="0">consist of morphemes concatenated to a root morpheme or to other morphemes</definiens>
			</definition>
			<definition id="3">
				<sentence>Here are some examples of the multi-word expressions that we consider under this grouping:3 ; 4 ( 1 ) hi olmazsa hi ( never ) +Adverb ol ( be ) +Verb+Neg+Aor+Cond+A3sg hi _olmazsa+Adverb at least ( literally if it never is ) ( 2 ) ipe sapa gelmez ip ( rope ) +Noun+A3sg+Pnon+Dat sap ( handle ) +Noun+A3sg+Pnon+Dat gel ( come ) +Verb+Neg+Aor+A3sg ipe_sapa_gelmez+Adj worthless ( literally ( he ) does not come to rope and handle ) Multi-word expressions that are considered under this heading are compound and support verb formations where there are two or more lexical items the last of which is a verb or is a derivation involving a verb .</sentence>
				<definiendum id="0">ol</definiendum>
				<definiendum id="1">sap</definiendum>
			</definition>
			<definition id="4">
				<sentence>Turkish employs quite a number of non-lexicalized collocations where the sentential role of the collocation has ( almost ) nothing to do with the parts-ofspeech and the morphological features of the individual forms involved .</sentence>
				<definiendum id="0">non-lexicalized collocations</definiendum>
				<definiens id="0">the sentential role of the collocation has ( almost ) nothing to do with the parts-ofspeech and the morphological features of the individual forms involved</definiens>
			</definition>
			<definition id="5">
				<sentence>X and Y are further duplicated or contrasted morphological patterns and Z is a certain clitic token .</sentence>
				<definiendum id="0">Z</definiendum>
			</definition>
			<definition id="6">
				<sentence>The rst component is a standard tokenizer which splits input text into constituent tokens .</sentence>
				<definiendum id="0">rst component</definiendum>
				<definiens id="0">a standard tokenizer which splits input text into constituent tokens</definiens>
			</definition>
</paper>

		<paper id="1709">
			<definition id="0">
				<sentence>Self-assessment can be seen as an instrument for training { users get elaborate feedback for their answers and are invited to try again .</sentence>
				<definiendum id="0">Self-assessment</definiendum>
				<definiens id="0">an instrument for training { users get elaborate feedback for their answers and are invited to try again</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 4 : SETEI session for creating the SET \What is a parser ? ''</sentence>
				<definiendum id="0">\What</definiendum>
				<definiens id="0">SETEI session for creating the SET</definiens>
			</definition>
			<definition id="2">
				<sentence>In general , in all elds where short textual descriptions are the best way to answer questions , SETs are a good way to automatise training and testing .</sentence>
				<definiendum id="0">SETs</definiendum>
				<definiens id="0">a good way to automatise training and testing</definiens>
			</definition>
			<definition id="3">
				<sentence>In training or assessment situations where correct answers to questions do not consist of one ( or a few ) isolated items ( words , numbers , symbols ) but where a complete description in natural language is required , and when human tutors are not available , SET is the right tool to use .</sentence>
				<definiendum id="0">SET</definiendum>
				<definiens id="0">assessment situations where correct answers to questions do not consist of one ( or a few ) isolated items ( words , numbers , symbols ) but where a complete description in natural language is required</definiens>
			</definition>
</paper>

		<paper id="2001">
			<definition id="0">
				<sentence>Robustness plays an important role in semantic interpretation .</sentence>
				<definiendum id="0">Robustness</definiendum>
				<definiens id="0">plays an important role in semantic interpretation</definiens>
			</definition>
			<definition id="1">
				<sentence>Answer Validation is an important module of a Question-Answering system for which a method exploiting co-occurrence frequencies of keywords extracted from Web documents is proposed in the paper “Answer Validation by Keyword Association” by M. Tonoike , T. Utsuro , and S. Sato .</sentence>
				<definiendum id="0">Answer Validation</definiendum>
				<definiendum id="1">“Answer Validation</definiendum>
				<definiens id="0">an important module of a Question-Answering system for which a method exploiting co-occurrence frequencies of keywords extracted from Web documents is proposed in the paper</definiens>
			</definition>
</paper>

		<paper id="2316">
			<definition id="0">
				<sentence>Thesubjectcouldrequestamessagebymessagenumber , for example , but not by content or sender .</sentence>
				<definiendum id="0">Thesubjectcouldrequestamessagebymessagenumber</definiendum>
				<definiens id="0">for example , but not by content or sender</definiens>
			</definition>
</paper>

		<paper id="2306">
			<definition id="0">
				<sentence>The AGP is an integrated set of assistants to generate multi-modal dialogue applications in a semi-automatic way .</sentence>
				<definiendum id="0">AGP</definiendum>
				<definiens id="0">an integrated set of assistants to generate multi-modal dialogue applications in a semi-automatic way</definiens>
			</definition>
			<definition id="1">
				<sentence>The AGP consists of assistants , which are tools ( partly with a GUI ) producing models .</sentence>
				<definiendum id="0">AGP</definiendum>
				<definiens id="0">consists of assistants , which are tools ( partly with a GUI ) producing models</definiens>
			</definition>
			<definition id="2">
				<sentence>All these models generated within the AGP are described in GDialogXML ( GEMINI Dialog XML ) , which is an object-oriented abstract dialogue modelling language .</sentence>
				<definiendum id="0">GEMINI Dialog XML )</definiendum>
				<definiens id="0">an object-oriented abstract dialogue modelling language</definiens>
			</definition>
			<definition id="3">
				<sentence>The resulting output is called generic retrieval model ( GRM ) , which consists of the modality and language independent parts of a dialogue , which is mainly the application flow .</sentence>
				<definiendum id="0">GRM</definiendum>
				<definiens id="0">consists of the modality and language independent parts of a dialogue</definiens>
			</definition>
			<definition id="4">
				<sentence>Additionally the modality extension consists of special subdialogues which are specific for one modality only .</sentence>
				<definiendum id="0">modality extension</definiendum>
				<definiens id="0">consists of special subdialogues which are specific for one modality only</definiens>
			</definition>
			<definition id="5">
				<sentence>CitizenCare is an e-government dialogue system for citizen-to-administration interaction ( via multiple channels like internet and public terminals ) , filled with content for an exemplary community .</sentence>
				<definiendum id="0">CitizenCare</definiendum>
				<definiens id="0">an e-government dialogue system for citizen-to-administration interaction ( via multiple channels like internet and public terminals ) , filled with content for an exemplary community</definiens>
			</definition>
			<definition id="6">
				<sentence>The main functionality is an interactive authority and information guide , providing different views like an administrative view , based on the hierarchical structure of the authorities , and a concern-oriented view , giving the citizen all the information needed to make use of services offered by public administration authorities .</sentence>
				<definiendum id="0">main functionality</definiendum>
				<definiens id="0">an interactive authority and information guide , providing different views like an administrative view</definiens>
			</definition>
</paper>

		<paper id="2710">
			<definition id="0">
				<sentence>Sense-tagging is the process of linking an instance of a word to the WordNet synset representing its context-appropriate meaning .</sentence>
				<definiendum id="0">Sense-tagging</definiendum>
				<definiens id="0">the process of linking an instance of a word to the WordNet synset representing its context-appropriate meaning</definiens>
			</definition>
			<definition id="1">
				<sentence>The preprocessing stage segments the gloss into chunks and tokenizes the gloss contents into words and WordNet collocations .</sentence>
				<definiendum id="0">preprocessing stage</definiendum>
				<definiens id="0">segments the gloss into chunks and tokenizes the gloss contents into words</definiens>
			</definition>
			<definition id="2">
				<sentence>NLP needs high-quality sense-tagged corpora and sense inventories .</sentence>
				<definiendum id="0">NLP</definiendum>
				<definiens id="0">needs high-quality sense-tagged corpora and sense inventories</definiens>
			</definition>
</paper>

		<paper id="2202">
			<definition id="0">
				<sentence>E.g. , in a sentence-aligned corpus , the n : m relations that hold between sentences express the fact that the propositions contained in n sentences in L1 are basically the same as the propositions in m sentences in L2 ( lowest common denominator ) .</sentence>
				<definiendum id="0">E.g.</definiendum>
				<definiens id="0">m relations that hold between sentences express the fact that the propositions contained in n sentences in L1 are basically the same as the propositions in m sentences in L2 ( lowest common denominator )</definiens>
			</definition>
</paper>

		<paper id="0830">
			<definition id="0">
				<sentence>We have used the Learning Vector Quantization , which is a supervised learning algorithm based on the Kohonen neural model .</sentence>
				<definiendum id="0">Learning Vector Quantization</definiendum>
				<definiens id="0">a supervised learning algorithm based on the Kohonen neural model</definiens>
			</definition>
			<definition id="1">
				<sentence>Our system for SENSEVAL-3 uses a supervised learning algorithm for word sense disambiguation .</sentence>
				<definiendum id="0">system for SENSEVAL-3</definiendum>
				<definiens id="0">uses a supervised learning algorithm for word sense disambiguation</definiens>
			</definition>
			<definition id="2">
				<sentence>The presented disambiguator uses the Vector Space Model ( VSM ) as an information representation model .</sentence>
				<definiendum id="0">Vector Space Model</definiendum>
				<definiendum id="1">VSM</definiendum>
				<definiens id="0">an information representation model</definiens>
			</definition>
			<definition id="3">
				<sentence>Each sense of a word is represented as a vector in an n-dimensional space where n is the number of words in all its contexts .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="4">
				<sentence>Firstly , the SemCor ( the Brown Corpus labeled with the WordNet senses ) was fully used ( the Brown-1 , Brown-2 and Brown-v partitions ) .</sentence>
				<definiendum id="0">SemCor</definiendum>
				<definiens id="0">the Brown Corpus labeled with the WordNet senses</definiens>
			</definition>
			<definition id="5">
				<sentence>The LVQ algorithm ( Kohonen , 1995 ) performs supervised learning , which uses a set of inputs with their correctly annotated outputs adjusting the model when an error is committed between the model outputs and the known outputs .</sentence>
				<definiendum id="0">LVQ algorithm</definiendum>
				<definiens id="0">uses a set of inputs with their correctly</definiens>
			</definition>
			<definition id="6">
				<sentence>α ( t ) is a monotonically decreasing function and it represents the learning rate factor , beginning with 0.1 and decreasing lineally : ( ) ( ) ( ) P tt 0 1 α αα −=+ [ 4 ] where P is the number of iterations performed in the training .</sentence>
				<definiendum id="0">α ( t )</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">the number of iterations performed in the training</definiens>
			</definition>
</paper>

		<paper id="1504">
			<definition id="0">
				<sentence>A D-tree consists of dependency links ( directed arcs ) drawn above the sentence — and implicitly , of the sentence itself .</sentence>
				<definiendum id="0">D-tree</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the axioms we will use the following regular operations : Kleene’s closure ( a9a49a48 ) , finite iteration ( a9a51a50 ) , concatenation ( a9a51a5 ) , asymmetric difference ( a9a53a52a54a5 ) , union ( a9a56a55a11a5 ) , and intersection ( a9a56a57a11a5 ) — with this precedence order .</sentence>
				<definiendum id="0">Kleene’s closure</definiendum>
				<definiens id="0">concatenation ( a9a51a5 ) , asymmetric difference ( a9a53a52a54a5 ) , union ( a9a56a55a11a5 ) , and intersection ( a9a56a57a11a5 ) — with this precedence order</definiens>
			</definition>
			<definition id="2">
				<sentence>The boxed dot a59 denotes the language a31a58a46a60a52a60a19 # a24a61a33a48 .</sentence>
				<definiendum id="0">boxed dot a59</definiendum>
			</definition>
			<definition id="3">
				<sentence>We say that an arc a2 a3 a5 a2a13a3 properly embraces another arc a2 a7 a5 a2a8a7 , if and only if a3 a4a6a5 a19 a2 a3 a37 a2a13a3a75a24a8a7 a3 a4a6a5 a19 a2 a7 a37 a2 a7a61a24 and a3a10a9a12a11a99a19 a2 a7 a37 a2a8a7a61a24a13a7 a3a14a9a12a11 a19 a2 a3 a37 a2a9a3a75a24 , where a7 is the linear precedence order among the nodes .</sentence>
				<definiendum id="0">a7</definiendum>
			</definition>
			<definition id="4">
				<sentence>Nevertheless , we conjecture that D-trees of the Bach ( or MIX ) language ( cf. Joshi 1985 ) are not captured in our system when the number colors is fixed , because Colored Non-Projective Dependency Grammar ( Yli-Jyr¨a and Nyk¨anen , 2004 ) is a linear context-free rewriting system .</sentence>
				<definiendum id="0">Bach</definiendum>
				<definiens id="0">a linear context-free rewriting system</definiens>
			</definition>
			<definition id="5">
				<sentence>A chain of colored arcs a2 a3a31a5 a1 a26 a2 a7 , a2a8a7 a5 a1 a27 a2 a40 , a2 a40 a5 a1 a30 a2a22a25 , a74a75a74a75a74 a2 a50 a34 a3a35a5 a1a27a26a29a28 a26 a2 a50 , where a1a12 is the color of an arc a2 a12 a5 a1a31a30 a2 a12a17 a3 , is called a colored dependency path .</sentence>
				<definiendum id="0">a1a12</definiendum>
				<definiens id="0">the color of an arc a2 a12 a5 a1a31a30 a2 a12a17 a3 , is called a colored dependency path</definiens>
			</definition>
			<definition id="6">
				<sentence>The non-projectivity depth of a ( colored dependency ) path that does not contain an articulation node is the number of critical nodes visited by it .</sentence>
				<definiendum id="0">articulation node</definiendum>
				<definiens id="0">the number of critical nodes visited by it</definiens>
			</definition>
</paper>

		<paper id="2603">
			<definition id="0">
				<sentence>Confabulation provides an explicit mechanism that can now be used to build artificial intelligence .</sentence>
				<definiendum id="0">Confabulation</definiendum>
				<definiens id="0">provides an explicit mechanism that can now be used to build artificial intelligence</definiens>
			</definition>
			<definition id="1">
				<sentence>To create this word-level knowledge base , we count token bigram occurrences within our corpus and then calculate antecedent support conditional probabilities as follows : For a given token t i representing the i th word in our lexicon , for each word lexicon token t j that occurs immediately following t i in the training corpus , the antecedent support probability is approximated as : ) t ( c ) t , t ( c ) t|t ( p jjiji ≅ ( 1 ) where ) t , t ( c ji is the count of the times the j th word follows the i th word in the corpus and ) t ( c j is the total count of the j th word in the corpus , excluding occurrences immediately following a punctuation mark .</sentence>
				<definiendum id="0">c ji</definiendum>
				<definiendum id="1">c j</definiendum>
				<definiens id="0">word lexicon token t j that occurs immediately following t i in the training corpus , the antecedent support probability is approximated as : ) t</definiens>
			</definition>
			<definition id="2">
				<sentence>Segmentation of a sentence into word tokens and conceptual unit tokens A Semantically Replaceable Element ( SRE ) is a word or conceptual unit that can be used as a grammaticallyconsistent , semantically similar substitute in a given linguistic context .</sentence>
				<definiendum id="0">Semantically Replaceable Element ( SRE )</definiendum>
				<definiens id="0">a word or conceptual unit that can be used as a grammaticallyconsistent , semantically similar substitute in a given linguistic context</definiens>
			</definition>
			<definition id="3">
				<sentence>SRE expansion proceeds as follows : A test sentence without internal punctuation is presented to the system .</sentence>
				<definiendum id="0">SRE expansion proceeds</definiendum>
				<definiens id="0">A test sentence without internal punctuation is presented to the system</definiens>
			</definition>
</paper>

		<paper id="1703">
			<definition id="0">
				<sentence>The activity editor ( cf. Fig.2 ) is an authoring system .</sentence>
				<definiendum id="0">activity editor</definiendum>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>It is clear that ROUGE-N is a recall-related measure because the denominator of the equation is the total sum of the number of n-grams occurring at the reference summary side .</sentence>
				<definiendum id="0">ROUGE-N</definiendum>
				<definiens id="0">the total sum of the number of n-grams occurring at the reference summary side</definiens>
			</definition>
			<definition id="1">
				<sentence>BLEU measures how well a candidate translation matches a set of reference translations by counting the percentage of n-grams in the candidate translation overlapping wit h the references .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">measures how well a candidate translation matches a set of reference translations by counting the percentage of n-grams in the candidate translation overlapping wit h the references</definiens>
			</definition>
			<definition id="2">
				<sentence>Melamed ( 1995 ) used the ratio ( LCSR ) between the length of the LCS of two words and the length of the longer word of the two words to measure the cognateness between them .</sentence>
				<definiendum id="0">LCSR</definiendum>
				<definiens id="0">the length of the LCS of two words and the length of the longer word of the two words to measure the cognateness between them</definiens>
			</definition>
			<definition id="3">
				<sentence>We propose using LCS-based Fmeasure to estimate the similarity between two summaries X of length m and Y of length n , assuming X is a reference summary sentence and Y is a candidate summary sentence , as follows : Rlcs m YXLCS ) , ( = ( 2 ) Plcs n YXLCS ) , ( = ( 3 ) Flcs lcslcs lcslcs PR PR 2 2 ) 1 ( b b + += ( 4 ) Where LCS ( X , Y ) is the length of a longest common subsequence of X and Y , and ß = Plcs/Rlcs when ?</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiendum id="2">LCS</definiendum>
				<definiens id="0">a reference summary sentence</definiens>
				<definiens id="1">a candidate summary sentence</definiens>
				<definiens id="2">the length of a longest common subsequence of X</definiens>
			</definition>
			<definition id="4">
				<sentence>Notice that ROUGE-L is 1 when X = Y ; while ROUGE-L is zero when LCS ( X , Y ) = 0 , i.e. there is nothing in common between X and Y. Fmeasure or its equivalents has been shown to have met several theoretical criteria in measuring accuracy involving more than one factor ( Van Rijsbergen , 1979 ) .</sentence>
				<definiendum id="0">ROUGE-L</definiendum>
			</definition>
			<definition id="5">
				<sentence>ROUGE-L as defined in Equation 4 has the property that its value is less than or equal to the min imum of unigram F-measure of X and Y. Unigram recall reflects the proportion of words in X ( reference summary sentence ) that are also present in Y ( candidate summary sentence ) ; while unigram precision is the proportion of words in Y that are also in X. Unigram recall and precision count all cooccurring words regardless their orders ; while ROUGE-L counts only in-sequence co-occurrences .</sentence>
				<definiendum id="0">ROUGE-L</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiendum id="2">unigram precision</definiendum>
				<definiens id="0">reflects the proportion of words in X ( reference summary sentence</definiens>
				<definiens id="1">the proportion of words in Y that are also in X. Unigram recall and precision count all cooccurring words regardless their orders</definiens>
			</definition>
			<definition id="6">
				<sentence>In the case of ROUGE-L , S2 has a score of 3/4 = 0.75 and S3 has a score of 2/4 = 0.5 , with ß = 1 .</sentence>
				<definiendum id="0">S2</definiendum>
				<definiens id="0">a score of 3/4 = 0.75 and S3 has a score of 2/4 = 0.5 , with ß = 1</definiens>
			</definition>
			<definition id="7">
				<sentence>Given two sentences X and Y , the WLCS score of X and Y can be computed using the following dynamic programming procedure : ( 1 ) For ( i = 0 ; i &lt; =m ; i++ ) c ( i , j ) = 0 // initialize c-table w ( i , j ) = 0 // initialize w-table ( 2 ) For ( i = 1 ; i &lt; = m ; i++ ) For ( j = 1 ; j &lt; = n ; j++ ) If xi = yj Then // the length of consecutive matches at // position i-1 and j -1 k = w ( i-1 , j-1 ) c ( i , j ) = c ( i-1 , j-1 ) + f ( k+1 ) – f ( k ) // remember the length of consecutive // matches at position i , j w ( i , j ) = k+1 Otherwise If c ( i-1 , j ) &gt; c ( i , j-1 ) Then c ( i , j ) = c ( i-1 , j ) w ( i , j ) = 0 // no match at i , j Else c ( i , j ) = c ( i , j-1 ) w ( i , j ) = 0 // no match at i , j ( 3 ) WLCS ( X , Y ) = c ( m , n ) Where c is the dynamic programming table , c ( i , j ) stores the WLCS score ending at word xi of X and yj of Y , w is the table storing the length of consecutive matches ended at c table position i and j , and f is a function of consecutive matches at the table position , c ( i , j ) .</sentence>
				<definiendum id="0">c</definiendum>
				<definiendum id="1">f</definiendum>
				<definiens id="0">the length of consecutive matches at // position i-1 and j -1 k = w ( i-1 , j-1 ) c ( i , j ) = c ( i-1 , j-1 ) + f ( k+1 ) – f ( k ) // remember the length of consecutive // matches at position i , j w ( i , j ) = k+1 Otherwise If c ( i-1 , j ) &gt; c ( i , j-1</definiens>
				<definiens id="1">the table storing the length of consecutive matches ended at c table position i and j , and</definiens>
				<definiens id="2">a function of consecutive matches at the table position</definiens>
			</definition>
			<definition id="8">
				<sentence>F-measure based on WLCS can be computed as follows , given two sequences X of length m and Y of length n : Rwlcs     = − ) ( ) , ( 1 mf YXWLCSf ( 13 ) Pwlcs     = − ) ( ) , ( 1 nf YXWLCSf ( 14 ) Fwlcs wlcswlcs wlcswlcs PR PR 2 2 ) 1 ( b b + += ( 15 ) Where f -1 is the inverse function of f. In DUC , ß is set to a very big number ( ?</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiendum id="1">f -1</definiendum>
				<definiens id="0">based on WLCS can be computed as follows , given two sequences X of length m and Y of length n : Rwlcs     = − )</definiens>
			</definition>
			<definition id="9">
				<sentence>tistics Skip-bigram is any pair of words in their sentence order , allowing for arbitrary gaps .</sentence>
				<definiendum id="0">tistics Skip-bigram</definiendum>
				<definiens id="0">any pair of words in their sentence order , allowing for arbitrary gaps</definiens>
			</definition>
			<definition id="10">
				<sentence>Given translations X of length m and Y of length n , assuming X is a reference translation and Y is a candidate translation , we compute skip-bigram-based F-measure as follows : Rskip2 ) 2 , ( ) , ( 2mC YXSKIP= ( 16 ) Pskip2 ) 2 , ( ) , ( 2nC YXSKIP= ( 17 ) Fskip2 2 2 2 22 2 ) 1 ( skipskip skipskip PR PR b b + += ( 18 ) Where SKIP2 ( X , Y ) is the number of skip-bigram matches between X and Y , ß controlling the relative importance of Pskip2 and Rskip2 , and C is the combination function .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiendum id="2">C</definiendum>
				<definiens id="0">a reference translation</definiens>
				<definiens id="1">a candidate translation</definiens>
			</definition>
			<definition id="11">
				<sentence>The overall candidate summary score is the average of the content coverage scores of all the units in the manual summary .</sentence>
				<definiendum id="0">overall candidate summary score</definiendum>
				<definiens id="0">the average of the content coverage scores of all the units in the manual summary</definiens>
			</definition>
</paper>

		<paper id="0839">
			<definition id="0">
				<sentence>This paper describes the SyntaLex entries in the English Lexical Sample Task of SENSEVAL-3 .</sentence>
				<definiendum id="0">SyntaLex entries</definiendum>
				<definiens id="0">in the English Lexical Sample Task of SENSEVAL-3</definiens>
			</definition>
			<definition id="1">
				<sentence>A bigram is a pair of words that occur close to each other in text and in a particular order .</sentence>
				<definiendum id="0">bigram</definiendum>
				<definiens id="0">a pair of words that occur close to each other in text and in a particular order</definiens>
			</definition>
			<definition id="2">
				<sentence>The nodes in the decision trees are features of form : Pa3a4a1 = a6 Taga7 , Pa0 = a6 Taga7 or Pa1 = a6 Taga7 , where a6 Taga7 represents any Part of Speech .</sentence>
				<definiendum id="0">a6 Taga7</definiendum>
				<definiens id="0">represents any Part of Speech</definiens>
			</definition>
			<definition id="3">
				<sentence>The Optimal Ensemble of bigrams and PoS features is the accuracy of a hypothetical ensemble that accurately disambiguates an instance when any of the two individual classifiers correctly disambiguates the intended sense .</sentence>
				<definiendum id="0">Optimal Ensemble</definiendum>
				<definiens id="0">the accuracy of a hypothetical ensemble that accurately disambiguates an instance when any of the two individual classifiers correctly disambiguates the intended sense</definiens>
			</definition>
</paper>

		<paper id="2601">
			<definition id="0">
				<sentence>2 3 A Snapshot of the OntoSem Environment OntoSem is a text-processing environment that takes as input unrestricted raw text and carries out preprocessing , morphological analysis , syntactic analysis , and semantic analysis , with the results of semantic analysis represented as formal text-meaning representations ( TMRs ) that can then be used as the basis for many applications .</sentence>
				<definiendum id="0">OntoSem Environment OntoSem</definiendum>
				<definiens id="0">a text-processing environment that takes as input unrestricted raw text and carries out preprocessing , morphological analysis , syntactic analysis , and semantic analysis</definiens>
			</definition>
			<definition id="1">
				<sentence>• An OntoSem lexicon for each language processed , which contains syntactic and semantic zones ( linked using variables ) as well as calls to “meaning procedures” ( i.e. , programs that carry out procedural semantics , see McShane et al. forthcoming ) when applicable .</sentence>
				<definiendum id="0">OntoSem lexicon</definiendum>
				<definiens id="0">contains syntactic and semantic zones ( linked using variables ) as well as calls to “meaning procedures” ( i.e. , programs that carry out procedural semantics</definiens>
			</definition>
			<definition id="2">
				<sentence>• A fact repository , which contains real-world facts represented as numbered “remembered instances” of ontological concepts ( e.g. , SPEECH-ACT-3366 is the 3366 th instantiation of the concept SPEECH-ACT in the world model constructed during the processing of some given text ( s ) ) .</sentence>
				<definiendum id="0">fact repository</definiendum>
				<definiendum id="1">SPEECH-ACT-3366</definiendum>
				<definiens id="0">contains real-world facts represented as numbered “remembered instances” of ontological concepts ( e.g. ,</definiens>
			</definition>
			<definition id="3">
				<sentence>HIRE AGENT sem SOCIAL-ROLE default BUSINESS-ROLE relaxable-to CORPORATION THEME sem SOCIAL-ROLE LOCATION sem PLACE default BUILDING The fillers for ontological properties can be specified on various facets , including : sem , which indicates typical selectional restrictions ; default , which indicates the de3 It is noteworthy that many elliptical phenomena permit matching at the conceptual rather than instance-based level .</sentence>
				<definiendum id="0">HIRE AGENT sem SOCIAL-ROLE</definiendum>
				<definiendum id="1">default</definiendum>
				<definiens id="0">indicates typical selectional restrictions</definiens>
			</definition>
			<definition id="4">
				<sentence>( Note that SOCIAL-ROLE is a child of HUMAN in the ontology . )</sentence>
				<definiendum id="0">SOCIAL-ROLE</definiendum>
				<definiens id="0">a child of HUMAN in the ontology</definiens>
			</definition>
			<definition id="5">
				<sentence>Among these recovery rules is the option to apply the semantics of a constituent to the nascent TMR without recourse to its syntactic function .</sentence>
				<definiendum id="0">TMR</definiendum>
				<definiens id="0">the option to apply the semantics of a constituent to the nascent</definiens>
			</definition>
			<definition id="6">
				<sentence>The semantic structure ( sem-struc ) is headed by an INVITE event , whose AGENT is the subject of the clause ( note the linked variables ) and whose theme is a MOTIONEVENT .</sentence>
				<definiendum id="0">semantic structure</definiendum>
				<definiendum id="1">AGENT</definiendum>
				<definiens id="0">the subject of the clause ( note the linked variables ) and whose theme is a MOTIONEVENT</definiens>
			</definition>
</paper>

		<paper id="0708">
</paper>

		<paper id="1119">
			<definition id="0">
				<sentence>Our experiments show that a relatively small seed set ( e.g. , 10 million characters , which takes approximately three weeks for 4 persons to annotate the NE tags ) is enough to get a good improved model for initialization .</sentence>
				<definiendum id="0">million characters</definiendum>
				<definiens id="0">takes approximately three weeks for 4 persons to annotate the NE tags ) is enough to get a good improved model for initialization</definiens>
			</definition>
			<definition id="1">
				<sentence>The segmenter provides a unified approach to word segmentation and named entity ( NE ) recognition .</sentence>
				<definiendum id="0">segmenter</definiendum>
				<definiens id="0">provides a unified approach to word segmentation and named entity ( NE ) recognition</definiens>
			</definition>
			<definition id="2">
				<sentence>“城” is the abbreviation of “城市 ( city ) ” .</sentence>
				<definiendum id="0">“城”</definiendum>
				<definiens id="0">the abbreviation of “城市 ( city ) ”</definiens>
			</definition>
</paper>

		<paper id="2117">
			<definition id="0">
				<sentence>The most famous example is WordNet ( Fellbaum , 1998 ) for English – which has been visualized already at http : //www.visualthesaurus.com – and its various sisters for other languages .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">has been visualized already at http : //www.visualthesaurus.com –</definiens>
			</definition>
			<definition id="1">
				<sentence>A disadvantage of LSA is the positioning of polysemous words at a position between the two extremes , i.e. between the two senses which makes the approach worthless for polysemous words in the data .</sentence>
				<definiendum id="0">disadvantage of LSA</definiendum>
				<definiens id="0">the positioning of polysemous words at a position between the two extremes , i.e. between the two senses which makes the approach worthless for polysemous words in the data</definiens>
			</definition>
</paper>

		<paper id="2307">
			<definition id="0">
				<sentence>Draft : Tutorial annotation scheme .</sentence>
				<definiendum id="0">Draft</definiendum>
			</definition>
</paper>

		<paper id="3113">
			<definition id="0">
				<sentence>A citation may be formally defined as a portion of a sentence in a citing document which references another document or a set of other documents collectively .</sentence>
				<definiendum id="0">citation</definiendum>
				<definiens id="0">a portion of a sentence in a citing document which references another document or a set of other documents collectively</definiens>
			</definition>
			<definition id="1">
				<sentence>A citation index enables efficient retrieval of documents from a large collection—a citation index consists of source items and their corresponding lists of bibliographic descriptions of citing works .</sentence>
				<definiendum id="0">citation index</definiendum>
				<definiens id="0">enables efficient retrieval of documents from a large collection—a citation index consists of source items and their corresponding lists of bibliographic descriptions of citing works</definiens>
			</definition>
			<definition id="2">
				<sentence>Style ( lexical and syntactic choice ) , presentation ( organization of the text and display of the data ) , and argumentation structure are noted as the rhetorical means by which authors build a convincing case for their results .</sentence>
				<definiendum id="0">Style</definiendum>
			</definition>
			<definition id="3">
				<sentence>Style ( lexical and syntactic choice ) , presentation ( organization of the text and display of the data ) , and argumentation structure were noted as the rhetorical means by which authors build a convincing case for their results .</sentence>
				<definiendum id="0">Style</definiendum>
			</definition>
			<definition id="4">
				<sentence>The purposeful nature of citation function is a feature of scientific writing which can be exploited in a variety of ways .</sentence>
				<definiendum id="0">citation function</definiendum>
				<definiens id="0">a feature of scientific writing which can be exploited in a variety of ways</definiens>
			</definition>
</paper>

		<paper id="2013">
			<definition id="0">
				<sentence>Text document clustering is the grouping of text documents into semantically related groups , or asHayesputsit , “they are grouped because they are likely to be wanted together” ( Hayes , 1963 ) .</sentence>
				<definiendum id="0">Text document clustering</definiendum>
			</definition>
			<definition id="1">
				<sentence>Salton et al. define the inverse document frequency idf as idf t =log 2 n − log 2 df t + 1 ( 1 ) where df t is the number of documents in which term t appears and n the total number of documents .</sentence>
				<definiendum id="0">inverse document frequency idf</definiendum>
				<definiendum id="1">df t</definiendum>
				<definiens id="0">the number of documents in which term t appears and n the total number of documents</definiens>
			</definition>
			<definition id="2">
				<sentence>We choose the cosine distance , which measures the similarity of two documents by calculating the cosine of the angle between them .</sentence>
				<definiendum id="0">cosine distance</definiendum>
			</definition>
			<definition id="3">
				<sentence>The cosine distance is defined as follows : s ( d i , d j ) =cos ( sphericalangle ( vector d i , vector d j ) ) = vector d i · vector d j | vector d i |·| vector d j | ( 3 ) where | vector d i | and | vector d j | are the lengths of vectors vector d i and vector d j , respectively , and vector d i · vector d j is the dotproduct of the two vectors .</sentence>
				<definiendum id="0">cosine distance</definiendum>
			</definition>
			<definition id="4">
				<sentence>Precision is the probability of a document in cluster C being labeled L. Purity is the percentage of correctly clustered documents and can be calculated as : purity ( C , L ) : = summationdisplay C∈C |C| |D| · max L∈L prec ( C , L ) ( 5 ) yielding values in the range between 0 and 1 .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the probability of a document in cluster C being labeled L. Purity is the percentage of correctly clustered documents and can be calculated as : purity ( C , L ) : = summationdisplay C∈C |C| |D| · max L∈L prec ( C , L ) ( 5 ) yielding values in the range between 0 and 1</definiens>
			</definition>
			<definition id="5">
				<sentence>The intra-cluster entropy ( ice ) of a cluster C , as described by Steinbach et al. ( 2000 ) , considers the dispersion of documents in a cluster , and is defined as : ice ( C ) : = summationdisplay L∈L prec ( C , L ) · log ( prec ( C , L ) ) ( 6 ) Based on the intra-cluster entropy of all clusters , the average , weighted by the cluster size , is calculated .</sentence>
				<definiendum id="0">intra-cluster entropy ( ice ) of a cluster C</definiendum>
			</definition>
			<definition id="6">
				<sentence>Overall similarity is the weighted average of the intra-cluster similarities of all clusters .</sentence>
				<definiendum id="0">Overall similarity</definiendum>
				<definiens id="0">the weighted average of the intra-cluster similarities of all clusters</definiens>
			</definition>
			<definition id="7">
				<sentence>If word-by-word disambiguation would be 0005al0005al0005alhype false false true true true false false true true true false false true true true syn false true true true true false true true true true false true true true true pos purity entropy similarity 16 32 64 clusters Figure 7 : Test Results for ‘reut-max100’ used , the correct sense of a word could be chosen and only the hypernyms for the correct sense of the word could be taken into account .</sentence>
				<definiendum id="0">Test Results</definiendum>
				<definiens id="0">false false true true true false false true true true false false true true true syn false true true true true false true true true true false true true true true pos purity entropy</definiens>
			</definition>
</paper>

		<paper id="0864">
</paper>

		<paper id="0816">
			<definition id="0">
				<sentence>Word Sense Disambiguation ( WSD ) is the task of deciding the appropriate sense for a particular use of a polysemous word , given its textual or discursive context .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
				<definiendum id="1">WSD</definiendum>
				<definiens id="0">the task of deciding the appropriate sense for a particular use of a polysemous word , given its textual or discursive context</definiens>
			</definition>
			<definition id="1">
				<sentence>The supervised UNED WSD system is an exemplar based classifier that performs the disambiguation task measuring the similarity between a new instance and the representation of some labelled examples .</sentence>
				<definiendum id="0">UNED WSD system</definiendum>
				<definiens id="0">an exemplar based classifier that performs the disambiguation task measuring the similarity between a new instance and the representation of some labelled examples</definiens>
			</definition>
			<definition id="2">
				<sentence>The training corpus is represented in the usual two-dimension matrix A as shown in Figure 1 , where • c1 , ... , cN is the set of examples or contexts in the training corpus .</sentence>
				<definiendum id="0">cN</definiendum>
				<definiens id="0">the set of examples or contexts in the training corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>• lem1 , ... , lemT is the set of different words or lemmas in all the training contexts .</sentence>
				<definiendum id="0">lemT</definiendum>
				<definiens id="0">the set of different words or lemmas in all the training contexts</definiens>
			</definition>
			<definition id="4">
				<sentence>More formally , vectorq = q.A = ( cos ( q , c1 ) , ... , cos ( q , cj ) , ... , cos ( q , cN ) ) where cos ( q , cj ) = Tsummationdisplay i=1 wiq bardblqbardbl wij bardblcjbardbl and bardblxbardbl = radicalBiggsummationdisplay i x2i At this point , both senses and the representation of the new instance vectorq are represented in the same context space ( Figure 2 ) and a similarity measure can be defined between them : sim ( vectorsenik , vectorq ) where senik is the k candidate sense for the ambiguous lemma lemi .</sentence>
				<definiendum id="0">senik</definiendum>
			</definition>
			<definition id="5">
				<sentence>idf weight where dfi is the number of contexts that contain lemi .</sentence>
				<definiendum id="0">dfi</definiendum>
				<definiens id="0">the number of contexts that contain lemi</definiens>
			</definition>
			<definition id="6">
				<sentence>We assign the weights wij and wiq to have vectorq a vector of co-occurrences , where qj is the number of different nouns and adjectives that co-occurr in q and the training context cj .</sentence>
				<definiendum id="0">qj</definiendum>
				<definiens id="0">the number of different nouns and adjectives that co-occurr in q and the training context cj</definiens>
			</definition>
			<definition id="7">
				<sentence>Multiwordnet : developing an aligned multilingual database .</sentence>
				<definiendum id="0">Multiwordnet</definiendum>
				<definiens id="0">developing an aligned multilingual database</definiens>
			</definition>
</paper>

		<paper id="1811">
</paper>

		<paper id="2404">
			<definition id="0">
				<sentence>Each of these meanings is referred to as a sense , and word sense disambiguation is the process of identifying the intended sense of a target word based on the context in which it is used .</sentence>
				<definiendum id="0">word sense disambiguation</definiendum>
				<definiens id="0">the process of identifying the intended sense of a target word based on the context in which it is used</definiens>
			</definition>
			<definition id="1">
				<sentence>The training data consists of sentences which have potential target words tagged by a human expert with their intended sense .</sentence>
				<definiendum id="0">data</definiendum>
				<definiens id="0">consists of sentences which have potential target words tagged by a human expert with their intended sense</definiens>
			</definition>
			<definition id="2">
				<sentence>The noun phrases ( the line ) have the verbs fasten and cross as the head of parent phrases .</sentence>
				<definiendum id="0">noun phrases</definiendum>
				<definiens id="0">the line</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , phrase housing the target word is a noun phrase , parent phrase is a verb phrase and so on .</sentence>
				<definiendum id="0">parent phrase</definiendum>
				<definiens id="0">a verb phrase and so on</definiens>
			</definition>
			<definition id="4">
				<sentence>posSenseval uses the Brill Tagger while parseSenseval employs the Collins Parser .</sentence>
				<definiendum id="0">posSenseval</definiendum>
				<definiendum id="1">Tagger</definiendum>
				<definiens id="0">uses the Brill</definiens>
			</definition>
			<definition id="5">
				<sentence>The Baseline Ensemble is the accuracy attained by a hypothetical ensemble technique which correctly disambiguates an instance only when both the classifiers identify the intended sense correctly .</sentence>
				<definiendum id="0">Baseline Ensemble</definiendum>
				<definiens id="0">the accuracy attained by a hypothetical ensemble technique</definiens>
			</definition>
			<definition id="6">
				<sentence>In effect , the Baseline Ensemble quantifies the redundancy among the two feature sets .</sentence>
				<definiendum id="0">Baseline Ensemble</definiendum>
				<definiens id="0">quantifies the redundancy among the two feature sets</definiens>
			</definition>
			<definition id="7">
				<sentence>The Optimal Ensemble is the accuracy of a hypothetical ensemble technique which accurately disambiguates an instance when any of the two classifiers correctly disambiguates the intended sense .</sentence>
				<definiendum id="0">Optimal Ensemble</definiendum>
				<definiens id="0">the accuracy of a hypothetical ensemble technique which accurately disambiguates an instance when any of the two classifiers correctly disambiguates the intended sense</definiens>
			</definition>
			<definition id="8">
				<sentence>Thus , the Optimal Ensemble is the upper bound to the accuracy achievable by combining the two feature sets using an ensemble technique .</sentence>
				<definiendum id="0">Optimal Ensemble</definiendum>
				<definiens id="0">the upper bound to the accuracy achievable by combining the two feature sets using an ensemble technique</definiens>
			</definition>
			<definition id="9">
				<sentence>If the accuracies of individual classifiers is X and Y , the Optimal Ensemble can be defined as follows : OptimalEnsemble = ( X −BaselineEnsemble ) + ( Y −BaselineEnsemble ) +BaselineEnsemble We use a simple ensemble technique to combine some of the best lexical and syntactic features identified in the previous sections .</sentence>
				<definiendum id="0">Optimal Ensemble</definiendum>
			</definition>
</paper>

		<paper id="3246">
			<definition id="0">
				<sentence>For each example , we define tp as the number of candidates correctly produced by the system ; fp as the number of candidates which are not correct roots ; and fn as the number of correct roots the system did not produce .</sentence>
				<definiendum id="0">fn</definiendum>
				<definiens id="0">the number of candidates correctly produced by the system</definiens>
			</definition>
			<definition id="1">
				<sentence>SNoW is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiens id="0">a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example</definiens>
			</definition>
</paper>

		<paper id="0834">
			<definition id="0">
				<sentence>The SVM ( Vapnik , 1995 ) performs optimization to find a hyperplane with the largest margin that separates training examples into two classes .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">performs optimization to find a hyperplane with the largest margin that separates training examples into two classes</definiens>
			</definition>
			<definition id="1">
				<sentence>Words We use 7 features to encode this knowledge source : a0a2a1a4a3a6a5a7a0a8a1a10a9a11a5a7a0a8a1a13a12a14a5a15a0a17a16a6a5a15a0a2a12a18a5a7a0a19a9a20a5a15a0a17a3 , where a0a8a1 a21 ( a0 a21 ) is the POS of thea6 th token to the left ( right ) ofa0 , and a0a17a16 is the POS of a0 .</sentence>
				<definiendum id="0">a0a17a16</definiendum>
				<definiens id="0">the POS of a0</definiens>
			</definition>
			<definition id="2">
				<sentence>, the POS feature vector is a22a24a23a26a25 a5 a27 a28a29a5 a25a30a25 a5 a25a31a25a30a32 a5a14a33a34a5a36a35a14a5a36a35a2a37 where a35 denotes the POS tag of a null token .</sentence>
				<definiendum id="0">POS feature vector</definiendum>
				<definiendum id="1">a35</definiendum>
				<definiens id="0">the POS tag of a null token</definiens>
			</definition>
			<definition id="3">
				<sentence>a35 , where a35 denotes a null token .</sentence>
				<definiendum id="0">a35</definiendum>
			</definition>
			<definition id="4">
				<sentence>Based on the official test keys released , the micro-averaged recall drops to 0.643 , which seems to suggest that the English sense is a helpful knowledge source for the translation and sense subtask .</sentence>
				<definiendum id="0">sense</definiendum>
				<definiens id="0">seems to suggest that the English</definiens>
				<definiens id="1">a helpful knowledge source for the translation and sense subtask</definiens>
			</definition>
</paper>

		<paper id="2413">
			<definition id="0">
				<sentence>We use a log-linear model as classifier , which defines the probability of a class a1 given an feature vector a2a3 as a4a6a5 a1a8a7 a2 a3a10a9a12a11a14a13 a15a17a16a19a18a21a20a23a22a25a24a27a26a28a24a30a29a32a31a34a33 a35a37a36 where a15 is a normalisation constant , a38 a18 a5a39a3a41a40 a1 a9 the value of feature a3 a18 for class a1 , and a42 a18 the weight assigned to a38 a18 .</sentence>
				<definiendum id="0">a15</definiendum>
				<definiens id="0">a normalisation constant</definiens>
			</definition>
			<definition id="1">
				<sentence>Argument identification is a binary decision for all sequences between LABEL ( semantic argument ) and NOLABEL ( no semantic argument ) , which allows us to pool the frequencies of all argument labels .</sentence>
				<definiendum id="0">Argument identification</definiendum>
				<definiendum id="1">NOLABEL</definiendum>
				<definiens id="0">a binary decision for all sequences between LABEL ( semantic argument</definiens>
				<definiens id="1">no semantic argument ) , which allows us to pool the frequencies of all argument labels</definiens>
			</definition>
			<definition id="2">
				<sentence>EM-based clustering , originally introduced for the induction of a semantically annotated lexicon ( Rooth et al. , 1999 ) , regards classes as hidden variables in the context of maximum likelihood estimation from incomplete data via the expectation maximisation algorithm .</sentence>
				<definiendum id="0">EM-based clustering</definiendum>
				<definiens id="0">hidden variables in the context of maximum likelihood estimation from incomplete data via the expectation maximisation algorithm</definiens>
			</definition>
</paper>

		<paper id="3231">
</paper>

		<paper id="1103">
</paper>

		<paper id="3255">
			<definition id="0">
				<sentence>WFST is a finite-state device in which output symbols and output weights are defined as well as input symbols .</sentence>
				<definiendum id="0">WFST</definiendum>
				<definiens id="0">a finite-state device in which output symbols and output weights are defined as well as input symbols</definiens>
			</definition>
			<definition id="1">
				<sentence>First , T model ( a68 ) translates the Japanese word to an English word .</sentence>
				<definiendum id="0">a68</definiendum>
				<definiens id="0">translates the Japanese word to an English word</definiens>
			</definition>
			<definition id="2">
				<sentence>NULL model ( a71 ) deletes special word NULL .</sentence>
				<definiendum id="0">NULL model</definiendum>
				<definiens id="0">deletes special word NULL</definiens>
			</definition>
			<definition id="3">
				<sentence>Fertility model ( a72 ) merges the same continuous words into one word .</sentence>
				<definiendum id="0">Fertility model</definiendum>
			</definition>
			<definition id="4">
				<sentence>If WFST a74 represents all permutations of the input sentence , decoding can be considered to search for the best path of a74 a69 a68 a69 a71 a69 a72 a69 a73 .</sentence>
				<definiendum id="0">WFST a74</definiendum>
				<definiens id="0">represents all permutations of the input sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>kaku tekisuto SGMLdeko-do ka sareruha each text encoded in SGMLNULL encoded encoded T Model ( T ) NULL Model ( N ) Fertility Model ( F ) Language Model ( L ) each text encoded in SGMLencoded encoded each text is in SGMLencoded each text is in SGMLencoded Figure 1 : Translation with WFST Cascade Model encoded : encoded/ n ( 1|encoded ) ε : encoded/ n ( 0|encoded ) encoded : encoded/ n ( 2|encoded ) encoded : ε/ n ( 3|encoded ) /n ( 2|encoded ) encoded : ε/ n ( 4|encoded ) /n ( 3|encoded ) encoded : ε/1.0 encoded : ε/1.0 encoded : ε/1.0 Figure 4 : Fertility Model However , the composed WFST for machine translation is not obviously determinizable .</sentence>
				<definiendum id="0">3|encoded ) /n</definiendum>
				<definiens id="0">encoded in SGMLNULL encoded encoded T Model ( T ) NULL Model ( N ) Fertility Model ( F ) Language Model ( L ) each text encoded in SGMLencoded encoded each text is in SGMLencoded each text is in SGMLencoded Figure 1 : Translation with WFST Cascade Model encoded : encoded/ n ( 1|encoded ) ε : encoded/ n ( 0|encoded ) encoded : encoded/ n ( 2|encoded ) encoded : ε/ n</definiens>
			</definition>
			<definition id="6">
				<sentence>a71 is the total number of hypothesis lists .</sentence>
				<definiendum id="0">a71</definiendum>
				<definiens id="0">the total number of hypothesis lists</definiens>
			</definition>
</paper>

		<paper id="2209">
			<definition id="0">
				<sentence>The JMdict XML structure contains one element type : &lt; entry &gt; , which in turn contains sequence number , kanji word , kana word , information and translation elements .</sentence>
				<definiendum id="0">JMdict XML structure</definiendum>
				<definiens id="0">contains one element type : &lt; entry &gt; , which in turn contains sequence number , kanji word , kana word , information and translation elements</definiens>
			</definition>
			<definition id="1">
				<sentence>The translation area consists of one or more sense elements that contain at a minimum a single gloss .</sentence>
				<definiendum id="0">translation area</definiendum>
				<definiens id="0">consists of one or more sense elements that contain at a minimum a single gloss</definiens>
			</definition>
			<definition id="2">
				<sentence>Closely related to the JMdict project is the Japanese-Multilingual Named Entity Dictionary ( JMnedict ) project .</sentence>
				<definiendum id="0">JMdict project</definiendum>
			</definition>
</paper>

		<paper id="2103">
			<definition id="0">
				<sentence>Linguistic knowledge , i.e. , the knowledge about linguistically relevant units of text and relations holding between them , is a particularly convenient way to enhance the distributional model .</sentence>
				<definiendum id="0">Linguistic knowledge</definiendum>
				<definiens id="0">the knowledge about linguistically relevant units of text and relations holding between them , is a particularly convenient way to enhance the distributional model</definiens>
			</definition>
			<definition id="1">
				<sentence>The lexical context permitting occurrence of the target word consists of words and phrases whose meanings have something to do with the meaning of the target word .</sentence>
				<definiendum id="0">lexical context permitting occurrence of the target word</definiendum>
				<definiens id="0">consists of words and phrases whose meanings have something to do with the meaning of the target word</definiens>
			</definition>
			<definition id="2">
				<sentence>The Naïve Bayes algorithm classifies a test instance n by finding a class c that maximizes p ( c|nr ) .</sentence>
				<definiendum id="0">Naïve Bayes algorithm</definiendum>
				<definiens id="0">classifies a test instance n by finding a class c that maximizes p ( c|nr )</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , in the sentence She bought a nice hat context words for hat are bought ( the head of the predicate-object relation ) and nice ( the attributive modifier ) .</sentence>
				<definiendum id="0">nice</definiendum>
				<definiens id="0">the head of the predicate-object relation</definiens>
			</definition>
</paper>

		<paper id="0844">
			<definition id="0">
				<sentence>During a generic iteration , the algorithm selects those terms t in P showing an interconnection between at least one sense S of t and one or more senses in I. The likelihood for a sense S of being the correct interpretation of t , given the semantic context I , is estimated by the function CxTf I : , where C is the set of all the concepts in the ontology O , defined as follows : = otherwise SynsetstSensesSifISSS tSf I 0 ) ( } ) '| ) ' , ( ( { ) , ( where Senses ( t ) is the subset of concepts C in O associated with the term t , and } ) ' ... | ) ... ( ( { ' ) ' , ( 1121 121 SSSSeeewSS nn e n eee n = , i.e. a function ( ’ ) of the weights ( w ) of each path connecting S with S’ , where S and S’ are represented by semantic graphs .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiendum id="1">, ( ( {</definiendum>
				<definiendum id="2">Senses ( t )</definiendum>
				<definiens id="0">selects those terms t in P showing an interconnection between at least one sense S of t and one or more senses in I. The likelihood for a sense S of being the correct interpretation of t , given the semantic context I , is estimated by the function CxTf I : , where C is the set of all the concepts in the ontology O , defined as follows : = otherwise SynsetstSensesSifISSS tSf I 0 ) ( } ) '| ) '</definiens>
				<definiens id="1">the subset of concepts C in O associated with the term t , and } ) ' ... | ) ... ( ( { '</definiens>
				<definiens id="2">SSSSeeewSS nn e n eee n = , i.e. a function ( ’ ) of the weights ( w ) of each path connecting S with S’ , where S and S’ are represented by semantic graphs</definiens>
			</definition>
			<definition id="1">
				<sentence>The terminal symbols ( E ) are edge labels , while the non-terminal symbols ( N ) encode ( sub ) paths between concepts ; S G is the start symbol of G and P G the set of its productions .</sentence>
				<definiendum id="0">S G</definiendum>
			</definition>
			<definition id="2">
				<sentence>We associate a weight with each production A in P G , where NA and * ) ( EN , i.e. is a sequence of terminal and non-terminal symbols .</sentence>
				<definiendum id="0">NA</definiendum>
				<definiendum id="1">i.e.</definiendum>
				<definiens id="0">a sequence of terminal and non-terminal symbols</definiens>
			</definition>
			<definition id="3">
				<sentence>6 ofkind object # 1 This leads to : I = { retrospective # 1 , statue # 1 , artist # 1 , exhibition # 2 , object # 1 , art # 1 } P = { work , life , selection , representative , painting } During the second iteration , a hyponymy/holonymy path ( rule S 2 ) is found : art # 1 2 kindhas painting # 1 ( painting is a kind of art ) which leads to : I = { retrospective # 1 , statue # 1 , artist # 1 , exhibition # 2 , object # 1 , art # 1 , painting # 1 } P = { work , life , selection , representative } The third iteration finds a co-occurrence ( topic rule ) path between artist # 1 and sense 12 of life ( biography , life history ) : artist # 1 topic life # 12 then , we get : I = { retrospective # 1 , statue # 1 , artist # 1 , exhibition # 2 , object # 1 , art # 1 , painting # 1 , life # 12 } P = { work , selection , representative } The algorithm stops because no additional matches are found .</sentence>
				<definiendum id="0">painting</definiendum>
				<definiens id="0">a kind of art</definiens>
			</definition>
			<definition id="4">
				<sentence>The main run , named OntoLearn , uses a threshold to select only those senses with a weight over a given threshold .</sentence>
				<definiendum id="0">OntoLearn</definiendum>
				<definiens id="0">uses a threshold to select only those senses with a weight over a given threshold</definiens>
			</definition>
			<definition id="5">
				<sentence>OntoLearnEx uses a nongreedy version of the SSI algorithm .</sentence>
				<definiendum id="0">OntoLearnEx</definiendum>
			</definition>
</paper>

		<paper id="2506">
			<definition id="0">
				<sentence>Q/A is an Information Retrieval ( IR ) paradigm that returns a short list of answers , extracted from relevant documents , to a question formulated in natural language .</sentence>
				<definiendum id="0">Q/A</definiendum>
				<definiens id="0">an Information Retrieval ( IR ) paradigm that returns a short list of answers , extracted from relevant documents , to a question formulated in natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>Name Entity ( NE ) recognition is a natural language technology that identifies names of people , organizations , locations and dates or monetary values .</sentence>
				<definiendum id="0">Name Entity ( NE ) recognition</definiendum>
				<definiens id="0">a natural language technology that identifies names of people , organizations , locations and dates or monetary values</definiens>
			</definition>
			<definition id="2">
				<sentence>Rocchio and Support Vector Machines are both based on the Vector Space Model .</sentence>
				<definiendum id="0">Support Vector Machines</definiendum>
				<definiens id="0">both based on the Vector Space Model</definiens>
			</definition>
			<definition id="3">
				<sentence>In this approach , the document d is described as a vector ~d = &lt; wdf1 ; : : ; wdfjFj &gt; in a jFjdimensional vector space , where F is the adopted set of features .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">the adopted set of features</definiens>
			</definition>
			<definition id="4">
				<sentence>Their difference is the learning algorithm to evaluate the b and the~a parameters : the former uses a simple heuristic while the second solves an optimization problem .</sentence>
				<definiendum id="0">the~a parameters</definiendum>
				<definiens id="0">the former uses a simple heuristic while the second solves an optimization problem</definiens>
			</definition>
			<definition id="5">
				<sentence>The parameters ~a is evaluated by the equation : ~af = max ( 0 ; 1jPj X d2P wdf ¡ ‰j¯Pj X d2¯P wdf ) ( 3 ) where P is the set of training documents that belongs to C and ‰ is a parameter that emphasizes the negative information .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">the set of training documents that belongs to C and ‰ is a parameter that emphasizes the negative information</definiens>
			</definition>
			<definition id="6">
				<sentence>1 ) of the word frequency f in the question q , together with the IDF derived from training documents as follows : wqf = l q f £IDF ( f ) qP r2Fq ( l qr £IDF ( r ) ) 2 ( 5 ) This weighting mechanism uses the Inverse Document Frequency ( IDF ) of features instead of computing the Inverse Question Frequency .</sentence>
				<definiendum id="0">l qr £IDF</definiendum>
				<definiens id="0">uses the Inverse Document Frequency ( IDF ) of features instead of computing the Inverse Question Frequency</definiens>
			</definition>
			<definition id="7">
				<sentence>The Mean Reciprocal Answer Rank ( MRAR ) is used to compute the overall performance of Q/A systems8 , defined as MRAR = 1n Pi 1ranki , where n is the number of questions and ranki is the rank of the answer i. Since we believe that TC information is meaningful to prefer out incorrect answers , we defined a second measure to evaluate Q/A .</sentence>
				<definiendum id="0">Mean Reciprocal Answer Rank ( MRAR</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">ranki</definiendum>
				<definiens id="0">the number of questions</definiens>
			</definition>
			<definition id="8">
				<sentence>For this purpose we designed the Signed Reciprocal Answer Rank ( SRAR ) , which is defined as 1n Pj2A 1srankj , where A is the set of answers given for the test-set questions , jsrankjj is the rank position of the answer j and srankj is positive if j is correct and negative if it is not correct .</sentence>
				<definiendum id="0">Signed Reciprocal Answer Rank ( SRAR )</definiendum>
				<definiendum id="1">A</definiendum>
				<definiendum id="2">jsrankjj</definiendum>
				<definiens id="0">the set of answers given for the test-set questions ,</definiens>
			</definition>
</paper>

		<paper id="2309">
			<definition id="0">
				<sentence>The practical utility of distinguishing these relations arises from discovering ways in which to both represent and utilise this information for NLG ( among other applications ) , so we will address these issues in section et al. , 2000 ) representing the state of the dialogue in the PTT ( Poesio and Traum , 1998 ) model of dialogue must be updated to reflect this new information , with Conversational Acts ( Matheson et al. , 2000 ) that do not simply indicate DofE as in ( Thomas and Matheson , 2003 ) , but also annotate the relation underlying the expectation being denied .</sentence>
				<definiendum id="0">PTT ( Poesio</definiendum>
				<definiens id="0">but also annotate the relation underlying the expectation being denied</definiens>
			</definition>
			<definition id="1">
				<sentence>where B1 involves an expectation similar to the one above involving beautiful people marrying , namely , that adding vinegar makes things tangy , which is a general causeeffect relationship .</sentence>
				<definiendum id="0">B1</definiendum>
				<definiens id="0">involves an expectation similar to the one above involving beautiful people marrying</definiens>
			</definition>
			<definition id="2">
				<sentence>Knott presents a taxonomy of cue phrases distinguished as feature-theoretic constructs rather than markers of one or more of a set of rhetorical relations as postulated in RST .</sentence>
				<definiendum id="0">Knott</definiendum>
				<definiens id="0">presents a taxonomy of cue phrases distinguished as feature-theoretic constructs rather than markers of one or more of a set of rhetorical relations as postulated in RST</definiens>
			</definition>
</paper>

		<paper id="1305">
			<definition id="0">
				<sentence>The current experiment demonstrates how the model generalizes to a number of new and different relative phrases , as well as additional sentence types including : conjoined ( John took the key and opened the door ) , reflexive ( The boy said that the dog was chased by the cat ) , and reflexive pronoun ( The block said that it pushed the cylinder ) sentence types , for a total of 38 distinct abstract grammatical constructions .</sentence>
				<definiendum id="0">reflexive pronoun</definiendum>
				<definiens id="0">conjoined ( John took the key and opened the door</definiens>
			</definition>
			<definition id="1">
				<sentence>A lexical categorization error consists of a given word being assigned to the wrong category and processed as such ( e.g. an open class word being processed as a closed class word , or vice-versa ) .</sentence>
				<definiendum id="0">lexical categorization error</definiendum>
				<definiens id="0">consists of a given word being assigned to the wrong category and processed as such ( e.g. an open class word being processed as a closed class word , or vice-versa )</definiens>
			</definition>
</paper>

		<paper id="0508">
			<definition id="0">
				<sentence>Terminology is a major obstacle for processing research papers and at the same time a key access path to the knowledge encoded in those papers .</sentence>
				<definiendum id="0">Terminology</definiendum>
				<definiens id="0">a major obstacle for processing research papers and at the same time a key access path to the knowledge encoded in those papers</definiens>
			</definition>
			<definition id="1">
				<sentence>Terminology provides the means to name and access domain-specific concepts and objects .</sentence>
				<definiendum id="0">Terminology</definiendum>
				<definiens id="0">provides the means to name and access domain-specific concepts and objects</definiens>
			</definition>
			<definition id="2">
				<sentence>While open domain Question Answering systems typically are targeted at large text collections and use relatively little linguistic information , ExtrAns answers questions over such domains by exploiting linguistic knowledge from the documents and terminological knowledge about a specific domain .</sentence>
				<definiendum id="0">ExtrAns</definiendum>
				<definiens id="0">answers questions over such domains by exploiting linguistic knowledge from the documents and terminological knowledge about a specific domain</definiens>
			</definition>
			<definition id="3">
				<sentence>Various applications of the ExtrAns system have been developed , from the original prototype aimed at the Unix documentation files ( Moll´a et al. , 2000 ) to a version targeting the Aircraft Maintenance Manuals ( AMM ) of the Airbus A320 ( Moll´a et al. , 2003 ; Rinaldi et al. , 2004 ) .</sentence>
				<definiendum id="0">Unix documentation files</definiendum>
			</definition>
			<definition id="4">
				<sentence>The GENIA corpus removes these problems completely by providing pre-annotated terminological units .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">removes these problems completely by providing pre-annotated terminological units</definiens>
			</definition>
			<definition id="5">
				<sentence>The organizing unit is the WordNet style synset which includes strict synonymy as well as three weaker synonymy relations .</sentence>
				<definiendum id="0">organizing unit</definiendum>
				<definiens id="0">includes strict synonymy as well as three weaker synonymy relations</definiens>
			</definition>
			<definition id="6">
				<sentence>The tokenizer detects the terms ( previously collected in the Thesaurus ) as they appear in the input stream , and packs them into single lexical tokens prior to syntactical analysis , assigning them the syntactic properties of their head word .</sentence>
				<definiendum id="0">tokenizer</definiendum>
				<definiens id="0">detects the terms ( previously collected in the Thesaurus ) as they appear in the input stream , and packs them into single lexical tokens prior to syntactical analysis , assigning them the syntactic properties of their head word</definiens>
			</definition>
			<definition id="7">
				<sentence>The PubMed4 system uses the UMLS to relate metathesaurus concepts against a controlled vocabulary used to index the abstracts .</sentence>
				<definiendum id="0">PubMed4 system</definiendum>
			</definition>
</paper>

		<paper id="2102">
			<definition id="0">
				<sentence>The classifier is either ‘Sem’ , in which case the explanation is to be interpreted as a substitutive definition , or else it is a field label in some encyclopedic classification , such as ‘Myth’ for mythological entries , ‘Phil’ for philosophical entries , etc. , in which case the explanation is merely a gloss in natural language .</sentence>
				<definiendum id="0">‘Phil’</definiendum>
				<definiens id="0">philosophical entries , etc. , in which case the explanation is merely a gloss in natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>One , called external sandhi , is a regular homomorphism operating on the two strings representing two contiguous words in the stream of speech .</sentence>
				<definiendum id="0">external sandhi</definiendum>
				<definiens id="0">a regular homomorphism operating on the two strings representing two contiguous words in the stream of speech</definiens>
			</definition>
			<definition id="2">
				<sentence>Verb formation ( which sequences of preverbs are allowed to prefix which root ) is explicit in the dictionary structure , but it is also treated at the level of the segmentation algorithm , since this affix glueing obeys external sandhi and not internal sandhi , a peculiarity which may follow from the historical development of the language ( preverbs derive from postpositions ) .</sentence>
				<definiendum id="0">Verb formation</definiendum>
			</definition>
			<definition id="3">
				<sentence>pibati ( a cat drinks milk ) has one possible segmentation , where maarjaras , nominative singular masculine of maarjara ( and here the stem is a hyperlink to the entry in the lexicon glosing it as chat i.e. cat ) combines by external sandhi with the following word by rewriting into maarjaro , followed by dugdham which is the accusative singular masculine of dugdha ( draught ) or the accusative or nominative singular neuter of dugdha ( milk same vocable ) , which combines by external sandhi with the following word by rewriting into its nasalisation dugdham .</sentence>
				<definiendum id="0">dugdha</definiendum>
				<definiens id="0">a hyperlink to the entry in the lexicon glosing it as chat i.e. cat</definiens>
				<definiens id="1">the accusative singular masculine of dugdha ( draught ) or the accusative or nominative singular neuter of</definiens>
			</definition>
</paper>

		<paper id="1805">
</paper>

		<paper id="0845">
			<definition id="0">
				<sentence>Semantic Role Labeling ( SRL ) is a task that has recently received a lot of attention in the NLP community .</sentence>
				<definiendum id="0">Semantic Role Labeling ( SRL )</definiendum>
			</definition>
			<definition id="1">
				<sentence>Recall Attempted Single Model 0.891 0.795 89.2 % Frame Separated 0.894 0.798 89.2 % Baseline 0.444 0.396 89.2 % Table 1 : Boosting Models : Validation Set Results ments boosting on top of decision stumps ( decision trees of one level ) , and was originally designed for text classification .</sentence>
				<definiendum id="0">Boosting Models</definiendum>
				<definiens id="0">decision trees of one level ) , and was originally designed for text classification</definiens>
			</definition>
			<definition id="2">
				<sentence>Recall Attempted svm , boosting , maxent ( bin ) svm , boosting , maxent ( bin ) , snow svm , boosting , maxent ( bin ) , DL svm , boosting , maxent ( multi ) , DL , snow Baseline 0.444 0.396 89.2 % Table 6 : Combined Models : Validation Set Results The top-performing system is the combined system that uses the SVM , boosting and the binary implementation of maximum entropy .</sentence>
				<definiendum id="0">Combined Models</definiendum>
				<definiens id="0">the combined system that uses the SVM , boosting and the binary implementation of maximum entropy</definiens>
			</definition>
</paper>

		<paper id="2304">
			<definition id="0">
				<sentence>Computer games is an interesting application for spoken and multimodal dialogue systems .</sentence>
				<definiendum id="0">Computer games</definiendum>
				<definiens id="0">an interesting application for spoken and multimodal dialogue systems</definiens>
			</definition>
			<definition id="1">
				<sentence>Spoken dialogue systems have so far mostly been designed with an overall goal to carry out a specific task , e.g. accessing time table information or ordering tickets ( e.g. Zue et al. 1991 ; Aust et al. 1995 ) .</sentence>
				<definiendum id="0">Spoken dialogue systems</definiendum>
				<definiens id="0">have so far mostly been designed with an overall goal to carry out a specific task , e.g. accessing time table information or ordering tickets</definiens>
			</definition>
			<definition id="2">
				<sentence>Interactivity has been defined as “a kind of drama where the audience can modify the course of the actions [ … ] thus having an active role” ( Szilas 1999 ) .</sentence>
				<definiendum id="0">Interactivity</definiendum>
			</definition>
</paper>

		<paper id="2806">
			<definition id="0">
				<sentence>Mental spaces ( Fauconnier , 1985 ) are partial cognitive structures built up during discourse that keep track of entities and relations in different contexts .</sentence>
				<definiendum id="0">Mental spaces</definiendum>
				<definiens id="0">partial cognitive structures built up during discourse that keep track of entities and relations in different contexts</definiens>
			</definition>
			<definition id="1">
				<sentence>Mental spaces provide an important partitioning of contextual knowledge that allows scalable reasoning in a partitioned large knowledge base .</sentence>
				<definiendum id="0">Mental spaces</definiendum>
				<definiens id="0">an important partitioning of contextual knowledge that allows scalable reasoning in a partitioned large knowledge base</definiens>
			</definition>
			<definition id="2">
				<sentence>The Eiffel Tower is the only entity local to this DepictionSpace , and it maps to the physical Eiffel Tower .</sentence>
				<definiendum id="0">Eiffel Tower</definiendum>
				<definiens id="0">the only entity local to this DepictionSpace , and it maps to the physical Eiffel Tower</definiens>
			</definition>
			<definition id="3">
				<sentence>Schemas are the basic ECG unit of meaning , capturing embodied concepts such as image schemas , actions , and events .</sentence>
				<definiendum id="0">Schemas</definiendum>
				<definiens id="0">the basic ECG unit of meaning , capturing embodied concepts such as image schemas , actions , and events</definiens>
			</definition>
			<definition id="4">
				<sentence>The evokes relation is neither a subcase-of or part-of relation , but is analogous to spreading activation in the neural sense .</sentence>
				<definiendum id="0">relation</definiendum>
				<definiens id="0">neither a subcase-of or part-of relation , but is analogous to spreading activation in the neural sense</definiens>
			</definition>
			<definition id="5">
				<sentence>Simulation is a dynamic process which includes executing the X-schemas specified in the SemSpec and propagating belief updates in a belief network .</sentence>
				<definiendum id="0">Simulation</definiendum>
				<definiens id="0">a dynamic process which includes executing the X-schemas specified in the SemSpec and propagating belief updates in a belief network</definiens>
			</definition>
			<definition id="6">
				<sentence>Local-content provides the local semantics of mental spaces , maintaining a list of predications that are true in this space , ceteris paribus .</sentence>
				<definiendum id="0">Local-content</definiendum>
				<definiens id="0">provides the local semantics of mental spaces , maintaining a list of predications that are true in this space</definiens>
			</definition>
			<definition id="7">
				<sentence>Cause-Effect is a predication that contains a pointer to a Mental-Space The condition , often preceding the conclusion in a conditional statement , sets up or locates the space in which the conclusion is to be placed .</sentence>
				<definiendum id="0">Cause-Effect</definiendum>
				<definiens id="0">a predication that contains a pointer to a Mental-Space The condition , often preceding the conclusion in a conditional statement , sets up or locates the space in which the conclusion is to be placed</definiens>
			</definition>
			<definition id="8">
				<sentence>The abstract construction Conditional-Conjunction is a supertype of lexical constructions If and other conditionals conjunctions .</sentence>
				<definiendum id="0">abstract construction Conditional-Conjunction</definiendum>
			</definition>
			<definition id="9">
				<sentence>CONSTRUCTION Conditional-Statement CONSTRUCTIONAL cond : Condition statement : Clause MEANING cond .</sentence>
				<definiendum id="0">CONSTRUCTION Conditional-Statement CONSTRUCTIONAL</definiendum>
				<definiens id="0">Condition statement : Clause MEANING cond</definiens>
			</definition>
			<definition id="10">
				<sentence>Our proposed formalization of mental spaces allows systems to be scalable in both size and semantic depth : ( i ) Our formalization makes explicit how mental spaces partition contextual knowledge into manageable chunks , Parent-Space Local-content alternatives neutral neutral epistemic-stance : neutral condition alt : Conditional-Schema parent-space : ums conclusion : Game will not be cancelled premise : It does n't rain tomorrow ~1 status ~2 epistemic-stance : neutral condition : It rains tomorrow cond : Conditional-Schema parent-space : Focus-Space ( Base ) ums conclusion : Game will be cancelled premise : It rains tomorrow status 1 1 2 predicted-event : Game will be cancelled Prediction-Schema basis-of-prediction likelihood-of-prediction 2 alt .</sentence>
				<definiendum id="0">Conditional-Schema parent-space</definiendum>
				<definiens id="0">semantic depth : ( i ) Our formalization makes explicit how mental spaces partition contextual knowledge into manageable chunks</definiens>
			</definition>
			<definition id="11">
				<sentence>( iv ) CPRM provides a tightly coupled , scalable inference mechanism that handles the couplings between mental spaces .</sentence>
				<definiendum id="0">CPRM</definiendum>
				<definiens id="0">provides a tightly coupled , scalable inference mechanism that handles the couplings between mental spaces</definiens>
			</definition>
</paper>

		<paper id="3101">
			<definition id="0">
				<sentence>We apply it to five molecular biology EI and information extraction systems : ABGene ( Tanabe and Wilbur 2002a , Tanabe and Wilbur 2002b ) ; KeX/PROPER ( Fukuda et al. 1997 ) ; Yapex ( Franzén et al. 2002 ) ; the stochastic POS tagging-based system described in Cohen et al. ( in submission ) ; and the entity identification component of Ono et al.’s information extraction system ( Ono et al. 2001 ) , and show how it gives detailed useful information about each that is not apparent from the standard metrics and that is not documented in the cited publications .</sentence>
				<definiendum id="0">information extraction</definiendum>
				<definiendum id="1">Yapex</definiendum>
				<definiens id="0">the stochastic POS tagging-based system described in Cohen et al. ( in submission ) ; and the entity identification component of Ono et al.’s information extraction system ( Ono et al. 2001 ) , and show how it gives detailed useful information</definiens>
			</definition>
			<definition id="1">
				<sentence>A catalogue is a list of test conditions , or qualities of particular test inputs ( Marick 1997 ) .</sentence>
				<definiendum id="0">catalogue</definiendum>
			</definition>
			<definition id="2">
				<sentence>ID : 136 name_vs_symbol : n length : 3 case : a contains_a_numeral : y contains_Arabic_numeral : y Arabic_numeral_position : f contains_Roman_numeral : &lt; several typographic features omitted &gt; contains_punctuation : 1 contains_hyphen : 1 contains_forward_slash : &lt; several punctuation-related features omitted &gt; contains_function_word : function_word_position : contains_past_participle : 1 past_participle_position : i contains_present_participle : present_participle_position : source_authority : HGNC ID : 2681 `` Approved Gene Name '' field original_form_in_source : death-associated protein 6 data : death-associated protein 6 Figure 1 A representative entry from the entity data file .</sentence>
				<definiendum id="0">y Arabic_numeral_position</definiendum>
				<definiens id="0">death-associated protein 6 data : death-associated protein 6 Figure 1 A representative entry from the entity data file</definiens>
			</definition>
			<definition id="3">
				<sentence>However , Boolean queries over the separate feature sets let them be manipulated and queried independently .</sentence>
				<definiendum id="0">Boolean</definiendum>
				<definiens id="0">queries over the separate feature sets let them be manipulated and queried independently</definiens>
			</definition>
			<definition id="4">
				<sentence>The aim of the present study is to evaluate the impact on QoL… where QoL is an abbreviation for quality of life .</sentence>
				<definiendum id="0">QoL</definiendum>
				<definiens id="0">an abbreviation for quality of life</definiens>
			</definition>
</paper>

		<paper id="0609">
			<definition id="0">
				<sentence>FOCAL contains a large-screen ( 150° ) semi-immersive virtual reality environment as its primary display , allowing vast quantities of information ( real or virtual ) to be displayed .</sentence>
				<definiendum id="0">FOCAL</definiendum>
			</definition>
			<definition id="1">
				<sentence>Spoken dialogue with virtual characters known as VAs ( Virtual Advisers ) is one of the means of delivering information ( Estival et al. , 2003 ) .</sentence>
				<definiendum id="0">Spoken dialogue with virtual characters</definiendum>
				<definiendum id="1">VAs ( Virtual Advisers</definiendum>
			</definition>
			<definition id="2">
				<sentence>RDF provides some semantics , but proper , formal semantics requires languages based on logics .</sentence>
				<definiendum id="0">RDF</definiendum>
				<definiens id="0">provides some semantics , but proper , formal semantics requires languages based on logics</definiens>
			</definition>
			<definition id="3">
				<sentence>A commonly used view of an architecture for the Semantic Web is a layered architecture , with XML as the bottom layer , RDF as the middle layer , and logic ( e.g. DL ) as the top layer ( sometimes the top layer distinguishes ontological vocabulary , logic , proof ; on top of the logic layer a trust layer is sometimes placed ) .</sentence>
				<definiendum id="0">commonly used view of an architecture for the Semantic Web</definiendum>
				<definiendum id="1">logic</definiendum>
				<definiens id="0">a layered architecture , with XML as the bottom layer</definiens>
			</definition>
			<definition id="4">
				<sentence>SHIQ is one such language , another is the closely related language OWL The ontological language chosen for FOCAL is SHIQ , a DL language of the DAML+OIL project ( http : //www.daml.org/ ) , a successor of the OIL project ( http : //www.ontoknowledge , org/oil/ ) .</sentence>
				<definiendum id="0">SHIQ</definiendum>
				<definiens id="0">one such language , another is the closely related language OWL The ontological language chosen for FOCAL is SHIQ , a DL language of the DAML+OIL project</definiens>
			</definition>
			<definition id="5">
				<sentence>FaCT ( http : //www.cs.man.ac.uk/~horrocks/FaCT/ ) is a reasoner for the SHIQ logic employed in the OilEd ontology editor ( http : //oiled.man.ac.uk/ ) .</sentence>
				<definiendum id="0">FaCT ( http</definiendum>
				<definiens id="0">a reasoner for the SHIQ logic employed in the OilEd ontology editor ( http : //oiled.man.ac.uk/ )</definiens>
			</definition>
			<definition id="6">
				<sentence>Multiple facts involving n-ary relation and higherorder relation are present in the current version of the FOCAL ontology .</sentence>
				<definiendum id="0">Multiple facts</definiendum>
				<definiens id="0">involving n-ary relation and higherorder relation are present in the current version of the FOCAL ontology</definiens>
			</definition>
			<definition id="7">
				<sentence>For instance , we show in ( 1 ) an example of a query as to whether ( the individual ) AUSTRALIA is an instance of ( the concept ) nation , and give the server 's answer to that query , i.e. T ( for true ) .</sentence>
				<definiendum id="0">AUSTRALIA</definiendum>
				<definiens id="0">an instance of ( the concept ) nation , and give the server 's answer to that query</definiens>
			</definition>
			<definition id="8">
				<sentence>AUSTRALIA nation ) T A DL-based ontology , such as our OilEd `` Focal '' ontology , is a knowledge base ( KB ) expressed in a DL language .</sentence>
				<definiendum id="0">AUSTRALIA nation ) T A DL-based ontology</definiendum>
				<definiens id="0">a knowledge base ( KB ) expressed in a DL language</definiens>
			</definition>
			<definition id="9">
				<sentence>The Internal Reasoning Agents comprise : The Output Agents comprise : • Transcriber The Transcriber agent receives notification of user 's communicative acts from IF and of the system 's communicative acts from DM .</sentence>
				<definiendum id="0">Internal Reasoning Agents comprise</definiendum>
				<definiens id="0">Transcriber agent receives notification of user 's communicative acts from IF and of the system 's communicative acts from DM</definiens>
			</definition>
			<definition id="10">
				<sentence>Secondly , an ontology is a knowledge base ( KB ) , expressed in a formal language , and therefore it provides ( formally expressed ) knowledge for more complex language processing .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">a knowledge base ( KB ) , expressed in a formal language , and therefore it provides ( formally expressed ) knowledge for more complex language processing</definiens>
			</definition>
</paper>

		<paper id="3219">
			<definition id="0">
				<sentence>Multisequence alignment ( MSA ) is used to identify sentences that share formal ( and presumably semantic ) properties .</sentence>
				<definiendum id="0">Multisequence alignment</definiendum>
				<definiendum id="1">MSA</definiendum>
			</definition>
			<definition id="1">
				<sentence>A word alignment A of S and T can be expressed as a function from each of the source and target tokens to a unique cept ( Brown et al. 1993 ) ; isomorphically , a cept represents an aligned subset of the source and target tokens .</sentence>
				<definiendum id="0">cept</definiendum>
				<definiens id="0">represents an aligned subset of the source and target tokens</definiens>
			</definition>
			<definition id="2">
				<sentence>This algorithm reduces easily to the Viterbi algorithm ; such a dynamic programming approach guarantees an efficient optimal search ( worst case O ( kn ) , where n is the maximal target length and k is the maximal number of replacements for any word ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the maximal target length and k is the maximal number of replacements for any word )</definiens>
			</definition>
</paper>

		<paper id="3237">
			<definition id="0">
				<sentence>The probability assignment is done according to : P ( T|W ) = n productdisplay i=1 P ( t i |x i ( W , T i−1 1 ) ) where t i is the tag corresponding to word i and x i ( W , T i−1 1 ) is the conditioning information at position i in the word sequence on which the probability model is built .</sentence>
				<definiendum id="0">probability assignment</definiendum>
			</definition>
			<definition id="1">
				<sentence>By way of example , the event associated with the first word in the example in Section 2 is ( *bdw* denotes a special boundary type ) : MXC 1 currentword=primetime previousword=*bdw* nextword=continues t1=*bdw* t1,2=*bdw* , *bdw* prefix1=p prefix2=pr prefix3=pri suffix1=e suffix2=me suffix3=ime The maximum entropy probability model P ( y|x ) uses features which are indicator functions of the type : f ( y , x ) = { 1 , 0 , if y = MXC and x.w i = primetime o/w Assuming a set of features F whose cardinality is F , the probability assignment is made according to : p Λ ( y|x ) =Z −1 ( x , Λ ) · exp bracketleftBigg F summationdisplay i=1 λ i f i ( x , y ) bracketrightBigg Z ( x , Λ ) = summationdisplay y exp bracketleftBigg F summationdisplay i=1 λ i f i ( x , y ) bracketrightBigg where Λ= { λ 1 ... λ F } ∈R F is the set of realvalued model parameters .</sentence>
				<definiendum id="0">probability assignment</definiendum>
				<definiens id="0">a special boundary type ) : MXC 1 currentword=primetime previousword=*bdw* nextword=continues t1=*bdw* t1,2=*bdw* , *bdw* prefix1=p prefix2=pr prefix3=pri suffix1=e suffix2=me suffix3=ime The maximum entropy probability model P ( y|x ) uses features which are indicator functions of the type</definiens>
			</definition>
</paper>

		<paper id="2708">
			<definition id="0">
				<sentence>The Prague Czech-English Dependency Treebank ( PCEDT ) is a new syntactically annotated Czech-English parallel resource .</sentence>
				<definiendum id="0">Prague Czech-English Dependency Treebank ( PCEDT )</definiendum>
				<definiens id="0">a new syntactically annotated Czech-English parallel resource</definiens>
			</definition>
			<definition id="1">
				<sentence>The Prague Czech-English Dependency Treebank ( PCEDT ) is a project of creating a Czech-English syntactically annotated parallel corpus motivated by research in the field of machine translation .</sentence>
				<definiendum id="0">Prague Czech-English Dependency Treebank ( PCEDT )</definiendum>
			</definition>
			<definition id="2">
				<sentence>Since Czech is a language with relatively high degree of word-order freedom , and its sentences contain certain syntactic phenomena , such as discontinuous constituents ( non-projective constructions ) , which can not be straightforwardly handled using the annotation scheme of Penn Treebank ( Marcus et al. , 1993 ; Linguistic Data Consortium , 1999 ) , based on phrase-structure trees , we decided to adopt for the PCEDT the dependency-based annotation scheme of the Prague Dependency Treebank – PDT ( Linguistic Data Consortium , 2001 ) .</sentence>
				<definiendum id="0">Czech</definiendum>
				<definiens id="0">a language with relatively high degree of word-order freedom , and its sentences contain certain syntactic phenomena</definiens>
			</definition>
			<definition id="3">
				<sentence>The PDT is annotated on three levels : morphological layer ( lowest ) , analytic layer ( middle ) – surface syntactic annotation , and tectogrammatical layer ( highest ) – level of linguistic meaning .</sentence>
				<definiendum id="0">PDT</definiendum>
				<definiens id="0">annotated on three levels : morphological layer ( lowest ) , analytic layer ( middle ) – surface syntactic annotation</definiens>
			</definition>
			<definition id="4">
				<sentence>Lemmatization of English Czech is an inflective language , rich in morphology , therefore lemmatization ( assigning base forms ) is indispensable in almost any linguistic application .</sentence>
				<definiendum id="0">Czech</definiendum>
				<definiens id="0">an inflective language , rich in morphology</definiens>
			</definition>
			<definition id="5">
				<sentence>Because the handling of coordination in PDT is different from the Penn Treebank annotation style and the output of Jason Eisner’s head assigning scripts , in the case of a phrase containing a coordinating conjunction ( CC ) , we consider the rightmost CC as the head .</sentence>
				<definiendum id="0">CC</definiendum>
				<definiens id="0">of a phrase containing a coordinating conjunction</definiens>
			</definition>
			<definition id="6">
				<sentence>However , functional ( synsemantic ) words , such as prepositions , punctuation marks , determiners , subordinating conjunctions , certain particles , auxiliary and modal verbs are handled differently .</sentence>
				<definiendum id="0">functional ( synsemantic</definiendum>
				<definiens id="0">such as prepositions , punctuation marks , determiners , subordinating conjunctions , certain particles , auxiliary and modal verbs are handled differently</definiens>
			</definition>
			<definition id="7">
				<sentence>These data are assigned morphological gramatemes ( the full set of values ) and syntactic grammatemes , and the nodes are reordered according to topic-focus articulation ( information structure ) .</sentence>
				<definiendum id="0">morphological gramatemes</definiendum>
				<definiens id="0">the full set of values</definiens>
			</definition>
			<definition id="8">
				<sentence>Czech analytical parsing consists of a statistical dependency parser for Czech – either Collins parser ( Collins et al. , 1999 ) or Charniak parser ( Charniak , 1999 ) , both adapted to dependency grammar – and a module for automatic analytical function assignment ( ˇZabokrtsk´y et al. , 2002 ) .</sentence>
				<definiendum id="0">Czech analytical parsing</definiendum>
			</definition>
			<definition id="9">
				<sentence>The Czech part is a free translation of the English version .</sentence>
				<definiendum id="0">Czech part</definiendum>
			</definition>
			<definition id="10">
				<sentence>SMT Quick Run is a package of scripts and instructions for building statistical machine translation system from the PCEDT or any other parallel corpus .</sentence>
				<definiendum id="0">SMT Quick Run</definiendum>
				<definiens id="0">a package of scripts and instructions for building statistical machine translation system from the PCEDT</definiens>
			</definition>
			<definition id="11">
				<sentence>TrEd is a graphical editor and viewer of tree structures .</sentence>
				<definiendum id="0">TrEd</definiendum>
				<definiens id="0">a graphical editor and viewer of tree structures</definiens>
			</definition>
			<definition id="12">
				<sentence>Netgraph is a multi-platform client-server application for browsing , querying and viewing analytical and tectogrammatical dependency trees , either over the Internet or locally .</sentence>
				<definiendum id="0">Netgraph</definiendum>
				<definiens id="0">a multi-platform client-server application for browsing</definiens>
			</definition>
</paper>

		<paper id="2804">
			<definition id="0">
				<sentence>In the MIAMM project ( see section 2 ) we use no ontology a3The research presented here is funded by the German Ministry of Research and Technology under grant 01 IL 905 , the European Union under the grants IST-2000-29487 and IST-200132311 and IDS-Scheer AG .</sentence>
				<definiendum id="0">MIAMM project</definiendum>
			</definition>
			<definition id="1">
				<sentence>SmartKom SMARTKOM is a mixed-initiative dialogue system that provides full symmetric multimodality by combining speech , gesture , and facial expressions for both user input and system output ( Wahlster , 2003 ) .</sentence>
				<definiendum id="0">SmartKom SMARTKOM</definiendum>
			</definition>
			<definition id="2">
				<sentence>As it is depicted in Figure 1 , SMARTKOM realizes a flexible and adaptive shell for multimodal dialogues and addresses three different application scenarios : Figure 1 : SMARTKOM’s dialogue backbone and application scenarios SMARTKOM PUBLIC realizes an advanced multimodal information and communication kiosk for , e. g. , shopping malls .</sentence>
				<definiendum id="0">SMARTKOM</definiendum>
				<definiens id="0">SMARTKOM’s dialogue backbone and application scenarios SMARTKOM PUBLIC realizes an advanced multimodal information and communication kiosk for</definiens>
			</definition>
			<definition id="3">
				<sentence>Software modules communicate via so-called data pools that correspond to named message queues .</sentence>
				<definiendum id="0">Software modules</definiendum>
				<definiens id="0">communicate via so-called data pools that correspond to named message queues</definiens>
			</definition>
			<definition id="4">
				<sentence>The MIAMM architecture follows the ”standard” architecture of interactive systems , with the consecutive steps mode analysis , mode coordination , interaction management , presentation planning , and mode design .</sentence>
				<definiendum id="0">MIAMM architecture</definiendum>
				<definiens id="0">follows the ”standard” architecture of interactive systems , with the consecutive steps mode analysis , mode coordination , interaction management , presentation planning , and mode design</definiens>
			</definition>
			<definition id="5">
				<sentence>The system consists of two modules for natural language input processing , namely recognition and interpretation .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of two modules for natural language input processing , namely recognition and interpretation</definiens>
			</definition>
			<definition id="6">
				<sentence>The visualization module renders the graphic output and interprets the force imposed by the user to the haptic buttons .</sentence>
				<definiendum id="0">visualization module</definiendum>
				<definiens id="0">renders the graphic output and interprets the force imposed by the user to the haptic buttons</definiens>
			</definition>
			<definition id="7">
				<sentence>The dialogue manager consists of two main blocks , Figure 2 : The force-feedback device developed in the MIAMM project .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">consists of two main blocks</definiens>
			</definition>
			<definition id="8">
				<sentence>the multimodal FUSION ( see section 3.2 ) which is responsible for the resolution of multimodal references using the contextual information hold in the dialogue history , and the AP , that interprets the user intention and triggers a suitable system response .</sentence>
				<definiendum id="0">multimodal FUSION</definiendum>
				<definiens id="0">responsible for the resolution of multimodal references using the contextual information hold in the dialogue history , and the AP , that interprets the user intention and triggers a suitable system response</definiens>
			</definition>
			<definition id="9">
				<sentence>The discourse module is the central repository for modality dependent and modality independent information .</sentence>
				<definiendum id="0">discourse module</definiendum>
				<definiens id="0">the central repository for modality dependent and modality independent information</definiens>
			</definition>
			<definition id="10">
				<sentence>The most important off-line optimization is the computation of a fixed rule application order with the objective to avoid wasting time by the generation of sub-optimal results .</sentence>
				<definiendum id="0">most important off-line optimization</definiendum>
				<definiens id="0">the computation of a fixed rule application order with the objective to avoid wasting time by the generation of sub-optimal results</definiens>
			</definition>
			<definition id="11">
				<sentence>Modality Fusion combines the different results from the analyzers ; Discourse Modeling interprets in context ; Action Planning determines the next system action ; Presentation Management splits and coordinates the output on the different output modalities .</sentence>
				<definiendum id="0">Modality Fusion</definiendum>
				<definiens id="0">combines the different results from the analyzers ; Discourse Modeling interprets in context ; Action Planning determines the next system action ; Presentation Management splits and coordinates the output on the different output modalities</definiens>
			</definition>
			<definition id="12">
				<sentence>The planning of a multimodal presentation consists of two parts : static gesture-sensitive graphical elements and a corresponding multimodal animation of the agent including gestures referring to objects with aligned audiovisual speech output .</sentence>
				<definiendum id="0">planning of a multimodal presentation</definiendum>
				<definiens id="0">consists of two parts : static gesture-sensitive graphical elements and a corresponding multimodal animation of the agent including gestures referring to objects with aligned audiovisual speech output</definiens>
			</definition>
			<definition id="13">
				<sentence>The design of the Natural Language Generation ( NLG ) module is guided by the need to ( i ) adapt only knowledge sources when adding a new application and ( ii ) generalizing the knowledge sources from the applications .</sentence>
				<definiendum id="0">Natural Language Generation</definiendum>
			</definition>
			<definition id="14">
				<sentence>E.g. , the NLG module in SmartKom uses syntactic structure and discourse information to supply richly annotated text for the Concept-To-Speech ( CTS ) approach .</sentence>
				<definiendum id="0">E.g.</definiendum>
				<definiendum id="1">Concept-To-Speech</definiendum>
				<definiens id="0">syntactic structure and discourse information to supply richly annotated text for the</definiens>
			</definition>
			<definition id="15">
				<sentence>Multimodality More modalities allow for more natural communication , which normally employs multiple channels of expression , suited to the content to be communicated .</sentence>
				<definiendum id="0">Multimodality More modalities</definiendum>
				<definiens id="0">allow for more natural communication , which normally employs multiple channels of expression , suited to the content to be communicated</definiens>
			</definition>
</paper>

		<paper id="1909">
			<definition id="0">
				<sentence>Natural language texts can be viewed as resources containing uniform data in such a way that methods similar to those used in Data Base Knowledge Extraction can be applied to them .</sentence>
				<definiendum id="0">Base Knowledge Extraction</definiendum>
				<definiens id="0">resources containing uniform data in such a way that methods similar to those used in Data</definiens>
			</definition>
			<definition id="1">
				<sentence>C ) Preparation and selection of the data : consists in the identification and selection of relevant terms form the preprocessed ones .</sentence>
				<definiendum id="0">selection of the data</definiendum>
				<definiens id="0">consists in the identification and selection of relevant terms form the preprocessed ones</definiens>
			</definition>
			<definition id="2">
				<sentence>D ) Knowledge Extraction : consists of the application of machine learning techniques to identify patterns that can classify or cluster the documents in the collection .</sentence>
				<definiendum id="0">Extraction</definiendum>
				<definiens id="0">consists of the application of machine learning techniques to identify patterns that can classify or cluster the documents in the collection</definiens>
			</definition>
			<definition id="3">
				<sentence>For the experiments with the usual methods , irrelevant terms ( stop-words ) were eliminated from the documents , on the basis of a list of stop-words , containing 476 terms ( mainly articles , prepositions , auxiliary verbs , pronouns , etc ) .</sentence>
				<definiendum id="0">irrelevant terms</definiendum>
				<definiens id="0">containing 476 terms ( mainly articles , prepositions , auxiliary verbs , pronouns , etc )</definiens>
			</definition>
			<definition id="4">
				<sentence>Weka is a collection of machine learning algorithms for data mining tasks that contains tools for data pre-processing , classification , regression , clustering , association rules , and visualization .</sentence>
				<definiendum id="0">Weka</definiendum>
				<definiens id="0">a collection of machine learning algorithms for data mining tasks that contains tools for data pre-processing , classification , regression , clustering , association rules , and visualization</definiens>
			</definition>
			<definition id="5">
				<sentence>Decision Tree is a supervised learning algorithm based on the recursive division of the training examples in representative subsets , using the metric of information gain .</sentence>
				<definiendum id="0">Decision Tree</definiendum>
				<definiens id="0">a supervised learning algorithm based on the recursive division of the training examples in representative subsets , using the metric of information gain</definiens>
			</definition>
			<definition id="6">
				<sentence>5 0 17 0 33 Table 3 : Confusion Matrix PD1 ( 150 terms ) Considering the larger group in each row and column ( highlighted in the table ) as the intended cluster for each class , the corresponding precision is of 50,52 % .</sentence>
				<definiendum id="0">corresponding precision</definiendum>
				<definiens id="0">Confusion Matrix PD1 ( 150 terms ) Considering the larger group in each row and column ( highlighted in the table</definiens>
			</definition>
</paper>

		<paper id="0811">
			<definition id="0">
				<sentence>WordNet : An electronic lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An electronic lexical database</definiens>
			</definition>
</paper>

		<paper id="1109">
</paper>

		<paper id="0847">
			<definition id="0">
				<sentence>Word sense disambiguation ( WSD ) is to assign appropriate meaning to a given ambiguous word in a text .</sentence>
				<definiendum id="0">Word sense disambiguation ( WSD</definiendum>
				<definiens id="0">to assign appropriate meaning to a given ambiguous word in a text</definiens>
			</definition>
			<definition id="1">
				<sentence>LocalA contains only part of speech tags with position information : POS¡nl ; ... , POS¡1 ; POS0 ; POS+1 ; ... , POS+nl , where POS¡i ( POS+i ) is the part of speech ( POS ) of the i-th words to the left ( right ) of target word w , and POS0 is the POS of w. Association for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems LocalB enriches the local context by including the following features : local words with position information ( W¡nl , ... , W¡1 , W+1 , ... , W+nl ) , bigram templates ( ( W¡nl ; W¡ ( nl¡1 ) ) , ... , ( W¡1 ; W+1 ) , ... , ( W+ ( nl¡1 ) ; W+nl ) ) , local words with POS tags ( W POS ) ( position information is not considered ) , and part of speech tags with position information .</sentence>
				<definiendum id="0">POS¡i ( POS+i )</definiendum>
				<definiendum id="1">POS0</definiendum>
				<definiens id="0">contains only part of speech tags with position information : POS¡nl ; ...</definiens>
				<definiens id="1">the part of speech ( POS ) of the i-th words to the left ( right ) of target word w</definiens>
				<definiens id="2">the POS of w. Association for Computational Linguistics for the Semantic Analysis of Text</definiens>
				<definiens id="3">Third International Workshop on the Evaluation of Systems LocalB enriches the local context by including the following features : local words with position information ( W¡nl , ... , W¡1 , W+1 , ... , W+nl ) , bigram templates</definiens>
				<definiens id="4">local words with POS tags ( W POS ) ( position information is not considered ) , and part of speech tags with position information</definiens>
			</definition>
			<definition id="2">
				<sentence>Test data consists of 380 untagged examples for the same 20 target words .</sentence>
				<definiendum id="0">Test data</definiendum>
			</definition>
</paper>

		<paper id="0820">
			<definition id="0">
				<sentence>Conceptual Density ( CD ) is a measure of the correlation among the sense of a given word and its context .</sentence>
				<definiendum id="0">Conceptual Density ( CD )</definiendum>
				<definiens id="0">a measure of the correlation among the sense of a given word and its context</definiens>
			</definition>
			<definition id="1">
				<sentence>The foundation of this measure is the Conceptual Distance , defined as the length of the shortest path which connects two concepts in a hierarchical semantic net .</sentence>
				<definiendum id="0">Conceptual Distance</definiendum>
				<definiens id="0">the length of the shortest path which connects two concepts in a hierarchical semantic net</definiens>
			</definition>
			<definition id="2">
				<sentence>This pushed us to modify the CD formula by including also the information about frequency that comes from WN : a8a10a9a12a11 a45 a15 a32a35a34 a15a1a0 a17a20a19 a45a3a2 a11 a48 a49 a51a6a53 a8a42a9 a17a5a4a7a6a9a8a11a10 ( 3 ) where a45 is the number of relevant synsets , a12 is a constant ( the best results were obtained over the SemCor corpus with a12 near to 0.10 ) , and a0 is an integer representing the frequency of the subhierarchy-related sense in WN ( 1 means the most frequent , 2 the second most frequent , etc. ) .</sentence>
				<definiendum id="0">a45</definiendum>
				<definiendum id="1">a12</definiendum>
				<definiendum id="2">a0</definiendum>
				<definiens id="0">the number of relevant synsets</definiens>
				<definiens id="1">a constant ( the best results were obtained over the SemCor corpus with a12 near to 0.10 ) , and</definiens>
				<definiens id="2">an integer representing the frequency of the subhierarchy-related sense</definiens>
			</definition>
			<definition id="3">
				<sentence>Each weight is proportional to the frequency of such senses , and is calculated as a45 a9a65a64 a11a66a0 a15a9a67 a17 a19 a49a39a54 a0 a51 a49a39a54 a67 , where a0 is an integer representing the frequency of the sense of the word to be disambiguated and a67 gives the same information for the context word .</sentence>
				<definiendum id="0">a0</definiendum>
				<definiens id="0">an integer representing the frequency of the sense of the word to be disambiguated and a67 gives the same information for the context word</definiens>
			</definition>
			<definition id="4">
				<sentence>When a subhierarchy is below a certain averaged depth ( which was determined in an empirical way to be approximately 4 ) and , therefore , its sense of the noun to be disambiguated is more specific , the conceptual density of Formula 3 is augmented proportionally to the number of the contained relevant synsets : a8a10a9 a51 a11a72a71 a53 a38a74a73 a34 a11 a51 a34 a17a40a75 a49a26a76a58a77 a71 a53 a38a78a73a2a34a31a79 a49 a17a5a80 ( 4 ) where a71 a53 a38a78a73a2a34 a11 a51 a34 a17 returns the depth of the current subhierarchy ( a51 a34 ) with respect to the top of the WordNet hierarchy ; a49a25a76a25a77 a71 a53 a38a78a73a2a34 is the averaged depth of all subhierarchies in SemCor ; its value , as said before , was empirically determined to be equal to 4 ; and a0 is a constant ( the best results were obtained , over SemCor , with a0 a19 0.70 ) .</sentence>
				<definiendum id="0">a0</definiendum>
				<definiens id="0">a certain averaged depth ( which was determined in an empirical way to be approximately 4 ) and , therefore , its sense of the noun to be disambiguated is more specific , the conceptual density of Formula 3 is augmented proportionally to the number of the contained relevant synsets : a8a10a9 a51 a11a72a71 a53 a38a74a73 a34 a11 a51 a34 a17a40a75 a49a26a76a58a77 a71 a53 a38a78a73a2a34a31a79 a49 a17a5a80 ( 4 ) where a71 a53 a38a78a73a2a34 a11 a51 a34 a17 returns the depth of the current subhierarchy</definiens>
				<definiens id="1">the averaged depth of all subhierarchies in SemCor</definiens>
			</definition>
			<definition id="5">
				<sentence>Finally , we used WordNet Domains to assign extra weights to the senses having the same domain of the head synset ( e.g. heart ( 2 ) in the gloss of blood ( 1 ) : “the fluid that is pumped by the heart” ) .</sentence>
				<definiendum id="0">WordNet Domains</definiendum>
				<definiens id="0">“the fluid that is pumped by the heart” )</definiens>
			</definition>
</paper>

		<paper id="0110">
			<definition id="0">
				<sentence>The Stephany corpus ( Stephany , 1995 ) is a database of conversations between children and caretakers , broadly transcribed , currently with no notations for lexical stress , included as part of the CHILDES database ( MacWhinney , 2000 ) .</sentence>
				<definiendum id="0">Stephany corpus</definiendum>
				<definiens id="0">a database of conversations between children and caretakers , broadly transcribed</definiens>
			</definition>
			<definition id="1">
				<sentence>The test corpus consists of 373 utterance tokens with a total of 980 words ( 306 types ) .</sentence>
				<definiendum id="0">test corpus</definiendum>
			</definition>
			<definition id="2">
				<sentence>The last metric ( word type ) is slightly more conservative than Brent’s ( 1999a ) in that the word type must have been actually spoken in the same utterance ( not the same block of 500 utterances ) in which it was detected to count as a match .</sentence>
				<definiendum id="0">last metric</definiendum>
				<definiens id="0">the same utterance ( not the same block of 500 utterances ) in which it was detected to count as a match</definiens>
			</definition>
</paper>

		<paper id="0215">
			<definition id="0">
				<sentence>LiveTree is an integrated workbench for supervised and unsupervised creation , storage and manipulation of the discourse structure of text documents under the U-LDM .</sentence>
				<definiendum id="0">LiveTree</definiendum>
				<definiens id="0">an integrated workbench for supervised and unsupervised creation , storage and manipulation of the discourse structure of text documents under the U-LDM</definiens>
			</definition>
			<definition id="1">
				<sentence>Similar to the DLTAG system described in Forbes et al ( 2003 ) LiveTree is an experimental discourse parser implementing a theory of sentential and discourse relations .</sentence>
				<definiendum id="0">LiveTree</definiendum>
				<definiens id="0">an experimental discourse parser implementing a theory of sentential and discourse relations</definiens>
			</definition>
			<definition id="2">
				<sentence>Accordingly , LiveTree serves as both the user interface and theory development environment for PALSUMM , a text summarization system built on top of LIDAS ( See Section 5 below ) In this paper , we describe the resources LiveTree workbench provides for discourse level theoretical development as well as document handling , manual and automatic text annotation and parsing .</sentence>
				<definiendum id="0">LiveTree</definiendum>
				<definiens id="0">discourse level theoretical development as well as document handling , manual and automatic text annotation and parsing</definiens>
			</definition>
			<definition id="3">
				<sentence>LiveTree is made up by : ( 1 ) a Model Manager which provides interfaces for manipulation , storage and retrieval of actual documents and discourse representations ; ( 2 ) a Module Manager , which handles and provides access to the main GUI and to all installed modules ; and ( 3 ) a Service Manager providing a polling interface for all active LiveTree Services .</sentence>
				<definiendum id="0">LiveTree</definiendum>
				<definiendum id="1">Model Manager</definiendum>
				<definiens id="0">provides interfaces for manipulation , storage and retrieval of actual documents and discourse representations ; ( 2 ) a Module Manager , which handles and provides access to the main GUI and to all installed modules</definiens>
			</definition>
			<definition id="4">
				<sentence>The U-LDM is a theory of discourse structure and semantics that has as its goal assigning the correct interpretation to natural language utterances .</sentence>
				<definiendum id="0">U-LDM</definiendum>
				<definiens id="0">a theory of discourse structure and semantics that has as its goal assigning the correct interpretation to natural language utterances</definiens>
			</definition>
			<definition id="5">
				<sentence>1.1 Overview of LiveTree LiveTree is an integrated workbench for supervised and unsupervised creation , storage and manipulation of the discourse structure of text documents under the ULDM .</sentence>
				<definiendum id="0">LiveTree LiveTree</definiendum>
				<definiens id="0">an integrated workbench for supervised and unsupervised creation , storage and manipulation of the discourse structure of text documents under the ULDM</definiens>
			</definition>
			<definition id="6">
				<sentence>The Document Module ( DM ) enables full document creation , modification and annotation at the document , region/selection , and sentence level .</sentence>
				<definiendum id="0">Document Module</definiendum>
				<definiens id="0">full document creation , modification and annotation at the document , region/selection , and sentence level</definiens>
			</definition>
			<definition id="7">
				<sentence>The DM provides the visual representation of an HTML document 1 and preserves the text organization , formatting , and nontextual information ( figures , tables , etc. ) of HTML source documents .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiens id="0">provides the visual representation of an HTML document 1 and preserves the text organization , formatting , and nontextual information ( figures , tables , etc. ) of HTML source documents</definiens>
			</definition>
			<definition id="8">
				<sentence>The Document Stub Interface provides the mapping between a document 's content and notions of paragraphs , sentences , units and spans .</sentence>
				<definiendum id="0">Document Stub Interface</definiendum>
				<definiens id="0">provides the mapping between a document 's content and notions of paragraphs , sentences , units and spans</definiens>
			</definition>
			<definition id="9">
				<sentence>In the current implementation , a document is divided in paragraphs according to standard notions ; paragraphs are then tokenized in sentences using simple heuristics and sentences are segmented into Basic also be supported by implementing the Document Stub Interface ( DSI ) appropriately , The Model Manager ( MM ) is the main access point to models , defined as the synchronized unions of a document and its ( annotated ) discourse structure .</sentence>
				<definiendum id="0">Model Manager ( MM )</definiendum>
				<definiens id="0">a document is divided in paragraphs according to standard notions ; paragraphs are then tokenized in sentences using simple heuristics and sentences are segmented into Basic also be supported by implementing the Document Stub Interface ( DSI ) appropriately , The</definiens>
				<definiens id="1">the synchronized unions of a document and its ( annotated ) discourse structure</definiens>
			</definition>
			<definition id="10">
				<sentence>The MM requires that appropriate LiveTree SerFeature Document Handling Discourse Segmentation ( Automatic &amp; Manual ) Discourse Structure Creation Document and Sentence Level ( Automatic &amp; Manual ) Semantic Content Inspection Search Description Support for HTML Documents ( Import , Export , Create , Edit , Print , Tokenize in sentences ) Support for LDM Discourse Segments ( Automatic Sentence Segmentation ; Manual Editing of Segments ; Manual Sentence Segmentation ; Inspect Segments ' Syntax Content ) Support for LDM DPT and BDU Trees ( Automatic Discourse Parsing ; Sub-tree Attachment via Drag `n Drop ; Editing including Node Type Editing and Content Editing ; Node/Sub-tree Removal ; Node-Specific Notes Editing ; Expand/Collapse Sub-Trees ; Export to JPG ; Printing ; Extensible Semantic Composition ) Support for Feature Structure-like Semantic Content of LDM Nodes ( Node Specific via mouse selection ; F-Structure graphical view ; In Place Editing ; Grammar Condition Querying ) Full Text and RE search on : Document content , Node Surface Content , Nodes Semantic Content , Node-Specific Notes ; Online retrieval of matching sources Grammar Editor : reusable conditions ; easy-to-use GUI Support for Manual Grammar Testing ( Check for rule enablement between attachment point and MBDU selected from actual subtrees ; Support Scripted Testing with XML Based Language ) Implements and supports serialization and deserialization in LiveTree XML format of LDM Annotation for documents .</sentence>
				<definiendum id="0">Content of LDM Nodes</definiendum>
				<definiens id="0">Automatic Sentence Segmentation ; Manual Editing of Segments ; Manual Sentence Segmentation ; Inspect Segments ' Syntax Content ) Support for LDM DPT and BDU Trees ( Automatic Discourse Parsing ; Sub-tree Attachment via Drag `n Drop</definiens>
				<definiens id="1">F-Structure graphical view ; In Place Editing ; Grammar Condition Querying ) Full Text and RE search on : Document content , Node Surface Content , Nodes Semantic Content , Node-Specific Notes ; Online retrieval of matching sources Grammar Editor : reusable conditions ; easy-to-use GUI Support for Manual Grammar Testing ( Check for rule enablement between attachment point and MBDU selected from actual subtrees ; Support Scripted Testing with XML Based Language ) Implements and supports serialization and deserialization in LiveTree XML format of LDM Annotation for documents</definiens>
			</definition>
</paper>

		<paper id="1507">
			<definition id="0">
				<sentence>ISST is a multi-layered corpus , annotated at the syntactic and lexico-semantic levels .</sentence>
				<definiendum id="0">ISST</definiendum>
				<definiens id="0">a multi-layered corpus , annotated at the syntactic and lexico-semantic levels</definiens>
			</definition>
			<definition id="1">
				<sentence>Italian is one of the languages for which a set of annotation guidelines has been developed in the context of the EAGLES project ( Expert Advisory Group on Language Engineering Standards ( Monachini , 1995 ) ) .</sentence>
				<definiendum id="0">Italian</definiendum>
				<definiens id="0">one of the languages for which a set of annotation guidelines has been developed in the context of the EAGLES project ( Expert Advisory Group on Language Engineering Standards</definiens>
			</definition>
			<definition id="2">
				<sentence>functor-argument relations The Turin University Treebank ( TUT ) is a corpus of Italian sentences annotated by specifying relational structures augmented with morphosyntactic information and semantic role ( henceforth ARS ) in a monostratal dependency-based representation .</sentence>
				<definiendum id="0">Turin University Treebank</definiendum>
				<definiens id="0">a corpus of Italian sentences annotated by specifying relational structures augmented with morphosyntactic information and semantic role ( henceforth ARS ) in a monostratal dependency-based representation</definiens>
			</definition>
			<definition id="3">
				<sentence>The ARS schema consists of i ) morphosyntactic , ii ) functional-syntactic and iii ) semantic components , specifying part-of-speech , grammatical relations , and thematic role information , respectively .</sentence>
				<definiendum id="0">ARS schema</definiendum>
				<definiens id="0">consists of i ) morphosyntactic , ii ) functional-syntactic and iii ) semantic components , specifying part-of-speech , grammatical relations , and thematic role information</definiens>
			</definition>
			<definition id="4">
				<sentence>PUNCT ) [ 6 ; END ] Because we are interested in extracting dependency relations , we can focus on the functional-syntactic component of the TUT annotation , where information relating to grammatical relations ( heads and dependents ) is encoded .</sentence>
				<definiendum id="0">PUNCT</definiendum>
				<definiens id="0">information relating to grammatical relations ( heads and dependents ) is encoded</definiens>
			</definition>
			<definition id="5">
				<sentence>In the particular case of the TUT annotation schema , we see that for all instances of dependents labeled as ARG ( or one of its sublabels ) , the DG head/dependent articulation coincides with the CG functor/argument asymmetry .</sentence>
				<definiendum id="0">ARG</definiendum>
				<definiens id="0">one of its sublabels ) , the DG head/dependent articulation coincides with the CG functor/argument asymmetry</definiens>
			</definition>
			<definition id="6">
				<sentence>The general pattern of these rules is : infer Γprime turnstileleft A from Γ turnstileleft A , where Γprime is some rearrangement of the constituents of Γ .</sentence>
				<definiendum id="0">Γprime</definiendum>
			</definition>
			<definition id="7">
				<sentence>Our simple example sentences could be converted into the following fa-structures : Allen trianglerightsld ( mangia triangleleftsld ( la triangleleftsld mela ) Allen trianglerightsld ( mangia triangleleftsld ( la triangleleftsld ( mela triangleright rossa ) ) Allen trianglerightsld ( ( ha triangleleft mangiato ) triangleleftsld ( la triangleleftsld mela ) ) The second step is to run the BuszkowskiPenn type-inference algorithm ( in its extended form , discussed above ) on the fa-structures obtained from TUT , and to reduce the lexicon by factoring ( identification of unifiable assignments ) and ( in a later phase ) structural derivability .</sentence>
				<definiendum id="0">mangia triangleleftsld</definiendum>
				<definiens id="0">identification of unifiable assignments ) and ( in a later phase ) structural derivability</definiens>
			</definition>
</paper>

		<paper id="2112">
			<definition id="0">
				<sentence>The electronic dictionaries ( EDs ) are not merely a straightforward extension of their printed counterparts , but they entail additional purely computational problems .</sentence>
				<definiendum id="0">electronic dictionaries</definiendum>
				<definiens id="0">a straightforward extension of their printed counterparts , but they entail additional purely computational problems</definiens>
			</definition>
			<definition id="1">
				<sentence>Rjecnik.com4 is the oldest one in these language pairs and is still active and expanding .</sentence>
				<definiendum id="0">Rjecnik.com4</definiendum>
				<definiens id="0">the oldest one in these language pairs and is still active and expanding</definiens>
			</definition>
			<definition id="2">
				<sentence>As a result , a direct by-product of our ED is an SC WordNet .</sentence>
				<definiendum id="0">ED</definiendum>
				<definiens id="0">an SC WordNet</definiens>
			</definition>
			<definition id="3">
				<sentence>Domain tags : agriculture ( agr ) , archaeological ( archl ) , architecture ( archt ) , biology ( bio ) , botany ( bot ) , computer ( c ) , diplomacy ( dipl ) , electrical ( elect ) , chemistry ( chem ) , culinary ( cul ) , law ( law ) , linguistic ( ling ) , mathematics ( mat ) , medicine ( med ) , military ( mil ) , mythology ( myt ) , music ( mus ) , religion ( rel ) , sports ( sp ) , and zoology ( zoo ) .</sentence>
				<definiendum id="0">medicine</definiendum>
				<definiendum id="1">religion</definiendum>
				<definiendum id="2">zoology</definiendum>
				<definiens id="0">agriculture ( agr ) , archaeological ( archl ) , architecture ( archt ) , biology ( bio ) , botany ( bot ) , computer ( c ) , diplomacy ( dipl ) , electrical ( elect )</definiens>
			</definition>
			<definition id="4">
				<sentence>Computer science subareas , cob tag ( e.g. , cob pl ) : internet ( int ) , programing languages ( pl ) , computational linguistics ( cl ) , graph theory ( gt ) , cryptography ( crypt ) , data structures ( ds ) , formal languages ( fl ) , computer networks ( cn ) , information retrieval ( ir ) , and object oriented programming ( oop ) .</sentence>
				<definiendum id="0">cob tag</definiendum>
				<definiendum id="1">retrieval</definiendum>
				<definiens id="0">pl ) , computational linguistics ( cl ) , graph theory ( gt ) , cryptography ( crypt ) , data structures ( ds ) , formal languages ( fl ) , computer networks ( cn ) , information</definiens>
			</definition>
			<definition id="5">
				<sentence>Misc. : abbreviation ( abb ) , abbreviation expansion ( abbE ) , colloquial ( coll ) , description ( desc ) , example ( eg ) , obsolete ( obs ) , see ( see ) , unique entry identifier ( id ) , and vulgar ( vul ) .</sentence>
				<definiendum id="0">vulgar</definiendum>
				<definiens id="0">abbreviation ( abb ) , abbreviation expansion ( abbE ) , colloquial ( coll ) , description ( desc ) , example ( eg )</definiens>
			</definition>
</paper>

		<paper id="2308">
			<definition id="0">
				<sentence>Clarification is initiated in two ways in our data : a phrase or declarative sentence that repeats the problematic part ( 70 % ) the same + a question-particle jah/yes , vä/or , ühesõnaga / in short ( 23 % ) .</sentence>
				<definiendum id="0">Clarification</definiendum>
				<definiens id="0">a phrase or declarative sentence that repeats the problematic part</definiens>
			</definition>
			<definition id="1">
				<sentence>Repairs are initiated regarding the immediately previous turn in 90 % of cases , but there are some examples , where client clarifies information which ( s ) he got earlier in the conversation and breaks the process of giving information by consultant , as in the following example .</sentence>
				<definiendum id="0">client</definiendum>
				<definiens id="0">clarifies information which ( s ) he got earlier in the conversation and breaks the process of giving information by consultant</definiens>
			</definition>
</paper>

		<paper id="1311">
			<definition id="0">
				<sentence>Likewise , the pattern — the syntagm and the equivalence class of complementary-distribution symbols that may appear in its open slot — is the main representational building block of our system , ADIOS ( for Automatic DIstillation Of Structure ) .</sentence>
				<definiendum id="0">ADIOS</definiendum>
			</definition>
			<definition id="1">
				<sentence>ADIOS represents a corpus of sentences as an initially highly redundant directed graph , which can be informally visualized as a tangle of strands that are partially segregated into bundles .</sentence>
				<definiendum id="0">ADIOS</definiendum>
				<definiens id="0">a corpus of sentences as an initially highly redundant directed graph , which can be informally visualized as a tangle of strands that are partially segregated into bundles</definiens>
			</definition>
			<definition id="2">
				<sentence>A pattern is an abstraction of a bundle of sentences that are identical up to variation in one place , where one of several symbols — the members of the equivalence class associated with the pattern — may appear ( Figure 1 ) .</sentence>
				<definiendum id="0">pattern</definiendum>
			</definition>
			<definition id="3">
				<sentence>Fourth , as we showed earlier ( Figure 2 ) , ADIOS incorporates both context-sensitive substitution and recursion .</sentence>
				<definiendum id="0">ADIOS</definiendum>
				<definiens id="0">incorporates both context-sensitive substitution and recursion</definiens>
			</definition>
			<definition id="4">
				<sentence>At the same time , whereas the cognitive grammarians typically face the chore of hand-crafting structures that would refl ect the logic of language as they perceive it , ADIOS discovers the primitives of grammar empirically and autonomously .</sentence>
				<definiendum id="0">ADIOS</definiendum>
				<definiens id="0">discovers the primitives of grammar empirically and autonomously</definiens>
			</definition>
			<definition id="5">
				<sentence>A construction grammar consists of elements that differ in their complexity and in the degree to which they are specified : an idiom such as “ big deal” is a fully specified , immutable construction , whereas the expression “ the X , the Y” – as in “ the more , the better” ( Kay and Fillmore , 1999 ) – is a partially specified template .</sentence>
				<definiendum id="0">construction grammar</definiendum>
				<definiendum id="1">better”</definiendum>
				<definiens id="0">consists of elements that differ in their complexity and in the degree to which they are specified : an idiom such as “ big deal” is a fully specified , immutable construction , whereas the expression “ the X , the Y” – as in “ the more , the</definiens>
			</definition>
			<definition id="6">
				<sentence>The generation process operates as a depth-first search of the tree corresponding to a pattern .</sentence>
				<definiendum id="0">generation process</definiendum>
				<definiens id="0">a depth-first search of the tree corresponding to a pattern</definiens>
			</definition>
			<definition id="7">
				<sentence>We next used a standard test developed for English as Second Language ( ESL ) classes , which has been administered in G¨oteborg ( Sweden ) to more than 10 ; 000 upper secondary levels students ( that is , children who typically had 9 years of school , but only 6-7 years of English ) .</sentence>
				<definiendum id="0">ESL ) classes</definiendum>
				<definiens id="0">upper secondary levels students ( that is , children who typically had 9 years of school , but only 6-7 years of English )</definiens>
			</definition>
			<definition id="8">
				<sentence>The test consists of 100 three-choice questions , such as She asked me at once ( choices : come , to come , coming ) and The tickets have been paid for , so you not worry ( choices : may , dare , need ) ; the average score for the population mentioned is 65 % .</sentence>
				<definiendum id="0">test</definiendum>
			</definition>
			<definition id="9">
				<sentence>A manuscript by Frank Keller lists magnitude estimation data for eight sentences.5 We compared these to the scores produced by ADIOS , and obtained a significant correlation ( Figure 7 ) .</sentence>
				<definiendum id="0">manuscript by Frank Keller</definiendum>
			</definition>
</paper>

		<paper id="3251">
			<definition id="0">
				<sentence>Current systems ( Ravichandran et al. , 2003 ) already employ traditional information extraction and machine learning for extracting answers from relevant documents .</sentence>
				<definiendum id="0">Current systems</definiendum>
				<definiens id="0">Ravichandran et al. , 2003 ) already employ traditional information extraction and machine learning for extracting answers from relevant documents</definiens>
			</definition>
			<definition id="1">
				<sentence>Predictive annotation ( Prager et al. , 1999 ) is one of the techniques that bring together corpus processing and smarter queries .</sentence>
				<definiendum id="0">Predictive annotation</definiendum>
				<definiens id="0">one of the techniques that bring together corpus processing and smarter queries</definiens>
			</definition>
			<definition id="2">
				<sentence>Its neighborhood consists of training instances that share a number of features with the new data point .</sentence>
				<definiendum id="0">neighborhood</definiendum>
			</definition>
			<definition id="3">
				<sentence>k-nearest training data points Q1 : :Qk can be used in order to estimate the probability that the test question q will observe an answer type j : P ( j ; q ) = kX i=0 P ( jjQi ) ( q ; Qi ) ( 1 ) where P ( j ; Qi ) is the probability of observing an answer of type j when asking question Qi .</sentence>
				<definiendum id="0">Qi )</definiendum>
			</definition>
			<definition id="4">
				<sentence>( q ; Qi ) represents a distance function between q and Qi , and is a normalizing factor over the set of all viable answer types in the neighborhood of q. Current Question Answering systems use IR in a straight-forward fashion .</sentence>
				<definiendum id="0">Qi )</definiendum>
				<definiens id="0">a normalizing factor over the set of all viable answer types in the neighborhood of q. Current Question Answering systems use IR in a straight-forward fashion</definiens>
			</definition>
			<definition id="5">
				<sentence>The Query Content Model is a cluster-specific collection of content features that generate the best document set ( Table 1 ) .</sentence>
				<definiendum id="0">Query Content Model</definiendum>
			</definition>
			<definition id="6">
				<sentence>We let C be the class variable and Fi the feature variable : I ( C ; Fi ) = H ( C ) H ( CjFi ) = X c2C X fi20 ; 1 P ( c ; fi ) log P ( c ; fi ) P ( c ) P ( f i ) where H ( C ) is the entropy of the class variable and H ( CjFi ) is the entropy of the class variable conditioned on the feature variable .</sentence>
				<definiendum id="0">H ( C )</definiendum>
			</definition>
			<definition id="7">
				<sentence>The Extraction Model uses a support vector machine ( SVM ) classifier ( Joachims , 2002 ) with a linear kernel .</sentence>
				<definiendum id="0">Extraction Model</definiendum>
				<definiendum id="1">SVM</definiendum>
				<definiens id="0">uses a support vector machine</definiens>
			</definition>
</paper>

		<paper id="1704">
			<definition id="0">
				<sentence>VINCI is a Natural Language Generation environment designed for use in computer-aided second language instruction .</sentence>
				<definiendum id="0">VINCI</definiendum>
				<definiens id="0">a Natural Language Generation environment designed for use in computer-aided second language instruction</definiens>
			</definition>
			<definition id="1">
				<sentence>In a typical fairy tale we have a collection of characters , including a pompous twit ( a king or a rich merchant ) , a victim or heroine ( the twit’s daughter ) , a villain ( a sorcerer or witch ) , a hero ( a prince or a brave woodcutter ) , a goodfairy ( the victim’s fairy godmother ) , a magicobj ( a sword or a silver goblet ) .</sentence>
				<definiendum id="0">pompous twit</definiendum>
				<definiens id="0">a king or a rich merchant ) , a victim or heroine ( the twit’s daughter ) , a villain ( a sorcerer or witch ) , a hero ( a prince or a brave woodcutter ) , a goodfairy ( the victim’s fairy godmother</definiens>
			</definition>
			<definition id="2">
				<sentence>A semantic expression is a representation of the content of an utterance in a form in which the grammatical constraints of any particular natural language have been abstracted away , leaving only some expression of meaning behind .</sentence>
				<definiendum id="0">semantic expression</definiendum>
				<definiens id="0">a representation of the content of an utterance in a form in which the grammatical constraints of any particular natural language have been abstracted away , leaving only some expression of meaning behind</definiens>
			</definition>
			<definition id="3">
				<sentence>So goodfairy ( and hence Wanda ) becomes the agent of the act of giving , magicobj ( the magic sword ) becomes its theme , and hero its bene ciary .</sentence>
				<definiendum id="0">goodfairy</definiendum>
				<definiens id="0">the agent of the act of giving</definiens>
			</definition>
</paper>

		<paper id="0905">
			<definition id="0">
				<sentence>To resolve these problems , OntoSem uses both static knowledge ( multivalued selectional restrictions and lateral constraints among co-arguments of a predicate ) and context-generated heuristics , including information in the nascent TMR and measuring distances among any two concepts in the ontological search space .</sentence>
				<definiendum id="0">OntoSem</definiendum>
				<definiens id="0">uses both static knowledge ( multivalued selectional restrictions and lateral constraints among co-arguments of a predicate ) and context-generated heuristics , including information in the nascent TMR and measuring distances among any two concepts in the ontological search space</definiens>
			</definition>
			<definition id="1">
				<sentence>n zer determines the e , eech acts , speaker attitudes etc. , to produce to the danger '' 1 at n 4 at n opt + r3 cat n e str N ENT ) In the lexicon , variables ( e.g. , $ var2 ) support sy ” modalities , aspect , tim p TMRs .</sentence>
				<definiendum id="0">n zer</definiendum>
				<definiens id="0">determines the e , eech acts , speaker attitudes etc. , to produce to the danger '' 1 at n 4 at n opt + r3 cat n e str N ENT</definiens>
			</definition>
			<definition id="2">
				<sentence>Results from the operation of the preprocessor , syntactic analysis and semantic analysis c The preprocessor statistics are recorded as follows ( m is the number of mat a mismatches ) : a ) abbreviations , time , date and number recognition ( m/n ) ; b ) named entity recognition ( m/n ) ; c ) part of speech tagging ( m/n ) .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">the number of mat a mismatches ) : a ) abbreviations , time , date and number recognition ( m/n )</definiens>
			</definition>
			<definition id="3">
				<sentence>The ontological distance is computed using the Ontosearch algorithm ( Onyshkevych 1997 ) that returns a score between 0.0 and 1.0 reflecting how close the two concepts are in the ontology , with a score of 1.0 indicating a Example Semantic Evaluation perfect match .</sentence>
				<definiendum id="0">ontological distance</definiendum>
				<definiens id="0">returns a score between 0.0 and 1.0 reflecting how close the two concepts are in the ontology , with a score of 1.0 indicating a Example Semantic Evaluation perfect match</definiens>
			</definition>
</paper>

		<paper id="0808">
			<definition id="0">
				<sentence>SENSEVAL is an evaluation exercise of the latest word-sense disambiguation ( WSD ) systems .</sentence>
				<definiendum id="0">SENSEVAL</definiendum>
				<definiens id="0">an evaluation exercise of the latest word-sense disambiguation ( WSD ) systems</definiens>
			</definition>
			<definition id="1">
				<sentence>It serves as a forum that brings together researchers in WSD and domains that use WSD for various tasks .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">a forum that brings together researchers in WSD and domains that use</definiens>
			</definition>
			<definition id="2">
				<sentence>Examples are extracted from the ROCO corpus , a 400 million words corpus consisting of a collection of Romanian newspapers collected on the Web over a three years period ( 1999-2002 ) .</sentence>
				<definiendum id="0">ROCO corpus</definiendum>
			</definition>
			<definition id="3">
				<sentence>Word Main English senses senses Train Test Word Main English senses senses Train Test translation ( fine ) ( coarse ) size size translation ( fine ) ( coarse ) size size NOUNS ac needle 16 7 127 65 accent accent 5 3 172 87 actiune action 10 7 261 128 canal channel 6 5 134 66 circuit circuit 7 5 200 101 circulatie circulation 9 3 221 114 coroana crown 15 11 252 126 delfin doplhin 5 4 31 15 demonstratie demonstration 6 3 229 115 eruptie eruption 2 2 54 27 geniu genius 5 3 106 54 nucleu nucleus 7 5 64 33 opozitie opposition 12 7 266 134 perie brush 5 3 46 24 pictura painting 5 2 221 111 platforma platform 11 8 226 116 port port 7 3 219 108 problema problem 6 4 262 131 proces process 11 3 166 82 reactie reaction 7 6 261 131 stil style 14 4 199 101 timbru stamp 7 3 231 116 tip type 7 4 263 131 val wave 15 9 242 121 valoare value 23 9 251 125 VERBS cistiga win 5 4 227 115 citi read 10 4 259 130 cobori descend 11 6 252 128 conduce drive 7 6 265 134 creste grow 14 6 209 103 desena draw 3 3 54 27 desface untie 11 5 115 58 fierbe boil 11 4 83 43 indulci sweeten 7 4 19 10 ADJECTIVES incet slow 6 3 224 113 natural natural 12 5 242 123 neted smooth 7 3 34 17 oficial official 5 3 185 96 simplu simple 15 6 153 82 Table 2 : Target words in the SENSEVAL-3 Romanian Lexical Sample task Five teams participated in this word sense disambiguation task .</sentence>
				<definiendum id="0">size size NOUNS</definiendum>
				<definiens id="0">Word Main English senses senses Train Test Word Main English senses senses Train Test translation ( fine ) ( coarse ) size size translation ( fine ) ( coarse )</definiens>
			</definition>
</paper>

		<paper id="1510">
			<definition id="0">
				<sentence>XDG combines the benefits of these two positions , and attempts to circumvent their problems .</sentence>
				<definiendum id="0">XDG</definiendum>
			</definition>
			<definition id="1">
				<sentence>XDG is a descendant of Topological Dependency Grammar ( TDG ) ( Duchier and Debusmann , 2001 ) , pushing the underlying methodology further by generalizing it in two aspects : number of dimensions : two in TDG ( ID and LP ) , arbitrary many in XDG set of principles : fixed in TDG , extensible principle library in XDG The structure of this paper is as follows : In x2 , we introduce XDG and the XDG solver used for parsing and generation .</sentence>
				<definiendum id="0">XDG</definiendum>
				<definiens id="0">a descendant of Topological Dependency Grammar ( TDG )</definiens>
			</definition>
			<definition id="2">
				<sentence>An XDG analysis ( V ; Ei ; Fi ) ni=1 is an element of Ana = Ana1 Anan where all dimensions share the same set of nodes V. We call a dimension of a grammar grammar dimension .</sentence>
				<definiendum id="0">XDG analysis</definiendum>
				<definiens id="0">an element of Ana = Ana1 Anan where all dimensions share the same set of nodes</definiens>
			</definition>
			<definition id="3">
				<sentence>Because XDG allows us to write grammars with completely free word order , XDG solving is an NP-complete problem ( Koller and Striegnitz , 2002 ) .</sentence>
				<definiendum id="0">XDG solving</definiendum>
				<definiens id="0">us to write grammars with completely free word order</definiens>
			</definition>
			<definition id="4">
				<sentence>2 ) The order of the daughters Roman ( under the edge labeled vf ) , Peter ( mf ) and lesen ( rbf ) is compatible with the total order prescribing vf mf rbf .</sentence>
				<definiendum id="0">lesen</definiendum>
				<definiens id="0">compatible with the total order prescribing vf mf rbf</definiens>
			</definition>
			<definition id="5">
				<sentence>On the ID dimension , we make use of the following one-dimensional principles : tree ( ID ) valency ( ID ; inID ; outID ) government ( ID ; casesID ; governID ) agreement ( ID ; casesID ; agreeID ) ( 3 ) The LP dimension uses the following principles : tree ( LP ) valency ( LP ; inLP ; outLP ) order ( LP ; onLP ; LP ) projectivity ( LP ) ( 4 ) where the total order LP is defined as : detf nounf vf lbf mf partf rbf ( 5 ) We make use of the following multi-dimensional principles : climbing ( LP ; ID ) linking ( LP ; ID ) ( 6 ) We split the lexicon into two parts .</sentence>
				<definiendum id="0">tree ( LP ) valency</definiendum>
				<definiens id="0">detf nounf vf lbf mf partf rbf ( 5 ) We make use of the following multi-dimensional principles : climbing ( LP ; ID ) linking</definiens>
			</definition>
			<definition id="6">
				<sentence>Here , Peter is the subject of versucht .</sentence>
				<definiendum id="0">Peter</definiendum>
				<definiens id="0">the subject of versucht</definiens>
			</definition>
			<definition id="7">
				<sentence>( 13 ) We get only one analysis on the ID dimension , where Peter is the subject and roman the object .</sentence>
				<definiendum id="0">Peter</definiendum>
				<definiens id="0">the subject and roman the object</definiens>
			</definition>
			<definition id="8">
				<sentence>Peter versucht einen Roman zu lesen ag prop patag ( 17 ) Here , Peter is the agent of versucht , and also the agent of lesen .</sentence>
				<definiendum id="0">Peter</definiendum>
				<definiens id="0">the agent of versucht , and also the agent of lesen</definiens>
			</definition>
			<definition id="9">
				<sentence>Peter is the only word which can be the agent of both , because it is a subject and the agents of versucht and lesen must be subjects by the linking principle .</sentence>
				<definiendum id="0">Peter</definiendum>
				<definiens id="0">the only word which can be the agent of both</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>SmartMail presents the user with a task-focused summary of a message .</sentence>
				<definiendum id="0">SmartMail</definiendum>
				<definiens id="0">presents the user with a task-focused summary of a message</definiens>
			</definition>
			<definition id="1">
				<sentence>SmartMail performs a superficial analysis of an email message to distinguish the header , message body ( containing the new message content ) , and forwarded sections .</sentence>
				<definiendum id="0">SmartMail</definiendum>
				<definiens id="0">performs a superficial analysis of an email message to distinguish the header , message body ( containing the new message content ) , and forwarded sections</definiens>
			</definition>
</paper>

		<paper id="3244">
			<definition id="0">
				<sentence>Natural language processing involves many kinds of linguistic expressions , such as sentences , phrases , documents and the collection of documents .</sentence>
				<definiendum id="0">Natural language processing</definiendum>
				<definiens id="0">involves many kinds of linguistic expressions , such as sentences , phrases , documents and the collection of documents</definiens>
			</definition>
			<definition id="1">
				<sentence>To measure the distance between two vectors ~u ; ~v , a dot product or Euclidean distance d ( ~u ; ~v ) 2 = ( ~u ~v ) T ( ~u ~v ) ( 1 ) = Pni=1 ( ui vi ) 2 ( where T denotes a transposition ) has been employed so far 1 , with a heuristic feature weighting such as tf .</sentence>
				<definiendum id="0">T</definiendum>
			</definition>
			<definition id="2">
				<sentence>Suppose that each data ( for example , sentences or documents ) is a vector ~s 2 Rn , and the whole corpus can be divided into N clusters , X1 : : : XN .</sentence>
				<definiendum id="0">X1</definiendum>
				<definiens id="0">for example , sentences or documents</definiens>
			</definition>
			<definition id="3">
				<sentence>That is , each vector has a dimension n , and the number of clusters is N. For each cluster Xi , cluster centroid ci is calculated as ~ci = 1=jXijP~s2Xi ~s , where jXj denotes the number of data in X. When necessary , each element in ~sj or ~ci is referenced as sjk or cik ( k = 1 : : : n ) .</sentence>
				<definiendum id="0">jXj</definiendum>
				<definiendum id="1">~ci</definiendum>
				<definiens id="0">the number of data in X. When necessary , each element in ~sj or</definiens>
			</definition>
			<definition id="4">
				<sentence>Mathematically , this is formulated as a quadratic minimization problem M = arg min M NX i=1 X ~sj2Xi dM ( ~sj ; ~ci ) 2 = arg min M NX i=1 X ~sj2Xi ( ~sj ~ci ) T M ( ~sj ~ci ) ( 4 ) under a scale constraint ( j j means determinant ) jMj = 1 : ( 5 ) Scale constraint ( 5 ) is necessary for excluding a degenerate solution M = O. 1 is an arbitrary constant : when we replace 1 by c , c2M becomes a new solution .</sentence>
				<definiendum id="0">c2M</definiendum>
				<definiens id="0">an arbitrary constant : when we replace 1 by c</definiens>
			</definition>
			<definition id="5">
				<sentence>Here , R equals the cardinality of the cluster ; therefore , R-precision shows the precision of cluster recovery .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">equals the cardinality of the cluster</definiens>
			</definition>
			<definition id="6">
				<sentence>Therefore , each cluster consists of Japanese sentences that are possible translations from the same English seed sentence that the cluster has .</sentence>
				<definiendum id="0">cluster</definiendum>
			</definition>
			<definition id="7">
				<sentence>We first decompose data matrix X by SVD : X = USV 1 and build a k-dimensional compressed representation Xk = VkX ; where Vk denotes a k-largest submatrix of V .</sentence>
				<definiendum id="0">Vk</definiendum>
			</definition>
			<definition id="8">
				<sentence>( a ) “wine” dataset ( b ) “protein” dataset ( c ) “iris” dataset ( d ) “soybean” dataset Figure 4 : K-means clustering of UCI Machine Learning dataset results .</sentence>
				<definiendum id="0">“protein” dataset ( c ) “iris” dataset</definiendum>
			</definition>
</paper>

		<paper id="1807">
			<definition id="0">
				<sentence>The formal definition follows the Aristotelian schema : X = Y + specific characteristics , where X is the defined term ( the “definiendum” ) , “=” means an equivalence relation , Y stands for the generic class to which X belongs ( the “Genus” ) , and specific characteristics detail in which respect X is different from the other items composing the same generic class .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">the defined term ( the “definiendum” ) , “=” means an equivalence relation</definiens>
				<definiens id="1">the generic class to which X belongs ( the “Genus” ) , and specific characteristics detail in which respect X is different from the other items composing the same generic class</definiens>
			</definition>
			<definition id="1">
				<sentence>Hypernymy Synonymy # extracted sentences 270 585 Precision ( def ) 61 % 66 % Precision ( rel ) 26 % 15 % Recall ( rel ) 4 % 36 % Table 4 : Evaluation of precision ( test corpus ) and recall ( random sample of test corpus ) CompuTerm 2004 3rd International Workshop on Computational Terminology 59 • the proportion of extracted sentences that corresponded to definitions ( def ) , and • the proportion of correct semantic relations found in retrieved definitions ( rel ) .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">random sample of test corpus ) CompuTerm 2004 3rd International Workshop on Computational Terminology 59 • the proportion of extracted sentences that corresponded to definitions ( def ) , and • the proportion of correct semantic relations found in retrieved definitions ( rel )</definiens>
			</definition>
			<definition id="2">
				<sentence>Recall is the proportion of retrieved definitions which correctly display the semantic relation identified in the sample corpus among all the definitions present in this sample which were tagged as having this semantic relation by the human evaluator.2 The precision of extracted definitions is comparable to Rebeyrolle’s results .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the proportion of retrieved definitions which correctly display the semantic relation identified in the sample corpus among all the definitions present in this sample which were tagged as having this semantic relation by the human evaluator.2 The precision</definiens>
			</definition>
			<definition id="3">
				<sentence>“Other” gives the number of retrieved definitions following another semantic relation , “Undecidable” represents the number of definitions for which we could not determine the semantic relation,3 and “Non definition” presents the number of retrieved sentences that were not definitions.4 2The percentage of definitions of hypernymic and synonymic type among all definitions in the sample of the test corpus is given in table 2 .</sentence>
				<definiendum id="0">“Undecidable”</definiendum>
				<definiens id="0">the number of definitions for which we could not determine the semantic relation,3 and “Non definition” presents the number of retrieved sentences that were not definitions.4 2The percentage of definitions of hypernymic and synonymic type among all definitions in the sample of the test corpus is given in table 2</definiens>
			</definition>
</paper>

		<paper id="3002">
			<definition id="0">
				<sentence>Motivated by Béchet et al. ( 2002 ) , we propose a strategic way called logical ngram modeling , which combines the statistical n-gram with the existing regular grammar .</sentence>
				<definiendum id="0">ngram modeling</definiendum>
				<definiens id="0">combines the statistical n-gram with the existing regular grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>As the examples show in Table 1 , the goal ‘request_facility’ means a request ( dialogue act ) for some facilities ( additional information ) .</sentence>
				<definiendum id="0">goal ‘request_facility’</definiendum>
				<definiens id="0">additional information )</definiens>
			</definition>
			<definition id="2">
				<sentence>θθ − Φ∈ ≈ 1 , ) , ( ) , ( maxarg~ LWPWAPL NWL ( 3 ) where A is an acoustic speech signal , and P ( A , W ) is a product of an acoustic score P ( A|W ) and a language score P ( W ) .</sentence>
				<definiendum id="0">P ( A , W )</definiendum>
				<definiens id="0">a product of an acoustic score P ( A|W ) and a language score P ( W )</definiens>
			</definition>
			<definition id="3">
				<sentence>‘Recognition’ denotes the experiments on automatic speechrecognized utterances ( at 79 % WAcc ) , whereas ‘Orthography’ means their exact manual transcriptions .</sentence>
				<definiendum id="0">‘Recognition’</definiendum>
				<definiens id="0">whereas ‘Orthography’ means their exact manual transcriptions</definiens>
			</definition>
			<definition id="4">
				<sentence>While the Reg model requires C times ( C denotes the number of defined concepts ) of WFST operations to determine concepts , the LNgram needs only D+1 times ( D &lt; &lt; C ) , where D is the number of concepts appearing in the top hypothesis produced by the n-gram semantic model .</sentence>
				<definiendum id="0">C times ( C</definiendum>
				<definiens id="0">the number of defined concepts ) of WFST operations to determine concepts , the LNgram needs only D+1 times ( D &lt; &lt; C ) , where D is the number of concepts appearing in the top hypothesis produced by the n-gram semantic model</definiens>
			</definition>
</paper>

		<paper id="2711">
			<definition id="0">
				<sentence>The Prague Dependency Treebank1 ( PDT ) meets the wide-spread aspirations of building corpora with rich annotation schemes .</sentence>
				<definiendum id="0">Prague Dependency Treebank1 ( PDT )</definiendum>
				<definiens id="0">meets the wide-spread aspirations of building corpora with rich annotation schemes</definiens>
			</definition>
			<definition id="1">
				<sentence>The Valency Lexicon of Czech Verbs , Version 1.0 ( VALLEX 1.0 ) is a collection of linguistically annotated data and documentation , resulting from this attempt at formal description of valency frames of Czech verbs .</sentence>
				<definiendum id="0">Valency Lexicon of Czech Verbs</definiendum>
			</definition>
			<definition id="2">
				<sentence>Structure of the XML file is defined using a DTD file ( Document Type Definition ) , which naturally mirrors logical structure of the data ( described in Sec .</sentence>
				<definiendum id="0">DTD file</definiendum>
				<definiens id="0">Document Type Definition ) , which naturally mirrors logical structure of the data ( described in Sec</definiens>
			</definition>
			<definition id="3">
				<sentence>FrameNet ( ( Fillmore , 2002 ) ) groups lexical units ( pairings of words and senses ) into sets according to whether they permit parallel semantic descriptions .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">pairings of words and senses ) into sets according to whether they permit parallel semantic descriptions</definiens>
			</definition>
			<definition id="4">
				<sentence>The word entry consists of a sequence of frame entries ( Sec .</sentence>
				<definiendum id="0">word entry</definiendum>
			</definition>
			<definition id="5">
				<sentence>Lemma variants are groups of two ( or more ) lemmas that are interchangable in any context without any change of the meaning ( e.g. doveˇdeˇt se/dozveˇdeˇt se ) .</sentence>
				<definiendum id="0">Lemma variants</definiendum>
				<definiens id="0">groups of two ( or more ) lemmas that are interchangable in any context without any change of the meaning ( e.g. doveˇdeˇt se/dozveˇdeˇt se )</definiens>
			</definition>
			<definition id="6">
				<sentence>Each word entry consists of a non-empty sequence of frame entries , typically corresponding to the individual meanings ( senses ) of the headword lemma ( s ) ( from this point of view , VALLEX 1.0 can be classified as a Sense Enumerated Lexicon ) .</sentence>
				<definiendum id="0">word entry</definiendum>
				<definiens id="0">consists of a non-empty sequence of frame entries , typically corresponding to the individual meanings ( senses ) of the headword lemma ( s ) ( from this point of view</definiens>
			</definition>
			<definition id="7">
				<sentence>The prepositions occurring in VALLEX 1.0 are the following : bez , do , jako , k , kolem , kvu˚li , mezi , mı´sto , na , nad , na u´kor , o , od , ohledneˇ , okolo , oproti , po , pod , podle , pro , proti , prˇed , prˇes , prˇi , s , u , v , ve prospeˇch , vu˚cˇi , v za´jmu , z , za .</sentence>
				<definiendum id="0">vu˚cˇi</definiendum>
				<definiens id="0">jako , k , kolem , kvu˚li , mezi , mı´sto , na , nad , na u´kor , o , od , ohledneˇ , okolo , oproti , po , pod , podle , pro , proti , prˇed , prˇes , prˇi , s , u , v , ve prospeˇch ,</definiens>
			</definition>
			<definition id="8">
				<sentence>The abbreviation ‘inf’ stands for infinitive verbal complementation .</sentence>
				<definiendum id="0">abbreviation ‘inf’</definiendum>
			</definition>
			<definition id="9">
				<sentence>Then the controllee is an element that would be a ‘subject’ of the infinitive ( which is structurally excluded on the surface ) , and controller is the co-indexed expression .</sentence>
				<definiendum id="0">controller</definiendum>
				<definiens id="0">structurally excluded on the surface ) , and</definiens>
			</definition>
</paper>

		<paper id="3248">
			<definition id="0">
				<sentence>Another well-known word alignment approach , HMM ( Vogel et al. , 1996 ) , makes the alignment probabilities depend on the alignment position of the previous word .</sentence>
				<definiendum id="0">HMM</definiendum>
			</definition>
			<definition id="1">
				<sentence>, ... ,1 , Mm m =λ The alignment probability can be defined as follows ( Och and Ney , 2002 ) : ∑∑ ∑ = = = = ' 1 ] ) , ( exp [ ] ) , ( exp [ ) | ( ) | ( 1 ' 1 c M ne M m ecmm M m ecmm ecec neneh neneh nenepneneP λ λ λ ( 3.1 ) The decision rule to choose the most probable aligned target NE of the English NE is ( Och and Ney , 2002 ) : { }       = = ∑ = M m ecmm ne ec ne c neneh nenePen c c 1 ) , ( maxarg ) | ( maxargˆ λ ( 3.2 ) In our approach , considering the characteristics of NE translation , we adopt 4 features : translation score , transliteration score , the source NE and target NE’s co-occurrence score , and distortion score for distinguishing identical NEs in the same sentence .</sentence>
				<definiendum id="0">alignment probability</definiendum>
				<definiendum id="1">English NE</definiendum>
				<definiendum id="2">c 1</definiendum>
				<definiens id="0">translation score , transliteration score , the source NE and target NE’s co-occurrence score , and distortion score for distinguishing identical NEs in the same sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>To find the most probable PinYin string from English NE , we rewrite Formula ( 3.5 ) as the following : ) | ( * ) ( maxarg rePrPr r = ) ( 3.7 ) where r represents the romanization ( PinYin string ) , } ... , { 21 m rrrr = .</sentence>
				<definiendum id="0">r</definiendum>
				<definiens id="0">represents the romanization ( PinYin string ) , } ...</definiens>
			</definition>
			<definition id="3">
				<sentence>For each of the factor , we have ) | ( ) | ( 1 ∏ = = m i ii rePreP ( 3.8 ) ) | ( ) | ( ) ( ) ( 1 3 2121 − = −∏ = i m i ii rrrPrrPrPrP ( 3.9 ) where i e is an English syllable and i r is a Chinese PinYin substring .</sentence>
				<definiendum id="0">i e</definiendum>
				<definiendum id="1">i r</definiendum>
				<definiens id="0">an English syllable and</definiens>
			</definition>
			<definition id="4">
				<sentence>To deal with the two situations , let sur e denote the surface English string , the final transliteration score is defined by taking the maximum value of the two XDice coefficients : ) ) , ( ) , , ( max ( ) , ( surpytlpy ecXDiceecXDice ecTl = ( 3.11 ) This formula does not differentiate foreign person names and Chinese person names , and foreign person names’ transliteration strings or Chinese person names’ PinYin strings can be handled appropriately .</sentence>
				<definiendum id="0">PinYin strings</definiendum>
				<definiens id="0">taking the maximum value of the two XDice coefficients : ) ) , ( ) , , ( max ( )</definiens>
			</definition>
			<definition id="5">
				<sentence>We calculate the co-occurrence score of the source English NE and the candidate Chinese NE with the following formula : ∑ = ) ( * , ) , ( ) | ( e ec ecco necount nenecount neneP ( 3.12 ) where ) , ( ec nenecount is the number of times c ne and e ne appear together and ) ( * , e necount is the number of times that e ne appears .</sentence>
				<definiendum id="0">ec nenecount</definiendum>
				<definiens id="0">the co-occurrence score of the source English NE and the candidate Chinese NE with the following formula : ∑ = ) ( * , )</definiens>
				<definiens id="1">the number of times c ne and e ne appear together and ) ( *</definiens>
			</definition>
			<definition id="6">
				<sentence>To apply the maximum entropy model for NE alignment , we process in two steps : selecting the NE candidates and training the maximum entropy model parameters .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
			</definition>
			<definition id="7">
				<sentence>S is the alignment set we compute with our models based on S’ , and T is the set consisting of all the true alignments based on S’ .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the set consisting of all the true alignments based on S’</definiens>
			</definition>
</paper>

		<paper id="2116">
			<definition id="0">
				<sentence>Large-scale lexicons for computational semantics often lack suﬃcient distinguishing information for the concepts serving to define words .</sentence>
				<definiendum id="0">Large-scale lexicons</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Link Parser outputs syntactic dependencies among words , punctuation , and sentence boundary markers .</sentence>
				<definiendum id="0">Link Parser</definiendum>
				<definiens id="0">outputs syntactic dependencies among words , punctuation , and sentence boundary markers</definiens>
			</definition>
			<definition id="2">
				<sentence>The Berkeley FrameNet ( Fillmore et al. , 2001 ) project provides the most recent large-scale annotation of semantic roles .</sentence>
				<definiendum id="0">Berkeley FrameNet</definiendum>
				<definiens id="0">the most recent large-scale annotation of semantic roles</definiens>
			</definition>
			<definition id="3">
				<sentence>The goal of relation disambiguation is to determine the underlying semantic role indicated by particular words in a phrase or by word order .</sentence>
				<definiendum id="0">relation disambiguation</definiendum>
				<definiens id="0">to determine the underlying semantic role indicated by particular words in a phrase or by word order</definiens>
			</definition>
			<definition id="4">
				<sentence>The common inventory incorporates some of the general relation types defined by Gildea and Jurafsky ( 2002 ) for their experiments in classifying semantic relations in FrameNet using a reduced inventory .</sentence>
				<definiendum id="0">common inventory</definiendum>
				<definiens id="0">incorporates some of the general relation types defined by Gildea and Jurafsky ( 2002 ) for their experiments in classifying semantic relations in FrameNet using a reduced inventory</definiens>
			</definition>
			<definition id="5">
				<sentence>Mean gives the mean of the assessment ratings ( from 1 to 5 ) .</sentence>
				<definiendum id="0">Mean</definiendum>
				<definiens id="0">gives the mean of the assessment ratings ( from 1 to 5 )</definiens>
			</definition>
			<definition id="6">
				<sentence>Score gives ratings relative to scale from 0 to 1 .</sentence>
				<definiendum id="0">Score</definiendum>
				<definiens id="0">gives ratings relative to scale from 0 to 1</definiens>
			</definition>
</paper>

		<paper id="2011">
			<definition id="0">
				<sentence>Atomic propositions consist of a relational term ( the predicate ) and one or more arguments .</sentence>
				<definiendum id="0">Atomic propositions</definiendum>
			</definition>
			<definition id="1">
				<sentence>In these cases the working memory can be subdivided in a short term part ( STWM ) that has a limited capacity and a LTWM that is a part of the long term memory represented by the network of propositions .</sentence>
				<definiendum id="0">STWM</definiendum>
				<definiendum id="1">LTWM</definiendum>
				<definiens id="0">a part of the long term memory represented by the network of propositions</definiens>
			</definition>
			<definition id="2">
				<sentence>Kintsch uses a diffusion of activation pocedure that is a simplified version of the one developed by McClelland and Rumelhart ( J.L. McClelland , D.E. Rumelhart , 1986 ) .</sentence>
				<definiendum id="0">Kintsch</definiendum>
				<definiens id="0">uses a diffusion of activation pocedure that is a simplified version of the one developed by McClelland</definiens>
			</definition>
			<definition id="3">
				<sentence>Firstly an activation vector is defined whose elements are indexed over the nodes of LTWM .</sentence>
				<definiendum id="0">activation vector</definiendum>
				<definiens id="0">defined whose elements are indexed over the nodes of LTWM</definiens>
			</definition>
			<definition id="4">
				<sentence>If j is the selected unit , the probability that this node establishes a link with the unit i is : 11 ... ii i NN UkP UkUk= ++ where ki is the degree of the unit i 1 , i.e. the number of links established by it , while Ui is the fitness value associated to the node , and it can be computed as the ratio between the number of paragraphs that contain both i and j and the number of paragraphs that contain either i or j. LTM is an associative network that is updated with the content of the WM. Whenever a link of the WM corresponds to a link present in the LTM , the weight of this one is increased by “1” .</sentence>
				<definiendum id="0">ki</definiendum>
				<definiendum id="1">Ui</definiendum>
				<definiendum id="2">LTM</definiendum>
				<definiens id="0">the degree of the unit i 1</definiens>
			</definition>
			<definition id="5">
				<sentence>Since the scale free network that represents the content of the WM is used to update the content of LTM , this associative networks should take the form of a scale free graph .</sentence>
				<definiendum id="0">LTM</definiendum>
				<definiens id="0">the content of the WM is used to update the content of</definiens>
			</definition>
			<definition id="6">
				<sentence>A taxonomical representation can be considered as an important step towards the creation of an ontological representation .</sentence>
				<definiendum id="0">taxonomical representation</definiendum>
				<definiens id="0">an important step towards the creation of an ontological representation</definiens>
			</definition>
</paper>

		<paper id="2201">
			<definition id="0">
				<sentence>At the moment , the ETAP-3 environment comprises the following main options : 1 ) a rule based machine translation system ; 2 ) a Universal Networking Language ( UNL ) translation engine ; 3 ) a system of synonymous paraphrasing of sentences ; 4 ) a workbench for syntactic annotation of text corpora ; and 5 ) a grammar checker .</sentence>
				<definiendum id="0">Universal Networking Language ( UNL</definiendum>
				<definiens id="0">a system of synonymous paraphrasing of sentences ; 4 ) a workbench for syntactic annotation of text corpora</definiens>
			</definition>
			<definition id="1">
				<sentence>The general zone stores all types of monolingual information : part of speech , syntactic features , semantic features , subcategorization frames , lexical functions , syntactic and pre-syntactic rules , generation rules , and some other data .</sentence>
				<definiendum id="0">general zone</definiendum>
				<definiens id="0">stores all types of monolingual information : part of speech , syntactic features , semantic features , subcategorization frames , lexical functions , syntactic and pre-syntactic rules , generation rules</definiens>
			</definition>
			<definition id="2">
				<sentence>Default translation is a single word that translates the given word in nonspecific contexts ( it is introduced by a special label : TRANS ) .</sentence>
				<definiendum id="0">Default translation</definiendum>
				<definiens id="0">a single word that translates the given word in nonspecific contexts ( it is introduced by a special label : TRANS )</definiens>
			</definition>
			<definition id="3">
				<sentence>UNL is a formal language intended to represent information in a way that allows the generation of a text expressing this information in a large number of natural languages .</sentence>
				<definiendum id="0">UNL</definiendum>
			</definition>
			<definition id="4">
				<sentence>A UNL expression is an oriented hyper-graph that corresponds to a NL sentence in the amount of information conveyed .</sentence>
				<definiendum id="0">UNL expression</definiendum>
				<definiens id="0">an oriented hyper-graph that corresponds to a NL sentence in the amount of information conveyed</definiens>
			</definition>
			<definition id="5">
				<sentence>Our approach to UNL ( described in Boguslavsky et al. 2000 ) is to build a bridge between UNL and one of the internal representations of ETAP , namely Normalized Syntactic Structure ( NormSS ) , and in this way link UNL with all other levels of text representation , including the conventional orthographic form of the text .</sentence>
				<definiendum id="0">UNL</definiendum>
				<definiendum id="1">NormSS</definiendum>
				<definiens id="0">to build a bridge between UNL and one of the internal representations of ETAP</definiens>
			</definition>
			<definition id="6">
				<sentence>The most important of them are as follows : a ) Both UNL expressions and NormSSs occupy an intermediate position between the surface and the semantic levels of representation .</sentence>
				<definiendum id="0">NormSSs occupy</definiendum>
				<definiens id="0">an intermediate position between the surface and the semantic levels of representation</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , if we receive UW ( 5 ) open ( mod &lt; thing ) and do not find it in our UNL dictionary , we can replace it with the English word that stands in the position of the headword , that is open. However , this headword is ambiguous. In ETAP’s English dictionary there are three entries for open the adjective , the verb and the noun. A simple rule allows selecting the correct entry on the basis of the UW restriction : ( mod &lt; thing ) means that the headword serves as a modifier of things. Hence , its English correlate is an adjective and not a verb or a noun. Russian dictionary The UNL-related information is distributed among the three ETAP dictionaries : UNL , English and Russian. The general idea is to combine ( a ) the idea of having the English NormSS as an intermediate level between UNL and the Russian NormSS and as a source of Russian and English generation and ( b ) the requirement of adequately treating cases of non-isomorphism between the English and the Russian concepts. As shown in section 2.1 , the ETAP dictionary entry contains several bilingual sub-zones , according to the number of working languages. In particular , the Russian dictionary has sub-zones for English and UNL , the English dictionary – for Russian and UNL and the UNL dictionary – for English and Russian. Let us consider two cases : ( 1 ) the Russian and the English words are synonymous ( as , for example , to divorce and razvodit’sja ) and ( 2 ) they are not synonymous ( as , for example , to marry and zhenit’sja ) . The relevant fragments of the dictionary entries ( with some simplifications ) are as follows. UNL dictionary : NAME : divorce ( agt &gt; human ) ZONE : EN TRANS : divorce ZONE : RU &lt; none &gt; NAME : marry ( agt &gt; human ) ZONE : EN TRANS : marry ZONE : RU &lt; none &gt; NAME : marry ( agt &gt; male ) ZONE : EN &lt; none &gt; ZONE : RU TRANS : zhenit’sja English dictionary NAME : divorce ZONE : RU TRANS : razvodit’sja ZONE : UNL TRANS : divorce ( agt &gt; human ) NAME : marry ZONE : RU TRANS : zhenit’sja / vyxodit’ zamuzh ZONE : UNL TRANS : marry ( agt &gt; human ) Russian dictionary NAME : razvodit’sja ZONE : EN TRANS : divorce ZONE : UNL TRANS : divorce ( agt &gt; human ) NAME : zhenit’sja ZONE : EN TRANS : marry ZONE : UNL TRANS : marry ( agt &gt; human ) Suppose we have to process a UNL expression that contains UW “divorce ( agt &gt; human ) ” .</sentence>
				<definiendum id="0">UNL</definiendum>
				<definiens id="0">with the English word that stands in the position of the headword</definiens>
				<definiens id="1">an adjective and not a verb or a noun. Russian dictionary The UNL-related information is distributed among the three ETAP dictionaries : UNL , English and Russian. The general idea is to combine ( a ) the idea of having the English NormSS as an intermediate level between UNL and the Russian NormSS and as a source of Russian and English generation</definiens>
			</definition>
</paper>

		<paper id="1101">
			<definition id="0">
				<sentence>Chinese is a language with less morphology and no case marker .</sentence>
				<definiendum id="0">Chinese</definiendum>
				<definiens id="0">a language with less morphology and no case marker</definiens>
			</definition>
			<definition id="1">
				<sentence>In example ( 2 ) , the comma is a delimiter comma as well as a mul_dep_line_cross comma .</sentence>
				<definiendum id="0">comma</definiendum>
				<definiens id="0">a delimiter comma as well as a mul_dep_line_cross comma</definiens>
			</definition>
			<definition id="2">
				<sentence>Adjoining a Comma A segment is a group of words between two commas or a group of words from the beginning ( or end ) of a sentence to its nearest comma .</sentence>
				<definiendum id="0">Adjoining a Comma A segment</definiendum>
				<definiens id="0">a group of words between two commas or a group of words from the beginning</definiens>
			</definition>
			<definition id="3">
				<sentence>( a ) , 在他们写˛作业之ˇ，� ( b ) 他们—去的 ，� In example ( a ) , the PP has the embedded clause as its complement .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">has the embedded clause as its complement</definiens>
			</definition>
			<definition id="4">
				<sentence>Kernel function Inter-P Inter-R Intra-P Intra-R Inter-F Intra-F Total-P linear 74.22 % 77.87 % 72.52 % 70.61 % 76.00 % 71.56 % 73.14 % Polynomial d=2 79.84 % 81.15 % 84.51 % 83.77 % 80.49 % 84.14 % 82.86 % Polynomial d=3 78.57 % 81.15 % 88.39 % 86.84 % 79.84 % 87.61 % 84.86 % RBF γ = 0.5 78.46 % 83.61 % 88.64 % 85.53 % 80.95 % 87.05 % 84.86 % RBF γ = 1.5 78.69 % 78.69 % 89.04 % 89.04 % 78.69 % 89.04 % 85.43 % RBF γ = 2.5 80.62 % 85.25 % 88.24 % 85.53 % 82.87 % 86.86 % 85.43 % RBF γ = 3.5 79.41 % 88.52 % 85.05 % 79.82 % 83.72 % 82.35 % 82.86 % Table 6 : experimental results with different kernel functions Word Window Inter-P Inter-R Intra-P Intra-R Inter-F Intra-F Total-P Win3 80.45 % 87.70 % 84.33 % 80.26 % 83.92 % 82.25 % 82.86 % Win2-3 85.60 % 87.70 % 88.00 % 86.84 % 86.64 % 87.42 % 87.14 % Table 7 : experimental results for word window size Inter-P Inter-R Intra-P Intra-R Inter-F Intra-F Total-P POS sequence 75.42 % 72.95 % 80.60 % 82.02 % 74.17 % 81.30 % 78.86 % Table 8 : experimental results for using part of speech sequence Original parser Integrated parser Average dependency parsing accuracy 7 73.8 % 83.4 % Average complete sentence accuracy 23.8 % 25.4 % Table 9 : comparison of parsing accuracy of the original parser with the integrated parser 7 The evaluation measures are used as it is defined in Kim ( 2001 ) .</sentence>
				<definiendum id="0">Kernel function Inter-P Inter-R Intra-P Intra-R Inter-F Intra-F Total-P linear</definiendum>
				<definiens id="0">experimental results with different kernel functions Word Window Inter-P Inter-R Intra-P Intra-R Inter-F Intra-F Total-P Win3 80.45 %</definiens>
			</definition>
			<definition id="5">
				<sentence>2001 , Introduction to the CoNLL-2001 shared task : clause identification , Proceeding of CoNLL-2001 B. Say and V. Akman 1997 , current approaches to punctuation in computational linguistics , Computers and the Humanities , 1997 P.L. Shiuan and C.T.H. Ann 1996 , A divide-andconquer strategy for parsing , Proceedings of the ACL/SIGPARSE 5 th international workshop on parsing technologies , Santa Cruz , USA , pp57-66 Fei Xia 2000 , The bracketing Guidelines for the Penn Chinese Treebank ( 3.0 ) Vladimir N Vapnik 1995 The nature of statistical learning theory .</sentence>
				<definiendum id="0">Computers</definiendum>
				<definiens id="0">current approaches to punctuation in computational linguistics</definiens>
			</definition>
</paper>

		<paper id="1904">
			<definition id="0">
				<sentence>These guidelines have been developed by language engineers for ( semi- ) automatic annotation of morphosyntactic information.6 Syntactic annotation Penn Treebank ( bracketing guidelines , “BG” ) ( Bies et al. , 1995 ) , SPARKLE ( Carroll et al. , 1997 ) , VerbMobil , German Treebank ( Stegmann et al. , 2000 ) .7 Semantic/pragmatic annotation PropBank ( PropBank Project , 2002 ) , Penn Discourse Treebank ( Mitsakaki et al. , 2004 ) , DAMSL ( Dialog Act Markup in Several Layers , Allen and Core ( 1997 ) ) .</sentence>
				<definiendum id="0">“BG” )</definiendum>
				<definiendum id="1">DAMSL</definiendum>
				<definiens id="0">developed by language engineers for ( semi- ) automatic annotation of morphosyntactic information.6 Syntactic annotation Penn Treebank ( bracketing guidelines</definiens>
			</definition>
			<definition id="1">
				<sentence>[ . . . ] Subjunctive : We suggested that he do/VB it. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . VB or VBP If you are unsure whether a form is subjunctive ( VB ) or a present tense verb ( VBP ) , replace the subject by a third person pronoun .</sentence>
				<definiendum id="0">Subjunctive</definiendum>
				<definiens id="0">subjunctive ( VB ) or a present tense verb ( VBP ) , replace the subject by a third person pronoun</definiens>
			</definition>
			<definition id="2">
				<sentence>Content-based structure ( N ) Instructions are often presented in thematic units , e.g. all tags encoding nominal features are grouped together .</sentence>
				<definiendum id="0">Content-based structure</definiendum>
				<definiens id="0">thematic units , e.g. all tags encoding nominal features are grouped together</definiens>
			</definition>
			<definition id="3">
				<sentence>Usually , annotation documentation emerges from the annotating practice , supporting the annotator in the annotation task .</sentence>
				<definiendum id="0">annotation documentation</definiendum>
				<definiens id="0">emerges from the annotating practice , supporting the annotator in the annotation task</definiens>
			</definition>
			<definition id="4">
				<sentence>We sketch how the guidelines can be encoded by XML , which enables the generation of user-adapted representations through stylesheet technology ( e.g. XSLT ) .</sentence>
				<definiendum id="0">XML</definiendum>
			</definition>
</paper>

		<paper id="2412">
			<definition id="0">
				<sentence>The annotations provided for the development of systems include , apart from the argument boundaries and role labels , the levels of processing treated in the previous editions of the CoNLL shared task , i.e. , words , PoS tags , base chunks , clauses , and named entities .</sentence>
				<definiendum id="0">PoS</definiendum>
				<definiens id="0">tags , base chunks , clauses , and named entities</definiens>
			</definition>
			<definition id="1">
				<sentence>Precision ( p ) is the proportion of arguments predicted by a system which are correct .</sentence>
				<definiendum id="0">Precision ( p )</definiendum>
				<definiens id="0">the proportion of arguments predicted by a system which are correct</definiens>
			</definition>
			<definition id="2">
				<sentence>Recall ( r ) is the proportion of correct arguments which are predicted by a system .</sentence>
				<definiendum id="0">Recall ( r )</definiendum>
				<definiens id="0">the proportion of correct arguments which are predicted by a system</definiens>
			</definition>
			<definition id="3">
				<sentence>There are 13 types of adjuncts : AM-ADV : general-purpose AM-MOD : modal verb AM-CAU : cause AM-NEG : negation marker AM-DIR : direction AM-PNC : purpose AM-DIS : discourse marker AM-PRD : predication AM-EXT : extent AM-REC : reciprocal AM-LOC : location AM-TMP : temporal AM-MNR : manner In this section we describe the pipeline of processors to compute the annotations which form the input part of the data : part-of-speech ( PoS ) tags , chunks , clauses and named entities .</sentence>
				<definiendum id="0">general-purpose AM-MOD</definiendum>
				<definiens id="0">the pipeline of processors to compute the annotations which form the input part of the data : part-of-speech ( PoS ) tags , chunks , clauses and named entities</definiens>
			</definition>
			<definition id="4">
				<sentence>The DT B-NP ( S* O ( A0* * San NNP I-NP * B-ORG * * Francisco NNP I-NP * I-ORG * * Examiner NNP I-NP * I-ORG *A0 ) * issued VBD B-VP * O issue ( V*V ) * a DT B-NP * O ( A1* ( A1* special JJ I-NP * O * * edition NN I-NP * O *A1 ) *A1 ) around IN B-PP * O ( AM-TMP* * noon NN B-NP * O *AM-TMP ) * yesterday NN B-NP * O ( AM-TMP*AM-TMP ) * that WDT B-NP ( S* O ( C-A1* ( R-A1*R-A1 ) was VBD B-VP ( S* O * * filled VBN I-VP * O fill * ( V*V ) entirely RB B-ADVP * O * ( AM-MNR*AM-MNR ) with IN B-PP * O * * earthquake NN B-NP * O * ( A2* news NN I-NP * O * * and CC I-NP * O * * information NN I-NP *S ) S ) O *C-A1 ) *A2 ) .</sentence>
				<definiendum id="0">DT B-NP ( S* O</definiendum>
				<definiendum id="1">WDT B-NP ( S* O</definiendum>
				<definiens id="0">A0* * San NNP I-NP * B-ORG * * Francisco NNP I-NP * I-ORG * * Examiner NNP I-NP * I-ORG *A0 ) * issued VBD B-VP * O issue ( V*V ) * a DT B-NP * O ( A1* ( A1* special JJ I-NP * O * * edition NN I-NP * O *A1</definiens>
			</definition>
			<definition id="5">
				<sentence>Input consists of words ( 1st ) , PoS tags ( 2nd ) , base chunks ( 3rd ) , clauses ( 4th ) and named entities ( 5th ) .</sentence>
				<definiendum id="0">Input</definiendum>
			</definition>
			<definition id="6">
				<sentence>Very relevant to the SRL strategy is the availability of global sentential information when decisions are taken .</sentence>
				<definiendum id="0">SRL strategy</definiendum>
				<definiens id="0">the availability of global sentential information when decisions are taken</definiens>
			</definition>
			<definition id="7">
				<sentence>“prop.” stands for the treatment of all propositions of a sentence ; possible values are : s ( separate ) and j ( joint ) .</sentence>
				<definiendum id="0">“prop.”</definiendum>
				<definiens id="0">the treatment of all propositions of a sentence ; possible values are : s ( separate )</definiens>
			</definition>
</paper>

		<paper id="1121">
			<definition id="0">
				<sentence>A matching of G was defined as M , a subset of E with the property that no two edges of M have a common vertex .</sentence>
				<definiendum id="0">matching of G</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">a subset of E with the property that no two edges of M have a common vertex</definiens>
			</definition>
			<definition id="1">
				<sentence>BAM : If M= &lt; S , EM , T &gt; is a best alignment matching of G= &lt; S , E , T &gt; , then M must meet the following conditions : 1 ) All the vertexes in the complete bipartite graph are ordered ; 2 ) The weight of any edges in EM d ( si , tj ) has : d ( si , tj ) &lt; D ( where D is alignment threshold ) ; at the same time , there are no edges { sk , tr } which made k &lt; i and r &gt; j , or k &gt; i and r &lt; j ; Figure 1 K3,3 complete bipartite graph 3 ) If we consider : |S|=m and |T|=n , then the edge { sm , tn } belonged to EM ; Best alignment matching can be attained by searching for the smallest weight of edge in collection E , until the weight of every edge d ( si , tj ) is equal or more than the alignment threshold D. Generally , the alignment threshold D is determined according to experience because different texts have different styles. If each sentence in the text S ( or T ) corresponds with a vertex in V1 ( or V2 ) , the text S or T can be denoted by S ( s1 , s2 , s3 , …si , …sj , …sm ) or T ( t1 , t2 , t3…ti , …tj , …tn ) . Considering the form merely , each element in S combined with any element in T can create a complete bipartite graph. Thus the alignment task can be seen as the process of searching for the BAM in the complete bipartite graph. As shown in figure 2 , the edge e = { si , tj } belongs to M ; this means that the i-th sentence in text S and the j-th sentence in text T can make an alignment anchor. Each edge is corresponding to an alignment value. In order to ensure the bilingual texts are divided with the same fragment number , we default that the last sentence in the bilingual text is aligned. That is to say , { sm , tn } E∈M was correct , if |S|=m and |T|=n in the BAM mathematical model. We stipulated the smaller the alignment value is , the more similar the sentence pair is to a candidate anchor. The smallest value of the sentence pair is found from the complete bipartite graph. That means the selected sentence pair is the most probable aligned ( 1:1 ) sentence bead. Alignment process is completed until the alignment anchors become saturated under alignment threshold value. Sentence pairs extracted from all sentence pairs are seen as alignment anchors. These anchors divide the whole texts into short aligned fragments. The definition of BAM ensures that the selected sentence pairs can not produce cross-alignment errors , and some cases of ( 1 : more ) or ( more : 1 ) alignment fragments can be attained by the fragments pairs between two selected alignment anchors. All ( 1:1 ) sentence beads are extracted from different styles of bilingual texts. The distribution states that all of them are similar as presented in figure 3. The horizontal axis denotes the sentence number in Chinese text , and the vertical axis denotes the sentence number in English text. -20020406080100120140160180 -20 0 20 40 60 80 100 120 140 160 180 200 Se nte nc e N um be r in E ng lis h T ex t Sentence Number in Chinese Text Beads Statistical results show that more than 85 % sentence beads are ( 1:1 ) sentence beads in bilingual texts and their distributions obey an obvious law well. ( DeKai Wu , 1994 ) offered that ( 1:1 ) sentence beads occupied 89 % in English-Chinese as well. If we select these style sentence beads as candidate anchors , the alignment method will be general on any other language pairs. The main points of our alignment method using sentences location information are : locating by the whole text , collocating by sentence length and checking by a bilingual dictionary. Location information of any sentence pair is used fully. Three lengths are used : are sentence length , upper context length above the sentence pair and nether context length below the sentence. All this information is considered to calculate the alignment weight of each sentence pair. Finally , the sentence pair with high weight will be checked by a English-Chinese bilingual dictionary. In order to study the relationship between every sentence pair of { si , tj } , four parameters are defined : Whole text length ratio : P0 = Ls / Lt ; Upper context length ratio : Pu [ i , j ] = Usi / Utj ; Nether context length ratio : Pd [ i , j ] = Dsi / Dtj Sentence length ratio : Pl [ i , j ] = Lsi / Ltj ; Figure 2 Sketch map of Km , n BAM under alignment threshold D t1 t2 t3 t4 t5 t6 t7 ti tj tn-2 tn-1 tn s1 s2 s3 s4 s5 s6 s7 si sj sm-2 sm-1 sm ···· ···· Figure 3 Distribution of ( 1:1 ) sentence beads in bilingual texts Where si the i-th sentence of S ; tj the j-th sentence of T ; Ls the length of source language text S ; Lt the length of target language text T ; Lsi the length of si ; Ltj the length of tj ; Usi the upper context length above sentence si ; Utj the upper context length above sentence tj ; Dsi the nether context length below sentence si ; Dtj the nether context length below sentence tj ; Figure 4 illustrates clearly the relationship of all variables. If si and tj can construct a ( 1:1 ) alignment anchor , P [ i , j ] must be less than the alignment threshold , where P [ i , j ] denotes the integrated alignment value between si and tj. We assume that the weight coefficient of Pl [ i , j ] is 1. Only considering the form , Pu [ i , j ] and Pd [ i , j ] must have the same weight coefficient. Here the weight coefficient is set α. We constructed a formal alignment function on every sentence pair : P [ i , j ] = α ( Pu [ i , j ] -P0 ) ² + ( Pl [ i , j ] -P0 ) ² +α ( Pd [ i , j ] -P0 ) ² Where , the parameter α is the weight coefficient , if can adjust the weight of sentence pair length and the weight of context lengths well. The longer the text is , the more insensitive the effect of the context-length is. So α’s value should increase in order to balance the whole proportion. The short text is vice versa. In this paper we define : α= ( Ls/Lsi + Lt/Ltj ) /2 According to the definition of BAM , the smaller the alignment function value of P [ i , j ] is , the more the probability of sentence pair { si , tj } being a ( 1:1 ) sentence bead is. In this paper , we adopt a greedy algorithm to select alignment anchors according to all the alignment function values of P [ i , j ] which are less than the alignment threshold. This procedure can be implemented with a time complexity of O ( m*n ) . To obtain further improvement in alignment accuracy requires calculation of the similarity of the sentence pairs. An English-Chinese bilingual dictionary is adopted to calculate the semantic similarity between the two sentences in a sentence pair. The similarity formula based on a bilingual dictionary is followed : Where L| | is the bytes number of all elements , Match ( T ) is ( according to English-Chinese dictionary ) the English words which have Chinese translation in the Chinese sentence , Match ( S ) is the matched Chinese fragments. According to the above dictionary check , alignment precision is improved greatly. We take a statistic on all the errors and find that most errors are partial alignment errors. Partial alignment means that the alignment location is correct , but a half pair of the alignment pairs is not integrated. It is very difficult to avoid these errors when only taking into account the sentence location and length information. Thus in order to reduce this kind of error , we check the semantic similarity of the context-adjacent sentence pairs also. Because these pairs could be other alignment patterns , such as ( 1:2 ) or ( 2:1 ) , the similarity formulas have some difference from the ( 1:1 ) sentence pair formula. Here , a simple judgement is performed. It is shown as : If（Lsi-1 * P0 &gt; Ltj-1） else Here , those alignment anchors whose similarities exceed the similarity threshold based on the bilingual dictionary will become the final alignment anchors .</sentence>
				<definiendum id="0">D</definiendum>
				<definiens id="0">a best alignment matching of G= &lt; S , E , T &gt; , then M must meet the following conditions : 1 ) All the vertexes in the complete bipartite graph are ordered ; 2 ) The weight of any edges in EM d ( si , tj ) has : d ( si</definiens>
				<definiens id="1">alignment threshold</definiens>
				<definiens id="2">no edges { sk , tr } which made k &lt; i and r &gt; j , or k &gt; i and r &lt; j ; Figure 1 K3,3 complete bipartite graph 3 ) If we consider : |S|=m and |T|=n , then the edge { sm , tn } belonged to EM ; Best alignment matching can be attained by searching for the smallest weight of edge in collection E , until the weight of every edge d ( si , tj ) is equal or more than the alignment threshold D. Generally , the alignment threshold D is determined according to experience because different texts have different styles. If each sentence in the text S ( or T ) corresponds with a vertex in V1 ( or V2 ) , the text S or T can be denoted by S ( s1 , s2 , s3 , …si , …sj , …sm ) or T ( t1 , t2 , t3…ti , …tj , …tn ) . Considering the form merely , each element in S combined with any element in T can create a complete bipartite graph. Thus the alignment task can be seen as the process of searching for the BAM in the complete bipartite</definiens>
				<definiens id="3">the i-th sentence in text S and the j-th sentence in text T can make an alignment anchor. Each edge is corresponding to an alignment value. In order to ensure the bilingual texts are divided with the same fragment number , we default that the last sentence in the bilingual text is aligned. That is to say</definiens>
				<definiens id="4">if |S|=m and |T|=n in the BAM mathematical model. We stipulated the smaller the alignment value is , the more similar the sentence pair is to a candidate anchor. The smallest value of the sentence pair is found from the complete bipartite graph. That means the selected sentence pair is the most probable aligned ( 1:1 ) sentence bead. Alignment process is completed until the alignment anchors become saturated under alignment threshold value. Sentence pairs extracted from all sentence pairs are seen as alignment anchors. These anchors divide the whole texts into short aligned fragments. The definition of BAM ensures that the selected sentence pairs can not produce cross-alignment errors , and some cases of ( 1 : more ) or ( more : 1 ) alignment fragments can be attained by the fragments pairs between two selected alignment anchors. All ( 1:1 ) sentence beads</definiens>
				<definiens id="5">the sentence number in English text. -20020406080100120140160180 -20 0 20 40 60 80 100 120 140 160 180 200 Se nte nc e N um be r in E ng lis h T ex t Sentence Number in Chinese Text Beads Statistical results show that more than 85 % sentence beads are ( 1:1 ) sentence beads in bilingual texts and their distributions obey an obvious law well. ( DeKai Wu , 1994 ) offered that ( 1:1 ) sentence beads</definiens>
				<definiens id="6">locating by the whole text , collocating by sentence length and checking by a bilingual dictionary. Location information of any sentence pair is used fully. Three lengths are used : are sentence length , upper context length above the sentence pair and nether context length below the sentence. All this information is considered to calculate the alignment weight of each sentence pair. Finally , the sentence pair with high weight will be checked by a English-Chinese bilingual dictionary. In order to study the relationship between every sentence pair of { si , tj } , four parameters are defined : Whole text length ratio : P0 = Ls / Lt</definiens>
				<definiens id="7">1:1 ) sentence beads in bilingual texts Where si the i-th sentence of S ; tj the j-th sentence of T ; Ls the length of source language text S ; Lt the length of target language text T ; Lsi the length of si ; Ltj the length of tj ; Usi the upper context length above sentence si ; Utj the upper context length above sentence tj ; Dsi the nether context length below sentence si ; Dtj the nether context length below sentence tj ; Figure 4 illustrates clearly the relationship of all variables. If si and tj can construct a ( 1:1 ) alignment anchor</definiens>
				<definiens id="8">the integrated alignment value between si and tj. We assume that the weight coefficient of Pl [ i , j ] is 1. Only considering the form</definiens>
				<definiens id="9">the weight coefficient , if can adjust the weight of sentence pair length and the weight of context lengths well. The longer the text</definiens>
				<definiens id="10">a greedy algorithm to select alignment anchors according to all the alignment function values of P [ i , j ] which are less than the alignment threshold. This procedure can be implemented with a time complexity of O ( m*n ) . To obtain further improvement in alignment accuracy requires calculation of the similarity of the sentence pairs. An English-Chinese bilingual dictionary is adopted to calculate the semantic similarity between the two sentences in a sentence pair. The similarity formula based on a bilingual dictionary is followed : Where L| | is the bytes number of all elements , Match ( T ) is ( according to English-Chinese dictionary ) the English words which have Chinese translation in the Chinese sentence , Match ( S ) is the matched Chinese fragments. According to the above dictionary check , alignment precision is improved greatly. We take a statistic on all the errors and find that most errors are partial alignment errors. Partial alignment means that the alignment location is correct , but a half pair of the alignment pairs is not integrated. It is very difficult to avoid these errors when only taking into account the sentence location and length information. Thus in order to reduce this kind of error , we check the semantic similarity of the context-adjacent sentence pairs also. Because these pairs could be other alignment patterns</definiens>
			</definition>
</paper>

		<paper id="2403">
			<definition id="0">
				<sentence>Convolution kernels are a viable alternative to flat feature representation that aims to capture the structural information in term of sub-structures .</sentence>
				<definiendum id="0">Convolution kernels</definiendum>
				<definiens id="0">a viable alternative to flat feature representation that aims to capture the structural information in term of sub-structures</definiens>
			</definition>
			<definition id="1">
				<sentence>Position : Indicates if the constituent , i.e. the potential argument , appears before or after the predicate in the sentence , e.g. after for Arg1 and before for Arg0 ( see Figure 1 ) .</sentence>
				<definiendum id="0">Position</definiendum>
				<definiens id="0">appears before or after the predicate in the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Voice : This feature distinguishes between active or passive voice for the predicate phrase , e.g. active for every argument ( see Figure 1 ) .</sentence>
				<definiendum id="0">Voice</definiendum>
				<definiens id="0">This feature distinguishes between active or passive voice for the predicate phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>Governing Category : This feature applies to noun phrases only , and it indicates if the NP is dominated by a sentence phrase ( typical for subject arguments with active voice predicates ) , or by a verb phrase ( typical for object arguments ) , e.g. the NP associated with Arg1 is dominated by a verbal phrase VP ( see Figure 1 ) .</sentence>
				<definiendum id="0">verbal phrase VP</definiendum>
				<definiens id="0">dominated by a sentence phrase ( typical for subject arguments with active voice predicates ) , or by a verb phrase ( typical for object arguments</definiens>
			</definition>
			<definition id="4">
				<sentence>It follows that h ( ~x ) = Pn2N Ii ( n ) , where N is the set of the ~x’s nodes .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">h ( ~x ) = Pn2N Ii ( n ) , where</definiens>
			</definition>
			<definition id="5">
				<sentence>† if the production at nx and nz are the same , and nx and nz are pre-terminals then ∆ ( nx ; nz ) = 1 ; ( 2 ) † if the production at nx and nz are the same , and nx and nz are not pre-terminals then ∆ ( nx ; nz ) = nc ( nx ) Y j=1 ( 1+∆ ( ch ( nx ; j ) ; ch ( nz ; j ) ) ) ; ( 3 ) where nc ( nx ) is the number of children of nx and ch ( n ; i ) is the i-th child of the node n. Note that as the productions are the same ch ( nx ; i ) = ch ( nz ; i ) .</sentence>
				<definiendum id="0">nz</definiendum>
				<definiendum id="1">nc ( nx )</definiendum>
				<definiendum id="2">ch ( n ; i )</definiendum>
				<definiens id="0">the i-th child of the node n. Note that as the productions are the same ch ( nx ; i ) = ch ( nz ; i )</definiens>
			</definition>
</paper>

		<paper id="2614">
			<definition id="0">
				<sentence>These event representations typically decompose seman1see ( Dowty , 1991 ) and ( Levin and Rappaport Hovav , 1996 ) tic roles in terms of primitive predicates representing concepts such as causality , agentivity , inchoativity , and stativity ( Dowty , 1979 ; Jackendoff , 1983 ; Pustejovsky , 1991b ; Rappaport Hovav and Levin , 1998 ) .</sentence>
				<definiendum id="0">stativity</definiendum>
				<definiens id="0">tic roles in terms of primitive predicates representing concepts such as causality , agentivity</definiens>
			</definition>
			<definition id="1">
				<sentence>Rappaport Hovav and Levin’s more recent theory of event templates ( 1998 ) also defines a basic inventory of event building blocks in terms of Vendler’s event types : ( 5 ) a. [ x ACT &lt; MANNER &gt; ] ( activity ) b. [ x &lt; STATE &gt; ] ( state ) c. [ BECOME [ x &lt; STATE &gt; ] ] ( achievement ) d. [ x CAUSE [ BECOME [ y &lt; STATE &gt; ] ] ] ( accomplishment ) e. [ [ x ACT &lt; MANNER &gt; ] CAUSE [ BECOME [ y &lt; STATE &gt; ] ] ] ( accomplishment ) ( Rappaport Hovav and Levin , 1998:108 ) A verb’s meaning consists of a constant paired with a particular event template drawn from the basic inventory above .</sentence>
				<definiendum id="0">verb’s meaning</definiendum>
				<definiens id="0">defines a basic inventory of event building blocks in terms of Vendler’s event types : ( 5 ) a. [ x ACT &lt; MANNER &gt; ] ( activity ) b. [ x &lt; STATE &gt; ] ( state ) c. [ BECOME [ x &lt; STATE &gt; ] ] ( achievement ) d. [ x CAUSE [ BECOME [ y &lt; STATE &gt; ] ] ] ( accomplishment ) e. [ [ x ACT &lt; MANNER &gt; ] CAUSE [ BECOME [ y &lt; STATE</definiens>
				<definiens id="1">consists of a constant paired with a particular event template drawn from the basic inventory above</definiens>
			</definition>
			<definition id="2">
				<sentence>One important bit of evidence is the existence of activity/achievement verb pairs in English , which are not present in Mandarin : ( 9 ) English activity achievement look ( at ) see listen ( to ) hear study learn look for find ( 10 ) Mandarin activity achievement kan4 ‘look’ kan4 jian4 ‘look-perceive’ = see ting1 ‘listen’ ting1 jian4 ‘listen-perceive’ = hear xue2 ‘study’ xue2 hui4 ‘study-able’ = learn zhao3 ‘look for’ zhao3 dao4 ‘look.for-arrive’ = find In English , for example , the verb look expresses an atelic activity , while the verb see expresses a telic achievement that lexicalizes the attainment of a goal ( i.e. , the successful act of perception ) .</sentence>
				<definiendum id="0">telic achievement</definiendum>
				<definiens id="0">the existence of activity/achievement verb pairs in English</definiens>
				<definiens id="1">the successful act of perception )</definiens>
			</definition>
			<definition id="3">
				<sentence>Similar minimal pairs related to prenominal modifiers show this same contrast : ( 19 ) a. sui4 shattered ( de5 ) DE bo1li2 glass ‘shattered glass’ ( stative/adjective ) b. sui4 shattered le5 LE de5 DE bo1li2 glass ‘glass that was shattered’ ( resultative participle ) The above pair represents a subtle but detectable difference in meaning ; whereas ( 19a ) describes a pure state , ( 19b ) describes the result of an event .</sentence>
				<definiendum id="0">above pair</definiendum>
				<definiens id="0">a subtle but detectable difference in meaning</definiens>
			</definition>
</paper>

		<paper id="2706">
			<definition id="0">
				<sentence>The first two arguments , though labeled by “semantically descriptive” tags ACT and PAT ( Actor and Patient , respectively ) correspond to the first and the second argument of a verb ( cf. Tesni`ere’s ( Tesni`ere , 1959 ) first and second actant ) , the other three arguments of the verb being then differentiated ( in accordance with semantic considerations ) as ADDR ( essee ) , ORIG ( in ) or EFF ( ect ) ; these five functors belong to the set of participants ( arguments ) and are distinguished from ( free ) modifications ( adjuncts ) such as LOC ( ative ) , several types of directional and temporal ( e.g. TWHEN ) modifications , APP ( urtenance ) , R ( e ) STR ( ictive attribute ) , DIFF ( erence ) , PREC ( eding cotext referred to ) , etc. on the basis of two basic operational criteria ( Panevov´a , 1974 ) , ( Panevov´a , 1994 ) : ( i ) can the given type of modification modify in principle every verb ?</sentence>
				<definiendum id="0">R ( e ) STR ( ictive attribute ) , DIFF ( erence</definiendum>
				<definiens id="0">the verb being then differentiated ( in accordance with semantic considerations</definiens>
				<definiens id="1">the set of participants ( arguments ) and are distinguished from ( free ) modifications ( adjuncts ) such as LOC ( ative ) , several types of directional and temporal ( e.g. TWHEN ) modifications , APP ( urtenance )</definiens>
			</definition>
			<definition id="1">
				<sentence>In the Functional Generative Description ( Sgall et al. , 1986 ) , TFA is captured as one of the basic aspects of the underlying structure , namely as the left-to-right dimension of the dependency tree , working with the basic opposition of contextual boundness ; the contextually bound ( CB ) nodes stand to the left of the non-bound ( NB ) nodes , with the verb as the root of the tree being either contextually bound or non-bound .</sentence>
				<definiendum id="0">Functional Generative Description</definiendum>
				<definiendum id="1">TFA</definiendum>
				<definiendum id="2">CB</definiendum>
				<definiens id="0">nodes , with the verb as the root of the tree being either contextually bound or non-bound</definiens>
			</definition>
			<definition id="2">
				<sentence>The attribute coref contains the identifier of the antecedent ; if there are more than one antecedents of one anaphor , the attribute coref includes a sequence of identifiers of the relevant antecedents ; since every node of a TGTS has an identifier of its own it is a simple programming task to select the specific information on the antecedent .</sentence>
				<definiendum id="0">coref</definiendum>
				<definiens id="0">includes a sequence of identifiers of the relevant antecedents ; since every node of a TGTS has an identifier of its own it is a simple programming task to select the specific information on the antecedent</definiens>
			</definition>
			<definition id="3">
				<sentence>The attribute corlemma is used for cases of a coreference between a node and an entity that has no corresponding counterpart in the TGTS ( s ) : for the time being , there are two possible values of this attribute , namely segm in the case of a coreferential link to a whole segment of the preceding text ( not just a sentence ) , and exoph in the case of an exophoric relation .</sentence>
				<definiendum id="0">exoph</definiendum>
				<definiens id="0">a sentence ) , and</definiens>
			</definition>
</paper>

		<paper id="0803">
			<definition id="0">
				<sentence>They have amply demonstrated that FrameNet is a substantial lexical resource that will permit extensive further research and exploitation in NLP applications in the future .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">a substantial lexical resource that will permit extensive further research and exploitation in NLP applications in the future</definiens>
			</definition>
			<definition id="1">
				<sentence>A worthy objective for the Senseval community is the development of a wide range of methods for automating frame semantics , specifically identifying and labeling semantic roles in sentences .</sentence>
				<definiendum id="0">worthy objective</definiendum>
				<definiens id="0">the development of a wide range of methods for automating frame semantics , specifically identifying and labeling semantic roles in sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>The FrameNet project ( Johnson et al. , 2003 ) has put together a body of hand-labeled data and the Gildea and Jurafsky study has put together a set of suitable metrics for evaluating the performance of an automatic system .</sentence>
				<definiendum id="0">FrameNet project</definiendum>
				<definiens id="0">a body of hand-labeled data and the Gildea and Jurafsky study has put together a set of suitable metrics for evaluating the performance of an automatic system</definiens>
			</definition>
			<definition id="3">
				<sentence>FrameNet recognizes the permissibility of “conceptually salient” frame elements that have not been instantiated in a sentence ; these are called null instantiations ( see Johnson et al. for a fuller description ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiendum id="1">null instantiations</definiendum>
				<definiens id="0">recognizes the permissibility of “conceptually salient” frame elements that have not been instantiated in a sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>FrameNet Explorer provides several facilities for examining the FrameNet data : by frame , frame element , and lexical units .</sentence>
				<definiendum id="0">FrameNet Explorer</definiendum>
				<definiens id="0">provides several facilities for examining the FrameNet data : by frame , frame element</definiens>
			</definition>
			<definition id="5">
				<sentence>Recall was computed as the number of correct answers divided by the number of frame elements in the test set .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the number of correct answers divided by the number of frame elements in the test set</definiens>
			</definition>
</paper>

		<paper id="2803">
			<definition id="0">
				<sentence>Carmel-Tools is used to author domain specific semantic knowledge sources for the Carmel Workbench ( Ros´e , 2000 ; Ros´e et al. , 2002 ) that contains broad coverage domain general syntactic and lexical knowledge sources for robust language understanding in English .</sentence>
				<definiendum id="0">Carmel-Tools</definiendum>
				<definiens id="0">broad coverage domain general syntactic and lexical knowledge sources for robust language understanding in English</definiens>
			</definition>
			<definition id="1">
				<sentence>The Carmel-Tools authoring process involves designing a Predicate Language Definition , augmenting the base lexical resources by either loading raw human tutoring corpora or entering example texts by hand , and annotating example texts with their corresponding representation in the defined Predicate Language Definition .</sentence>
				<definiendum id="0">Carmel-Tools authoring process</definiendum>
				<definiens id="0">involves designing a Predicate Language Definition , augmenting the base lexical resources by either loading raw human tutoring corpora or entering example texts by hand , and annotating example texts with their corresponding representation in the defined Predicate Language Definition</definiens>
			</definition>
			<definition id="2">
				<sentence>Compiled knowledge sources contain pointers back to the annotated examples that are responsible for their creation .</sentence>
				<definiendum id="0">Compiled knowledge sources</definiendum>
				<definiens id="0">contain pointers back to the annotated examples that are responsible for their creation</definiens>
			</definition>
			<definition id="3">
				<sentence>It also segments the file into a list of student sentence strings , which are then loaded into a Corpus Examples list , which appears on the right hand side of the interface .</sentence>
				<definiendum id="0">student sentence strings</definiendum>
				<definiens id="0">appears on the right hand side of the interface</definiens>
			</definition>
			<definition id="4">
				<sentence>Predicate mapping rules are generated for each template by first converting the corresponding syntactic feature structure into the semantic representation defined by the automatically generated ontology and lexicon with semantic pointers .</sentence>
				<definiendum id="0">Predicate mapping rules</definiendum>
				<definiens id="0">each template by first converting the corresponding syntactic feature structure into the semantic representation defined by the automatically generated ontology and lexicon with semantic pointers</definiens>
			</definition>
</paper>

		<paper id="1911">
			<definition id="0">
				<sentence>German is a language with a relatively free word order in which the subject usually precedes the object , but can also follow it : In ( 1 ) , the subject “Turnverein Neur¨onnebeck” precedes the object “Fairneßpokal” ; in ( 2 ) the same object precedes the subject , without changing the original meaning of the sentence .</sentence>
				<definiendum id="0">German</definiendum>
				<definiendum id="1">subject “Turnverein Neur¨onnebeck”</definiendum>
				<definiens id="0">a language with a relatively free word order in which the subject</definiens>
				<definiens id="1">precedes the object “Fairneßpokal” ; in ( 2 ) the same object precedes the subject , without changing the original meaning of the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The Negra corpus ( Skut et al. , 1998 ) is an annotated collection of 20,602 sentences ( 355,096 erature to express information structure ( for a recent overview see Kruiff-Korbayov´a and Steedman ( 2003 ) ) .</sentence>
				<definiendum id="0">Negra corpus</definiendum>
				<definiens id="0">an annotated collection of 20,602 sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>In fact , none of our OVS sentences contained a fronted reflexive pronoun .</sentence>
				<definiendum id="0">OVS</definiendum>
				<definiens id="0">sentences contained a fronted reflexive pronoun</definiens>
			</definition>
			<definition id="3">
				<sentence>For instance , geographic familiarity with the catchment area of the Frankfurter Rundschau is considered specific knowledge : In ( 4 ) , “Waldstadion” is one of the local soccer stadiums in Frankfurt .</sentence>
				<definiendum id="0">“Waldstadion”</definiendum>
				<definiens id="0">one of the local soccer stadiums in Frankfurt</definiens>
			</definition>
			<definition id="4">
				<sentence>( SVO ) pro given pro new full given full new pro &lt; full 92 3 28 67 full &lt; pro 23 10 14 19 ( OVS ) pro given pro new full given full new pro &lt; full 69 7 30 46 full &lt; pro 70 21 37 54 Table 5 : Linear order frequency of pronoun-full NP pairs for given and new complements .</sentence>
				<definiendum id="0">SVO</definiendum>
				<definiens id="0">Linear order frequency of pronoun-full NP pairs for given and new complements</definiens>
			</definition>
</paper>

		<paper id="0915">
			<definition id="0">
				<sentence>We have defined document normalization as the process that first derives the normalized communicative content of a text in a constrained domain ( e.g. drug leaflets ) , and then generates the normalized version of the text in the language of the original document .</sentence>
				<definiendum id="0">document normalization</definiendum>
				<definiens id="0">the process that first derives the normalized communicative content of a text in a constrained domain ( e.g. drug leaflets ) , and then generates the normalized version of the text in the language of the original document</definiens>
			</definition>
			<definition id="1">
				<sentence>This allows obtaining identical semantic interpretations for paraphrases such as ProductX is a colorless , non flammable liquid and ProductX is a liquid that has no colour and that does not burn easily .</sentence>
				<definiendum id="0">ProductX</definiendum>
				<definiens id="0">a colorless , non flammable liquid</definiens>
				<definiens id="1">a liquid that has no colour and that does not burn easily</definiens>
			</definition>
			<definition id="2">
				<sentence>The icon represents a semantic object that dominates a semantic subtree containing no underspecifications ; the icon represents a semantic object that does not take part in any underspecification , but which dominates a subtree that contains at least one ; the icon represents a semantic type that is underspecified , that is for which at least two semantic objects are in competition ; finally , the icon denotes semantic objects in competition , which are ordered for a given type by decreasing score of plausibility .</sentence>
				<definiendum id="0">icon</definiendum>
				<definiens id="0">a semantic object that dominates a semantic subtree containing no underspecifications</definiens>
				<definiens id="1">for which at least two semantic objects are in competition</definiens>
				<definiens id="2">semantic objects in competition , which are ordered for a given type by decreasing score of plausibility</definiens>
			</definition>
</paper>

		<paper id="2423">
</paper>

		<paper id="3107">
</paper>

		<paper id="2322">
			<definition id="0">
				<sentence>1 In this paper we present an overview of recent theoretical and computational developments in discourse theory and parsing under the Linguistic Discourse Model ( LDM ) framework , a semantic account of discourse structure .</sentence>
				<definiendum id="0">Discourse Model</definiendum>
				<definiens id="0">an overview of recent theoretical and computational developments in discourse theory and parsing under the Linguistic</definiens>
			</definition>
			<definition id="1">
				<sentence>course Model ( C-LDM ) Unlike the Discourse Structures Model ( DSM ) of Grosz and Sidner ( 1986 ) , a pragmatic and psychological theory that aims to clarify the relationship between speakers’ intentions and their focus of attention in discourse , or the rhetorical model of Rhetorical Structures Theory ( Mann and Thompson , 1988 ) that is designed to identify the coherence relations between segments of text , the Linguistic Discourse Model ( LDM ) ( Polanyi and Scha , 1984 ; Polanyi , 1988 ; Polanyi and van den Berg , 1996 ) is a syntactically informed , semantically driven model developed to provide proper semantic interpretation for every utterance in a discourse despite the apparent discontinuities that are present even in well structured written texts .</sentence>
				<definiendum id="0">C-LDM ) Unlike the Discourse Structures Model</definiendum>
				<definiendum id="1">Polanyi</definiendum>
				<definiens id="0">aims to clarify the relationship between speakers’ intentions and their focus of attention in discourse , or the rhetorical model of Rhetorical Structures Theory ( Mann and Thompson , 1988 ) that is designed to identify the coherence relations between segments of text , the Linguistic Discourse Model ( LDM ) ( Polanyi and Scha , 1984 ;</definiens>
				<definiens id="1">a syntactically informed , semantically driven model developed to provide proper semantic interpretation for every utterance in a discourse despite the apparent discontinuities that are present even in well structured written texts</definiens>
			</definition>
			<definition id="2">
				<sentence>Therefore , like DSM and RST , the LDM incorporates an explicit tree structured model of relationships between discourse segments as its model of discourse “syntax” .</sentence>
				<definiendum id="0">LDM</definiendum>
			</definition>
			<definition id="3">
				<sentence>The analysis of intra-sentential structure is done by sentential syntax which identifies the syntactic and semantic structures within the sentence and makes the resulting analysis available for discourse processing .</sentence>
				<definiendum id="0">sentential syntax</definiendum>
				<definiens id="0">identifies the syntactic and semantic structures within the sentence and makes the</definiens>
			</definition>
			<definition id="4">
				<sentence>Basic discourse units ( BDUs ) , resulting from a segmentation of the discourse according to rules of discourse segmentation , form the content of the leaves of the tree .</sentence>
				<definiendum id="0">Basic discourse units</definiendum>
				<definiendum id="1">BDUs</definiendum>
				<definiens id="0">resulting from a segmentation of the discourse according to rules of discourse segmentation , form the content of the leaves of the tree</definiens>
			</definition>
			<definition id="5">
				<sentence>( Polanyi , 1985 ; Grosz and Sidner 1986 ; Webber , 1991 ) The LDM posits three structural relations between discourse units : a. Units related by bearing a similar relationship to an existing or newly formed common parent in the tree ( lists , narratives ) .</sentence>
				<definiendum id="0">LDM</definiendum>
				<definiens id="0">posits three structural relations between discourse units : a. Units related by bearing a similar relationship to an existing or newly formed common parent in the tree ( lists , narratives )</definiens>
			</definition>
			<definition id="6">
				<sentence>BDUs , under this model , are discourse segments of a type that can be independently continued : operator segments are one example of non-BDU segments .</sentence>
				<definiendum id="0">BDUs</definiendum>
				<definiens id="0">discourse segments of a type that can be independently continued : operator segments</definiens>
			</definition>
			<definition id="7">
				<sentence>The process , which includes constructing a BDU tree of the sentence , can be summarized as follows : segment , we would answer that this sentences concerns one eventuality ( something being fun ) , not two .</sentence>
				<definiendum id="0">process</definiendum>
				<definiens id="0">includes constructing a BDU tree of the sentence</definiens>
			</definition>
			<definition id="8">
				<sentence>Eventualities ( activities or states ) and their participants .</sentence>
				<definiendum id="0">Eventualities</definiendum>
			</definition>
			<definition id="9">
				<sentence>A rule is a pair : Rule &lt; C , O &gt; where C is the set of constraints that enable the rule and O is the associated operation .</sentence>
				<definiendum id="0">rule</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">O</definiendum>
				<definiens id="0">the set of constraints that enable the rule</definiens>
				<definiens id="1">the associated operation</definiens>
			</definition>
			<definition id="10">
				<sentence>Reported speech/reporting clause Subordination M-BDU Realis status differs from Status of AP ( MBDU is Irrealis ; AP is Realis OR MBDU is Realis ; AP is Irrealis ) Nary-Attachment ( intrasentential ) Tense ( AP ) = past Tense ( MBDU ) = pluperfect AP is time-reference for MBDU Nary-Attachment ( intrasentential ) VerbClass ( AP ) =”SpeechAct” Type ( MBDU ) = ADJUNCT Nary-Attachment ( intrasentential ) Tense ( AP ) = present Tense ( MBDU ) = past AP is time-reference for MBDU Coordinate Parent ( AP ) is Coordination Parent ( AP ) would coordinate with MBDU AP would coordinate with MBDU Subordination Tense ( AP ) = past Genericty ( AP ) = specific Tense ( MBDU ) = present Genericty ( MBDU ) = generic Subordination M-BDU genericity status differs from Status of AP ( MBDU is specific ; AP is generic OR MBDU is generic ; AP is specific ) Subordination SUBJ ( MBDU ) = OBJ ( AP ) Subordination SUBJ ( MBDU ) XCOMP ( AP ) Subordination MBDU/Lexeme is a subcase of AP/Lexeme Role ( AP/Lexeme ) = Role ( MBDU/Lexeme ) Right Headed Subordination ( intrasentential ) Type ( AP ) = ADJUNCT Type ( MBDU ) = S Nary-Attach ( intrasentential ) PRED ( ADJUNCT ( AP ) ) = “if” AP is Irrealis MBDU is Realis Nary-Attachment ( intrasentential ) AP and MBDU related by logical connective ( cf Webber &amp; Joshi , 1998 ; Forbes ( 2003 ) Subordination Tense ( AP ) = past Tense ( MBDU ) = pluperfect Subordination Tense ( AP ) = present Tense ( MBDU ) = past Subordinate AP is Bottom of DPT M-BDU is Footnote or Parenthetical Coordinate AP is Narrative ( = Specific , punctual , event ) MBDU is Narrative Coordinate Tense ( AP ) = Tense ( MBDU ) Aspect ( AP ) = Aspect ( MBDU ) Coordinate MBDU/Lexeme is synonym or antonym of AP/Lexeme Role ( AP/Lexeme ) = Role ( MBDU/Lexeme ) Subordinate AP is Bottom of DPT Table 3 .</sentence>
				<definiendum id="0">Subordination Tense</definiendum>
				<definiendum id="1">AP</definiendum>
				<definiendum id="2">MBDU</definiendum>
				<definiendum id="3">AP</definiendum>
				<definiendum id="4">specific ) Subordination SUBJ</definiendum>
				<definiens id="0">Reported speech/reporting clause Subordination M-BDU Realis status differs from Status of AP ( MBDU is Irrealis ; AP is Realis OR MBDU is Realis ; AP is Irrealis ) Nary-Attachment ( intrasentential ) Tense ( AP ) = past Tense ( MBDU ) = pluperfect AP is time-reference for MBDU Nary-Attachment ( intrasentential ) VerbClass ( AP ) =”SpeechAct” Type ( MBDU ) = ADJUNCT Nary-Attachment ( intrasentential ) Tense ( AP ) = present Tense ( MBDU ) = past AP is time-reference for MBDU Coordinate Parent ( AP ) is Coordination Parent ( AP ) would coordinate with MBDU AP would coordinate with MBDU</definiens>
				<definiens id="1">generic Subordination M-BDU genericity status differs from Status of AP ( MBDU is specific ;</definiens>
				<definiens id="2">generic OR</definiens>
			</definition>
			<definition id="11">
				<sentence>The PALSUMM Text Summarization System is a domain independent symbolic sentence extraction system that produces high level readable summaries that preserve the language and style of the original text and eliminate problems with unresolved or incorrect reference .</sentence>
				<definiendum id="0">PALSUMM Text Summarization System</definiendum>
				<definiens id="0">a domain independent symbolic sentence extraction system that produces high level readable summaries that preserve the language and style of the original text and eliminate problems with unresolved or incorrect reference</definiens>
			</definition>
</paper>

		<paper id="0828">
			<definition id="0">
				<sentence>The TALP system belongs to the supervised Machine Learning family .</sentence>
				<definiendum id="0">TALP system</definiendum>
			</definition>
			<definition id="1">
				<sentence>Constraint classification ( Har-Peled et al. , 2002 ) is a learning framework that generalises many multiclass classification and ranking schemes .</sentence>
				<definiendum id="0">Constraint classification</definiendum>
				<definiens id="0">a learning framework that generalises many multiclass classification and ranking schemes</definiens>
			</definition>
			<definition id="2">
				<sentence>CC ( base ) refers to the constrain–classification setting on the starting feature set .</sentence>
				<definiendum id="0">CC</definiendum>
				<definiens id="0">the constrain–classification setting on the starting feature set</definiens>
			</definition>
			<definition id="3">
				<sentence>OVA ( best ) and CC ( best ) mean one–vs–all and constraint–classification with their respective feature selection .</sentence>
				<definiendum id="0">OVA</definiendum>
				<definiendum id="1">CC</definiendum>
				<definiens id="0">best ) mean one–vs–all and constraint–classification with their respective feature selection</definiens>
			</definition>
</paper>

		<paper id="1806">
			<definition id="0">
				<sentence>The induced ontology consists of domain concepts related by kind-of and part-of links , but does not include more specialized relations or axioms .</sentence>
				<definiendum id="0">induced ontology</definiendum>
			</definition>
			<definition id="1">
				<sentence>The structure of the ontology is a directed acyclic graph ( DAG ) .</sentence>
				<definiendum id="0">DAG</definiendum>
				<definiens id="0">a directed acyclic graph</definiens>
			</definition>
			<definition id="2">
				<sentence>We use the log likelihood ratio ( LLR ) ( Dunning 1993 ) given by -2log 2 ( H o ( p ; k 1 , n 1 , k 2 , n 2 ) /H a ( p 1 , p 2 ; n 1 , k 1 , n 2 , k 2 ) ) LLR measures the extent to which a hypothesized model of the distribution of cell counts , H a , differs from the null hypothesis , H o ( namely , that the percentage of documents containing this term is the same in both corpora ) .</sentence>
				<definiendum id="0">LLR</definiendum>
				<definiens id="0">measures the extent to which a hypothesized model of the distribution of cell counts</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , the Gene Ontology can be used to infer that ‘ATP-dependent RNA helicase’ is a kind of ‘RNA-helicase’ .</sentence>
				<definiendum id="0">Gene Ontology</definiendum>
				<definiens id="0">a kind of ‘RNA-helicase’</definiens>
			</definition>
			<definition id="4">
				<sentence>CBS is based on the algorithm of ( Lawrie et al. 2001 ) , which used a greedy approximation of the Domination Set Problem for graphs to discover subsumption relations among terms .</sentence>
				<definiendum id="0">CBS</definiendum>
				<definiens id="0">used a greedy approximation of the Domination Set Problem for graphs to discover subsumption relations among terms</definiens>
			</definition>
			<definition id="5">
				<sentence>In Table 2 , we provide some examples of how the LLR term scoring statistic performed with respect to five others on selected unigrams in the Topic 230 domain : term frequency , document frequency , term frequency times inverse document frequency ( TF*IDF ) , pointwise mutual information ( MI ) , and information gain ( IG ) .</sentence>
				<definiendum id="0">document frequency , term frequency times inverse document frequency</definiendum>
				<definiens id="0">mutual information ( MI ) , and information gain ( IG )</definiens>
			</definition>
</paper>

		<paper id="2207">
			<definition id="0">
				<sentence>( 5 ) X is a model which was designated to stimulate… X est un modèle qui a été conçu pour stimuler… GOVDEP PROPAGATION TO ALIGN DEPENDENT VERBS .</sentence>
				<definiendum id="0">X</definiendum>
			</definition>
			<definition id="1">
				<sentence>Propagation patterns are given in the form CDep-REL-CGov , where CDep is the POS of the dependent , REL is the syntactic relation and CGov , the POS of the governor .</sentence>
				<definiendum id="0">Propagation patterns</definiendum>
				<definiendum id="1">CDep</definiendum>
				<definiendum id="2">REL</definiendum>
				<definiendum id="3">CGov</definiendum>
				<definiens id="0">the syntactic relation and</definiens>
			</definition>
</paper>

		<paper id="1512">
</paper>

		<paper id="2319">
			<definition id="0">
				<sentence>“Chan” : channel ( speaker ) ; “DA” : full dialog act label ( multiple tags are separated by “^” ) ; “==” : incomplete DA ; “xx xx” : disfluency interruption point between words ; “xx-” : incomplete word ; “AP” : adjacency pairs ( use arbitrary identifiers ) .</sentence>
				<definiendum id="0">“AP” : adjacency pairs</definiendum>
				<definiens id="0">full dialog act label ( multiple tags are separated by “^” ) ; “==” : incomplete DA</definiens>
			</definition>
</paper>

		<paper id="0907">
			<definition id="0">
				<sentence>There is a close relationship between syntax and semantics here , in that syntax provides the basic argument and modifier positions for the head verb of the relative clause , which semantics fleshes out by way of selectional restrictions .</sentence>
				<definiendum id="0">relative clause</definiendum>
				<definiens id="0">semantics fleshes out by way of selectional restrictions</definiens>
			</definition>
			<definition id="1">
				<sentence>Relative clause interpretation is a core component of text understanding , as demonstrated in the context of the MUC conference series ( Cardie , 1992 ; Hobbs et al. , 1997 ) .</sentence>
				<definiendum id="0">Relative clause interpretation</definiendum>
			</definition>
			<definition id="2">
				<sentence>Features used in the interpretation of RCCs include a generalised case frame description , a verb class characterisation , head noun semantics , morphological analysis of the head verb , and various constructional templates .</sentence>
				<definiendum id="0">Features</definiendum>
				<definiens id="0">used in the interpretation of RCCs include a generalised case frame description , a verb class characterisation</definiens>
			</definition>
			<definition id="3">
				<sentence>Minimum verb morpheme content involves determining the morphemic content of the head verb of the relative clause for each verb stem it is compatible with , and selecting the verb stem ( s ) which are morphologically least complex .</sentence>
				<definiendum id="0">Minimum verb morpheme content</definiendum>
				<definiens id="0">involves determining the morphemic content of the head verb of the relative clause for each verb stem it is compatible with , and selecting the verb stem ( s ) which are morphologically least complex</definiens>
			</definition>
			<definition id="4">
				<sentence>This can be formalised as : a0a2a1a2a3a5a4a7a6a9a8a11a10a13a12a15a14a2a16a18a17 a19a21a20a23a22 a6a9a8a25a24a26 a12a15a14 a22 a22 a6a9a8 a22a27a20a28a22 a12a15a14 a22 where a29a31a30 is the set of case slots in the input , a32a34a33 the set of case slots in the current case frame , and a35a36 the case slot overlap operator .</sentence>
				<definiendum id="0">a29a31a30</definiendum>
				<definiens id="0">the set of case slots in the input</definiens>
			</definition>
			<definition id="5">
				<sentence>The representational preference ( a37a39a38 ) of lexical form a40 of verb entry a41 ( i.e. a40a43a42 ) is defined as the likelihood of a41 being realised as a40 : a44a46a45 a4a48a47a50a49a51a16a52a17 a19a43a20 a42a54a53a31a55a57a56 a4a48a47a54a49a54a16 a19a21a20a59a58a61a60a63a62 a64a66a65 a42a54a53a67a55a68a56 a4 a0 a49a51a16 This is normalised over the representational preference for all source entries a40 a0 , producing the verb score ( a69a71a70 ) for each a40a43a42 : a72a74a73 a4a48a47a50a49a51a16a52a17 a44a75a45 a4a48a47 a49 a16 a58a61a60 a44a76a45 a4a48a47 a60 a16 All frequencies are calculated based on the EDR corpus ( EDR , 1995 ) , a 2m morpheme corpus of largely technical Japanese prose .</sentence>
				<definiendum id="0">representational preference ( a37a39a38</definiendum>
				<definiendum id="1">EDR corpus</definiendum>
				<definiens id="0">the likelihood of a41 being realised as a40 : a44a46a45 a4a48a47a50a49a51a16a52a17 a19a43a20 a42a54a53a31a55a57a56 a4a48a47a54a49a54a16 a19a21a20a59a58a61a60a63a62 a64a66a65 a42a54a53a67a55a68a56 a4 a0 a49a51a16 This is normalised over the representational preference for all source entries a40 a0 , producing the verb score ( a69a71a70 ) for each a40a43a42 : a72a74a73 a4a48a47a50a49a51a16a52a17 a44a75a45 a4a48a47 a49 a16 a58a61a60 a44a76a45 a4a48a47 a60 a16 All frequencies are calculated based on the</definiens>
			</definition>
			<definition id="6">
				<sentence>disambiguation Japanese cosubordinated clauses ( i.e. dependent but not embedded clauses , as indicated by the use of a conjunction such as nagara , te , tutu or si , or through continuative type conjugation : Van Valin ( 1984 ) ) offer an additional avenue for disambiguation : ( 6 ) [ [ Kim-ga Kim-NOM k¯oaN-si , design ] seisaku-sita produced ] kikai machine “a machine designed and produced by Kim” ( 7 ) [ [ kyoneN last year hatumei-sare invented ] ry¯uk¯o-sita got popular ] mono thing “things which were invented and gained popularity last year” As is apparent in ( 6 ) and ( 7 ) , a consistent RCC interpretation is maintained across cosubordinated clauses , e.g. in ( 6 ) , kikai “machine” is the DIRECT OBJECT of both k¯oaN-si and seisaku-sita.2 It is possible to put this observation to use when interpreting cosubordinated RCCs , by coordinating the feature vectors for the unit clauses to produce a unique , coherent interpretation for the overall RCC .</sentence>
				<definiendum id="0">disambiguation Japanese cosubordinated clauses</definiendum>
				<definiens id="0">indicated by the use of a conjunction such as nagara , te , tutu or si , or through continuative type conjugation : Van Valin ( 1984 ) ) offer an additional avenue for disambiguation : ( 6 ) [ [ Kim-ga Kim-NOM k¯oaN-si , design ] seisaku-sita produced ] kikai machine “a machine designed and produced by Kim” ( 7 ) [ [ kyoneN last year hatumei-sare invented ] ry¯uk¯o-sita got popular ] mono</definiens>
			</definition>
			<definition id="7">
				<sentence>85 86 87 88 89 90 91 Classification accuracy ( % ) Disambiguation method Training set Test set RandomUC ANDUC ORUC HeuristicUC Figure 1 : Evaluation of unit clause disambiguation strategies 85 86 87 88 89 90 91 OR AND Classification accuracy ( % ) Method for combining clausal analyses Training set Test set Upper Bound CI CIHeuristic*UCHeuristicUC Figure 2 : Evaluation of cosubordinated clause disambiguation strategies First , we evaluate analytical disambiguation by decomposing each RCC into its component cosubordinated RCCs and selecting most plausible interpretation for each unit clause ( UC ) .</sentence>
				<definiendum id="0">Classification accuracy</definiendum>
				<definiens id="0">Evaluation of unit clause disambiguation strategies 85 86 87 88 89 90 91 OR AND Classification accuracy ( % ) Method for combining clausal analyses Training set Test set Upper Bound CI CIHeuristic*UCHeuristicUC Figure 2 : Evaluation of cosubordinated clause disambiguation strategies First , we evaluate analytical disambiguation by decomposing each RCC into its component cosubordinated RCCs and selecting most plausible interpretation for each unit clause</definiens>
			</definition>
			<definition id="8">
				<sentence>HeuristicUC outperforms the RandomUC baseline to a level of statistical significance,4 in both training and testing .</sentence>
				<definiendum id="0">HeuristicUC</definiendum>
				<definiens id="0">outperforms the RandomUC baseline to a level of statistical significance,4 in both training and testing</definiens>
			</definition>
			<definition id="9">
				<sentence>65 70 75 80 85 90 C N V C+N C+V N+V C+N+V Classification accuracy ( % ) Parameter configuration Training set Test set Figure 3 : Evaluation of different parameter combinations ( C = case slot instantiation , N = head noun semantics , and V = head verb class ) is marginally worse than RandomUC in both training and testing .</sentence>
				<definiendum id="0">V C+N C+V N+V C+N+V Classification accuracy</definiendum>
				<definiens id="0">head verb class ) is marginally worse than RandomUC in both training and testing</definiens>
			</definition>
</paper>

		<paper id="1115">
			<definition id="0">
				<sentence>Finally we considered effectiveness on a representative test sampling of the full data set , rather than the downsampled , balanced set , adding a proportional number of unseen non-final words to the test set .</sentence>
				<definiendum id="0">effectiveness</definiendum>
				<definiens id="0">on a representative test sampling of the full data set</definiens>
			</definition>
</paper>

		<paper id="2402">
			<definition id="0">
				<sentence>Latent Semantic Indexing ( LSI ) ( Deerwester et al. , 1990 ) is a well-known application of spectral analysis to word-by-document matrices .</sentence>
				<definiendum id="0">Latent Semantic Indexing ( LSI )</definiendum>
				<definiens id="0">a well-known application of spectral analysis to word-by-document matrices</definiens>
			</definition>
			<definition id="1">
				<sentence>LSI uses spectral analysis for measuring document or word similarities .</sentence>
				<definiendum id="0">LSI</definiendum>
				<definiens id="0">uses spectral analysis for measuring document or word similarities</definiens>
			</definition>
			<definition id="2">
				<sentence>Expectation Maximization ( EM ) is an iterative algorithm for model parameter estimation ( Dempster et al. , 1977 ) .</sentence>
				<definiendum id="0">Expectation Maximization</definiendum>
				<definiendum id="1">EM )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Global optimization ( Spectral ) vs. local optimization Secondly , starting from the status initialized by labeled data , EM performs local maximization , and co-training and other bootstrapping methods proceed greedily .</sentence>
				<definiendum id="0">Global optimization</definiendum>
				<definiens id="0">Spectral ) vs. local optimization Secondly , starting from the status initialized by labeled data , EM performs local maximization , and co-training and other bootstrapping methods proceed greedily</definiens>
			</definition>
			<definition id="4">
				<sentence>Also note that the reported numbers for TRB , cotraining , co-EM , and EM are the best performance among the explored parameter settings ( described in Section on a corpus disjoint from the test corpora once and used for all the experiments ( Section 5.2 ) .</sentence>
				<definiendum id="0">EM</definiendum>
			</definition>
</paper>

		<paper id="2214">
			<definition id="0">
				<sentence>For instance we can say that TENNIS is a more specific domain than SPORT , or that ARCHITECTURE is more general than TOWN PLANNING .</sentence>
				<definiendum id="0">TENNIS</definiendum>
			</definition>
			<definition id="1">
				<sentence>Domain hierarchies can be usefully integrated into other linguistic resources and are also profitably used in many Natural Language Processing ( NLP ) tasks such as Word Sense Disambiguation ( Magnini et al. 2002 ) , Text Categorization ( Schutze , 1998 ) , Information Retrieval ( Walker and Amsler , 1986 ) .</sentence>
				<definiendum id="0">Domain hierarchies</definiendum>
				<definiendum id="1">Text Categorization</definiendum>
				<definiendum id="2">Information Retrieval</definiendum>
				<definiens id="0">other linguistic resources and are also profitably used in many Natural Language Processing ( NLP ) tasks such as Word Sense Disambiguation ( Magnini et al. 2002 )</definiens>
			</definition>
			<definition id="2">
				<sentence>The first version of the WDH was composed of 164 domain labels selected starting from the subject field codes used in current dictionaries , and the subject codes contained in the Dewey Decimal Classification ( DDC ) , a general knowledge organization tool which is the most widely used taxonomy for library organization purposes .</sentence>
				<definiendum id="0">Decimal Classification</definiendum>
				<definiens id="0">composed of 164 domain labels selected starting from the subject field codes used in current dictionaries , and the subject codes contained in the Dewey</definiens>
			</definition>
			<definition id="3">
				<sentence>The Dewey Decimal Classification ( DDC ) system ( Mitchell et al. 1996 ) is the most widely used taxonomy for library classification purposes providing a logical system for the organization of every item of knowledge through well-defined subject codes hierarchically organized .</sentence>
				<definiendum id="0">Dewey Decimal Classification ( DDC ) system</definiendum>
			</definition>
			<definition id="4">
				<sentence>The DDC hierarchical structure allows a topic to be defined as part of the broader topic above it , and that determines the meaning of the class and its relation to other classes .</sentence>
				<definiendum id="0">DDC hierarchical</definiendum>
				<definiens id="0">part of the broader topic above it , and that determines the meaning of the class and its relation to other classes</definiens>
			</definition>
			<definition id="5">
				<sentence>At the broadest level , called Main Classes ( or First summary ) , the DDC is composed of ten mutually exclusive main classes , which together cover the entire world of knowledge .</sentence>
				<definiendum id="0">Main Classes</definiendum>
				<definiens id="0">First summary ) , the DDC is composed of ten mutually exclusive main classes , which together cover the entire world of knowledge</definiens>
			</definition>
			<definition id="6">
				<sentence>In this paper we described the revision of the WORDNET DOMAINS Hierarchy ( WDH ) , with the aim of providing it with a clear semantics , and evaluating the coverage and balancing of a subset of the WDH , called Basic Domains .</sentence>
				<definiendum id="0">WORDNET DOMAINS Hierarchy</definiendum>
				<definiens id="0">semantics , and evaluating the coverage and balancing of a subset of the WDH , called Basic Domains</definiens>
			</definition>
</paper>

		<paper id="3240">
			<definition id="0">
				<sentence>The Coordinator ( Winograd , 1987 ) was one such system , in which users augmented email messages with additional annotations indicating intent .</sentence>
				<definiendum id="0">Coordinator</definiendum>
				<definiens id="0">in which users augmented email messages with additional annotations indicating intent</definiens>
			</definition>
			<definition id="1">
				<sentence>Information includes data believed to be fact as well as opinions , and also attached data files .</sentence>
				<definiendum id="0">Information</definiendum>
			</definition>
			<definition id="2">
				<sentence>The email corpora used in our experiments consist of four different email datasets collected from working groups who signed agreements to make their email accessible to researchers .</sentence>
				<definiendum id="0">email corpora</definiendum>
			</definition>
			<definition id="3">
				<sentence>The first three datasets , N01F3 , N02F2 , and N03F2 are annotated subsets of a larger corpus , the CSpace email corpus , which contains approximately 15,000 email messages collected from a management course at Carnegie Mellon University .</sentence>
				<definiendum id="0">CSpace email corpus</definiendum>
				<definiens id="0">contains approximately 15,000 email messages collected from a management course at Carnegie Mellon University</definiens>
			</definition>
			<definition id="4">
				<sentence>To evaluate inter-annotator agreement , we doublelabeled N03F2 for the verbs Deliver , Commit , Request , Amend , and Propose , and the noun , Meeting , and computed the kappa statistic ( Carletta , 1996 ) for each of these , defined as R RA − −= 1κ where A is the empirical probability of agreement on a category , and R is the probability of agreement for two annotators that label documents at random ( with the empirically observed frequency of each label ) .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the verbs Deliver , Commit , Request , Amend , and Propose , and the noun , Meeting , and computed the kappa statistic</definiens>
				<definiens id="1">R RA − −= 1κ where A is the empirical probability of agreement on a category , and</definiens>
			</definition>
			<definition id="5">
				<sentence>VP is an implementation of the voted perceptron algorithm ( Freund &amp; Schapire , 1999 ) .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">an implementation of the voted perceptron algorithm</definiens>
			</definition>
			<definition id="6">
				<sentence>DT is a simple decision tree learning system , which learns trees of depth at most five , and chooses splits to maximize the function ( ) 00112 −+−+ + WWWW suggested by Schapire and Singer ( 1999 ) as an appropriate objective for “weak learners” .</sentence>
				<definiendum id="0">DT</definiendum>
				<definiens id="0">a simple decision tree learning system , which learns trees of depth at most five</definiens>
			</definition>
			<definition id="7">
				<sentence>AB is an implementation of the confidence-rated boosting method described by Singer and Schapire ( 1999 ) , used to boost the DT algorithm 10 times .</sentence>
				<definiendum id="0">AB</definiendum>
				<definiens id="0">an implementation of the confidence-rated boosting method described by Singer and Schapire</definiens>
			</definition>
			<definition id="8">
				<sentence>Minorthird : Methods for Identifying Names and Ontological Relations in Text using Heuristics for Inducing Regularities from Data , http : //minorthird.sourceforge.net .</sentence>
				<definiendum id="0">Minorthird</definiendum>
			</definition>
			<definition id="9">
				<sentence>Ifile : An Application of Machine Learning to Mail Filtering .</sentence>
				<definiendum id="0">Ifile</definiendum>
				<definiens id="0">An Application of Machine Learning to Mail Filtering</definiens>
			</definition>
			<definition id="10">
				<sentence>Swiftfile : An intelligent assistant for organizing e-mail .</sentence>
				<definiendum id="0">Swiftfile</definiendum>
				<definiens id="0">An intelligent assistant for organizing e-mail</definiens>
			</definition>
</paper>

		<paper id="2707">
			<definition id="0">
				<sentence>MATE workbench : an annotation tool for XML coded speech corpora .</sentence>
				<definiendum id="0">MATE workbench</definiendum>
				<definiens id="0">an annotation tool for XML coded speech corpora</definiens>
			</definition>
</paper>

		<paper id="2109">
			<definition id="0">
				<sentence>The template consists of the following major parts : The first part contains information which is typically found in dictionaries .</sentence>
				<definiendum id="0">template</definiendum>
				<definiens id="0">consists of the following major parts : The first part contains information which is typically found in dictionaries</definiens>
			</definition>
</paper>

		<paper id="3209">
			<definition id="0">
				<sentence>Sentence boundary detection is a problem that has received limited attention in the text-based computational linguistics community ( Schmid , 2000 ; Palmer and Hearst , 1994 ; Reynar and Ratnaparkhi , 1997 ) , but which has recently acquired renewed importance through an effort by the DARPA EARS program ( DARPA Information Processing Technology Office , 2003 ) to improve automatic speech transcription technology .</sentence>
				<definiendum id="0">Sentence boundary detection</definiendum>
				<definiens id="0">a problem that has received limited attention in the text-based computational linguistics community</definiens>
				<definiens id="1">acquired renewed importance through an effort by the DARPA EARS program ( DARPA Information Processing Technology Office , 2003 ) to improve automatic speech transcription technology</definiens>
			</definition>
			<definition id="1">
				<sentence>The HMM is a generative modeling approach , since it describes a stochastic process with hidden variables ( the locations of sentence boundaries ) that produces the observable data .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">a generative modeling approach</definiens>
				<definiens id="1">the locations of sentence boundaries ) that produces the observable data</definiens>
			</definition>
			<definition id="2">
				<sentence>The SU error rate is defined as the total number of deleted or inserted SU boundary events , divided by the number of true SU boundaries.1 For diagnostic purposes a secondary evaluation condition allows use of the correct word transcripts .</sentence>
				<definiendum id="0">SU error rate</definiendum>
				<definiens id="0">the total number of deleted or inserted SU boundary events , divided by the number of true SU boundaries.1 For diagnostic purposes a secondary evaluation condition allows use of the correct word transcripts</definiens>
			</definition>
			<definition id="3">
				<sentence>1 w i ) The N-gram estimator maximizes the joint word+event sequence likelihood P ( W ; E ) on the training data ( modulo smoothing ) , and does not guarantee that the correct event posteriors needed for classification according to Equation ( 1 ) are maximized .</sentence>
				<definiendum id="0">N-gram estimator</definiendum>
				<definiens id="0">maximizes the joint word+event sequence likelihood P ( W ; E ) on the training data ( modulo smoothing ) , and does not guarantee that the correct event posteriors needed for classification according to Equation ( 1 ) are maximized</definiens>
			</definition>
			<definition id="4">
				<sentence>The HMM made more effective use of prosodic information and degraded less with errorful word recognition .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">made more effective use of prosodic information and degraded less with errorful word recognition</definiens>
			</definition>
</paper>

		<paper id="3102">
			<definition id="0">
				<sentence>For example , “MAPK1” is a member of the “MAPK family” and the “MAPK family” is a member of the family of the “Ser/Thr protein kinase family” ; in turn , this family is a member of “protein kinase” , and “protein kinase” is a type of “kinase” .</sentence>
				<definiendum id="0">“MAPK1”</definiendum>
				<definiendum id="1">“MAPK family”</definiendum>
				<definiens id="0">a member of the family of the “Ser/Thr protein kinase family” ; in turn</definiens>
			</definition>
			<definition id="1">
				<sentence>“TAP1” is the synonym for “transporter 1 , ATP-binding cassette , sub-family B ( MDR/TAP ) ” , and “transient receptor potential cation channel , subfamily C , member 4 associated protein.”</sentence>
				<definiendum id="0">“TAP1”</definiendum>
			</definition>
			<definition id="2">
				<sentence>For example , LRE2 is a synonym for “LINE retrotransposable element 2” and “LINE retrotransposable element 3” .</sentence>
				<definiendum id="0">LRE2</definiendum>
				<definiens id="0">a synonym for “LINE retrotransposable element 2” and “LINE retrotransposable element 3”</definiens>
			</definition>
</paper>

		<paper id="0850">
			<definition id="0">
				<sentence>It has been renamed for SENSEVAL-3 as Duluth-xLSS , where x is a one letter abbreviation of the language to which it is being applied , and LSS stands for Lexical Sample Supervised .</sentence>
				<definiendum id="0">x</definiendum>
				<definiendum id="1">LSS</definiendum>
				<definiens id="0">a one letter abbreviation of the language to which it is being applied</definiens>
			</definition>
			<definition id="1">
				<sentence>The SenseTools package converts unigram , bigram , and co–occurrence features as discovered by NSP into the ARFF format required by the Weka Machine Learning system ( Witten and Frank , 2000 ) .</sentence>
				<definiendum id="0">SenseTools package</definiendum>
				<definiens id="0">converts unigram , bigram , and co–occurrence features as discovered by NSP into the ARFF format required by the Weka Machine Learning system</definiens>
			</definition>
			<definition id="2">
				<sentence>Weka is a freely available Java based suite of machine learning methods .</sentence>
				<definiendum id="0">Weka</definiendum>
				<definiens id="0">a freely available Java based suite of machine learning methods</definiens>
			</definition>
			<definition id="3">
				<sentence>As a final factor in our evaluation , Duluth-ELSU is a WordNet based system .</sentence>
				<definiendum id="0">Duluth-ELSU</definiendum>
				<definiens id="0">a WordNet based system</definiens>
			</definition>
			<definition id="4">
				<sentence>The Duluth-ELSU system is an unsupervised approach that is based on WordNet content , in particular relatedness scores that are computed by measuring gloss overlaps of the candidate senses of a target word with the possible senses of neighboring words .</sentence>
				<definiendum id="0">Duluth-ELSU system</definiendum>
				<definiens id="0">an unsupervised approach that is based on WordNet content , in particular relatedness scores that are computed by measuring gloss overlaps of the candidate senses of a target word with the possible senses of neighboring words</definiens>
			</definition>
</paper>

		<paper id="2801">
			<definition id="0">
				<sentence>However , such techniques introduce additional ambiguity and can lead to a loss of fidelity ( i.e. , a mismatch between the semantic interpretation and what the language producer meant ) .</sentence>
				<definiendum id="0">fidelity</definiendum>
				<definiens id="0">a mismatch between the semantic interpretation and what the language producer meant )</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , NLU subsystems for tutoring must attempt to extract correct elements from student answers that they do not fully understand .</sentence>
				<definiendum id="0">NLU subsystems</definiendum>
				<definiens id="0">for tutoring must attempt to extract correct elements from student answers that they do not fully understand</definiens>
			</definition>
			<definition id="2">
				<sentence>The problem with such robustness features is that they introduce additional ambiguity and can lead to a loss of fidelity ( i.e. , a mismatch between the semantic interpretation and what the language producer meant ) if no clarification or confirmation request is made .</sentence>
				<definiendum id="0">fidelity</definiendum>
				<definiens id="0">a mismatch between the semantic interpretation and what the language producer meant ) if no clarification or confirmation request is made</definiens>
			</definition>
			<definition id="3">
				<sentence>NUBEE uses an application-specific logical framework which closely resembles minimal recursion semantics ( MRS ) ( Copestake et al. , 1999 ) .</sentence>
				<definiendum id="0">NUBEE</definiendum>
			</definition>
			<definition id="4">
				<sentence>Building such a representation is difficult because the NLU process consists of a series of tasks : preprocessing ( in a typed system , this consists of spelling correction and unknown word handling ) , syntactic and semantic analysis , and reference resolution .</sentence>
				<definiendum id="0">NLU process</definiendum>
				<definiens id="0">consists of a series of tasks : preprocessing ( in a typed system , this consists of spelling correction and unknown word handling ) , syntactic and semantic analysis , and reference resolution</definiens>
			</definition>
			<definition id="5">
				<sentence>Consider the example of the word “manager” and assume it has a speech recognition confidence score of semantic value of a0a2a1 : MANAGER ( a3a5a4 ) where a0a6a1 is a handle and a3a7a4 a variable .</sentence>
				<definiendum id="0">a0a6a1</definiendum>
				<definiens id="0">a handle</definiens>
			</definition>
</paper>

		<paper id="0823">
			<definition id="0">
				<sentence>Multiwordnet : developing an aligned multilingual database .</sentence>
				<definiendum id="0">Multiwordnet</definiendum>
				<definiens id="0">developing an aligned multilingual database</definiens>
			</definition>
</paper>

		<paper id="3213">
			<definition id="0">
				<sentence>Addressee ) , and PropBank uses roles specific to a verb ( such as Arg0 , Arg1 , Arg2 ) , VerbNet uses an intermediate level of thematic roles ( such as Agent , Theme , Recipient ) .</sentence>
				<definiendum id="0">Addressee</definiendum>
				<definiendum id="1">VerbNet</definiendum>
				<definiens id="0">uses an intermediate level of thematic roles ( such as Agent</definiens>
			</definition>
			<definition id="1">
				<sentence>Also , VerbNet has few verbs that take sentence complements , and for now we do not consider them .</sentence>
				<definiendum id="0">VerbNet</definiendum>
				<definiens id="0">few verbs that take sentence complements</definiens>
			</definition>
</paper>

		<paper id="0815">
			<definition id="0">
				<sentence>The Logic al Form ( LF ) employed in this task is a flat , scope-free first order logic representation that embeds lexical and syntactic information .</sentence>
				<definiendum id="0">Logic al Form</definiendum>
				<definiendum id="1">LF</definiendum>
				<definiens id="0">a flat , scope-free first order logic representation that embeds lexical and syntactic information</definiens>
			</definition>
			<definition id="1">
				<sentence>The main function of the LFP is to build an inverted index identifying all dependent tokens .</sentence>
				<definiendum id="0">LFP</definiendum>
				<definiens id="0">to build an inverted index identifying all dependent tokens</definiens>
			</definition>
			<definition id="2">
				<sentence>Given the fact that we are dealing with the main verb , the LFP inverts the subject and object dependencies , inserts them into the head verb token property slot and assigns their respective word identifier values .</sentence>
				<definiendum id="0">LFP</definiendum>
				<definiens id="0">inverts the subject and object dependencies , inserts them into the head verb token property slot and assigns their respective word identifier values</definiens>
			</definition>
			<definition id="3">
				<sentence>The token ‘study’ is an example of this as it serves as the object of the head verb ‘like’ .</sentence>
				<definiendum id="0">token ‘study’</definiendum>
				<definiens id="0">serves as the object of the head verb ‘like’</definiens>
			</definition>
			<definition id="4">
				<sentence>Argument , predicate , and sentence level precision and recall measures are used to evaluate performance of the system as compared to a gold-standard .</sentence>
				<definiendum id="0">Argument</definiendum>
				<definiens id="0">predicate , and sentence level precision and recall measures are used to evaluate performance of the system as compared to a gold-standard</definiens>
			</definition>
			<definition id="5">
				<sentence>Precision is defined to be the number of correctly ident ified predicates divided by the number of all attempted predicates .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the number of correctly ident ified predicates divided by the number of all attempted predicates</definiens>
			</definition>
			<definition id="6">
				<sentence>Recall is defined as the number of correctly identified predicates divided by the real number of predicates that were supposed to be identified in the target transformation .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the number of correctly identified predicates divided by the real number of predicates that were supposed to be identified in the target transformation</definiens>
			</definition>
			<definition id="7">
				<sentence>Sentence-argument is defined as the number of sentences that have all arguments correctly identified divided by the number of sentences attempted .</sentence>
				<definiendum id="0">Sentence-argument</definiendum>
				<definiens id="0">the number of sentences that have all arguments correctly identified divided by the number of sentences attempted</definiens>
			</definition>
			<definition id="8">
				<sentence>Sentence-argument-predicate is defined to be the number of sentences that have all arguments correctly identified divided by the number of sentences which have all predicates correctly identified .</sentence>
				<definiendum id="0">Sentence-argument-predicate</definiendum>
				<definiens id="0">the number of sentences that have all arguments correctly identified divided by the number of sentences which have all predicates correctly identified</definiens>
			</definition>
</paper>

		<paper id="2906">
</paper>

		<paper id="0826">
			<definition id="0">
				<sentence>The preprocessing consists of the removal of suffixes and the elimination of the irrelevant data .</sentence>
				<definiendum id="0">preprocessing</definiendum>
				<definiens id="0">consists of the removal of suffixes and the elimination of the irrelevant data</definiens>
			</definition>
			<definition id="1">
				<sentence>fill NoSenses fill NoContexts fill Wordsenses scan corpora c akt =actual entry in corpora ( a context ) w=actual word in entry ( the ambiguous word ) s k =actual sense of entry scan c akt v j =actual word in entry if v j &lt; &gt; w then if v j in words then vi=wordid from words where w=v j else add words v j endif if ( exists entry in occurrences where wordid=vi and senseid=s k ) then increment C ( wordid , senseid ) in occurrences , where wordid=vi and senseid=s k else add occurrences ( wordid , senseid , 1 ) endif step to next word endscan step to next entry endscan corpora As it is obvious , the database is filled up ( so the system is trained ) only upon the training corpus provided for the Senseval3 Romanian Lexical Sample task .</sentence>
				<definiendum id="0">fill NoSenses</definiendum>
				<definiendum id="1">entry</definiendum>
				<definiens id="0">exists entry in occurrences where wordid=vi and senseid=s k ) then increment C ( wordid , senseid ) in occurrences</definiens>
			</definition>
</paper>

		<paper id="2410">
			<definition id="0">
				<sentence>The most useful lexical preferences are captured by the quadruple ( v , n1 , p , n2 ) where v is the verb , n1 is the head of the direct object , p is the preposition and n2 is the head of the prepositional phrase .</sentence>
				<definiendum id="0">v</definiendum>
				<definiendum id="1">n1</definiendum>
				<definiendum id="2">p</definiendum>
				<definiendum id="3">n2</definiendum>
				<definiens id="0">The most useful lexical preferences are captured by the quadruple ( v , n1 , p</definiens>
				<definiens id="1">the head of the direct object ,</definiens>
				<definiens id="2">the head of the prepositional phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>The maximum entropy approach of Ratnaparkhi et al. ( 1994 ) uses the mutual information clustering algorithm described in ( Brown et al. , 1992 ) .</sentence>
				<definiendum id="0">maximum entropy</definiendum>
			</definition>
			<definition id="2">
				<sentence>Instead the smoothed probability of a word is defined as the total probability of all similar words S ( w ) as drawn from a thesaurus , weighted by their similarity α ( w , wprime ) .</sentence>
				<definiendum id="0">smoothed probability of a word</definiendum>
				<definiens id="0">the total probability of all similar words S ( w ) as drawn from a thesaurus , weighted by their similarity α ( w , wprime )</definiens>
			</definition>
			<definition id="3">
				<sentence>The similarity function reflects how often the two words appear in the same context .</sentence>
				<definiendum id="0">similarity function</definiendum>
				<definiens id="0">reflects how often the two words appear in the same context</definiens>
			</definition>
			<definition id="4">
				<sentence>Similarity-based smoothing techniques of the kind described here have not yet been applied to probabilistic PP attachment models .</sentence>
				<definiendum id="0">Similarity-based smoothing</definiendum>
				<definiens id="0">techniques of the kind described here have not yet been applied to probabilistic PP attachment models</definiens>
			</definition>
			<definition id="5">
				<sentence>The smoothed frequency of a prepositional phrase fs ( a , c ) is the weighted average frequency of the set of similar PPs S ( c ) : fs ( a , c ) = summationdisplay cprime∈S ( c ) α ( c , cprime ) f ( a , cprime ) ( 4 ) These smoothed frequencies are used to calculate the conditional probabilities for the model .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiendum id="1">) : fs</definiendum>
				<definiens id="0">the weighted average frequency of the set of similar PPs S ( c</definiens>
			</definition>
			<definition id="6">
				<sentence>neighbours ( k ) rank 0.01 rank 0.05 rank 0.1 average single Figure 2 : Accuracy for different smoothing functions on the development set plotted against k , the number of similar words used for smoothing β = 0.01 ) then accuracy levels off very quickly as less similar neighbours are assigned zero frequency .</sentence>
				<definiendum id="0">neighbours</definiendum>
				<definiens id="0">different smoothing functions on the development set plotted against k , the number of similar words used for smoothing β = 0.01 ) then accuracy levels off very quickly as less similar neighbours</definiens>
			</definition>
</paper>

		<paper id="1907">
			<definition id="0">
				<sentence>A House of Lords Judgment is defined as a J element whose BODY element is composed of a number of LORD elements ( usually five ) .</sentence>
				<definiendum id="0">House of Lords Judgment</definiendum>
			</definition>
			<definition id="1">
				<sentence>This showed that the human annotators distinguish the seven categories with a reproducibility of K=.83 ( N=1,955 , k=2 ; where K is the kappa co-efficient , N is the number of sentences and k is the number of annotators ) .</sentence>
				<definiendum id="0">K</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">k</definiendum>
				<definiens id="0">the kappa co-efficient</definiens>
				<definiens id="1">the number of sentences</definiens>
				<definiens id="2">the number of annotators</definiens>
			</definition>
			<definition id="2">
				<sentence>The approaches fall into three basic paradigms based on the methods they use to match abstract content to sentences from the source document : longest comAuthors Paradigm Level Teufel and Moens ( 1997 ) Longest common subsequence matching Sentence Mani and Bloedorn ( 1998 ) IR ( a0 overlapping wordsa0a2a1 cosine-based similarity metric ) Sentence Banko et al. ( 1999 ) IR ( a0 overlapping wordsa0 w/ extra weight for proper nouns ) Sentence Marcu ( 1999 ) IR ( cosine-based similarity metric ) Clause Jing and McKeown ( 1999 ) HMM ( prefers ordered , contiguous words , sentences ) Word Table 4 : Methods for automatic alignment of abstracts with their source documents .</sentence>
				<definiendum id="0">IR</definiendum>
				<definiens id="0">a0 overlapping wordsa0 w/ extra weight for proper nouns ) Sentence Marcu ( 1999 ) IR ( cosine-based similarity metric ) Clause Jing and McKeown ( 1999 ) HMM ( prefers ordered , contiguous words , sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>Mani and Bloedorn ( 1998 ) discuss an IR method using a cosine-based similarity metric over tfa0 idf scores with an additional term that counts the number of abstract words present in a source sentence .</sentence>
				<definiendum id="0">cosine-based</definiendum>
				<definiens id="0">similarity metric over tfa0 idf scores with an additional term that counts the number of abstract words present in a source sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>A shortcoming of the bag-of-words IR approaches is the fact that they do not encode order preferences .</sentence>
				<definiendum id="0">shortcoming of the bag-of-words IR approaches</definiendum>
				<definiens id="0">the fact that they do not encode order preferences</definiens>
			</definition>
</paper>

		<paper id="1000">
</paper>

		<paper id="2320">
</paper>

		<paper id="3215">
			<definition id="0">
				<sentence>In this paper we use the following conditional model : p ( yjx ) = 1Z ( x ) e P i i fi ( y ) ( 1 ) where y is a normal-form derivation and x is a sentence .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">a sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The dependency between take and That can be recovered by co-indexing the heads of NPs in an excellent publication that I enjoy reading NP=N N=N N ( NPnNP ) = ( S [ dcl ] =NP ) NP ( S [ dcl ] nNP ) = ( S [ ng ] nNP ) ( S [ ng ] nNP ) =NP &gt; &gt; T &gt; BN S= ( SnNP ) ( S [ dcl ] nNP ) =NP ) &gt; &gt; BNP S [ dcl ] =NP &gt; NPnNP &lt; NP Figure 1 : Extraction from object relative clause ; 431 sentences in Sections 2-21 , 20 in Section 00 he believes in what he plays NP ( S [ dcl ] nNP ) =PP PP=NP NP= ( S [ dcl ] =NP ) NP ( S [ dcl ] nNP ) =NP ) &gt; B &gt; T ( S [ dcl ] nNP ) =NP ) S= ( SnNP ) &gt; BS [ dcl ] =NP &gt; NP &gt; S [ dcl ] nNP &lt; S [ dcl ] Figure 2 : Free object relative example ; 269 sentences in Sections 2-21 , 16 sentences in Section 00 That got hard to take NP ( S [ dcl ] nNP ) = ( S [ adj ] nNP ) ( S [ adj ] nNP ) = ( ( S [ to ] nNP ) =NP ) ( S [ to ] nNP ) = ( S [ b ] nNP ) ( S [ b ] nNP ) =NP ) &gt; B ( S [ to ] nNP ) =NP ) &gt; S [ adj ] nNP &gt; S [ dcl ] nNP &lt; S [ dcl ] Figure 3 : tough-adjective example ; 52 sentences in Sections 2-21 , 2 sentences in Section 00 the categories for hard and got. These cases are relatively rare , with around 50 occurring in the whole of the treebank , and only two in the development set ; the parser correctly recovers one of the two object dependencies for the tough-adjective cases in 00. For the free object relative cases in Section 00 , the parser recovers 14 of the 17 gold-standard dependencies2 between the relative pronoun and the head of the relative clause. The precision is 14/15. For the three gold standard cases that are misanalysed , the category NP=S [ dcl ] is assigned to the relative pronoun , rather than NP= ( S [ dcl ] =NP ) . For the cases involving object relative clauses the parser provides a range of errors for which it is useful to give a detailed analysis. Figure 4 gives the 20 sentences in Section 00 which contain a relative pronoun with the category ( NPnNP ) = ( S [ dcl ] =NP ) . There are 24 object dependencies in total , since some sentences contain more than one extraction ( 11 ) , and some extractions involve more than one head ( 8 , 18 , 19 ) . For evaluation , we determined whether the parser correctly re2One of the 16 sentences contains two such dependencies. covered the dependency between the head of the extracted object and the verb. For example , to get the two dependencies in sentence 18 correct , the parser would have to assign the correct lexical category to had , and return respect and confidence as objects. The parser correctly recovers 15 of the 24 object dependencies.3 Overall the parser hypothesises 20 extracted object dependencies , giving a precision of 15/20. Hockenmaier ( 2003a ) reports similar results for a CCG parser using a generative model : 14/24 recall and 14/21 precision. The results here are a significant improvement over those in Clark et al. ( 2002 ) , in which only 10 of the 24 dependencies were recovered correctly. Below is a detailed analysis of the mistakes made by the parser. For Sentence 1 the parser can not provide any analysis. This is because the correct category for estimated , ( ( S [ pt ] nNP ) =PP ) =NP , is not in the tag dictionary’s entry for estimated. Since estimated occurs around 200 times in the data , the supertagger only considers categories from the tag dictionary entry , and thus can not provide the correct category as an option. 3Unless stated otherwise the parser uses automatically assigned , rather than gold standard , POS tags. Court has estimated at $ 140 million. both parties.p by Frank Greer that analysts of every political persuasion agree was a tour de force. that Virginians have nurtured for generations.p Asian politicians have pursued in fits and starts for decades. 10. Mrs. Ward says that when the cheating was discovered , she wanted to avoid the morale-damaging public disclosure that a trial would bring.p 11. In CAT sections where students’ knowledge of two-letter consonant sounds is tested , the authors noted that Scoring High concentrated on the same sounds that the test does – to the exclusion of other sounds that fifth graders should know.p 12. Interpublic Group said its television programming operations – which it expanded earlier this year – agreed to supply more than 4,000 hours of original programming across Europe in 1990. 13. Interpublic is providing the programming in return for advertising time , which it said will be valued at more than $ 75 million in 1990 and $ 150 million in 1991.p 14. Mr. Sherwood speculated that the leeway that Sea Containers has means that Temple would have to substantially increase their bid if they’re going to top us.p 15. The Japanese companies bankroll many small U.S. companies with promising products or ideas , frequently putting their money behind projects that commercial banks won’t touch.p 16. In investing on the basis of future transactions , a role often performed by merchant banks , trading companies can cut through the logjam that small-company owners often face with their local commercial banks. 17. A high-balance customer that banks pine for , she didn’t give much thought to the rates she was receiving , nor to the fees she was paying.p 18. The events of April through June damaged the respect and confidence which most Americans previously had for the leaders of China.p 19. He described the situation as an escrow problem , a timing issue , which he said was rapidly rectified , with no losses to customers.p 20. But Rep. Marge Roukema ( R. , N.J. ) instead praised the House’s acceptance of a new youth training wage , a subminimum that GOP administrations have sought for many years. Figure 4 : Cases of object extraction from a relative clause in 00 ; the extracted object , relative pronoun and verb are in italics ; for sentences marked with a p the parser correctly recovers all dependencies involved in the object extraction. For Sentence 2 the correct category is assigned to the relative pronoun that , but a wrong attachment results in many as the object of placed rather than countries. In Sentence 5 the incorrect lexical category ( ( SnNP ) n ( SnNP ) ) =S [ dcl ] is assigned to the relative pronoun that. In fact , the correct category is provided as an option by the supertagger , but the parser is unable to select it. This is because the category for agree is incorrect , since again the correct category , ( ( S [ dcl ] nNP ) =NP ) = ( S [ dcl ] nNP ) , is not in the verb’s entry in the tag dictionary. In Sentence 6 the correct category is assigned to the relative pronoun , but a number of mistakes elsewhere result in the wrong noun attachment. In Sentences 8 and 9 the complementizer category S [ em ] =S [ dcl ] is incorrectly assigned to the relative pronoun that. For Sentence 8 the correct analysis is available but the parsing model chose incorrectly. For Sentence 9 the correct analysis is unavailable because the correct category for suffer , ( ( S [ b ] nNP ) =PP ) =NP , is not in the verb’s entry in the tag dictionary. In Sentence 13 the correct category is again assigned to the relative pronoun , but a wrong attachment results in return being the object of placed , rather than time. In Sentence 17 the wrong category S [ em ] =S [ b ] is assigned to the relative pronoun that. Again the problem is with the category for the verb , but for a different reason : the POS tagger incorrectly tags pine as a base form ( VB ) , rather than VBP , which completely misleads the supertagger. This small study only provides anecdotal evidence for the reasons the parser is unable to recover some long-range object dependencies. However , the analysis suggests that the parser fails largely for the same reasons it fails on other WSJ sentences : wrong attachment decisions are being made ; the lexical coverage of the supertagger is lacking for some verbs ; the model is sometimes biased towards incorrect lexical categories ; and the supertagger is occasionally led astray by incorrect POS tags. Note that the recovery of these dependencies is a difficult problem , since the parser must assign the correct categories to the relative pronoun and verb , and make two attachment decisions : one attaching the relative pronoun to the verb , and one attaching it to the noun phrase. The recall figures for the individual dependencies in the relative pronoun category are 16/21 for the verb attachment and 15/24 for the noun attachment. In conclusion , the kinds of errors made by the parser suggest that general improvements in the coverage of the lexicon and parsing models based on CCGbank will lead to better recovery of longrange object dependencies. Wide-coverage parsers are now being successfully used as part of open-domain QA systems , e.g. Pasca and Harabagiu ( 2001 ) . The speed and accuracy of our CCG parser suggests that it could be used to parse answer candidates , and we are currently integrating the parser into a QA system. We would also like to apply the parser to the questions , for two reasons : the use of CCG allows the parser to deal with extraction cases , which occur relatively frequently in questions ; and the comparison of potential answers with the question , performed by the answer extraction component , is simplified if the same parser is used for both. Initially we tried some experiments applying the parser to questions from previous TREC competitions. The results were extremely poor , largely because the questions contain constructions which appear very infrequently , if at all , in CCGbank.4 For example , there are no What questions with the general form of What President became Chief Justice after his precidency ? in CCGbank , but this is a very common form of Wh-question. ( There is a very small number ( 3 ) of similar question types beginning How or Which in Sections 2–21. ) One solution is to create new annotated question data and retrain the parser , perhaps combining the data with CCGbank. However , the creation of goldstandard derivation trees is very expensive. A novel alternative , which we pursue here , is to annotate questions at the lexical category level only. Annotating sentences with lexical categories is simpler than annotating with derivations , and can be done with the tools and resources we have available. The key question is whether training only the supertagger on new question data is enough to give high parsing accuracy ; in Section 6 we show that it is. The next Section describes the creation of the question corpus. We have created a corpus consisting of 1,171 questions beginning with the word What , taken from the TREC 9–12 competitions ( 2000–2003 ) . We chose to focus on What-questions because these are a com4An earlier version of our QA system used RASP ( Briscoe and Carroll , 2002 ) to parse the questions , but this parser also performed extremely poorly on some question types. 10. What state does Martha Stewart live in ? 11. What kind of a sports team is the Wisconsin Badgers ? 12. What English word contains the most letters ? 13. What king signed the Magna Carta ? 14. What caused the Lynmouth floods ? Figure 5 : Examples from the What-question corpus CATEGORY FOR What FREQ % S [ wq ] = ( S [ q ] =NP ) 728 62.2 ( S [ wq ] = ( S [ q ] =NP ) ) =N 221 18.9 ( S [ wq ] = ( S [ dcl ] nNP ) ) =N 207 17.7 S [ wq ] = ( S [ dcl ] nNP ) 15 1.3 Table 1 : Distribution of What categories in questions mon form of question , and many contain cases of extraction , including some unbounded object extraction. A sample of questions from the corpus is given in Figure 5. The questions were tokenised according to the Penn Treebank convention and automatically POS tagged. Some of the obvious errors made by the tagger were manually corrected. The first author then manually labelled 500 questions with lexical categories. The supertagger was trained on the annotated questions , and used to label the remaining questions , which were then manually corrected. The performance of the supertagger was good enough at this stage to significantly reduce the effort required for annotation. The second author has verified a subset of the annotated sentences. The question corpus took less than a week to create. Figure 6 gives the derivations for some example questions. The lexical categories , which make up the annotation in the question corpus , are in bold. Note the first example contains an unbounded object extraction , indicated by the question clause missing an object ( S [ q ] =NP ) which is an argument of What. Table 1 gives the distribution of categories assigned to the first word What in each question in the corpus. The first row gives the category of object question What. The second row is the object question determiner. The third row is the subject question determiner. And What Cruise Line does Kathie Gi ord advertise for ? ( S [ wq ] = ( S [ q ] =NP ) ) =N N=N N ( S [ q ] = ( S [ b ] nNP ) ) =NP N=N N ( S [ b ] nNP ) =PP PP=NP : &gt; &gt; &gt; BN N ( S [ b ] nNP ) =NP ) &gt; S [ wq ] = ( S [ q ] =NP ) NP &gt; S [ q ] = ( S [ b ] nNP ) &gt; BS [ q ] =NP &gt; S [ wq ] S [ wq ] What English word contains the most letters ?</sentence>
				<definiendum id="0">nNP ) =PP PP=NP NP= ( S</definiendum>
				<definiendum id="1">=NP ) NP</definiendum>
				<definiendum id="2">RASP</definiendum>
				<definiens id="0">co-indexing the heads of NPs in an excellent publication that I enjoy reading NP=N N=N N ( NPnNP ) = ( S [ dcl ] =NP ) NP ( S [ dcl ] nNP ) = ( S [ ng ] nNP ) ( S [ ng ] nNP ) =NP &gt; &gt; T &gt; BN S= ( SnNP ) ( S [ dcl ] nNP ) =NP ) &gt; &gt; BNP S [ dcl ] =NP &gt; NPnNP &lt; NP Figure 1 : Extraction from object relative clause</definiens>
				<definiens id="1">=NP &gt; NP &gt; S [ dcl ] nNP &lt; S [ dcl ] Figure 2 : Free object relative example ; 269 sentences in Sections 2-21 , 16 sentences in Section 00 That got hard to take NP ( S [ dcl ] nNP ) = ( S [ adj ] nNP ) ( S [ adj ] nNP ) = ( ( S [ to ] nNP ) =NP ) ( S [ to ] nNP ) = ( S [ b ] nNP ) ( S [ b ] nNP ) =NP ) &gt; B ( S [ to ] nNP ) =NP ) &gt; S [ adj ] nNP &gt; S [ dcl ] nNP &lt;</definiens>
				<definiens id="2">useful to give a detailed analysis. Figure 4 gives the 20 sentences in Section 00 which contain a relative pronoun with the category ( NPnNP ) = ( S [ dcl ] =NP ) . There are 24 object dependencies in total , since some sentences contain more than one extraction</definiens>
				<definiens id="3">Cases of object extraction from a relative clause in 00 ; the extracted object , relative pronoun and verb are in italics</definiens>
			</definition>
</paper>

		<paper id="1810">
			<definition id="0">
				<sentence>a10 a1a4a3a6a5a7a1 is defined as : a0a2a1a4a3a6a5a11a1a13a12a14a1a16a15a18a17a20a19a18a21a23a22a25a24 a24a27a26 ( 1 ) wherea1a15a18a17 is the total frequency of a terma0a26 , a24 is the total number of the documents , and a24 a26 is the total number of documents in which the terma0a26 occurs .</sentence>
				<definiendum id="0">wherea1a15a18a17</definiendum>
				<definiendum id="1">a24</definiendum>
				<definiendum id="2">a24 a26</definiendum>
				<definiens id="0">the total frequency of a terma0a26 ,</definiens>
				<definiens id="1">the total number of the documents , and</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , a76a78a77a2a79 a63a0 a65 a12 a30 a3a11a80a33a0a63a67a69a15a2a36a38a67 a65 a30 a3a7a80a37a0a63a67a82a81a84a83a38a36a38a67 a65 ( 2 ) where a30 denotes the set of all documents ; a67 the distribution of words in a30 ; a0 a focal term ; a30 a15 the set of all documents containing a0 ; a67a85a15 distribution of words in a30 a15 ; a67 a81a58a83 distribution of words in randomly selected documents whose size equals a30 a15 ; a30 a3a11a80a37a0a63a67 a26 a36a38a67a86a52 a65 the distance between two distributions of wordsa67 a26 anda67a86a52 .</sentence>
				<definiendum id="0">a30</definiendum>
				<definiens id="0">the set of all documents ; a67 the distribution of words in a30 ; a0 a focal term ; a30 a15 the set of all documents containing a0 ; a67a85a15 distribution of words in a30 a15 ; a67 a81a58a83 distribution of words in randomly selected documents whose size equals a30 a15</definiens>
			</definition>
			<definition id="2">
				<sentence>The element “learning” , which takes the highest values both ina0a51a1a4a3a6a5a7a1 and in term representativeness , is conspicuous in its lexical productivity .</sentence>
				<definiendum id="0">element “learning”</definiendum>
				<definiens id="0">takes the highest values both ina0a51a1a4a3a6a5a7a1 and in term representativeness</definiens>
			</definition>
			<definition id="3">
				<sentence>This indicates that “learning” represents an important concept of the given data and in the discourse of artificial intelligence , but only “indirectly” in combination with other elements in compounds where “learning” tend to contribute to as a modifier rather than a head .</sentence>
				<definiendum id="0">“learning”</definiendum>
				<definiens id="0">represents an important concept of the given data and in the discourse of artificial intelligence</definiens>
			</definition>
			<definition id="4">
				<sentence>The two “general” lexical elements , i.e. “model” CompuTerm 2004 Poster Session 3rd International Workshop on Computational Terminology 77 TF DF Comp ( A ) Comp ( H ) Simp a5 a63a3a38a36a24 a65 ( A ) a5 a63a3a38a36a24 a65 ( H ) system 2659 989 1922 1247 737 937 502 knowledge 2183 669 1399 443 784 424 137 learning 1776 462 1513 208 263 375 73 problem 1758 660 1197 558 561 334 152 model 1480 550 1144 687 343 447 263 information 1038 460 656 268 382 207 155 Note : Comp ( A ) indicates the number of compounds that contains the lexical element ; Comp ( H ) indicates the number of compounds that contains the lexical element as the head ; a143a145a144a18a146a51a147a11a148a150a149 ( A ) indicates the number of different compounds ( plus one simplex ) that contains the lexical element ; a143a46a144a151a146a51a147a11a148a150a149 ( H ) indicates the number of different compounds ( plus one simplex ) that contains the lexical element as the head .</sentence>
				<definiendum id="0">a143a145a144a18a146a51a147a11a148a150a149</definiendum>
				<definiens id="0">the number of different compounds ( plus one simplex ) that contains the lexical element as the head</definiens>
			</definition>
</paper>

		<paper id="0711">
			<definition id="0">
				<sentence>Anaphora resolution indicates the process of determining the antecedent of an anaphoric expression .</sentence>
				<definiendum id="0">Anaphora resolution</definiendum>
				<definiens id="0">indicates the process of determining the antecedent of an anaphoric expression</definiens>
			</definition>
			<definition id="1">
				<sentence>( 2 ) MOB1 exhibits genetic interaction with three other yeast genes required for the completion of mitosis , LTE1 , CDC5 , and CDC15 ( the latter two encode essential protein kinases ) .</sentence>
				<definiendum id="0">MOB1</definiendum>
				<definiendum id="1">CDC15</definiendum>
				<definiens id="0">exhibits genetic interaction with three other yeast genes required for the completion of mitosis , LTE1 , CDC5 , and</definiens>
			</definition>
			<definition id="2">
				<sentence>BioIE is a system that extracts general biological interactions of arbitrary types from the biomedical literature .</sentence>
				<definiendum id="0">BioIE</definiendum>
				<definiens id="0">a system that extracts general biological interactions of arbitrary types from the biomedical literature</definiens>
			</definition>
			<definition id="3">
				<sentence>BioAR identi es the antecedents of anaphoric expressions that appear in the results of BioIE and annotates the protein-referring phrases with SwissProt entries .</sentence>
				<definiendum id="0">BioAR identi</definiendum>
			</definition>
			<definition id="4">
				<sentence>In the process of resolving anaphoric noun phrases , BioAR rst locates the noun phrases with determiners ( DNPs ) , especially those with de nites ( i.e. the ) and demonstratives ( i.e. this , these , and those ) , as 5Among the 1,000 biological interactions , there are 31 possessive pronouns of the rst type and 17 possessive pronouns of the second type .</sentence>
				<definiendum id="0">BioAR rst</definiendum>
				<definiens id="0">locates the noun phrases with determiners ( DNPs ) , especially those with de nites ( i.e. the ) and demonstratives</definiens>
			</definition>
			<definition id="5">
				<sentence>6POSS indicates a possessive pronoun ; ANT indicates its antecedent ; NP which follows POSS indicates the rest of the noun phrase which starts with POSS ; and BeV indicates a beverb .</sentence>
				<definiendum id="0">6POSS</definiendum>
				<definiendum id="1">BeV</definiendum>
				<definiens id="0">indicates a possessive pronoun ; ANT indicates its antecedent ; NP which follows POSS indicates the rest of the noun phrase which starts with POSS</definiens>
			</definition>
			<definition id="6">
				<sentence>Swiss-Prot term Variation D ( 2 ) D2 S-receptor kinase S receptor kinase RNase P protein RNase P Thioredoxin h-type 1 Thioredoxin h ( THL1 ) Table 11 : Term variation examples Protein name Swiss-Prot entries Filamin A FLNA HUMAN , FLNA MOUSE Pop1p POP1 HUMAN , POP1 SCHPO , POP1 YEAST D3 dopamine D3DR CERAE , D3DR HUMAN , receptor D3DR MOUSE , D3DR RAT Table 12 : Protein name grounding examples component ( RPM2 YEAST ) , BioAR grounds the phrases in the results of BioIE , which refer to protein domains , with the descriptions of Swiss-Prot entries , by converting those phrases into the structures as utilized by Swiss-Prot .</sentence>
				<definiendum id="0">BioAR</definiendum>
				<definiens id="0">grounds the phrases in the results of BioIE , which refer to protein domains , with the descriptions of Swiss-Prot entries</definiens>
			</definition>
			<definition id="7">
				<sentence>BioAR takes 24 seconds to process 1,645 biological interactions in the training corpus .</sentence>
				<definiendum id="0">BioAR</definiendum>
				<definiens id="0">takes 24 seconds to process 1,645 biological interactions in the training corpus</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>The conventional metric for speech recognition is recognition accuracy calculated based on word accuracy : ACCY = Len ( Sub + Ins + Del ) Len 100 [ % ] ; ( 1 ) where Sub , Ins , Del , and Len are the numbers of substitutions , insertions , deletions , and words in the manual transcription , respectively .</sentence>
				<definiendum id="0">Len</definiendum>
				<definiens id="0">The conventional metric for speech recognition is recognition accuracy calculated based on word accuracy : ACCY = Len ( Sub + Ins + Del ) Len 100 [ % ] ; ( 1 ) where Sub , Ins , Del , and</definiens>
			</definition>
			<definition id="1">
				<sentence>Precision is an efficient way of evaluating the similarity of component occurrence between automatic results and targets with a different order of components and different lengths .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">an efficient way of evaluating the similarity of component occurrence between automatic results</definiens>
			</definition>
			<definition id="2">
				<sentence>When n is 1 , pn corresponds to the precision of each word , and when n is the same length as a summarized sentence ( n = M ) , pn indicates the precision of the summarized sentence itself .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the same length as a summarized sentence ( n = M ) , pn indicates the precision of the summarized sentence itself</definiens>
			</definition>
			<definition id="3">
				<sentence>The weighted summarization accuracy is given by WSumACCY = ~P ( v1 : : : vMjR ) SumACCY ~P ( ^v1 : : : ^v ^MjR ) ; ( 4 ) where ~P ( v1 : : : vMjR ) is the reliability score of a set of words v1 : : : vM in the manual summarization network , R , and M represents the total number of words in the target answer .</sentence>
				<definiendum id="0">~P</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">the reliability score of a set of words v1 : : : vM in the manual summarization network</definiens>
			</definition>
			<definition id="4">
				<sentence>1M 1 ; ( 5 ) where vm is the m-th word in the sentence extracted from the network as the target answer , and C ( x ; yjR ) indicates the number of subjects who selected the word connection of x and y. Here , “word connection” means an arc in the manual summarization network .</sentence>
				<definiendum id="0">vm</definiendum>
				<definiendum id="1">yjR</definiendum>
				<definiens id="0">the m-th word in the sentence extracted from the network as the target answer , and C ( x ;</definiens>
			</definition>
			<definition id="5">
				<sentence>HR is the number of subjects .</sentence>
				<definiendum id="0">HR</definiendum>
				<definiens id="0">the number of subjects</definiens>
			</definition>
</paper>

		<paper id="2008">
			<definition id="0">
				<sentence>The algorithm relies on a frame dataset ( FrameNet ) and a semantic network ( WordNet ) , to identify semantic relations between words in open text , as well as shallow semantic features associated with concepts in the text .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiendum id="1">WordNet</definiendum>
				<definiens id="0">shallow semantic features associated with concepts in the text</definiens>
			</definition>
			<definition id="1">
				<sentence>Semantics is the denotation of a string of symbols , either a sentence or a word .</sentence>
				<definiendum id="0">Semantics</definiendum>
				<definiens id="0">the denotation of a string of symbols , either a sentence or a word</definiens>
			</definition>
			<definition id="2">
				<sentence>The semantic parser attempts to solve this problem , and produces a syntax-independent representation of sentence meaning , so that semantic constituents can be accessed and processed in a more meaningful and flexible way , avoiding the sometimes rigid interpretations produced by a syntactic analyzer .</sentence>
				<definiendum id="0">semantic parser</definiendum>
				<definiens id="0">attempts to solve this problem , and produces a syntax-independent representation of sentence meaning</definiens>
			</definition>
			<definition id="3">
				<sentence>Assignment FrameNet ( Johnson et al. , 2002 ) provides the knowledge needed to identify case frames and semantic roles .</sentence>
				<definiendum id="0">Assignment FrameNet</definiendum>
				<definiens id="0">provides the knowledge needed to identify case frames and semantic roles</definiens>
			</definition>
			<definition id="4">
				<sentence>VerbNet is a verb lexicon compatible with WordNet , but with explicitly stated syntactic and semantic information using Levin’s verb classification ( Levin , 1993 ) .</sentence>
				<definiendum id="0">VerbNet</definiendum>
			</definition>
			<definition id="5">
				<sentence>Feature Values Nouns Number singular/plural Countability countable/uncountable Verbs Transitivity transitive/intransitive/double transitive Form normal/infi nitive/present participle/past participle Adjectives Type descriptive/restrictive/referential Attribute arbitrary Degree base/comparative/superlative Adverbs Type descriptive/restrictive/referential Attribute arbitrary Degree base/comparative/superlative Table 2 : Features for content words For example , for the word dog , the entry in the lexicon is defined as : lex ( dog , W ) : W= [ parse : dog , cat : noun , num : singular , count : countable ] .</sentence>
				<definiendum id="0">Feature Values</definiendum>
				<definiendum id="1">dog</definiendum>
				<definiens id="0">Nouns Number singular/plural Countability countable/uncountable Verbs Transitivity transitive/intransitive/double transitive Form normal/infi nitive/present participle/past participle Adjectives Type descriptive/restrictive/referential Attribute arbitrary Degree base/comparative/superlative Adverbs Type descriptive/restrictive/referential Attribute arbitrary Degree base/comparative/superlative Table 2 : Features for content words For example</definiens>
			</definition>
			<definition id="6">
				<sentence>Selectional restrictions are defined using a Disjunctive Normal Form ( DNF ) in the following format : [ Onto ( ID , P ) , Onto ( ID , P ) , ... ] , [ Onto ( ID , P ) , ... ] , ... Here , “Onto” is a noun and ID is its WordNet sense , which uniquely identifies Onto as a node in the semantic network .</sentence>
				<definiendum id="0">Disjunctive Normal Form</definiendum>
				<definiendum id="1">“Onto”</definiendum>
				<definiens id="0">a noun</definiens>
				<definiens id="1">a node in the semantic network</definiens>
			</definition>
			<definition id="7">
				<sentence>The general procedure of semantic parsing consists of three main steps 3 : ( 1 ) The syntactic-semantic analyzer analyzes the syntactic structure , and uses hand-coded rules as well as lexical semantic knowledge to identify some semantic relations between constituents .</sentence>
				<definiendum id="0">syntactic-semantic analyzer analyzes</definiendum>
			</definition>
			<definition id="8">
				<sentence>The grammar consists of a set of rules defining how constituents with different syntactic or semantic features can unify with each other .</sentence>
				<definiendum id="0">grammar</definiendum>
			</definition>
			<definition id="9">
				<sentence>is : [ assertion , [ [ tag , ext , np , person , [ [ entity , [ he ] , reference ( third ) ] , [ modification ( attribute ) , quantity ( single ) ] , [ modification ( attribute ) , gender ( male ) ] ] ] , [ target , v , kick , active , [ kick ] ] , [ modification ( attribute ) , time ( past ) ] , [ tag , obj , np , dog , [ [ modification ( reference ) , reference ( the ) ] , [ modification ( attribute ) , age ( old ) ] , [ target , n , dog , [ dog ] ] ] ] ] ] In the process of semantic role assignment , we first start by identifying all possible frames , according to the target word .</sentence>
				<definiendum id="0">obj</definiendum>
				<definiens id="0">past ) ] , [ tag ,</definiens>
				<definiens id="1">the ) ] , [ modification ( attribute ) , age ( old ) ] , [ target , n , dog</definiens>
			</definition>
			<definition id="10">
				<sentence>An exact match means that both syntactic features and selectional restrictions are matched , which increments the score of matching by 3 .</sentence>
				<definiendum id="0">exact match</definiendum>
				<definiens id="0">increments the score of matching by 3</definiens>
			</definition>
			<definition id="11">
				<sentence>Assume the following two rules , triggered for the target word break : 1 : [ active , [ ext , np , [ [ person ( 1 , p ) ] ] , agent ] , [ obj , np , [ [ object ( 1 , p ) ] ] , theme ] , [ comp , pp , with , [ [ instrumentality ( 3 , p ) ] ] , instrument ] ] 2 : [ [ ext , np , [ [ instrumentality ( 3 , p ) ] ] , instrument ] , [ obj , np , [ [ person ( 1 , n ) , object ( 1 , p ) ] ] , theme ] ] 3 : [ [ ext , np , [ [ person ( 1 , n ) , object ( 1 , p ) ] ] , theme ] ] And the sentences : A : I break the window with a hammer B : The hammer breaks the window C : The window breaks on the wall The features identified by the analyzer are : A’ : [ [ ext , np , active , person ] , [ obj , np , active , window ] , [ comp , pp , active , with , hammer ] ] B’ : [ [ ext , np , active , hammer ] , [ obj , np , active , window ] ] C’ : [ [ ext , np , active , window ] , [ comp , pp , on , wall ] ] Using the matching/scoring algorithm , the score for matching A’ to rule 1 is determined as 9 since there are 3 exact matches , and to rule 2 as 5 since there is an exact match for “the window” but a partial match for “I” .</sentence>
				<definiendum id="0">np</definiendum>
				<definiens id="0">active , [ ext , np , [ [ person ( 1 , p ) ] ] , agent ] , [ obj , np , [ [ object ( 1 , p ) ] ] , theme ] , [ comp , pp , with</definiens>
				<definiens id="1">n ) , object ( 1 , p ) ] ] , theme ] ] And the sentences : A : I break the window with a hammer B : The hammer breaks the window C : The window breaks on the wall The features identified by the analyzer are : A’ : [ [ ext , np , active , person ] , [ obj , np , active , window ] , [ comp , pp , active , with , hammer ] ] B’ : [ [ ext , np , active , hammer ] , [ obj , np , active , window ] ] C’ : [ [ ext , np , active , window ] , [ comp , pp</definiens>
			</definition>
			<definition id="12">
				<sentence>The semantic parser maintains all possible interpretations that can not be rejected by their syntactic and shallow semantic patterns , and rank all of them by their scores as the likelihood of being the correct interpretation .</sentence>
				<definiendum id="0">semantic parser</definiendum>
				<definiens id="0">maintains all possible interpretations that can not be rejected by their syntactic and shallow semantic patterns , and rank all of them by their scores as the likelihood of being the correct interpretation</definiens>
			</definition>
			<definition id="13">
				<sentence>The parsing process utilizes linguistic knowledge , consisting of rules derived from a frame dataset ( FrameNet ) , a semantic network ( WordNet ) , as well as hand-coded rules of syntax-semantics mappings , which encode natural selectional restrictions .</sentence>
				<definiendum id="0">parsing process</definiendum>
				<definiens id="0">utilizes linguistic knowledge , consisting of rules derived from a frame dataset ( FrameNet ) , a semantic network ( WordNet ) , as well as hand-coded rules of syntax-semantics mappings , which encode natural selectional restrictions</definiens>
			</definition>
</paper>

		<paper id="2411">
			<definition id="0">
				<sentence>We propose a new method for comparing two probability distributions over WordNet , which captures in a single measure the aggregate semantic distance of the component nodes , weighted by their probability .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>Other approaches instead assume a probability distribution over the entire sense hierarchy ; similarity is captured between individual senses by a formula over the information content ( negative log probabilities ) of relevant nodes ( e.g. , Jiang and Conrath , 1997 ; Lin , 1998 ) .</sentence>
				<definiendum id="0">content</definiendum>
				<definiens id="0">a probability distribution over the entire sense hierarchy ; similarity is captured between individual senses by a formula over the information</definiens>
			</definition>
			<definition id="2">
				<sentence>Similarly , McCarthy ( 2000 ) uses skew divergence ( a variant of KL divergence proposed by Lee , 1999 ) to compare the sense profile of one argument of a verb ( e.g. , the subject position of the intransitive ) to another argument of the same verb ( e.g. , the object position of the transitive ) , to determine if the verb participates in an argument alternation involving the two positions .</sentence>
				<definiendum id="0">McCarthy</definiendum>
			</definition>
			<definition id="3">
				<sentence>Formally , we define SPD as : a48a37a49a26a50a52a51 a19a21a20a23a22a23a24a26a25a28a27a54a53a56a55a15a57 a36a19a58a20a54a22a23a24a59a25a28a27a4a60a14a61a53a56a62a23a63a64a31 a65 a66a4a67a18a68 a55a70a69a10a71a73a72a61a15a74a76a75a28a77 a78 a67a18a68 a55a70a69a10a71a79a72a61a81a80a56a82a74a76a83 a84a18a85a86a22a18a87a37a88a58a89 a51a23a90 a36a18a91a92a63a2a93a94a91a47a95 a90 a89a81a84a18a88a97a96a6a27 a51a23a90 a36a18a91a92a63 ( 1 ) where a98a73a99a100a3a73a101a97a102a104a103a18a105a54a106a39a107a79a108a110a109 is the portion of the profile score at node a111 in a0a112a1a4a3a14a5a113a7a10a9a115a114a117a116a23a118 that travels to node a119 in a0a2a1a13a3a14a5a8a7a15a9a18a120a17a121a23a114a23a122 , and a108a37a123a70a106a115a103a54a98a73a102a112a124a115a9a92a105a14a106a39a107a12a108a104a109 is the semantic distance between node a111 and node a119 in the hierarchy .</sentence>
				<definiendum id="0">a108a37a123a70a106a115a103a54a98a73a102a112a124a115a9a92a105a14a106a39a107a12a108a104a109</definiendum>
				<definiens id="0">a48a37a49a26a50a52a51 a19a21a20a23a22a23a24a26a25a28a27a54a53a56a55a15a57 a36a19a58a20a54a22a23a24a59a25a28a27a4a60a14a61a53a56a62a23a63a64a31 a65 a66a4a67a18a68 a55a70a69a10a71a73a72a61a15a74a76a75a28a77 a78 a67a18a68 a55a70a69a10a71a79a72a61a81a80a56a82a74a76a83 a84a18a85a86a22a18a87a37a88a58a89 a51a23a90 a36a18a91a92a63a2a93a94a91a47a95 a90 a89a81a84a18a88a97a96a6a27 a51a23a90 a36a18a91a92a63 ( 1 ) where a98a73a99a100a3a73a101a97a102a104a103a18a105a54a106a39a107a79a108a110a109 is the portion of the profile score at node a111 in a0a112a1a4a3a14a5a113a7a10a9a115a114a117a116a23a118 that travels to node a119 in a0a2a1a13a3a14a5a8a7a15a9a18a120a17a121a23a114a23a122</definiens>
				<definiens id="1">the semantic distance between node a111 and node a119 in the hierarchy</definiens>
			</definition>
			<definition id="4">
				<sentence>We take this into account in the a98a37a99 a3a37a101a97a102a104a103 function , by including a weight component : a13a15a14a17a16a19a18a21a20a23a22 a51a25a24 a36a7a26a39a63a59a31a28a27a30a29a32a31a34a33a36a35 a22 a51 a26a39a63a104a93a38a37 a16a40a39a40a22 a31 a16a40a20 a51a25a24 a63 ( 2 ) where a41a113a9a46a123a43a42a45a44a21a103a47a105a13a108a110a109 is the weight of the destination node a119 and a0a104a3a73a1a17a103a117a123a81a3a73a102 a105a54a106a12a109 is the portion of a106a47a124a13a3a37a1a4a9a58a105a54a106a12a109 that we are moving .</sentence>
				<definiendum id="0">a41a113a9a46a123a43a42a45a44a21a103a47a105a13a108a110a109</definiendum>
				<definiens id="0">the weight of the destination node a119 and a0a104a3a73a1a17a103a117a123a81a3a73a102 a105a54a106a12a109 is the portion of a106a47a124a13a3a37a1a4a9a58a105a54a106a12a109 that we are moving</definiens>
			</definition>
			<definition id="5">
				<sentence>SPD refers to SPD without entropy , using the indicated node distance measure .</sentence>
				<definiendum id="0">SPD</definiendum>
				<definiens id="0">refers to SPD without entropy , using the indicated node distance measure</definiens>
			</definition>
			<definition id="6">
				<sentence>Given any pair of probability distributions over WordNet ( which we call a sense profile ) , SPD captures in a single measure the aggregate semantic distance of the component nodes , weighted by their probability .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiendum id="1">SPD</definiendum>
			</definition>
			<definition id="7">
				<sentence>SPD achieves a best performance of 70 % accuracy ( baseline 50 % ) on unseen test verbs , and no other measure we tested performed consistently as well as it did .</sentence>
				<definiendum id="0">SPD</definiendum>
				<definiens id="0">achieves a best performance of 70 % accuracy ( baseline 50 % ) on unseen test verbs</definiens>
			</definition>
</paper>

		<paper id="1307">
			<definition id="0">
				<sentence>B ) = P ( AB ) /P ( A ) , with P ( AB ) being the frequency of B following A , and P ( A ) the total frequency of A. Word boundaries are postulated at local minima , where the TP is lower than its neighbors .</sentence>
				<definiendum id="0">/P ( A )</definiendum>
				<definiens id="0">lower than its neighbors</definiens>
			</definition>
			<definition id="1">
				<sentence>The learning data consists of a random sample of child-directed English sentences from the CHILDES database [ 19 ] The words were then phonetically transcribed using the Carnegie Mellon Pronunciation Dictionary , and were then grouped into syllables .</sentence>
				<definiendum id="0">learning data</definiendum>
				<definiens id="0">consists of a random sample of child-directed English sentences from the CHILDES database [ 19 ] The words were then phonetically transcribed using the Carnegie Mellon Pronunciation Dictionary , and were then grouped into syllables</definiens>
			</definition>
			<definition id="2">
				<sentence>The CHILDES Project : Tools for Analyzing Talk .</sentence>
				<definiendum id="0">CHILDES Project</definiendum>
			</definition>
</paper>

		<paper id="0509">
			<definition id="0">
				<sentence>UMLS contains three knowledge sources : the Metathesaurus , the Semantic Network , and the Specialist Lexicon .</sentence>
				<definiendum id="0">UMLS</definiendum>
				<definiens id="0">contains three knowledge sources : the Metathesaurus , the Semantic Network , and the Specialist Lexicon</definiens>
			</definition>
</paper>

		<paper id="1102">
</paper>

		<paper id="0307">
			<definition id="0">
				<sentence>CDG represents a sentence’s grammatical structure as assignments of dependency relations to functional variables associated with each word in the sentence .</sentence>
				<definiendum id="0">CDG</definiendum>
				<definiens id="0">a sentence’s grammatical structure as assignments of dependency relations to functional variables associated with each word in the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Using a tight integration of multiple knowledge sources , together with distance modeling and synergistic dependencies , this parser achieves a parsing accuracy comparable to several state-of-the-art context-free grammar ( CFG ) based statistical parsers using a dependency-based evaluation metric .</sentence>
				<definiendum id="0">multiple knowledge sources</definiendum>
				<definiens id="0">a parsing accuracy comparable to several state-of-the-art context-free grammar ( CFG ) based statistical parsers using a dependency-based evaluation metric</definiens>
			</definition>
			<definition id="2">
				<sentence>Charniak ( Charniak , 2000 ) developed a state-of-the-art statistical CFG parser and then built an effective language model based on it ( Charniak , 2001 ) .</sentence>
				<definiendum id="0">Charniak</definiendum>
			</definition>
			<definition id="3">
				<sentence>Section 2 describes how CDG represents a sentence’s parse and then defines a SuperARV , which is a lexicalization of CDG parse rules used in our parsing model .</sentence>
				<definiendum id="0">CDG</definiendum>
				<definiendum id="1">SuperARV</definiendum>
				<definiens id="0">a lexicalization of CDG parse rules used in our parsing model</definiens>
			</definition>
			<definition id="4">
				<sentence>A SuperARV is formally defined as a four-tuple for a word , hC ; F , ( R ; L ; UC ; MC ) + ; DCi , where C is the lexical category of the word , F = fFname1 = Fvalue1 , : : : ; FNamef = FV aluefg is a feature vector ( where Fnamei is the name of a feature and Fvaluei is its corresponding value ) , DC represents the relative ordering of the positions of a word and all of its modifiees , ( R , L , UC , MC ) + is a list of one or more four-tuples , each representing an abstraction of a role value assignment , where R is a role variable , L is a functionality label , UC represents the relative position relation of a word and its dependent , and MC encodes some modifiee constraints , namely , the lexical category of the modifiee for this dependency relation .</sentence>
				<definiendum id="0">SuperARV</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">aluefg</definiendum>
				<definiendum id="3">Fnamei</definiendum>
				<definiendum id="4">Fvaluei</definiendum>
				<definiendum id="5">DC</definiendum>
				<definiendum id="6">R</definiendum>
				<definiendum id="7">L</definiendum>
				<definiendum id="8">UC</definiendum>
				<definiens id="0">a four-tuple for a word , hC ; F , ( R ; L ; UC ; MC ) + ; DCi , where</definiens>
				<definiens id="1">the lexical category of the word , F = fFname1 = Fvalue1 , : : : ; FNamef = FV</definiens>
				<definiens id="2">a feature vector ( where</definiens>
				<definiens id="3">the name of a feature and</definiens>
				<definiens id="4">the relative ordering of the positions of a word and all of its modifiees , ( R , L , UC , MC ) + is a list of one or more four-tuples , each representing an abstraction of a role value assignment , where</definiens>
				<definiens id="5">a role variable ,</definiens>
				<definiens id="6">a functionality label ,</definiens>
				<definiens id="7">the relative position relation of a word and its dependent , and MC encodes some modifiee constraints , namely , the lexical category of the modifiee for this dependency relation</definiens>
			</definition>
			<definition id="5">
				<sentence>The SuperARV structure provides an explicit way to organize information concerning one consistent set of dependency links for a word that can be directly derived from a CDG parse .</sentence>
				<definiendum id="0">SuperARV structure</definiendum>
			</definition>
			<definition id="6">
				<sentence>The dependency assignment probability when choosing the ( c+ 1 ) th left dependent ( with its position denoted dep ( k ; ¡ ( c + 1 ) ) ) is defined as : Pr ( link ( sdep ( k ; ¡ ( c+1 ) ) ; sk ; ¡ ( c + 1 ) jsyn ; H ) ) where H = hw ; sik ; hw ; sidep ( k ; ¡ ( c+1 ) ) ; hw ; sidep ( k ; ¡c ) dep ( k ; ¡1 ) .</sentence>
				<definiendum id="0">¡c ) dep</definiendum>
				<definiens id="0">c + 1 ) jsyn ; H ) ) where H = hw</definiens>
			</definition>
			<definition id="7">
				<sentence>The parsing procedure , which is completely incremental , is implemented as a simple best-first stack-based search .</sentence>
				<definiendum id="0">parsing procedure</definiendum>
				<definiens id="0">a simple best-first stack-based search</definiens>
			</definition>
			<definition id="8">
				<sentence>Note that ¢dep ( k ; § ( c+1 ) ) ; k represents the distance between position dep ( k ; § ( c + 1 ) ) and k. To avoid data sparsity problems , distance is bucketed and a discrete random variable is used to model it .</sentence>
				<definiendum id="0">k</definiendum>
			</definition>
			<definition id="9">
				<sentence>Term Denotes L ( sk ) , R ( sk ) all dependents of sk to the left and right of wk , respectively N ( L ( sk ) ) , N ( R ( sk ) ) the number of left and right dependents of sk , respectively dep ( k ; ¡c ) , dep ( k ; c ) cth left dependent and right dependent of sk , respectively dep ( k ; ¡1 ) , dep ( k ; 1 ) the position of the closest left dependent and right dependent of sk , respectively dep ( k ; ¡N ( L ( sk ) ) ) , dep ( k ; N ( L ( sk ) ) ) the position of the farthest left dependent and right dependent of sk , respectively Cat ( sk ) the lexical category of sk ModCat ( sk ; ¡c ) , ModCat ( sk ; c ) the lexical category of sk’s cth left and right dependent ( encoded in the SuperARV structure ) , respectively link ( si ; sj ; k ) the dependency relation between SuperARV si and sj with wi assigned as the kth dependent of sj , e.g. , link ( sdep ( k ; ¡ ( c+1 ) ) ; sk ; ¡ ( c + 1 ) ) indicates that wdep ( k ; ¡ ( c+1 ) ) is the ( c + 1 ) th left dependent of sk .</sentence>
				<definiendum id="0">Term Denotes L ( sk</definiendum>
				<definiendum id="1">R ( sk</definiendum>
				<definiens id="0">the number of left and right dependents of sk</definiens>
			</definition>
			<definition id="10">
				<sentence>D ( L ( sk ) ) , D ( R ( sk ) ) ) the number of left and right dependents of sk already assigned , respectively hw ; sidep ( k ; ¡c ) dep ( k ; ¡1 ) words and SuperARVs of sk’s closest left dependent up to its cth left dependent hw ; sidep ( k ; c ) dep ( k ; 1 ) words and SuperARVs of sk’s closest right dependent up to its cth right dependent syn a random variable denoting the synergistic relation between some dependents can either convert the CDG parses to CFG bracketing and then use PARSEVAL , or convert the CFG bracketing generated from the gold standard CFG parses to CDG parses and then use a metric based on dependency links .</sentence>
				<definiendum id="0">c ) dep</definiendum>
				<definiens id="0">the number of left and right dependents of sk already assigned</definiens>
				<definiens id="1">a random variable denoting the synergistic relation between some dependents can either convert the CDG parses to CFG bracketing and then use PARSEVAL , or convert the CFG bracketing generated from the gold standard CFG parses to CDG parses and then use a metric based on dependency links</definiens>
			</definition>
			<definition id="11">
				<sentence>Since the statistical Table 4 : Evaluation of five models on Section 23 sentences with and without traces : L denotes the best loosely coupled CDG parser and T the tightly coupled CDG parser .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">Evaluation of five models on Section 23 sentences with and without traces</definiens>
				<definiens id="1">the best loosely coupled CDG parser and T the tightly coupled CDG parser</definiens>
			</definition>
</paper>

		<paper id="1304">
			<definition id="0">
				<sentence>We assume that the languages to be learned are drawn 27 in some way from a possibly infinite class of languages , L , which is a set of formal mathematical objects .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">a set of formal mathematical objects</definiens>
			</definition>
			<definition id="1">
				<sentence>Without this latter constraint the notion is mathematically vacuous , since , for example , any context free grammar in Chomsky normal form can be parametrised with N3 + NM + 1 binary parameters where N is the number of non-terminals and M the number of terminals .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of non-terminals</definiens>
			</definition>
</paper>

		<paper id="1107">
			<definition id="0">
				<sentence>The purpose of Chinese chunking is to divide sentence into syntactically correlated parts of words after word segmentation and part-of-speech ( POS ) tagging .</sentence>
				<definiendum id="0">Chinese chunking</definiendum>
				<definiens id="0">to divide sentence into syntactically correlated parts of words after word segmentation and part-of-speech ( POS ) tagging</definiens>
			</definition>
			<definition id="1">
				<sentence>For example : g6984g20051/order ( g16698g17722/police wagon g16698g9795/caution light g16698g6265g3132/alarm whistle ) ‘Order the police Pattern 1 No. 2 Distributions Examples n_n 951 77 % ( modifier head ) 7 % ( coordination ) 16 % ( others ) ( g12050g1262/society g10628g16949/phenomenon ) ‘social phenomena’ ( g16833g16340/language g7003g4395/wordage ) ‘language and wordage’ ( g20330g18129/capital g7003g14414/art g14322g2500/stage ) ‘ the stage of capital art’ v_n_n 154 6 % ( v_n modify the last noun ) 94 % ( others ) g17839/enterg2390/factoryg5049g1166/worker g17879g18003/avoid g8873g5471/law g17143g1231/duty ‘avoid legal duties’ g11352_n_n 98 80 % ( n_n is modifier_head ) 20 % ( others ) g6203g2232/watch g11352/ofg1144g17902/traffic g16698g4531/cop ‘a orderly traffic cop’ g11263g11198/paralyticg11352/ofg13942g1319/bodyg2163g14033/function a_n_n 27 70 % ( a modify the first n ) 30 % ( others ) g20652/high g12197g6228/technology g1237g1006/company ‘high-tech company’ g13781/old g7044g19407/news g5049g1328g13785/worker ‘old news worker’ m_n_n 17 41 % ( m modify the first n ) 59 % ( others ) g1016/two g3281/nation g1166g8677/people ‘our two peoples’ g980g1135/some g1904g7461/country g3332g2318/area ‘some rural areas’ n_c_n 88 52 % ( word level coordination ) 48 % ( others ) g13475g8994/economy g2656/and g12050g1262/society ‘economy and society’ g17148g18339/quality g2656/and g6228g7427/technology g16213g8726/requirement 1 n , v , a , d , m , q , p , f , c are the POS tags of noun , verb , adjective , adverb , number , measure , preposition , localizer , conjunction respectively , ‘_’ means neighboring , ‘g11352/of’ is a common auxiliary word in Chinese .</sentence>
				<definiendum id="0">n_n</definiendum>
				<definiens id="0">word level coordination ) 48 % ( others ) g13475g8994/economy g2656/and g12050g1262/society ‘economy and society’ g17148g18339/quality g2656/and g6228g7427/technology g16213g8726/requirement 1 n , v , a , d , m , q , p , f , c are the POS tags of noun , verb , adjective , adverb , number , measure , preposition , localizer , conjunction respectively</definiens>
				<definiens id="1">a common auxiliary word in Chinese</definiens>
			</definition>
			<definition id="2">
				<sentence>They are NP ( noun chunk ) , VP ( verb chunk ) , ADJP ( adjective chunk ) , ADVP ( adverb chunk ) , PP ( prepositional chunk ) , CONJP ( conjunction ) , MP ( numerical chunk ) , TP ( temporal chunk ) , SP ( spatial chunk ) , INTJP ( interjection ) and INDP ( independent chunk ) .</sentence>
				<definiendum id="0">MP</definiendum>
				<definiens id="0">adjective chunk</definiens>
				<definiens id="1">adverb chunk ) , PP ( prepositional chunk</definiens>
				<definiens id="2">numerical chunk ) , TP ( temporal chunk ) , SP ( spatial chunk</definiens>
			</definition>
			<definition id="3">
				<sentence>The auxiliary ‘g11352/of’ is one of the most frequent words in Chinese and used to connect a premodifier with its nominal head .</sentence>
				<definiendum id="0">auxiliary ‘g11352/of’</definiendum>
				<definiens id="0">one of the most frequent words in Chinese and used to connect a premodifier with its nominal head</definiens>
			</definition>
			<definition id="4">
				<sentence>But if the spatial phrase is in the beginning of a sentence , or there is a punctuation ( except “g1940” ) in front of it , then the localizer and its preceding words could be chunked as a SP .</sentence>
				<definiendum id="0">spatial phrase</definiendum>
				<definiens id="0">in the beginning of a sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>corpusin ) ) context ( , ( of No. ) context ( in annotation same of No. ) ) context ( , cons ( PP P PP = ( 1 ) ∑ = = N i ii PcontextPcons N 1 ) ) ( , ( 1 cons ( S ) ( 2 ) Where P represents a pattern of the chunk ( POS or/and lexical sequence ) , context ( P ) represents the needed context to annotate this chunk , N represents the number of chunks in the whole corpus S. In order to improve the efficiency we also develop a semi-automatic tool that not only check mechanical errors but also detect those potential inconsistent annotations .</sentence>
				<definiendum id="0">P )</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">cons ( S ) ( 2 ) Where P represents a pattern of the chunk ( POS or/and lexical sequence ) , context (</definiens>
				<definiens id="1">the needed context to annotate this chunk</definiens>
			</definition>
			<definition id="6">
				<sentence>It is to assign each word a chunk mark , named M , which contains 5 classes : B , I , E , S ( a single word chunk ) and O ( outside all chunks ) .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">O</definiendum>
				<definiens id="0">outside all chunks )</definiens>
			</definition>
			<definition id="7">
				<sentence>2 ) Tag the chunk type , named X , which contains 11 types defined in Section 3 .</sentence>
				<definiendum id="0">X</definiendum>
			</definition>
			<definition id="8">
				<sentence>The features for MBL and SVM are the POS of current , left two and right two words , lexical of current , left one and right one word .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">current , left two and right two words , lexical of current , left one and right one word</definiens>
			</definition>
</paper>

		<paper id="0900">
</paper>

		<paper id="3218">
			<definition id="0">
				<sentence>SM ( HMIHY ) ( Gorin et al. , 1997 ) , makes available large corpora of real human-machine dialog interactions .</sentence>
				<definiendum id="0">SM</definiendum>
				<definiens id="0">makes available large corpora of real human-machine dialog interactions</definiens>
			</definition>
			<definition id="1">
				<sentence>containing between 5 and 10 words ; C3 : answers to the same con rmation prompt containing less than 5 words ; C4 : answers to other prompts and containing between 5 and 10 words ; C5 : answers to other prompts and containing between 10 and 15 words ; C6 : answers to other prompts and containing more than 15 words ; As we can see , 3 kinds of interaction are distinguished : request for a phone number , request for con rmation and other .</sentence>
				<definiendum id="0">C5</definiendum>
				<definiens id="0">answers to the same con rmation prompt containing less than 5 words</definiens>
			</definition>
			<definition id="2">
				<sentence>Perplexity WER % C % words 1-pass 2-pass 1-pass 2-pass 1 1.8 18.6 13.9 11.3 11.1 2 1.3 5.0 3.2 14.5 12.5 3 1.2 3.2 1.5 4.4 2.5 4 4.7 11 7.4 19.2 18 5 13.8 11.3 9.5 19.7 18.8 6 73.9 38.4 27.4 30.8 29.8 Table 1 : Results for each cluster obtained with the hierarchical clustering method , at the utterance level , on the HMIHY corpus By using these clusters for training speci c LMs and by dynamically choosing a speci c LM according to the dialog context for performing LM rescoring , we obtain the perplexity and Word-Error-Rate ( WER ) results of table 1 on the HMIHY test corpus .</sentence>
				<definiendum id="0">Perplexity WER</definiendum>
				<definiendum id="1">Word-Error-Rate ( WER</definiendum>
				<definiens id="0">Results for each cluster obtained with the hierarchical clustering method , at the utterance level , on the HMIHY corpus By using these clusters for training speci c LMs and by dynamically choosing a speci</definiens>
			</definition>
			<definition id="3">
				<sentence>A component value is the number of occurrences of the corresponding calltype within the utterance .</sentence>
				<definiendum id="0">component value</definiendum>
				<definiens id="0">the number of occurrences of the corresponding calltype within the utterance</definiens>
			</definition>
			<definition id="4">
				<sentence>labels : these are the 34 calltypes presented in section 2 and representing both application-speci c requests ( Pay Bill ) and dialog-based concepts like Yes , No , I want to talk to somebody , Help , etc ... . labels : we chose the bigrams of the previous calltypes that had the highest weighted Mutual Information and we store in the vectors their frequencies .</sentence>
				<definiendum id="0">c requests</definiendum>
			</definition>
</paper>

		<paper id="0101">
			<definition id="0">
				<sentence>In all of these approaches , contrast is a property of forms .</sentence>
				<definiendum id="0">contrast</definiendum>
				<definiens id="0">a property of forms</definiens>
			</definition>
			<definition id="1">
				<sentence>The probability that a particular target value will be chosen is 2 The formula used to calculate the activation of a stored target value through its frequency of previous use and proximity to the corresponding exemplar value is : A = n ( 2.141 ( -25 ( a-b ) ) 2 ) where n is the number of times that the target value under consideration has been produced in the previous six rounds , a is the target value , and b is the reference target value in the exemplar under current production .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">b</definiendum>
				<definiens id="0">formula used to calculate the activation of a stored target value through its frequency of previous use and proximity to the corresponding exemplar value is : A = n</definiens>
				<definiens id="1">the number of times that the target value under consideration has been produced in the previous six rounds</definiens>
			</definition>
</paper>

		<paper id="0504">
			<definition id="0">
				<sentence>The following excerpt gives a sense of urgency due to the use of the present progressive : ‘Pacific salmon contaminated by industrial pollutants in the ocean are carrying the chemicals to Alaska’s lakes…’ ( NYT-1 ) The passive voice is a major stylistic feature of scientific discourse where according to Ding ( 1998 ) it represents the world in terms of objects , things and materials .</sentence>
				<definiendum id="0">passive voice</definiendum>
			</definition>
			<definition id="1">
				<sentence>Compare the vocabulary of Nature : ‘Here we show that groups of migrating sockeye salmon ( Oncorhynchus nerka ) can act as bulk-transport vectors of persistent industrial pollutants known as polychlorinated biphenyls ( PCBs ) , which they assimilate from the ocean and then convey over vast distances back to their natal spawning lakes .</sentence>
				<definiendum id="0">Compare the vocabulary of Nature</definiendum>
				<definiendum id="1">Oncorhynchus nerka</definiendum>
				<definiens id="0">bulk-transport vectors of persistent industrial pollutants known as polychlorinated biphenyls ( PCBs ) , which they assimilate from the ocean and then convey over vast distances back to their natal spawning lakes</definiens>
			</definition>
</paper>

		<paper id="0861">
			<definition id="0">
				<sentence>a7 Naive Bayes ( NB ) is the well–known Bayesian algorithm that classifies an example by choosing the class that maximizes the product , over all features , of the conditional probability of the class given the feature .</sentence>
				<definiendum id="0">Naive Bayes ( NB )</definiendum>
				<definiens id="0">the well–known Bayesian algorithm that classifies an example by choosing the class that maximizes the product , over all features , of the conditional probability of the class given the feature</definiens>
			</definition>
			<definition id="1">
				<sentence>a7 AdaBoost ( AB ) is a method for learning an ensemble of weak classifiers and combine them into a strong global classification rule .</sentence>
				<definiendum id="0">AdaBoost ( AB )</definiendum>
				<definiens id="0">a method for learning an ensemble of weak classifiers and combine them into a strong global classification rule</definiens>
			</definition>
			<definition id="2">
				<sentence>a7 Domain Driven Disambiguation ( DDD ) is an unsupervised method that makes use of domain information in order to solve lexical ambiguity .</sentence>
				<definiendum id="0">DDD )</definiendum>
				<definiens id="0">an unsupervised method that makes use of domain information in order to solve lexical ambiguity</definiens>
			</definition>
			<definition id="3">
				<sentence>The conversion between WordNet-1.6 synsets ( SemCoron the output of the classifiers by applying an automatically derived mapping provided by TALP2 .</sentence>
				<definiendum id="0">WordNet-1.6 synsets</definiendum>
				<definiens id="0">the output of the classifiers by applying an automatically derived mapping provided by TALP2</definiens>
			</definition>
</paper>

		<paper id="3110">
			<definition id="0">
				<sentence>Termino attempts to reconcile this tension by maintaining a flexible , extensible relational database for storing terminological information and compiling finite state machines from this database to do term lookup .</sentence>
				<definiendum id="0">Termino</definiendum>
				<definiens id="0">attempts to reconcile this tension by maintaining a flexible , extensible relational database for storing terminological information and compiling finite state machines from this database to do term lookup</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , the UMLS Metathesaurus ( Humphreys et al. , 1998 ) , which provides a semantic classification of terms from a wide range of vocabularies in the clinical and biomedical domain , currently contains well over 2 million distinct English terms .</sentence>
				<definiendum id="0">UMLS Metathesaurus</definiendum>
				<definiens id="0">provides a semantic classification of terms from a wide range of vocabularies in the clinical and biomedical domain , currently contains well over 2 million distinct English terms</definiens>
			</definition>
			<definition id="2">
				<sentence>Information Extraction is the activity of identifying pre-defined classes of entities and relationships in natural language texts and storing this information in a structured format enabling rapid and effective access to the information , e.g. Gaizauskas and Wilks ( 1998 ) , Grishman ( 1997 ) .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiens id="0">the activity of identifying pre-defined classes of entities and relationships in natural language texts and storing this information in a structured format enabling rapid and effective access to the information</definiens>
			</definition>
			<definition id="3">
				<sentence>The AMBIT system contains several engines , of which Termino is one .</sentence>
				<definiendum id="0">AMBIT system</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Information Extraction Engine pulls selected information out of natural language text and pushes this information into a set of pre-defined templates .</sentence>
				<definiendum id="0">Information Extraction Engine</definiendum>
				<definiens id="0">pulls selected information out of natural language text and pushes this information into a set of pre-defined templates</definiens>
			</definition>
			<definition id="5">
				<sentence>The Query Engine allows users to access information through traditional free text search and search based on the structured information produced by the Information Extraction Engine , so that queries may refer to specific entities and classes of entities , and specific kinds of relations that are recognised to hold between them .</sentence>
				<definiendum id="0">Query Engine</definiendum>
				<definiens id="0">allows users to access information through traditional free text search and search based on the structured information produced by the Information Extraction Engine</definiens>
			</definition>
			<definition id="6">
				<sentence>The Text Indexing Engine is used to index text and extracted , structured information for the purposes of information retrieval .</sentence>
				<definiendum id="0">Text Indexing Engine</definiendum>
				<definiens id="0">used to index text and extracted , structured information for the purposes of information retrieval</definiens>
			</definition>
			<definition id="7">
				<sentence>The UMLS Metathesaurus provides a semantic classification of terms drawn from a wide range of vocabularies in the clinical and biomedical domain ( Humphreys et al. , 1998 ) .</sentence>
				<definiendum id="0">UMLS Metathesaurus</definiendum>
			</definition>
			<definition id="8">
				<sentence>The information in Termino is either imported from existing , outside knowledge sources , e.g. the Enzyme Nomenclature ( http : //www .</sentence>
				<definiendum id="0">Enzyme Nomenclature ( http</definiendum>
				<definiens id="0">either imported from existing , outside knowledge sources</definiens>
			</definition>
			<definition id="9">
				<sentence>Termino consists of two components : a database holding terminological information and a compiler for generating term recognizers from the contents of the database .</sentence>
				<definiendum id="0">Termino</definiendum>
				<definiens id="0">consists of two components : a database holding terminological information and a compiler for generating term recognizers from the contents of the database</definiens>
			</definition>
			<definition id="10">
				<sentence>A termoid consists of a string together with associated information of various kinds about the string .</sentence>
				<definiendum id="0">termoid</definiendum>
				<definiens id="0">consists of a string together with associated information of various kinds about the string</definiens>
			</definition>
			<definition id="11">
				<sentence>1Note that the UMLS Metathesaurus has no mechanism for storing this co-dependency between grammatical and semantic information .</sentence>
				<definiendum id="0">UMLS Metathesaurus</definiendum>
				<definiens id="0">has no mechanism for storing this co-dependency between grammatical and semantic information</definiens>
			</definition>
			<definition id="12">
				<sentence>MetaMap is a program available from at the National Library of Medicine – the developers of UMLS – specifically designed to discover UMLS Metathesaurus concepts referred to in text ( Aronson , 2001 ) .</sentence>
				<definiendum id="0">MetaMap</definiendum>
			</definition>
			<definition id="13">
				<sentence>Termino includes a relational database which is designed to store a large number of terms together with complex , heterogeneous information about these terms , such as morpho-syntactic information , links to concepts in ontologies , and other kinds of annotations .</sentence>
				<definiendum id="0">Termino</definiendum>
				<definiens id="0">includes a relational database which is designed to store a large number of terms together with complex , heterogeneous information about these terms , such as morpho-syntactic information , links to concepts in ontologies</definiens>
			</definition>
			<definition id="14">
				<sentence>Termino provides a firm basis on which to build largescale biomedical text processing applications .</sentence>
				<definiendum id="0">Termino</definiendum>
				<definiens id="0">provides a firm basis on which to build largescale biomedical text processing applications</definiens>
			</definition>
</paper>

		<paper id="1403">
			<definition id="0">
				<sentence>Localisation is one of the fastest growing industrial sectors in the digital world .</sentence>
				<definiendum id="0">Localisation</definiendum>
				<definiens id="0">one of the fastest growing industrial sectors in the digital world</definiens>
			</definition>
			<definition id="1">
				<sentence>Localisation Vectors of scalability and growth Geography / Languages Content Medium of delivery Europe Documents Manuals Asia Global CD-ROM Online Pure Internet-based General technical Any content Culture Symbols Rights Values Figure 3 : Vectors of scalability and growth While politicians all over the world want to make Information Society Technologies ( IST ) available and accessible in the language and locale of the people they represent , software and digital content publishers need to respond to the demands of their customers by supporting a wide variety of local languages and cultures in their products .</sentence>
				<definiendum id="0">Localisation Vectors</definiendum>
			</definition>
			<definition id="2">
				<sentence>Localisation becomes the catalyst for electronic multilingual production and publishing .</sentence>
				<definiendum id="0">Localisation</definiendum>
				<definiens id="0">becomes the catalyst for electronic multilingual production and publishing</definiens>
			</definition>
			<definition id="3">
				<sentence>• Start : mid-eighties – Packaged softward - &gt; multimedia - &gt; content • Ireland : the world centre ( certainly the European centre ) • 95 % of source orginates in the USA • International market more important for pubishers than domestic markets • MS : &gt; 60 % , &gt; US $ 5b .</sentence>
				<definiendum id="0">Ireland</definiendum>
				<definiens id="0">mid-eighties – Packaged softward - &gt; multimedia - &gt; content •</definiens>
			</definition>
			<definition id="4">
				<sentence>The ISO sees itself as a bridge between public and private sectors .</sentence>
				<definiendum id="0">ISO</definiendum>
				<definiens id="0">sees itself as a bridge between public and private sectors</definiens>
			</definition>
			<definition id="5">
				<sentence>Impact A support infrastructure must be put into place to maller players involved in localisation s to the widest variety of ation A first step in the implementation of the establishment of the y Laboratory and LOTS ) as part of the European-funded Cooperating with leading industry associations , ion and Localisation ( GALA ) and The Institute of Professionals ( TILP ) , and building on , a sophisticated online library with ground information on each of the ed and published .</sentence>
				<definiendum id="0">Localisation</definiendum>
				<definiens id="0">the widest variety of ation A first step in the implementation of the establishment of the y Laboratory and LOTS ) as part of the European-funded Cooperating with leading industry associations , ion</definiens>
			</definition>
			<definition id="6">
				<sentence>Unicode – The Unicode Consortium is a nonprofit organization founded to develop , extend and promote the use of the Unicode Standard , which specifies the representation of text in modern software products and standards .</sentence>
				<definiendum id="0">Unicode Consortium</definiendum>
				<definiens id="0">a nonprofit organization founded to develop , extend and promote the use of the Unicode Standard , which specifies the representation of text in modern software products and standards</definiens>
			</definition>
			<definition id="7">
				<sentence>WC3 – This consortium develops interoperable technologies ( specifications , guidelines , software , and tools ) to lead the Web to its full potential as a forum for information , commerce , communication , and collective understanding .</sentence>
				<definiendum id="0">interoperable technologies</definiendum>
				<definiens id="0">specifications , guidelines , software , and tools ) to lead the Web to its full potential as a forum for information , commerce , communication , and collective understanding</definiens>
			</definition>
			<definition id="8">
				<sentence>The LRC uses the facilities available in LOTS to verify standards and interoperability issues .</sentence>
				<definiendum id="0">LRC</definiendum>
				<definiens id="0">uses the facilities available in LOTS to verify standards and interoperability issues</definiens>
			</definition>
			<definition id="9">
				<sentence>The LRC is working with content and technology developers on agreements which will allow a wider deployment of authentic source material in a wider range of languages and file formats .</sentence>
				<definiendum id="0">LRC</definiendum>
				<definiens id="0">working with content and technology developers on agreements</definiens>
			</definition>
</paper>

		<paper id="1216">
			<definition id="0">
				<sentence>In the Message Understanding Conference ( MUC ) , Named entity Recognition aims to classify proper nouns , dates , time , measures and locations , etc .</sentence>
				<definiendum id="0">Message Understanding Conference</definiendum>
			</definition>
			<definition id="1">
				<sentence>We define the features of the word w to be the first non-stop word on either side of w and the intervening stop words ( which can be defined as the top-k most frequent words in the corpus ) .</sentence>
				<definiendum id="0">intervening stop words</definiendum>
				<definiens id="0">the top-k most frequent words in the corpus )</definiens>
			</definition>
			<definition id="2">
				<sentence>We use ( u 1 , u 2 … u n ) and ( v 1 , v 2 … v n ) to denote the feature vectors for the words u and v respectively , where n is the number of feature types extracted from a corpus .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">u n ) and ( v 1 , v 2 … v n ) to denote the feature vectors for the words u and v respectively</definiens>
				<definiens id="1">the number of feature types extracted from a corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>It is defined as : ( ) ( ) ( ) ( )         × = uPfP ufP ufpmi i i i , log , where P ( f i , u ) is the probability of f i co-occurring with u ; P ( f i ) is the probability of f i co-occurring with any word ; and P ( u ) is the probability of any feature co-occurring with u. The similarity between word u and v is defined as the Cosine of PMI : ( ) ( ) ( ) ( ) ( ) ∑∑ ∑ == = × × = n i i n i i n i ii word vfpmiufpmi vfpmiufpmi vusim 1 2 1 2 1 , , , , , Different similarity measures of distributional similarity can affect the quality of the result to s statistically significant degree .</sentence>
				<definiendum id="0">P ( f i</definiendum>
				<definiendum id="1">P ( f i )</definiendum>
				<definiendum id="2">v</definiendum>
				<definiendum id="3">Different similarity</definiendum>
				<definiens id="0">the probability of f i co-occurring with u ;</definiens>
				<definiens id="1">the probability of f i co-occurring with any word</definiens>
				<definiens id="2">the probability of any feature co-occurring with u. The similarity between word u and</definiens>
				<definiens id="3">measures of distributional similarity can affect the quality of the result to s statistically significant degree</definiens>
			</definition>
</paper>

		<paper id="0301">
			<definition id="0">
				<sentence>Like an LTAG ( Joshi and Schabes , 1997 ) , a Dynamic Version of Tree Adjoining Grammar ( DV { TAG ) consists of a set of elementary trees , divided into initial trees and auxiliary trees , and attachment operations for combining them .</sentence>
				<definiendum id="0">LTAG</definiendum>
				<definiens id="0">a Dynamic Version of Tree Adjoining Grammar ( DV { TAG ) consists of a set of elementary trees , divided into initial trees and auxiliary trees , and attachment operations for combining them</definiens>
			</definition>
			<definition id="1">
				<sentence>Three operations ( substitution , adjunction from the left and adjunction from the right ) are called forward operations because they insert the current elementary tree into the left context ; two other operations ( inverse substitution and inverse adjunction ) are called inverse operations because they insert the left context into the current elementary tree ; the sixth operation ( shift ) does not involve any insertion of new structural material .</sentence>
				<definiendum id="0">sixth operation</definiendum>
				<definiens id="0">substitution , adjunction from the left and adjunction from the right ) are called forward operations because they insert the current elementary tree into the left context</definiens>
				<definiens id="1">inverse substitution and inverse adjunction ) are called inverse operations because they insert the left context into the current elementary tree</definiens>
			</definition>
			<definition id="2">
				<sentence>The derivation tree represents the history of the derivation of the sentence : it describes the substitutions and the adjoinings that occur in a sentence derivation through a tree structure .</sentence>
				<definiendum id="0">derivation tree</definiendum>
				<definiens id="0">the history of the derivation of the sentence : it describes the substitutions and the adjoinings that occur in a sentence derivation through a tree structure</definiens>
			</definition>
			<definition id="3">
				<sentence>A derivation-dependency tree is a head-based version of the derivation tree .</sentence>
				<definiendum id="0">derivation-dependency tree</definiendum>
				<definiens id="0">a head-based version of the derivation tree</definiens>
			</definition>
			<definition id="4">
				<sentence>A Raising tree is any elementary tree that allows to combine on its left via either inverse substitution or adjunction .</sentence>
				<definiendum id="0">Raising tree</definiendum>
				<definiens id="0">any elementary tree that allows to combine on its left via either inverse substitution or adjunction</definiens>
			</definition>
			<definition id="5">
				<sentence>A Raised tree is a tree such that has been attached to according to inverse substitution or inverse adjunction .</sentence>
				<definiendum id="0">Raised tree</definiendum>
				<definiens id="0">attached to according to inverse substitution or inverse adjunction</definiens>
			</definition>
			<definition id="6">
				<sentence>The rst is the theoretical issue of semantic compositionality , because the superstructures do not re ect the incremental process in the semantic composition once words are not the minimal semantic units anymore ( as assumed in LTAG ) .</sentence>
				<definiendum id="0">rst</definiendum>
			</definition>
			<definition id="7">
				<sentence>A tree template is a single elementary tree that represents the set of elementary trees sharing the same structure except for the lexical anchor : one single structure is referred to by pointers from the word list .</sentence>
				<definiendum id="0">tree template</definiendum>
				<definiens id="0">a single elementary tree that represents the set of elementary trees sharing the</definiens>
			</definition>
</paper>

		<paper id="1906">
			<definition id="0">
				<sentence>FrameNet ( Baker et al. , 1998 ) , building on Fillmore’s theory of frame semantics , provides definitions of frames and their semantic roles , a lexical database and a manually annotated corpus of example sentences .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">Baker et al. , 1998 ) , building on Fillmore’s theory of frame semantics , provides definitions of frames and their semantic roles , a lexical database and a manually annotated corpus of example sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>TIGER syntactic annotations consist of relatively flat constituent graph representations , with edge labels that indicate functional information , such as head ( HD ) , subject ( SB ) , cf. Figure 1 .</sentence>
				<definiendum id="0">TIGER syntactic annotations</definiendum>
				<definiens id="0">consist of relatively flat constituent graph representations , with edge labels that indicate functional information , such as head ( HD ) , subject ( SB ) , cf. Figure 1</definiens>
			</definition>
			<definition id="2">
				<sentence>f is a function of f-structure .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">a function of f-structure</definiens>
			</definition>
			<definition id="3">
				<sentence>The frame elements are defined as f–projections of the verb’s SUBJ , OBJ and OBL OBJ functions .</sentence>
				<definiendum id="0">frame elements</definiendum>
			</definition>
			<definition id="4">
				<sentence>Figure 4 : Frame projection by DBA ( via transfer ) description integrates the semantics projection into the grammar and parsing process , DBA keeps it as a separate module .</sentence>
				<definiendum id="0">DBA</definiendum>
				<definiens id="0">Frame projection by DBA ( via transfer ) description integrates the semantics projection into the grammar and parsing process</definiens>
			</definition>
			<definition id="5">
				<sentence>For these , we define the frame information ( FRAME , FEE ) and the linking of semantic roles ( e.g. , the f–projection SemA of the SUBJ is defined as the SPEAKER role of the head’s semantic projection SemX ) .</sentence>
				<definiendum id="0">frame information ( FRAME</definiendum>
				<definiendum id="1">FEE )</definiendum>
			</definition>
			<definition id="6">
				<sentence>We model underspecification as disjunction , which is encoded by optional transfer rules that create alternative ( disjunctive ) contexts .</sentence>
				<definiendum id="0">disjunction</definiendum>
				<definiens id="0">encoded by optional transfer rules that create alternative ( disjunctive ) contexts</definiens>
			</definition>
			<definition id="7">
				<sentence>E.g. , like sell , the expression triggers a COMMERCE SELL frame with the appropriate semantic roles , here GOODS .</sentence>
				<definiendum id="0">E.g.</definiendum>
				<definiendum id="1">expression</definiendum>
				<definiens id="0">triggers a COMMERCE SELL frame with the appropriate semantic roles</definiens>
			</definition>
			<definition id="8">
				<sentence>By co-indexation with the SUBJ of versprechen we find an alternative non-local path , which we render as an inside-out functional equation ( ( XCOMP '' ) SUBJ ) .</sentence>
				<definiendum id="0">non-local path</definiendum>
				<definiens id="0">an inside-out functional equation ( ( XCOMP '' ) SUBJ )</definiens>
			</definition>
</paper>

		<paper id="1205">
			<definition id="0">
				<sentence>• OTL ( Outline ) : a characterization/ summary of the content of the paper .</sentence>
				<definiendum id="0">OTL</definiendum>
				<definiens id="0">a characterization/ summary of the content of the paper</definiens>
			</definition>
			<definition id="1">
				<sentence>• OWN : the author’s own work : ◊ MTH ( Method ) : experimental procedure ; ◊ RSL ( Result ) : the results of the experiment ; ◊ INS ( Insight ) : the author’s insights and findings obtained from experimental results ( including the interpretation ) or from previous work ◊ IMP ( Implication ) : the implications of experimental results ( e.g. conjectures , assessment , applications , future work ) or those of previous work ◊ ELS ( Else ) : anything else within OWN .</sentence>
				<definiendum id="0">OWN</definiendum>
				<definiens id="0">the author’s own work : ◊ MTH ( Method ) : experimental procedure</definiens>
				<definiens id="1">the implications of experimental results ( e.g. conjectures , assessment , applications , future work</definiens>
			</definition>
			<definition id="2">
				<sentence>• DFF ( Difference ) : a contrast or inconsistency between data and/or findings .</sentence>
				<definiendum id="0">DFF</definiendum>
				<definiendum id="1">Difference )</definiendum>
				<definiens id="0">a contrast or inconsistency between data and/or findings</definiens>
			</definition>
			<definition id="3">
				<sentence>It contains certain kind of linguistic signals such as : 3 ( 6 ) Indexicals : e.g. in this paper ; in the present study ; here ‘Reporting verbs’ or verbs for presentation : e.g. we show/ demonstrate/ present/ report However , OTL consists of a wider range of sentences .</sentence>
				<definiendum id="0">OTL</definiendum>
				<definiens id="0">contains certain kind of linguistic signals such as : 3 ( 6 ) Indexicals : e.g. in this paper ; in the present study ; here ‘Reporting verbs’ or verbs for presentation</definiens>
				<definiens id="1">consists of a wider range of sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>In the R-section , RSL zones were observed to follow MTH with no discourse connectives .</sentence>
				<definiendum id="0">RSL</definiendum>
			</definition>
			<definition id="5">
				<sentence>A generalization is : 5 ( 16 ) X indicate Y ( a variant : X , indicating Y ) X : results/experiments/studies , Y : biological statement or model , Verb variations from our sample : indicate/suggest/demonstrate/represent/reveal .</sentence>
				<definiendum id="0">generalization</definiendum>
				<definiens id="0">biological statement or model</definiens>
			</definition>
			<definition id="6">
				<sentence>A PBM zone ( in I-section ) and an IMP zone describing future work ( or limitations ) often look very similar on the surface , as illustrated in ( 38 ) , which is the last sentence in the article describing the limitation of the work presented .</sentence>
				<definiendum id="0">PBM zone</definiendum>
				<definiens id="0">the last sentence in the article describing the limitation of the work presented</definiens>
			</definition>
			<definition id="7">
				<sentence>The R-section consists of ‘problem-solving’ units following the experimental procedure .</sentence>
				<definiendum id="0">R-section</definiendum>
				<definiens id="0">consists of ‘problem-solving’ units following the experimental procedure</definiens>
			</definition>
			<definition id="8">
				<sentence>( 40 ) ( X * PandM MTH + ( RSL INS * IMP * ) * ) + X : an arbitrary zone , and PandM = [ ( PBM MTH ) ( MTH PBM ) ] Below are examples of an optional zone ( X ) placed at the beginning a problem-solving unit : 9 ( 41 ) [ It is possible that … ] IMP [ To test this possibility , ] PBM [ we examined … ] MTH ( 42 ) [ ... has revealed two motifs ( Fig .</sentence>
				<definiendum id="0">PandM</definiendum>
				<definiendum id="1">PBM MTH )</definiendum>
				<definiens id="0">an arbitrary zone , and</definiens>
			</definition>
			<definition id="9">
				<sentence>htm ) for these purposes ; 1 ) to define zone classes as ontology classes ; zone annotation is then expected to be a variant of named entity annotation , which we are familiar with , and 2 ) to link between expressions referring to results ( e.g. these results/ our results ) and their antecedent ( i.e. the RSL zone providing a concrete description of the experimental results ) , using the coreference tool .</sentence>
				<definiendum id="0">annotation</definiendum>
				<definiens id="0">a concrete description of the experimental results ) , using the coreference tool</definiens>
			</definition>
</paper>

		<paper id="2324">
			<definition id="0">
				<sentence>I will show that this object is an ordered directed acyclic graph ( DAG ) , 1SDRT stands for Segmented Discourse Representation Theory ( Asher , 1993 ) ( Asher and Lascarides , 2003 ) .</sentence>
				<definiendum id="0">DAG</definiendum>
				<definiens id="0">an ordered directed acyclic graph</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , an SDRS is is a couple of sets 〈U , Con〉 .</sentence>
				<definiendum id="0">SDRS</definiendum>
			</definition>
			<definition id="2">
				<sentence>U is a set of labels of DRS or SDRS which may be viewed as “speech act discourse referents” .</sentence>
				<definiendum id="0">U</definiendum>
			</definition>
			<definition id="3">
				<sentence>Con is a set of conditions on labels of the form : • pi : K , where pi is a label from U and K is a ( S ) DRS ( labelling ) ; • R ( pii , pij ) , where pii and pij are labels and R a discourse relation ( structuring ) .</sentence>
				<definiendum id="0">Con</definiendum>
				<definiendum id="1">K</definiendum>
				<definiens id="0">a set of conditions on labels of the form : • pi : K , where pi is a label from U and</definiens>
				<definiens id="1">a ( S ) DRS ( labelling ) ; • R ( pii , pij ) , where pii and pij are labels and R a discourse relation ( structuring )</definiens>
			</definition>
			<definition id="4">
				<sentence>The definition of left-dominance in a tree is the following ( Danlos , 2003 ) : a node X leftdominates a node Y iff Y is a daughter of X ( immediate dominance ) or there exists a daughter Z of X such that Y belongs to the left-frontier of the tree rooted at Z. For example , Ra left-dominates pi1 , Rb and pi2 in ( A ) , while Rb left-dominates Ra , pi1 and pi3 in ( B ) 18 .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">a daughter of X ( immediate dominance</definiens>
			</definition>
</paper>

		<paper id="2406">
			<definition id="0">
				<sentence>Sch¨utze represents each feature as a vector of words that co–occur with that feature in the training data .</sentence>
				<definiendum id="0">Sch¨utze</definiendum>
				<definiens id="0">represents each feature as a vector of words that co–occur with that feature in the training data</definiens>
			</definition>
			<definition id="1">
				<sentence>SVD has the effect of converting a word level feature space into a concept level semantic space that smoothes the fine distinctions between features that represent similar concepts .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">has the effect of converting a word level feature space into a concept level semantic space that smoothes the fine distinctions between features that represent similar concepts</definiens>
			</definition>
			<definition id="2">
				<sentence>Divisive methods start with all instances in the same cluster and split one cluster into two during each iteration until all instances are in their own cluster .</sentence>
				<definiendum id="0">Divisive methods</definiendum>
				<definiens id="0">start with all instances in the same cluster and split one cluster into two during each iteration until all instances are in their own cluster</definiens>
			</definition>
			<definition id="3">
				<sentence>In similarity space , each instance can be viewed as a node of a fully connected weighted graph whose edges indicate the similarity between the instances they connect .</sentence>
				<definiendum id="0">similarity</definiendum>
				<definiens id="0">a node of a fully connected weighted graph whose edges indicate the</definiens>
			</definition>
			<definition id="4">
				<sentence>Precision is defined as the number of instances that are clustered correctly divided by the number of instances clustered , while recall is the number of instances clustered correctly over the total number of instances .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">the number of instances that are clustered correctly divided by the number of instances clustered</definiens>
				<definiens id="1">the number of instances clustered correctly over the total number of instances</definiens>
			</definition>
			<definition id="5">
				<sentence>This further suggests that UPGMA performs much better than Repeated Bisections with larger amounts of training data .</sentence>
				<definiendum id="0">UPGMA</definiendum>
				<definiens id="0">performs much better than Repeated Bisections with larger amounts of training data</definiens>
			</definition>
</paper>

		<paper id="1905">
			<definition id="0">
				<sentence>TIGER : Linguistic interpretation of a german corpus .</sentence>
				<definiendum id="0">TIGER</definiendum>
				<definiens id="0">Linguistic interpretation of a german corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Parser evaluation : using a grammatical relation annotation scheme .</sentence>
				<definiendum id="0">Parser evaluation</definiendum>
			</definition>
</paper>

		<paper id="0856">
			<definition id="0">
				<sentence>The re nements consist of both exploiting a new technique ( Domain Relevance Estimation ) for domain detection in texts , and experimenting with the use of Latent Semantic Analysis to avoid reliance on manually annotated domain resources ( e.g. WORDNET DOMAINS ) .</sentence>
				<definiendum id="0">re nements</definiendum>
				<definiens id="0">consist of both exploiting a new technique ( Domain Relevance Estimation ) for domain detection in texts , and experimenting with the use of Latent Semantic Analysis to avoid reliance on manually annotated domain resources ( e.g. WORDNET DOMAINS )</definiens>
			</definition>
			<definition id="1">
				<sentence>Pattern abstraction is an effective methodology for WSD ( Mihalcea , 2002 ) .</sentence>
				<definiendum id="0">Pattern abstraction</definiendum>
				<definiens id="0">an effective methodology for WSD</definiens>
			</definition>
			<definition id="2">
				<sentence>Kernel methods is an area of recent interest in Machine Learning .</sentence>
				<definiendum id="0">Kernel methods</definiendum>
			</definition>
			<definition id="3">
				<sentence>For Senseval-3 we implemented the Kernels-WSD system , which exploits kernel methods to perform the following operations : ( i ) pattern abstraction ; ( ii ) combination of different knowledge sources , in particular domain information and syntagmatic information ; ( iii ) integration of unsupervised term proximity estimation in the supervised framework .</sentence>
				<definiendum id="0">Kernels-WSD system</definiendum>
				<definiens id="0">exploits kernel methods to perform the following operations : ( i ) pattern abstraction ; ( ii ) combination of different knowledge sources , in particular domain information and syntagmatic information ; ( iii ) integration of unsupervised term proximity estimation in the supervised framework</definiens>
			</definition>
			<definition id="4">
				<sentence>Then , an Expectation Maximization algorithm computes the parameters that maximize the likelihood of the model on the empirical data ( Gliozzo et al. , 2004 ) .</sentence>
				<definiendum id="0">Expectation Maximization algorithm</definiendum>
			</definition>
			<definition id="5">
				<sentence>abstraction and Kernel Methods One of the most discriminative features for lexical disambiguation is the lexical/syntactic pattern in which the word appears .</sentence>
				<definiendum id="0">abstraction</definiendum>
				<definiens id="0">the lexical/syntactic pattern in which the word appears</definiens>
			</definition>
			<definition id="6">
				<sentence>Collocations are sequences of words in the context of the word to disambiguate , and can be associated to word senses performing supervised learning .</sentence>
				<definiendum id="0">Collocations</definiendum>
				<definiens id="0">sequences of words in the context of the word to disambiguate</definiens>
			</definition>
			<definition id="7">
				<sentence>Kernel methods , e.g. Support Vector Machines ( SVMs ) , are state-of-the-art learning algorithms , and they are successfully adopted in many NLP tasks .</sentence>
				<definiendum id="0">Kernel methods</definiendum>
				<definiendum id="1">e.g. Support Vector Machines ( SVMs</definiendum>
			</definition>
			<definition id="8">
				<sentence>The learning algorithm , which compares all pairs of data items , exploits the information encoded in the kernel .</sentence>
				<definiendum id="0">learning algorithm</definiendum>
				<definiens id="0">compares all pairs of data items , exploits the information encoded in the kernel</definiens>
			</definition>
			<definition id="9">
				<sentence>We have de ned the syntagmatic kernel as the sum of n distinct word-sequence kernels for lemmata ( i.e. Collocation Kernel KC ) and sequences of POSs ( i.e. POS Kernel KPOS ) , according to the formula ( for our experiments we set n to 2 ) : KS ( x ; y ) = nX i=1 KCi ( x ; y ) + nX i=1 KPOSi ( x ; y ) ( 2 ) In the above de nition of syntagmatic kernel , only exact lemma/POS matches contribute to the similarity .</sentence>
				<definiendum id="0">POSs</definiendum>
				<definiens id="0">the sum of n distinct word-sequence kernels for lemmata</definiens>
				<definiens id="1">KS ( x ; y ) = nX i=1 KCi ( x ; y ) + nX i=1 KPOSi ( x ; y</definiens>
			</definition>
			<definition id="10">
				<sentence>The paradigmatic kernel takes into account the paradigmatic aspect of sense distinction ( i.e. domain aspects ) ( Gliozzo et al. , 2004 ) .</sentence>
				<definiendum id="0">paradigmatic kernel</definiendum>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>It discusses how we use a computer vision module to construct an XML representation that captures the components of the graphic and their relationship to one another , and how we use a Bayesian belief network to hypothesize the intentions of the graph designer .</sentence>
				<definiendum id="0">XML representation</definiendum>
				<definiens id="0">captures the components of the graphic and their relationship to one another</definiens>
			</definition>
			<definition id="1">
				<sentence>Our plan operators consist of : Goal : the goal that the operator achieves Data-requirements : requirements that the data must satisfy in order for the operator to be applicable in a graphic planning paradigm Display-constraints : features that constrain how the graphic is eventually constructed if this operator is part of the final plan Body : lower-level subgoals that must be accomplished in order to achieve the overall goal of the operator .</sentence>
				<definiendum id="0">plan operators</definiendum>
				<definiendum id="1">Body</definiendum>
				<definiens id="0">the goal that the operator achieves Data-requirements : requirements that the data must satisfy in order for the operator to be applicable in a graphic planning paradigm Display-constraints : features that constrain how the graphic is eventually constructed if this operator is part of the final plan</definiens>
			</definition>
			<definition id="2">
				<sentence>Perceive-info-to-interpolate ( &lt; viewer &gt; , &lt; g &gt; , &lt; axis &gt; , &lt; e &gt; , &lt; l1 &gt; , &lt; l2 &gt; , &lt; f &gt; ) Figure 5 : Operator that employs both perceptual and cognitive subgoals cused entity in the caption given that the graphic designer’s plan includes the viewer performing TaskA , or 3 ) the probability that the viewer performing Task-B will be part of the designer’s intended plan given that Task-A is part of his plan .</sentence>
				<definiendum id="0">Perceive-info-to-interpolate</definiendum>
			</definition>
</paper>

		<paper id="0863">
			<definition id="0">
				<sentence>Boosting is a powerful machine learning algorithm which has been shown to achieve good results on a variety of NLP problems .</sentence>
				<definiendum id="0">Boosting</definiendum>
			</definition>
			<definition id="1">
				<sentence>Our system was constructed around the Boostexter software ( Schapire and Singer , 2000 ) , which implements boosting on top of decision stumps ( deciAssociation for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems sion trees of one level ) , and was originally designed for text classification .</sentence>
				<definiendum id="0">deciAssociation</definiendum>
				<definiens id="0">Third International Workshop on the Evaluation of Systems sion trees of one level</definiens>
			</definition>
</paper>

		<paper id="3222">
			<definition id="0">
				<sentence>paths ( strings ) allows us to explore string kernels on these paths and combine them into tree kernels .</sentence>
				<definiendum id="0">paths</definiendum>
				<definiens id="0">strings ) allows us to explore string kernels on these paths and combine them into tree kernels</definiens>
			</definition>
			<definition id="1">
				<sentence>We apply these ideas in the context of parse disambiguation for sentence analyses produced by a Head-driven Phrase Structure Grammar ( HPSG ) , the grammar formalism underlying the Redwoods corpus ( Oepen et al. , 2002 ) .</sentence>
				<definiendum id="0">Redwoods corpus</definiendum>
				<definiens id="0">the context of parse disambiguation for sentence analyses produced by a Head-driven Phrase Structure Grammar ( HPSG</definiens>
			</definition>
			<definition id="2">
				<sentence>HPSG is a modern constraint-based lexicalist ( or “unification” ) grammar formalism.1 We build discriminative models using Support Vector Machines for ranking ( Joachims , 1999 ) .</sentence>
				<definiendum id="0">HPSG</definiendum>
				<definiens id="0">a modern constraint-based lexicalist ( or “unification” ) grammar formalism.1 We build discriminative models using Support Vector Machines for ranking</definiens>
			</definition>
			<definition id="3">
				<sentence>From a machine learning point of view , the parse selection problem can be formulated as follows : given a0 training examples ( a1a3a2 a5a5a4 a1a7a6 a2a9a8a10 a9a12a11a13a11a13a11a13a4 a1a7a6 a2a7a8a14a16a15a7a17a19a18 a9a8a9 , where each a1 a2 is a natural language sentence , a0 is the number of such sentences , a20a22a21a24a23 a11a13a11a13a11 a0 , a6 a2a7a8a25 is a parse tree for a1a3a2 , a26a12a2 is the number of parses for a given sentence a1a3a2 , a4 a1a7a6 a2a7a8a25 a9 is a feature representation for the parse tree a6 a2a7a8a25 , and we are given the training information which of all a6 a2a7a8a25 is the correct parse – learn how to correctly identify the correct parse of an unseen test sentence .</sentence>
				<definiendum id="0">a0</definiendum>
				<definiendum id="1">a26a12a2</definiendum>
				<definiens id="0">follows : given a0 training examples</definiens>
				<definiens id="1">a natural language sentence</definiens>
				<definiens id="2">the number of such sentences</definiens>
				<definiens id="3">the number of parses for a given sentence a1a3a2</definiens>
				<definiens id="4">a feature representation for the parse tree a6 a2a7a8a25 , and we are given the training information which of all a6 a2a7a8a25 is the correct parse – learn how to correctly identify the correct parse of an unseen test sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>We can denote a keyed string by a pair a1a60a59 a5a8a3 a9 , where a59a62a61 a58 is the key , and a3 is the string .</sentence>
				<definiendum id="0">a59a62a61 a58</definiendum>
				<definiendum id="1">a3</definiendum>
				<definiens id="0">the key , and</definiens>
				<definiens id="1">the string</definiens>
			</definition>
			<definition id="5">
				<sentence>Additionally , for reducing sparsity , for each keyed string a1 a29 a5a8a3 a9 , we also include a keyed string a1a60a63a65a64a3a66 a5a8a3 a9 , where a63a65a64a16a66 is the le-type of the word a29 .</sentence>
				<definiendum id="0">a63a65a64a16a66</definiendum>
				<definiens id="0">the le-type of the word a29</definiens>
			</definition>
			<definition id="6">
				<sentence>More specifically , the Repetition kernel is defined such that its vector space consists of all sequences from a58 composed of the same symbol .</sentence>
				<definiendum id="0">Repetition kernel</definiendum>
				<definiens id="0">such that its vector space consists of all sequences from a58 composed of the same symbol</definiens>
			</definition>
			<definition id="7">
				<sentence>The a56 is a restriction on the maximal span of the a57 -gram in the original string – e.g. if a35 a21 a37 and a56 a21a61a60 , the two letters of a a37 -gram can be at most a56 a53 a35a43a21 a37 letters apart in the original string .</sentence>
				<definiendum id="0">a56</definiendum>
				<definiens id="0">a restriction on the maximal span of the a57 -gram in the original string</definiens>
			</definition>
			<definition id="8">
				<sentence>In the following examples , the node labels are abbreviated as well ; a14a16a15a18a17 is a special symbol for end of path and a65a19a15a18a17 is a special symbol for start of path .</sentence>
				<definiendum id="0">a14a16a15a18a17</definiendum>
				<definiendum id="1">a65a19a15a18a17</definiendum>
				<definiens id="0">a special symbol for start of path</definiens>
			</definition>
</paper>

		<paper id="1604">
			<definition id="0">
				<sentence>Arabic word-forms consist of : – proclitics ( PCL ) , which include mono-consonantal conjunctions , e.g. wa- , ‘and’ , li- , ‘in order to’ , or prepositions , i.e. bi- , ‘in , at’ or ‘by’ , etc. ; – a prefix ( PRF ) .</sentence>
				<definiendum id="0">PCL )</definiendum>
				<definiens id="0">include mono-consonantal conjunctions , e.g. wa- , ‘and’ , li- , ‘in order to’ , or prepositions , i.e. bi- , ‘in , at’ or ‘by’ , etc. ; – a prefix ( PRF )</definiens>
			</definition>
			<definition id="1">
				<sentence>In generation , all ‘compatibility’ ( or ‘admit’ ) relations can in fact be rewritten in terms of ‘entail’ or ‘exclude’ rules associated with specific sets of word-formatives .</sentence>
				<definiendum id="0">‘compatibility’</definiendum>
				<definiens id="0">rewritten in terms of ‘entail’ or ‘exclude’ rules associated with specific sets of word-formatives</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>SEE allowed the judges to step through predefined units of the model summary ( elementary discourse units/EDUs ) ( Soricut and Marcu , 2003 ) and for each unit of that summary , mark the sentences in the peer summary that expressed [ all ( 4 ) , most ( 3 ) , some ( 2 ) , hardly any ( 1 ) or none ( 0 ) ] of the content in the current model summary unit .</sentence>
				<definiendum id="0">SEE</definiendum>
				<definiens id="0">allowed the judges to step through predefined units of the model summary ( elementary discourse units/EDUs ) ( Soricut and Marcu , 2003 ) and for each unit of that summary , mark the sentences in the peer summary that expressed</definiens>
			</definition>
			<definition id="1">
				<sentence>The average unigram overlap ( the number of unique unigrams in the intersection/the number of unique unigrams in the union ) for the two extra 50-word model summaries was had any tri-gram overlap at all .</sentence>
				<definiendum id="0">average unigram overlap</definiendum>
				<definiens id="0">the number of unique unigrams in the intersection/the number of unique unigrams in the union</definiens>
			</definition>
			<definition id="2">
				<sentence>There were 21 groups that participated in DUC-2003 , with 13 of them doing task 1 , 16 doing task 2 , 11 doing task 3 and only 9 trying task D305 D312 D315 D322 D323 D326 D330 D339 D355 D358 D362 D363 D364 D365 D368 D369 D377 D382 D384 D388 D397 D405 D410 D414 D419 D427 D432 D433 D440 D448 Docset 1−gram overlap Figure 8 : DUC-2003 unigram overlap by document set for 100-word models Judges and Models Beyond the main evaluation it was decided to do further investigation into the effects of model and judgment variation , in particular to focus on task 4 ( create short summaries of 10 documents that were relevant to a given question ) .</sentence>
				<definiendum id="0">judgment variation</definiendum>
				<definiens id="0">create short summaries of 10 documents that were relevant to a given question )</definiens>
			</definition>
</paper>

		<paper id="0603">
			<definition id="0">
				<sentence>Nor is this sort of information always explicitly presented in the documents retrieved by searches .</sentence>
				<definiendum id="0">Nor</definiendum>
			</definition>
			<definition id="1">
				<sentence>The metadata building process involves several steps that are entity and relation extraction from the tagged XML content repository , RDF metadata generation , and RDF metadata loading .</sentence>
				<definiendum id="0">metadata building process</definiendum>
				<definiens id="0">involves several steps that are entity and relation extraction from the tagged XML content repository</definiens>
			</definition>
</paper>

		<paper id="2104">
			<definition id="0">
				<sentence>According to these principles , LMF consists of the following elements : • a core metamodel ( i.e. the structural skeleton shared by any linguistic description at the lexical level ) ; • mechanisms for attaching lexical extensions ( see below ) to the core metamodel in order to build up more complex metamodels ; • mechanisms for selecting data categories used for lexical description and for determining how they relate to a metamodel ; • mechanisms for expressing any combination of the core metamodel and data categories as XML structures , i.e. by deciding to implement a given data category ( /gender/ ) as an XML element rather than as an attribute and by providing the corresponding vocabularies ( ‘gen’ , ‘gender’ , ‘genre’ ) ; • methods for describing how to extend LMF to analyze , design , and describe a variety of more specific lexical resources .</sentence>
				<definiendum id="0">LMF</definiendum>
			</definition>
			<definition id="1">
				<sentence>This component can , of course , be iterated , but no specific constraint is expressed as to its level of granularity in a lexical database ( e.g. proper treatment of homonyms ) , since this depends highly on languages and local editorial practices ; The Form component groups together all the general graphical or phonetic descriptions attached to the lexical entry ( reference orthographic form , transliteration , hyphenation , pronunciation , etc. ) ; 8 An experimental on-line data category registry is accessible under http : //syntax.loria.fr Finally , the Sense component is the one that actually organizes the lexical entry since it can be both repeated and further subdivided into senses .</sentence>
				<definiendum id="0">Sense component</definiendum>
				<definiens id="0">Form component groups together all the general graphical or phonetic descriptions attached to the lexical entry ( reference orthographic form , transliteration , hyphenation , pronunciation , etc.</definiens>
			</definition>
			<definition id="2">
				<sentence>To the Inflexion component : beside /word form/ , which identifies the actual inflected form in the component , it is necessary to associate the set of morphological features to provide a unique specification of the inflexion .</sentence>
				<definiendum id="0">Inflexion component</definiendum>
				<definiens id="0">identifies the actual inflected form in the component</definiens>
			</definition>
			<definition id="3">
				<sentence>The morphology component contains the identification of the plural inflexion paradigm for regular French nouns ( /fr-s-plural/ ) and the complete list of inflected word forms with associated morphological features , i.e. /number/ .</sentence>
				<definiendum id="0">morphology component</definiendum>
				<definiens id="0">contains the identification of the plural inflexion paradigm for regular French nouns ( /fr-s-plural/ ) and the complete list of inflected word forms with associated morphological features</definiens>
			</definition>
			<definition id="4">
				<sentence>Other useful metadata would be information about testimony and frequency of inflected forms in corpora , completeness of an inflexion list ( relevant for defective verbs such as pleuvoir ( ‘to rain’ ) or indication of special usages ( diachronic , diatopic or diastratic variation ) .</sentence>
				<definiendum id="0">completeness of an inflexion list</definiendum>
				<definiens id="0">‘to rain’ ) or indication of special usages ( diachronic , diatopic or diastratic variation )</definiens>
			</definition>
</paper>

		<paper id="1202">
			<definition id="0">
				<sentence>Digital libraries aim at structuring their records to facilitate user navigation .</sentence>
				<definiendum id="0">Digital libraries</definiendum>
				<definiens id="0">aim at structuring their records to facilitate user navigation</definiens>
			</definition>
			<definition id="1">
				<sentence>S. Teufel and M. Moens : Summarizing Scientific Articles : Experiments with Relevance and Rhetorical Status .</sentence>
				<definiendum id="0">Scientific Articles</definiendum>
				<definiens id="0">Experiments with Relevance and Rhetorical Status</definiens>
			</definition>
</paper>

		<paper id="1617">
</paper>

		<paper id="0822">
			<definition id="0">
				<sentence>The HKUST word sense disambiguation systems benefit from a new nonlinear Kernel Principal Component Analysis ( KPCA ) based disambiguation technique .</sentence>
				<definiendum id="0">HKUST word sense disambiguation systems</definiendum>
				<definiens id="0">benefit from a new nonlinear Kernel Principal Component Analysis ( KPCA ) based disambiguation technique</definiens>
			</definition>
			<definition id="1">
				<sentence>MH model ( Schapire and Singer , 2000 ) , which is a multi-class generalization of the original boosting algorithm , with boosting on top of decision stump classifiers ( decision trees of depth one ) .</sentence>
				<definiendum id="0">MH model</definiendum>
				<definiens id="0">a multi-class generalization of the original boosting algorithm , with boosting on top of decision stump classifiers ( decision trees of depth one )</definiens>
			</definition>
			<definition id="2">
				<sentence>Kernel PCA Kernel Principal Component Analysis is a nonlinear kernel method for extracting nonlinear principal components from vector sets where , conceptually , the n-dimensional input vectors are nonlinearly mapped from their original space Rn to a high-dimensional feature space F where linear PCA is performed , yielding a transform by which the input vectors can be mapped nonlinearly to a new set of vectors ( Sch¨olkopf et al. , 1998 ) .</sentence>
				<definiendum id="0">Kernel PCA Kernel Principal Component Analysis</definiendum>
				<definiens id="0">a nonlinear kernel method for extracting nonlinear principal components from vector sets where , conceptually , the n-dimensional input vectors are nonlinearly mapped from their original space Rn to a high-dimensional feature space F where linear PCA is performed</definiens>
			</definition>
			<definition id="3">
				<sentence>Nonlinear principal components ( Diamantaras and Kung , 1996 ) are defined as follows .</sentence>
				<definiendum id="0">Nonlinear principal components</definiendum>
			</definition>
			<definition id="4">
				<sentence>Then the lth nonlinear principal component of any test vector xt is defined as ylt = MX i=1 ^ li ( ( xi ) ( xt ) ) ( 6 ) where ^ li is the lth element of ^ l .</sentence>
				<definiendum id="0">lth nonlinear principal component of any test vector xt</definiendum>
				<definiens id="0">ylt = MX i=1 ^ li ( ( xi ) ( xt ) ) ( 6 ) where ^ li is the lth element of ^ l</definiens>
			</definition>
			<definition id="5">
				<sentence>WSD using KPCA In order to extract nonlinear principal components efficiently , first note that in both Equations ( 5 ) and ( 6 ) the explicit form of ( xi ) is required only in the form of ( ( xi ) ( xj ) ) , i.e. , the dot product of vectors in F. This means that we can calculate the nonlinear principal components by substituting a kernel function k ( xi ; xj ) for ( ( xi ) ( xj ) ) in Equations ( 5 ) and ( 6 ) without knowing the mapping explicitly ; instead , the mapping is implicitly defined by the kernel function .</sentence>
				<definiendum id="0">KPCA In order to extract nonlinear principal components</definiendum>
				<definiens id="0">( xi ) ( xj ) ) , i.e. , the dot product of vectors in F. This means that we can calculate the nonlinear principal components by substituting a kernel function k ( xi ; xj ) for ( ( xi ) ( xj ) ) in Equations ( 5 ) and ( 6 ) without knowing the mapping explicitly</definiens>
			</definition>
			<definition id="6">
				<sentence>On the Senseval3 data , the maximum entropy model fares slightly better : it remains significantly worse on the Multilingual ( ts ) task , but achieves statistically the same accuracy on the English ( fine ) task and is slightly Table 1 : Comparison of accuracy results for various HKUST ensemble and individual models on Sensevalattempted .</sentence>
				<definiendum id="0">maximum entropy</definiendum>
				<definiens id="0">various HKUST ensemble and individual models on Sensevalattempted</definiens>
			</definition>
			<definition id="7">
				<sentence>The KPCA-based model exhibits the accuracy and differentiation characteristics requisite for an effective additional voter , as shown in the foregoing secTable 3 : Comparison of the accuracies for the voting ensembles with and without the KPCA voter , confirming that adding the KPCA-based model to the voting ensemble always helps on Senseval-3 Lexical Sample tasks .</sentence>
				<definiendum id="0">KPCA-based model</definiendum>
			</definition>
			<definition id="8">
				<sentence>The system consists of an ensemble classifier utilizing combinations of maximum entropy , boosting , na¨ıve Bayes , and a new Kernel PCA based model .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of an ensemble classifier utilizing combinations of maximum entropy , boosting , na¨ıve Bayes , and a new Kernel PCA based model</definiens>
			</definition>
</paper>

		<paper id="1104">
			<definition id="0">
				<sentence>Compression by Partial Match ( PPM ) is an adaptive statistical modelling technique that is widely used in the field of text compression .</sentence>
				<definiendum id="0">Compression by Partial Match ( PPM</definiendum>
				<definiens id="0">an adaptive statistical modelling technique that is widely used in the field of text compression</definiens>
			</definition>
			<definition id="1">
				<sentence>The task of statistical language modelling is to determine the probability of a sequence of words .</sentence>
				<definiendum id="0">statistical language modelling</definiendum>
				<definiens id="0">to determine the probability of a sequence of words</definiens>
			</definition>
			<definition id="2">
				<sentence>PPM generates a prediction for each input character based on its preceding characters .</sentence>
				<definiendum id="0">PPM</definiendum>
				<definiens id="0">generates a prediction for each input character based on its preceding characters</definiens>
			</definition>
			<definition id="3">
				<sentence>PPM maintains predictions , computed from the training data , for larger context as well as all shorter con-texts .</sentence>
				<definiendum id="0">PPM</definiendum>
				<definiens id="0">maintains predictions , computed from the training data</definiens>
			</definition>
			<definition id="4">
				<sentence>In the following description of each method , e is the escape probability and p ( φ ) is the conditional probability for symbol φ , given a context .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">the conditional probability for symbol φ , given a context</definiens>
			</definition>
			<definition id="5">
				<sentence>|A| is the size the alphabet which determines the probability for each unseen character .</sentence>
				<definiendum id="0">|A|</definiendum>
				<definiens id="0">the size the alphabet which determines the probability for each unseen character</definiens>
			</definition>
			<definition id="6">
				<sentence>Static PPM is a little worse than modified Kneser-Ney smoothing method .</sentence>
				<definiendum id="0">Static PPM</definiendum>
				<definiens id="0">a little worse than modified Kneser-Ney smoothing method</definiens>
			</definition>
</paper>

		<paper id="0408">
			<definition id="0">
				<sentence>Extensible Dependency Grammar ( XDG ) is a new grammar formalism based on Topological Dependency Grammar ( TDG ) ( Duchier and Debusmann , 2001 ) .</sentence>
				<definiendum id="0">Extensible Dependency Grammar ( XDG )</definiendum>
			</definition>
			<definition id="1">
				<sentence>Extensible Dependency Grammar ( XDG ) is a new grammar formalism generalizing Topological Dependency Grammar ( TDG ) ( Duchier and Debusmann , 2001 ) .</sentence>
				<definiendum id="0">Extensible Dependency Grammar ( XDG )</definiendum>
			</definition>
			<definition id="2">
				<sentence>XDG characterizes linguistic structure along arbitrary many dimensions of description .</sentence>
				<definiendum id="0">XDG</definiendum>
				<definiens id="0">characterizes linguistic structure along arbitrary many dimensions of description</definiens>
			</definition>
			<definition id="3">
				<sentence>An XDG analysis ( V ; Ei ; Fi ) ni=1 is an element of Ana = Ana1 Anan where all dimensions share the same set of nodes V .</sentence>
				<definiendum id="0">XDG analysis</definiendum>
			</definition>
			<definition id="4">
				<sentence>Because XDG allows us to write grammars with completely free word order , XDG solving is an NP-complete problem ( Koller and Striegnitz , word literal inID outID inPA outPA link He he’ fsubj ?</sentence>
				<definiendum id="0">XDG solving</definiendum>
				<definiens id="0">us to write grammars with completely free word order</definiens>
			</definition>
</paper>

		<paper id="3241">
			<definition id="0">
				<sentence>Edinburgh EH8 9LW , UK keller @ inf.ed.ac.uk This paper provides evidence for Genzel and Charniak’s ( 2002 ) entropy rate principle , which predicts that the entropy of a sentence increases with its position in the text .</sentence>
				<definiendum id="0">entropy rate principle</definiendum>
				<definiens id="0">predicts that the entropy of a sentence increases with its position in the text</definiens>
			</definition>
			<definition id="1">
				<sentence>Genzel and Charniak ( 2002 , 2003 ) introduce the entropy rate principle , which states that speakers produce language whose entropy rate is on average constant .</sentence>
				<definiendum id="0">entropy rate principle</definiendum>
				<definiens id="0">states that speakers produce language whose entropy rate is on average constant</definiens>
			</definition>
			<definition id="2">
				<sentence>This experiment uses a subset of the British National Corpus as training data and tests on the Embra corpus , a set of newspaper articles annotated with eye-movement data .</sentence>
				<definiendum id="0">Embra corpus</definiendum>
				<definiens id="0">a subset of the British National Corpus as training data and tests on the</definiens>
			</definition>
			<definition id="3">
				<sentence>The per-word entropy was computed using an ngram language model , as proposed by G &amp; C:1 ˆH ( X ) = 1jXj ∑ xi2X logP ( xijxi ( n 1 ) : : : xi 1 ) ( 1 ) Here , ˆH ( X ) is the estimate of the per-word entropy of the sentence X , consisting of the words xi , and n is the size of the n-gram .</sentence>
				<definiendum id="0">ngram language model</definiendum>
				<definiendum id="1">xi2X logP ( xijxi</definiendum>
				<definiendum id="2">X</definiendum>
				<definiendum id="3">n</definiendum>
				<definiens id="0">the estimate of the per-word entropy of the sentence X , consisting of the words xi , and</definiens>
				<definiens id="1">the size of the n-gram</definiens>
			</definition>
			<definition id="4">
				<sentence>The parameters n ( n-gram size ) and c ( cut-off value ) were varied as indicated in the previous section .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">cut-off value ) were varied as indicated in the previous section</definiens>
			</definition>
</paper>

		<paper id="0802">
			<definition id="0">
				<sentence>In the end we selected the Chambers English– Hindi dictionary ( Awasthi , 1997 ) , which is a high quality bilingual dictionary that uses Devanagari script .</sentence>
				<definiendum id="0">Chambers English– Hindi dictionary</definiendum>
				<definiens id="0">a high quality bilingual dictionary that uses Devanagari script</definiens>
			</definition>
			<definition id="1">
				<sentence>UMD–SST is a supervised sense tagger based on the Support Vector Machine learning algorithm , and is described more fully in ( Cabezas et al. , 2001 ) .</sentence>
				<definiendum id="0">UMD–SST</definiendum>
			</definition>
</paper>

		<paper id="0701">
			<definition id="0">
				<sentence>This poses a great challenge to information retrieval ( IR ) and question-answering ( QA ) applications , which often rely on little data when responding to user queries .</sentence>
				<definiendum id="0">IR</definiendum>
				<definiens id="0">applications , which often rely on little data when responding to user queries</definiens>
			</definition>
			<definition id="1">
				<sentence>formulation below : ∑ = = n i i x xrf Z xrp 0 i ) ] , ( exp [ 1 ) | ( λ Here Z x is a normalization constant , f i ( r , x ) is a feature function over values of r and vector elements , n is the total number of feature functions , and λ i is the weight for a given feature function .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a feature function over values of r and vector elements</definiens>
			</definition>
</paper>

		<paper id="0111">
</paper>

		<paper id="0106">
			<definition id="0">
				<sentence>We employ a sigmoid function as above , which yields : Stem-like ( µ ) = [ 1 + e−c· ( Length ( µ ) −d ) ] −1 , ( 5 ) where d is the length threshold and c governs the steepness of the curve .</sentence>
				<definiendum id="0">d</definiendum>
				<definiens id="0">the length threshold and c governs the steepness of the curve</definiens>
			</definition>
			<definition id="1">
				<sentence>( 6 ) We then distribute the remaining probability mass proportionally between prefix ( PRE ) , suffix ( SUF ) , and stem ( STM ) , e.g. : p ( SUF | µ ) = Suffix-like ( µ ) · [ 1 − p ( NOI | µ ) ] Prefix-like ( µ ) + Suffix-like ( µ ) + Stem-like ( µ ) .</sentence>
				<definiendum id="0">SUF</definiendum>
				<definiendum id="1">STM</definiendum>
				<definiens id="0">p ( SUF | µ ) = Suffix-like ( µ ) · [ 1 − p ( NOI | µ ) ] Prefix-like ( µ ) + Suffix-like ( µ ) + Stem-like ( µ )</definiens>
			</definition>
			<definition id="2">
				<sentence>Recall is the proportion of correct boundaries discovered by the algorithm in relation to all morpheme boundaries in the gold standard .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the proportion of correct boundaries discovered by the algorithm in relation to all morpheme boundaries in the gold standard</definiens>
			</definition>
			<definition id="3">
				<sentence>The segmentation of ‘p¨a¨aaiheesta’ is not entirely correct : ‘p¨a¨a+aihe+e+sta’ contains an superfluous morph ( ‘e’ ) , which should be part of the stem , i.e. , ‘p¨a¨a+aihee+sta’ .</sentence>
				<definiendum id="0">superfluous morph</definiendum>
				<definiendum id="1">‘e’ )</definiendum>
			</definition>
</paper>

		<paper id="1902">
			<definition id="0">
				<sentence>In the singular in Russian , masculine animate nouns , which belong to Class I , form their accusative on the basis of the genitive form .</sentence>
				<definiendum id="0">masculine animate nouns</definiendum>
				<definiens id="0">belong to Class I , form their accusative on the basis of the genitive form</definiens>
			</definition>
			<definition id="1">
				<sentence>DATR is a default inheritance formalism , which means that information specified under a particular class node takes precedence over that what is inherited , overriding the inherited information .</sentence>
				<definiendum id="0">DATR</definiendum>
				<definiens id="0">a default inheritance formalism , which means that information specified under a particular class node takes precedence over that what is inherited , overriding the inherited information</definiens>
			</definition>
			<definition id="2">
				<sentence>The first dataset consists of nouns from the Uppsala corpus .</sentence>
				<definiendum id="0">first dataset</definiendum>
			</definition>
			<definition id="3">
				<sentence>The Uppsala corpus is a set of sub-corpora of various genres , containing approximately one million words ( Lönngren 1993 , Maier 1994 ) .</sentence>
				<definiendum id="0">Uppsala corpus</definiendum>
				<definiens id="0">a set of sub-corpora of various genres , containing approximately one million words</definiens>
			</definition>
			<definition id="4">
				<sentence>The second dataset consists of the nouns of a pilot version of the Russian Standard Corpus which is fully lemmatized and tagged .</sentence>
				<definiendum id="0">second dataset</definiendum>
				<definiens id="0">consists of the nouns of a pilot version of the Russian Standard Corpus which is fully lemmatized and tagged</definiens>
			</definition>
</paper>

		<paper id="1616">
</paper>

		<paper id="0605">
			<definition id="0">
				<sentence>EMMA is an XML language for describing the interpretation of user input , combining transcriptions of raw signals into words with metadata to help applications resolve uncertainties and contradictions in interpretations .</sentence>
				<definiendum id="0">EMMA</definiendum>
				<definiens id="0">an XML language for describing the interpretation of user input , combining transcriptions of raw signals into words with metadata to help applications resolve uncertainties and contradictions in interpretations</definiens>
			</definition>
</paper>

		<paper id="0100">
</paper>

		<paper id="2503">
			<definition id="0">
				<sentence>An AnsProlog knowledge base consists of rules of the form : l0 ˆ l1 ; : : : ; lm ; not lm+1 ; : : : ; not ln ( 4.1 ) where each of the lis is a literal , i.e. an atom , a , or its classical negation , -a and not is a logical connective called negation as failure or default negation .</sentence>
				<definiendum id="0">AnsProlog knowledge base</definiendum>
				<definiens id="0">consists of rules of the form : l0 ˆ l1 ; : : : ; lm ; not lm+1</definiens>
				<definiens id="1">a logical connective called negation as failure or default negation</definiens>
			</definition>
			<definition id="1">
				<sentence>Set X is closed under Π if , for every rule ( 4.1 ) of Π , l0 2 X whenever for every 1 • i • m , li 2 X and for every m+1 • j • n , lj 62 X. Definition 1 ( Answer set – part one ) A state X of ( Π ) is an answer set for Π if X is minimal ( in the sense of set-theoretic inclusion ) among the sets closed under Π .</sentence>
				<definiendum id="0">Π )</definiendum>
				<definiens id="0">an answer set for Π if X is minimal ( in the sense of set-theoretic inclusion ) among the sets closed under Π</definiens>
			</definition>
			<definition id="2">
				<sentence>The reduct , ΠX , of Π relative to X is the set of rules l0 ˆ l1 ; : : : ; lm for all rules ( 4.1 ) in Π such that lm+1 ; : : : ; ln 62 X. Thus ΠX is a program without default negation .</sentence>
				<definiendum id="0">lm for all rules</definiendum>
				<definiens id="0">the set of rules l0 ˆ l1 ; : : : ;</definiens>
				<definiens id="1">a program without default negation</definiens>
			</definition>
			<definition id="3">
				<sentence>Definition 2 ( Answer set – part two ) X is an answer set for Π if X is an answer set for ΠX .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">an answer set for Π if X is an answer set for ΠX</definiens>
			</definition>
</paper>

		<paper id="1614">
			<definition id="0">
				<sentence>Pakistan has a population of 140 million speaking more than 56 different languages .</sentence>
				<definiendum id="0">Pakistan</definiendum>
				<definiens id="0">has a population of 140 million speaking more than 56 different languages</definiens>
			</definition>
			<definition id="1">
				<sentence>Urdu is the lingua franca of these people , as many speak Urdu as a second language , also the national language of Pakistan .</sentence>
				<definiendum id="0">Urdu</definiendum>
				<definiens id="0">a second language , also the national language of Pakistan</definiens>
			</definition>
			<definition id="2">
				<sentence>1 Urdu Localization Project is a three-year initiative being undertaken by Center for Research in Urdu Language Processing ( www.crulp.org ) and is funded This project will enable translation and access of English content to literate and illiterate Urdu speakers .</sentence>
				<definiendum id="0">Urdu Localization Project</definiendum>
				<definiens id="0">a three-year initiative being undertaken by Center for Research in Urdu Language Processing</definiens>
			</definition>
			<definition id="3">
				<sentence>Urdu Localization Project aims to provide access to existing English language content to Urdu language speakers .</sentence>
				<definiendum id="0">Urdu Localization Project</definiendum>
				<definiens id="0">aims to provide access to existing English language content to Urdu language speakers</definiens>
			</definition>
</paper>

		<paper id="0103">
			<definition id="0">
				<sentence>Schwa is defined as the mid-central vowel that occurs in unstressed syllables .</sentence>
				<definiendum id="0">Schwa</definiendum>
				<definiens id="0">the mid-central vowel that occurs in unstressed syllables</definiens>
			</definition>
			<definition id="1">
				<sentence>Schwa deletion is a phonological phenomenon where schwa is absent in the pronunciation of a particular word , although ideally it should have been pronounced ( Ohala , 1983 ) .</sentence>
				<definiendum id="0">Schwa deletion</definiendum>
				<definiens id="0">a phonological phenomenon where schwa is absent in the pronunciation of a particular word</definiens>
			</definition>
			<definition id="2">
				<sentence>The deletion is a slow diachronic phenomenon , where in order to communicate faster , initially the speakers unintentionally deleted the schwas .</sentence>
				<definiendum id="0">deletion</definiendum>
				<definiens id="0">a slow diachronic phenomenon , where in order to communicate faster</definiens>
			</definition>
			<definition id="3">
				<sentence>A word w is defined as a 2-tuple &lt; w g , w p &gt; , where w g ∈ Σ g + and w p ∈ Σ p + A lexicon Λ is the union of all the valid words w of a language .</sentence>
				<definiendum id="0">word w</definiendum>
				<definiens id="0">a 2-tuple &lt; w g , w p &gt; , where w g ∈ Σ g + and w p ∈ Σ p + A lexicon Λ is the union of all the valid words w of a language</definiens>
			</definition>
			<definition id="4">
				<sentence>A grapheme-to-phoneme converter is defined as a function F g2p : Σ g + → Σ p + , such that ∀w &lt; w g , w p &gt; ∈ Λ , F g2p ( w g ) = w p In order to model the ease of articulation , we start with the modelling of phonotactic constraints .</sentence>
				<definiendum id="0">grapheme-to-phoneme converter</definiendum>
				<definiens id="0">a function F g2p : Σ g + → Σ p +</definiens>
			</definition>
			<definition id="5">
				<sentence>A consonant cluster is a string of the form C p C p + .</sentence>
				<definiendum id="0">consonant cluster</definiendum>
				<definiens id="0">a string of the form C p C p +</definiens>
			</definition>
			<definition id="6">
				<sentence>At the most generic level we can think of a consonant cluster ranking ( CCR ) function , where ℕ is the set of natural numbers CCR : C p + → ℕ The function CCR is independent of any language and every language has a threshold τ CCR , such that a consonant cluster x ∈ C p + is allowed in the language if and only if CCR ( x ) ≤ τ CCR We define two special variants of CCR , O_CCR and C_CCR , which ranks the admissibility of the consonant clusters at the onset and coda positions respectively .</sentence>
				<definiendum id="0">ℕ</definiendum>
				<definiens id="0">independent of any language and every language has a threshold τ CCR , such that a consonant cluster x ∈ C p + is allowed in the language if and only if CCR ( x ) ≤ τ CCR We define two special variants of CCR , O_CCR and C_CCR , which ranks the admissibility of the consonant clusters at the onset and coda positions respectively</definiens>
			</definition>
			<definition id="7">
				<sentence>Schwa following a y ( pronounced as /j/ ) can not be deleted if it is preceded by a high vowel because /j/ is a glide from high vowel to a low/medium vowel ( schwa ) , deletion of schwa would make the presence of the glide imperceptible .</sentence>
				<definiendum id="0">/j/</definiendum>
				<definiens id="0">a glide from high vowel to a low/medium vowel ( schwa ) , deletion of schwa would make the presence of the glide imperceptible</definiens>
			</definition>
</paper>

		<paper id="1206">
			<definition id="0">
				<sentence>Thus average empirical o set de was calculated by de = Pn i=1 di n ( 1 ) where n is the number of occurrences of the given pattern in the gene indexed sentences and di is the observed o set .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of occurrences of the given pattern in the gene indexed sentences</definiens>
			</definition>
</paper>

		<paper id="2323">
			<definition id="0">
				<sentence>Our similarity metrics measure both hierarchical and linear segment agreement using precision/recall metrics , interreliability similarities among annotations using the ( a0 ) metric , and percentage of non-crossing-brackets .</sentence>
				<definiendum id="0">interreliability</definiendum>
				<definiens id="0">similarities among annotations using the ( a0 ) metric , and percentage of non-crossing-brackets</definiens>
			</definition>
			<definition id="1">
				<sentence>In the BDC corpus , unlike the Penn Treebank , there are multiple annotations for each discourse which were not manually combined into one gold standard annotation .</sentence>
				<definiendum id="0">BDC corpus</definiendum>
				<definiens id="0">annotations for each discourse which were not manually combined into one gold standard annotation</definiens>
			</definition>
			<definition id="2">
				<sentence>In this paper , we define a segment as a triple a18a20a19 a3a22a21a23a3a9a24a22a25 , where a0a7a26 is the first utterance in the segment , a0a28a27 is the last utterance in the segment , and a24 is the segment’s level of embeddedness.2 We will sometimes refer to a0a7a26 and a0a28a27 as boundary utterances .</sentence>
				<definiendum id="0">segment</definiendum>
				<definiendum id="1">a0a7a26</definiendum>
				<definiendum id="2">a0a28a27</definiendum>
				<definiendum id="3">a24</definiendum>
				<definiens id="0">the first utterance in the segment</definiens>
				<definiens id="1">the last utterance in the segment</definiens>
				<definiens id="2">boundary utterances</definiens>
			</definition>
			<definition id="3">
				<sentence>The “flat” version ( FlatCNS ) ignores hierarchy and considers only the segment boundaries when determining agreement .</sentence>
				<definiendum id="0">“flat” version ( FlatCNS )</definiendum>
				<definiens id="0">ignores hierarchy and considers only the segment boundaries when determining agreement</definiens>
			</definition>
			<definition id="4">
				<sentence>The consensus and majority approaches are straightforward to compute , but CFU presents an optimization problem in which the greatest number of segments that can be combined without any internal conflicts must be found .</sentence>
				<definiendum id="0">CFU</definiendum>
				<definiens id="0">presents an optimization problem in which the greatest number of segments that can be combined without any internal conflicts must be found</definiens>
			</definition>
			<definition id="5">
				<sentence>We present a dynamic programming algorithm that computes the CFU in a0a2a1a4a3a6a5a8a7 time , where a3 is the number of utterances in the discourse .</sentence>
				<definiendum id="0">a3</definiendum>
				<definiens id="0">the number of utterances in the discourse</definiens>
			</definition>
			<definition id="6">
				<sentence>We define recall as the number of relevant segments in a0 divided by the total number of segments in a0 .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">the number of relevant segments in a0 divided by the total number of segments in a0</definiens>
			</definition>
			<definition id="7">
				<sentence>Recall measures the percentage of the annotator’s segments captured by the gold standard .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">measures the percentage of the annotator’s segments captured by the gold standard</definiens>
			</definition>
</paper>

		<paper id="2510">
			<definition id="0">
				<sentence>Introduction Question Answering ( QA ) systems ( as QA track of the Text Retrieval Conference ( TREC-QA ) competitions ( Voorhees 2001 ) ) , are able both to understand questions in natural language and to produce answers in the form of selected paragraphs extracted from very large collections of text .</sentence>
				<definiendum id="0">Introduction Question Answering ( QA ) systems</definiendum>
			</definition>
			<definition id="1">
				<sentence>A typical entry for a concept is : ID Course Label Course Subclassof Work Table 1 A concept where ID is the concept unique identifier , label is the readable name of the concept , subclassof indicates the relation to another class .</sentence>
				<definiendum id="0">ID</definiendum>
				<definiendum id="1">label</definiendum>
				<definiens id="0">the concept unique identifier</definiens>
			</definition>
			<definition id="2">
				<sentence>The content consists of concepts and relations from the ontology , the focus constraint3 ( the ontological type being questioned ) , and a count feature indicating the number of instances to be retrieved .</sentence>
				<definiendum id="0">content</definiendum>
				<definiens id="0">consists of concepts and relations from the ontology , the focus constraint3 ( the ontological type being questioned ) , and a count feature indicating the number of instances to be retrieved</definiens>
			</definition>
			<definition id="3">
				<sentence>The corresponding Italian representation is : all ( x ) ( ProfessoreAssociato ( x ) &amp; TeacherOf ( x , y ) &amp; Course ( y ) &amp; Subject ( y , French ) ) The first problem is establishing a correspondence between ‘lektor’ and ‘ProfessoreAssociato’ , which as shown in the ontology fragments below are not structurally equivalent .</sentence>
				<definiendum id="0">‘ProfessoreAssociato’</definiendum>
				<definiens id="0">as shown in the ontology fragments below are not structurally equivalent</definiens>
			</definition>
			<definition id="4">
				<sentence>Conclusion Our focus in this paper has been , in the context of ontology-based QA , to discuss how to interface between ontology and linguistic resources on the one hand , and ontology and natural language questions on the other while remaining within a unique framework .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">to discuss how to interface between ontology and linguistic resources on the one hand , and</definiens>
			</definition>
			<definition id="5">
				<sentence>( 2003 ) The Description Logics Handbook : Theory , Implementation , and Applications , Cambridge University Press Basili , Roberto , Michele Vindigni , Fabio Massimo Zanzotto ( 2003a ) Integrating ontological and linguistic knowledge for Conceptual Information Extraction , Web Intelligence Conference , Halifax , Canada , September 2003 Basili , Roberto , Maria Teresa Pazienza , and Fabio Massimo Zanzotto ( 2003b ) Exploiting the feature vector model for learning linguistic representations of relational concepts Workshop on Adaptive Text Extraction and Mining ( ATEM 2003 ) held in conjuction with Europena Conference on Machine Learning ( ECML 2003 ) Cavtat ( Croatia ) , September 2003 Basili , Roberto and Fabio Massimo Zanzotto ( 2002 ) Parsing Engineering and Empirical Robustness Journal of Natural Language Engineering 8/2-3 June 2002 Burger , John et al ( 2002 ) Issues , tasks and program structures to roadmap research in question &amp; answering ( Q &amp; A ) .</sentence>
				<definiendum id="0">Fabio Massimo Zanzotto</definiendum>
				<definiendum id="1">answering</definiendum>
				<definiens id="0">learning linguistic representations of relational concepts Workshop on Adaptive Text Extraction and Mining ( ATEM 2003 ) held in conjuction with Europena Conference on Machine Learning</definiens>
			</definition>
			<definition id="6">
				<sentence>FASTUS : A cascaded finite-state transducer for extracting information from naturallanguage text .</sentence>
				<definiendum id="0">FASTUS</definiendum>
				<definiens id="0">A cascaded finite-state transducer for extracting information from naturallanguage text</definiens>
			</definition>
			<definition id="7">
				<sentence>Vossen , Piek ( 1998 ) EuroWordNet : A Multilingual Database with Lexical Semantic Networks Kluwer Academic Publishers , Dordrecht , October 1998 Woods , W. , R. Kaplan , and B. Nash-Weber ( 1972 ) The Lunar Sciences Natural Language Information System : Final Report .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
				<definiens id="0">A Multilingual Database with Lexical Semantic Networks Kluwer Academic Publishers , Dordrecht , October 1998 Woods , W. , R. Kaplan , and B. Nash-Weber ( 1972 ) The Lunar Sciences Natural Language Information System : Final Report</definiens>
			</definition>
</paper>

		<paper id="1213">
			<definition id="0">
				<sentence>Challenges occur for example due to ambiguity in the left boundary of entities caused by descriptive naming , shortened forms due to abbreviation and aliasing , the di culty of creatfjdkim , yucca , okap , tsuruokag @ is.s.u-tokyo.ac.jp y collier @ nii.ac.jp We have shown that &lt; cons sem= '' G # protein '' &gt; interleukin-1 &lt; /cons &gt; ( &lt; cons sem= '' G # protein '' &gt; IL-1 &lt; /cons &gt; ) and &lt; cons sem= '' G # protein '' &gt; IL-2 &lt; /cons &gt; control &lt; cons sem= '' G # DNA '' &gt; IL-2 receptor alpha ( IL-2R alpha ) gene &lt; /cons &gt; transcription in &lt; cons sem= '' G # cell line '' &gt; CD4-CD8murine T lymphocyte precursors &lt; /cons &gt; .</sentence>
				<definiendum id="0">Challenges</definiendum>
				<definiens id="0">cons sem= '' G # DNA '' &gt; IL-2 receptor alpha ( IL-2R alpha ) gene &lt; /cons &gt; transcription in &lt; cons sem= '' G # cell line '' &gt; CD4-CD8murine T lymphocyte precursors &lt; /cons &gt;</definiens>
			</definition>
			<definition id="1">
				<sentence>The training set consists of abstracts retrieved from the MEDLINE database with MeSH terms ‘human’ , ‘blood cells’ and ‘transcription factors’ , and their publication year ranges over 1990 1999 .</sentence>
				<definiendum id="0">training set</definiendum>
				<definiens id="0">consists of abstracts retrieved from the MEDLINE database with MeSH terms ‘human’ , ‘blood cells’ and ‘transcription factors’ , and their publication year ranges over 1990 1999</definiens>
			</definition>
			<definition id="2">
				<sentence>P is the ratio of the number of correctly found NE chunks to the number of found NE chunks , and R is the ratio of the number of correctly found NE chunks to the number of true NE chunks .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">the ratio of the number of correctly found NE chunks to the number of found NE chunks , and</definiens>
			</definition>
			<definition id="3">
				<sentence>Roughly four types of classi cation models were applied by the eight participating systems ; Support Vector Machines ( SVMs ) , Hidden Markov Models ( HMMs ) , Maximum Entropy Markov Models ( MEMMs ) and Conditional Random Fields ( CRFs ) .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs ) , Hidden Markov Models</definiendum>
				<definiendum id="1">Maximum Entropy Markov Models</definiendum>
				<definiens id="0">applied by the eight participating systems</definiens>
			</definition>
			<definition id="4">
				<sentence>Classi cation Model ( CM ) : S : SVM ; H : HMM ; M : MEMM ; C : CRF ; lx : lexical features ; af : a x information ( character n-grams ) ; or : orthographic information ; sh : word shapes ; gn : gene sequences ( ATCG sequences ) ; wv : word variations ; ln : word length ; gz : gazetteers ; po : part-of-speech tags ; np : noun phrase tags ; sy : syntactic tags ; tr : word triggers ; ab : abbreviations ; ca : cascaded entities ; do : global document information ; pa : parentheses handling ; pr : previously predicted entity tags ; External resources ( ext ) : B : British National Corpus ; M : MEDLINE corpus ; P : Penn Treebank II corpus ; W : world wide web ; V : virtually generated corpus ; Y : Yapex ; G : GAPSCORE .</sentence>
				<definiendum id="0">Classi cation Model</definiendum>
				<definiens id="0">a x information ( character n-grams ) ; or : orthographic information ; sh : word shapes</definiens>
				<definiens id="1">syntactic tags ; tr : word triggers ; ab : abbreviations ; ca : cascaded entities</definiens>
			</definition>
			<definition id="5">
				<sentence>The GENIA corpus is a product of the GENIA project which is supported by the Information Mobility Project ( CREST , JST ) and the Genome Information Science Project ( MEXT ) .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
			</definition>
</paper>

		<paper id="3106">
			<definition id="0">
				<sentence>Text mining is the application of techniques of machine learning in conjunction with natural language processing , information extraction and algebraic/mathematical approaches to computational information retrieval ( Berry and Pottenger , 2003 ) .</sentence>
				<definiendum id="0">Text mining</definiendum>
				<definiens id="0">the application of techniques of machine learning in conjunction with natural language processing , information extraction and algebraic/mathematical approaches to computational information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>MeSH consists of two ontologies : descriptors or headings are a collection of terms for primary themes or topics contained in the literature ; and qualifiers or subheadings are terms combined with descriptors to indicate the specific aspect of a descriptor .</sentence>
				<definiendum id="0">MeSH</definiendum>
				<definiens id="0">consists of two ontologies : descriptors or headings are a collection of terms for primary themes or topics contained in the literature ; and qualifiers or subheadings are terms combined with descriptors to indicate the specific aspect of a descriptor</definiens>
			</definition>
			<definition id="2">
				<sentence>A descriptor ( or qualifier ) may have multiple parents , representing that the descriptor ( or qualifier ) includes multiple concepts in the MeSH ontology simultaneously .</sentence>
				<definiendum id="0">descriptor</definiendum>
				<definiens id="0">representing that the descriptor ( or qualifier ) includes multiple concepts in the MeSH ontology simultaneously</definiens>
			</definition>
			<definition id="3">
				<sentence>Weights are defined by wi =    0 if term ti is not assigned 1 if term ti is inferred 2 if term ti is assigned .</sentence>
				<definiendum id="0">Weights</definiendum>
				<definiens id="0">wi =    0 if term ti is not assigned 1 if term ti is inferred 2 if term ti is assigned</definiens>
			</definition>
			<definition id="4">
				<sentence>Second , AGNES computes an agglomerative coefficient a. Let md be the height at which d is first merged , and M is the height of the final merge , then a = mean d∈D parenleftBig 1 − mdM parenrightBig .</sentence>
				<definiendum id="0">AGNES</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">the height of the final merge</definiens>
			</definition>
			<definition id="5">
				<sentence>The term collection T is derived from terms in abstracts and titles , MeSH descriptors , MeSH qualifiers , or a combination of MeSH descriptors and qualifiers .</sentence>
				<definiendum id="0">MeSH descriptors</definiendum>
				<definiendum id="1">MeSH qualifiers</definiendum>
				<definiens id="0">derived from terms in abstracts and titles</definiens>
			</definition>
			<definition id="6">
				<sentence>The Rat Genome Database ( RGD ) is a NIH ( National Institutes of Health ) project developed at Medical College of Wisconsin ( MCW ) whose main objective is to collect , consolidate and integrate data generated from rat research ( Twigger et al. , 2002 ) .</sentence>
				<definiendum id="0">Rat Genome Database ( RGD )</definiendum>
			</definition>
			<definition id="7">
				<sentence>The document collection consists of 2713 papers .</sentence>
				<definiendum id="0">document collection</definiendum>
			</definition>
			<definition id="8">
				<sentence>The middle cluster consists of papers associated with the genetics and physiopathological diagnosis of Tourette’s Syndrome .</sentence>
				<definiendum id="0">middle cluster</definiendum>
			</definition>
</paper>

		<paper id="2114">
</paper>

		<paper id="0506">
			<definition id="0">
				<sentence>We relate in this paper , an experiment for designing a logic based QA system , WEBCOOP , that integrates knowledge representation and advanced reasoning procedures to generate cooperative responses to natural language ( NL ) queries on the web .</sentence>
				<definiendum id="0">WEBCOOP</definiendum>
				<definiens id="0">that integrates knowledge representation and advanced reasoning procedures to generate cooperative responses to natural language ( NL ) queries on the web</definiens>
			</definition>
			<definition id="1">
				<sentence>The WEBCOOP inference engine has to decide , via cooperative rules , what is relevant and how to organize it in a way that allows for the realization of a coherent and informative response .</sentence>
				<definiendum id="0">WEBCOOP inference engine</definiendum>
				<definiens id="0">has to decide , via cooperative rules , what is relevant and how to organize it in a way that allows for the realization of a coherent and informative response</definiens>
			</definition>
			<definition id="2">
				<sentence>A template is composed of three parts , S , F , and R , where : -S are specified elements , -F are functions that choose for each concept in the ontology , its appropriate lexicalization , R are logical formulas representing the rest of the response to be generated .</sentence>
				<definiendum id="0">template</definiendum>
			</definition>
			<definition id="3">
				<sentence>WEBCOOP has two main forms for encoding knowledge : ( 1 ) general knowledge and domain knowledge represented by means of a deductive knowledge base , that includes facts , rules and integrity constraints and ( 2 ) a large set of indexed texts , where indexes are logical formulae .</sentence>
				<definiendum id="0">indexes</definiendum>
				<definiens id="0">two main forms for encoding knowledge : ( 1 ) general knowledge and domain knowledge represented by means of a deductive knowledge base</definiens>
			</definition>
			<definition id="4">
				<sentence>It also includes rules which play at least two roles : data abstraction ( e.g. to describe the structure of an object , besides e.g. part-of descriptions found in the ontology ) : hotel stay cost ( Hotel ID , NbNights , Total ) : hotel ( Hotel ID , Night rate ) , Total is NbNights * Night rate .</sentence>
				<definiendum id="0">Total</definiendum>
				<definiens id="0">includes rules which play at least two roles : data abstraction ( e.g. to describe the structure of an object , besides e.g. part-of descriptions found in the ontology ) : hotel stay cost ( Hotel ID , NbNights , Total ) : hotel ( Hotel ID , Night rate</definiens>
				<definiens id="1">NbNights * Night rate</definiens>
			</definition>
			<definition id="5">
				<sentence>Since verbs are central in NLG , it is crucial that they get much information , in our system : thematic roles , selectional restrictions , syntactic alternations , Wordnet classification , and semantic representation ( a conceptual representation , a simplification of the Lexical Conceptual Structure ) .</sentence>
				<definiendum id="0">semantic representation</definiendum>
				<definiens id="0">thematic roles , selectional restrictions , syntactic alternations</definiens>
			</definition>
			<definition id="6">
				<sentence>Our knowldge extractor , which is based on the domain ontology , transforms each text fragment into the following logical representation : text ( F , http ) where F is a first-order formula that represents knowledge extracted ( in general ) from a web page , with address http ( or explicit text ) .</sentence>
				<definiendum id="0">knowldge extractor</definiendum>
			</definition>
			<definition id="7">
				<sentence>F is a response to Q iﬀ for all q i there is an f j such that : ( i ) q i unifies with f j or ( ii ) q i subsumes , via the concept ontology , f j ( e.g. means-of-transportation ( Y ) subsumes tramway ( Y ) ) , or ( iii ) q i rewrites , via rules of the knowledge base , into a conjunction of f j , e.g. : airportof ( Z , geneva ) rewrites into : airport ( Z ) ∧ localisation ( Z , in ( geneva ) ) .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">via the concept ontology , f j ( e.g. means-of-transportation ( Y ) subsumes tramway ( Y ) ) , or ( iii ) q i rewrites , via rules of the knowledge base</definiens>
			</definition>
			<definition id="8">
				<sentence>We reported in this paper an experiment for designing a logic based QA system , WEBCOOP , that integrates knowledge representation and advanced reasoning procedures to generate cooperative responses to natural language queries on the web .</sentence>
				<definiendum id="0">WEBCOOP</definiendum>
				<definiens id="0">generate cooperative responses to natural language queries on the web</definiens>
			</definition>
</paper>

		<paper id="1802">
			<definition id="0">
				<sentence>Pragmatic information ( valid usage conditions or contextual restriction for the terms ) , or purely evaluative statements ( usefulness or validity of a certain term for its intended purpose ) , might not be found in classical definitional contexts .</sentence>
				<definiendum id="0">Pragmatic information</definiendum>
				<definiens id="0">valid usage conditions or contextual restriction for the terms ) , or purely evaluative statements ( usefulness or validity of a certain term for its intended purpose )</definiens>
			</definition>
			<definition id="1">
				<sentence>NB : naïve Bayes ; IIS : Maximum Entropy with Improved Iterative Scaling ; GIS : Maximum Entropy with Generalized Iterative Scaling .</sentence>
				<definiendum id="0">NB</definiendum>
				<definiens id="0">naïve Bayes ; IIS : Maximum Entropy with Improved Iterative Scaling ; GIS : Maximum Entropy with Generalized Iterative Scaling</definiens>
			</definition>
			<definition id="2">
				<sentence>Best metrics for Histology corpus P R F NB ( 3/W ) IIS ( 3/W ) GIS ( 1/W ) Although our tests using collocations showed that structural regularities would perform well , our intuitions about improvement using more features ( more positions to the right or left of the lexical markers ) or a more grammatically restricted environment ( surrounding POS tags ) , turned out to be overly optimistic .</sentence>
				<definiendum id="0">GIS</definiendum>
				<definiens id="0">the right or left of the lexical markers ) or a more grammatically restricted environment ( surrounding POS tags ) , turned out to be overly optimistic</definiens>
			</definition>
</paper>

		<paper id="3211">
			<definition id="0">
				<sentence>They acquired the original data from the July 15 , 2002 release of PropBank , which the University of Pennsylvania created by manually labeling the constituents S NP VP She bought NP PP the vase in Egypt Arg0 Predicate Arg1 ArgM-Loc Figure 1 : Syntactic parse of the sentence in ( 2 ) of the Penn TreeBank gold-standard parses ( Marcus et al. , 1994 ) .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">the University of Pennsylvania created by manually labeling the constituents S NP VP She bought NP PP the vase</definiens>
			</definition>
			<definition id="1">
				<sentence>Breiman ( 2001 ) defines a random forest as “a classifier consisting of a collection of tree structured classifiers { h ( x , Θk ) , k=1 , ... } where the { Θk } are independently identically distributed random [ training ] vectors and each tree casts a unit vote for Section # sent # words # preds # args training 28 651 50 129 development 1.2 28 2.2 5.7 test 1.5 33 2.7 7.0 Table 1 : Number of sentences , words , marked predicates , and labeled arguments in thousands the most popular class at input x.” Thus Bagging ( Breiman , 1996 ) is a form of Random Forest , where each tree is grown based on the selection , with replacement , of N random training examples , where N is the number of total examples in the training set .</sentence>
				<definiendum id="0">N random</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">a random forest as “a classifier consisting of a collection of tree structured classifiers { h ( x , Θk ) , k=1 , ... } where the { Θk } are independently identically distributed random [ training ] vectors and each tree casts a unit vote for Section # sent # words # preds # args training 28 651 50 129 development 1.2 28 2.2 5.7 test 1.5 33 2.7 7.0 Table 1 : Number of sentences</definiens>
				<definiens id="1">a form of Random Forest , where each tree is grown based on the selection</definiens>
				<definiens id="2">the number of total examples in the training set</definiens>
			</definition>
			<definition id="2">
				<sentence>Additionally , it is not clear that this provided better results in ( Breiman , 2001 ) and preliminary experiments ( not reported here ) suggest that it might be more effective to simply find a good value for F. To create composed features , we randomly select a number of the input’s category values , C , given by the following equation : C = 1 , ˆV ≤ 4 C = ⌊1.5 + log2 ˆV⌋ , ˆV &gt; 4 ( 2 ) where ˆV is the number of category values still potentially relevant .</sentence>
				<definiendum id="0">ˆV</definiendum>
				<definiens id="0">a number of the input’s category values , C , given by the following equation</definiens>
			</definition>
			<definition id="3">
				<sentence>Breiman indicates that , when several of the inputs are categorical , in order to increase strength enough to obtain a good accuracy rate the number of inputs evaluated at each node must be increased to two-three times ⌊1 + log2 M⌋ ( where M is the number of inputs ) .</sentence>
				<definiendum id="0">M</definiendum>
				<definiens id="0">the number of inputs</definiens>
			</definition>
			<definition id="4">
				<sentence>Our compromise is first to use C and ˆV from equation 2 to calculate a baseline number of composable features for each input i. This quantity is the total number of potentially relevant category values divided by the number used to create a composed feature : fi = ˆVi Ci ( 3 ) Second , given the large number of composable features fi , we also evaluate a larger number , F , of random features at each node in the tree : F = max ( ⌈radicalbigf⌉ , min ( f , ⌊1.5 + 3log2 ( f ) ⌋ ) ) ( 4 ) where f is the sum of fi over all inputs .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">the total number of potentially relevant category values divided by the number used to create a composed feature : fi = ˆVi Ci</definiens>
			</definition>
			<definition id="5">
				<sentence>PREDICATE : the lemma of the predicate whose arguments are to be classified – the infinitive form of marked verbs in the corpus CONSTITUENT PHRASE TYPE : the syntactic type assigned to the constituent/argument being classified HEAD WORD ( HW ) : the head word of the target constituent PARSE TREE PATH ( PATH ) : the sequence of parse tree constituent labels from the argument to its predicate POSITION : a binary value indicating whether the target argument precedes or follows its predicate VOICE : a binary value indicating whether the predicate was used in an active or passive phrase SUB-CATEGORIZATION : the parse tree expansion of the predicate’s grandparent constituent Figure 2 : Baseline feature set of experiment 1 , see ( Gildea and Jurafsky , 2002 ) for details Four experiments are reported : the first uses the baseline features of Gildea and Jurafsky ( 2002 ) ; the second is composed of features proposed by Pradhan et al. ( 2003 ) and Surdeanu et al. ( 2003 ) ; the third experiment evaluates a new feature set ; and the final experiment addresses a method of reducing the feature space .</sentence>
				<definiendum id="0">PREDICATE</definiendum>
				<definiendum id="1">CONSTITUENT PHRASE TYPE</definiendum>
				<definiendum id="2">VOICE</definiendum>
				<definiens id="0">the lemma of the predicate whose arguments are to be classified – the infinitive form of marked verbs in the corpus</definiens>
				<definiens id="1">a binary value indicating whether the target argument precedes or follows its predicate</definiens>
				<definiens id="2">a binary value indicating whether the predicate was used in an active or passive phrase SUB-CATEGORIZATION</definiens>
			</definition>
			<definition id="6">
				<sentence>NAMED ENTITIES : seven binary-valued features indicating whether specific named entities ( PERSON , ORGANIZATION , DATE , TIME , MONEY , LOCATION , and PERCENT ) occurred anywhere in the target constituent ( Surdeanu et al. , 2003 ) HW POS : the grammatical part of speech of the target constituent’s head word ( Surdeanu et al. , 2003 ) CONTENT WORD ( CW ) : “lexicalized feature that selects an informative word from the constituent , different from the head word” ( Surdeanu et al. , 2003 ) VERB CLUSTER : a generalization of the verb predicate by clustering verbs into 64 classes ( Pradhan et al. , 2003 ) HALF PATH : the sequence of parse tree constituent labels from the argument to the lowest common ancestor of the predicate ( Pradhan et al. , 2003 ) Figure 3 : Additional features in experiment 2 Classifier Accuracy Boosted Decision Tree ( Surdeanu et al. , 2003 ) 83.7 Random Forest ( trained with CW ) 87.2 SVM ( Pradhan et al. , 2003 ) 88.9 Random Forest ( trained without CW ) 86.6 Table 3 : Results of experiment 2 prevent significance at p=0.1 for any other arguments , but the SVM appears to perform much better on ARG2 and ARG3 .</sentence>
				<definiendum id="0">CONTENT WORD ( CW )</definiendum>
				<definiens id="0">seven binary-valued features indicating whether specific named entities ( PERSON , ORGANIZATION , DATE , TIME , MONEY , LOCATION , and PERCENT ) occurred anywhere in the target constituent ( Surdeanu et al. , 2003 ) HW POS : the grammatical part of speech of the target constituent’s head word</definiens>
				<definiens id="1">“lexicalized feature that selects an informative word from the constituent , different from the head word” ( Surdeanu et al. , 2003 ) VERB CLUSTER : a generalization of the verb predicate by clustering verbs into 64 classes ( Pradhan et al. , 2003</definiens>
			</definition>
			<definition id="7">
				<sentence>GOVERNING PREPOSITION ( GP ) : if the constituent’s parent is a PP , this is the associated preposition ( e.g. , in “made of [ Arg2 gallium arsenide ] ” , this feature is ‘of’ , since the Arg2-NP is governed by an ‘of’-based PP ) CW BASE : starting with the CW , convert it to its singular form , remove any prefix , and convert digits to ‘n’ ( e.g. , this results in the following CW → CW Base mappings : accidents → accident , nonbinding → binding , repayments → payment , and 1012 → nnnn ) Figure 4 : Features in experiment 3 Feature Set Accuracy Extended ( see figures 2 &amp; 3 ) 86.6 Extended + CW BASE 87.4 Extended + GOVERNING PREPOSITION 87.4 Extended + CW BASE &amp; GP 88.3 Table 4 : Results of experiment 2 only at p=0.1 .</sentence>
				<definiendum id="0">GOVERNING PREPOSITION</definiendum>
				<definiens id="0">the following CW → CW Base mappings : accidents → accident , nonbinding → binding</definiens>
			</definition>
</paper>

		<paper id="0835">
			<definition id="0">
				<sentence>This task had no training data , but only test data based on the tagging of content words by the eXtended WordNet ( XWN ) project ( Mihalcea and Moldovan , 2001 ) .</sentence>
				<definiendum id="0">eXtended WordNet ( XWN ) project</definiendum>
				<definiens id="0">no training data , but only test data based on the tagging of content words by the</definiens>
			</definition>
			<definition id="1">
				<sentence>The low recall is a reflection of the small percentage of items attempted .</sentence>
				<definiendum id="0">low recall</definiendum>
				<definiens id="0">a reflection of the small percentage of items attempted</definiens>
			</definition>
</paper>

		<paper id="2416">
			<definition id="0">
				<sentence>In this paper , we select support vector machines ( SVMs ) ( Vapnik , 1995 ; Burges , 1998 ) to implement the semantic role classifiers , due to their ability to handle an extremely large number of ( overlapping ) features with quite strong generalization properties .</sentence>
				<definiendum id="0">SVMs )</definiendum>
				<definiens id="0">features with quite strong generalization properties</definiens>
			</definition>
			<definition id="1">
				<sentence>( e.g *S ) *S ) marks a position that two clauses end ) Named entities : The IOB tags of named entities .</sentence>
				<definiendum id="0">*S )</definiendum>
				<definiens id="0">marks a position that two clauses end ) Named entities : The IOB tags of named entities</definiens>
			</definition>
			<definition id="2">
				<sentence>Using available information we have created the following token level features : Token Position : The position of the phrase with respect to the predicate .</sentence>
				<definiendum id="0">Token Position</definiendum>
				<definiens id="0">The position of the phrase with respect to the predicate</definiens>
			</definition>
			<definition id="3">
				<sentence>Clause Position : a binary feature that indicates the token is inside or outside of the clause which contains the predicate Headword suffixes : suffixes of headwords of length 2 , 3 and 4 .</sentence>
				<definiendum id="0">Headword</definiendum>
				<definiens id="0">a binary feature that indicates the token is inside or outside of the clause which contains the predicate</definiens>
			</definition>
			<definition id="4">
				<sentence>Length : the number of words in a token .</sentence>
				<definiendum id="0">Length</definiendum>
				<definiens id="0">the number of words in a token</definiens>
			</definition>
</paper>

		<paper id="2508">
			<definition id="0">
				<sentence>Individuals participate in information-seeking dialogues ( whether with other humans or with interactive Q/A systems ) in order to learn new things – that is , to gather information that they do not currently possess .</sentence>
				<definiendum id="0">Individuals</definiendum>
			</definition>
</paper>

		<paper id="1808">
			<definition id="0">
				<sentence>A number of language-technology tasks can benefit from such word clusters , e.g. document classification applications , language modelling , resolving prepositional phrase attachment , conjunction scope identification , word sense disambiguation , word sense separation , automatic thesaurus generation , information retrieval , anaphor resolution , text simplification , topic identification , spelling correction ( Weeds , 2003 ) .</sentence>
				<definiendum id="0">e.g. document classification</definiendum>
				<definiens id="0">applications , language modelling , resolving prepositional phrase attachment , conjunction scope identification , word sense disambiguation , word sense separation , automatic thesaurus generation , information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>We define the dissimilarity of two words , p and q , as J ( p , q ) = ( D ( pbardblm ) +D ( qbardblm ) ) /2 , ( 1 ) where D ( pbardblm ) =summationtexta p ( a ) ( log2 p ( a ) −log2 m ( a ) ) and m ( a ) = ( p ( a ) + q ( a ) ) /2 for any feature a. This is the symmetrically weighted case of the Jensen–Shannon divergence ( Lin , 1991 ) , also known as the information radius or the mean divergence to the mean ( Dagan et al. , 1999 ) .</sentence>
				<definiendum id="0">the dissimilarity of two words</definiendum>
				<definiendum id="1">J</definiendum>
			</definition>
			<definition id="2">
				<sentence>The similarity matrix disw is a symmetric matrix of the dimensions 101 by 101 , as we also include the word w in the matrix .</sentence>
				<definiendum id="0">similarity matrix disw</definiendum>
				<definiens id="0">a symmetric matrix of the dimensions 101 by 101</definiens>
			</definition>
</paper>

		<paper id="0821">
			<definition id="0">
				<sentence>Association for Computational Linguistics for the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems Lexical Sample Coarse ( prec/rec ) Fine ( prec/rec ) UMD-SST 0.643/0.643 0.568/0.568 UMD-SST-gram 0.600/0.600 0.576/0.576 UMD-SST-docexp 0.541/0.542 0.516/0.491 Table 1 : UMD-SST variations on the SENSEVAL-2 English lexical sample task As described by Cabezas et al. ( 2001 ) , we have adopted the framework of support vector machines ( SVMs ) in order to perform supervised classification .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">the Semantic Analysis of Text , Barcelona , Spain , July 2004 SENSEVAL-3 : Third International Workshop on the Evaluation of Systems Lexical Sample Coarse</definiens>
			</definition>
			<definition id="1">
				<sentence>Language pair Precision ( % ) Recall ( % ) English-Chinese 0.445 0.445 English-Spanish 0.444 0.444 English-French 0.445 0.445 Table 4 : Unsupervised probabilistic model results ( fine-grained ) on the SENSEVAL-2 English allwords task United Nations Proceedings , and newswire translations from FBIS ( the Foreign Broadcast Information Service ) .</sentence>
				<definiendum id="0">Language pair Precision</definiendum>
			</definition>
</paper>

	</volume>
