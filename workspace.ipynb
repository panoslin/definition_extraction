{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a75e577969a4ea19"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T04:55:32.531225Z",
     "start_time": "2024-04-08T04:55:29.653156Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from argparse import Namespace\n",
    "from datetime import datetime\n",
    "from shutil import copyfile\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from data.loader import DataLoader\n",
    "from model.trainer import GCNTrainer\n",
    "from utils import (\n",
    "    scorer,\n",
    "    constant,\n",
    "    helper,\n",
    ")\n",
    "from utils.vocab import Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Parse arguments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f84e7d6f0b68ce09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    data_dir='dataset/definition/textbook',\n",
    "    vocab_dir='dataset/definition/textbook/vocab',\n",
    "    emb_dim=300,\n",
    "    ner_dim=30,\n",
    "    pos_dim=30,\n",
    "    hidden_dim=200,\n",
    "    num_layers=2,\n",
    "    input_dropout=0.5,\n",
    "    gcn_dropout=0.5,\n",
    "    word_dropout=0.04,\n",
    "    topn=10000000000.0,\n",
    "    lower=False,\n",
    "    ratio=1,\n",
    "    only_label=0,\n",
    "    sent_loss=100.0,\n",
    "    dep_path_loss=100.0,\n",
    "    consistency_loss=1.0,\n",
    "    prune_k=-1,\n",
    "    conv_l2=0,\n",
    "    pooling='max',\n",
    "    pooling_l2=0.003,\n",
    "    mlp_layers=2,\n",
    "    no_adj=False,\n",
    "    rnn=True,\n",
    "    rnn_hidden=200,\n",
    "    rnn_layers=1,\n",
    "    rnn_dropout=0.5,\n",
    "    lr=0.0003,\n",
    "    lr_decay=0.9,\n",
    "    decay_epoch=5,\n",
    "    optim='adamax',\n",
    "    num_epoch=100,\n",
    "    batch_size=50,\n",
    "    max_grad_norm=5.0,\n",
    "    log_step=20,\n",
    "    log='logs.txt',\n",
    "    save_epoch=100,\n",
    "    save_dir='./saved_models',\n",
    "    id='first_model',\n",
    "    info='',\n",
    "    seed=0,\n",
    "    cuda=False,\n",
    "    cpu=False,\n",
    "    load=False,\n",
    "    model_file=None\n",
    ")\n",
    "opt = vars(args)\n",
    "\n",
    "opt['num_class'] = len(constant.LABEL_TO_ID)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T04:55:32.535077Z",
     "start_time": "2024-04-08T04:55:32.531364Z"
    }
   },
   "id": "dd72a73236ec9c70",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Set random seed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4134762beb40c57"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(1234)\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "elif args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T04:55:32.537671Z",
     "start_time": "2024-04-08T04:55:32.533842Z"
    }
   },
   "id": "f33ebc55d0d55924",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Load vocab"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e7f4322efdd3c41"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab with 26106 words and 300 dims.\n"
     ]
    }
   ],
   "source": [
    "# vocabulary: set of unique words that the dataset contains.\n",
    "vocab = Vocab(os.path.join(opt['vocab_dir'], 'vocab.pkl'), load=True)\n",
    "opt['vocab_size'] = vocab.size\n",
    "\n",
    "# word embedding: vector representation of each word in the vocabulary\n",
    "emb_matrix = np.load(os.path.join(opt['vocab_dir'], 'embedding.npy'))\n",
    "\n",
    "print(f\"\"\"Loaded vocab with {vocab.size} words and {emb_matrix.shape[1]} dims.\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T04:55:32.597253Z",
     "start_time": "2024-04-08T04:55:32.538609Z"
    }
   },
   "id": "f0f49b2cc7a355bb",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11f9e2f2b1a55161"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataset/definition/textbook with batch size 50...\n",
      "354 batches created for dataset/definition/textbook/train.json\n",
      "45 batches created for dataset/definition/textbook/dev.json\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading data from {opt['data_dir']} with batch size {opt['batch_size']}...\")\n",
    "train_batch = DataLoader(os.path.join(opt['data_dir'], 'train.json'), opt, vocab, evaluation=False)\n",
    "dev_batch = DataLoader(os.path.join(opt['data_dir'], 'dev.json'), opt, vocab, evaluation=True)\n",
    "\n",
    "model_id = opt['id'] if len(opt['id']) > 1 else '0' + opt['id']\n",
    "model_save_dir = os.path.join(opt['save_dir'], model_id)\n",
    "opt['model_save_dir'] = model_save_dir\n",
    "os.makedirs(model_save_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T04:55:33.807481Z",
     "start_time": "2024-04-08T04:55:32.596253Z"
    }
   },
   "id": "75c9801be7cc9a90",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9663a577225af972"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config saved to file ./saved_models/first_model/config.json\n",
      "Overwriting old vocab file at ./saved_models/first_model/vocab.pkl\n"
     ]
    }
   ],
   "source": [
    "helper.save_config(opt, os.path.join(model_save_dir, 'config.json'), verbose=True)\n",
    "vocab.save(os.path.join(model_save_dir, 'vocab.pkl'))\n",
    "file_logger = helper.FileLogger(\n",
    "    os.path.join(model_save_dir, opt['log']),\n",
    "    header=\"# epoch\\ttrain_loss\\tsent_loss\\tdep_path_loss\\tdev_loss\\tdev_score\\tbest_dev_score\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T22:48:48.565758Z",
     "start_time": "2024-04-07T22:48:48.556063Z"
    }
   },
   "id": "a0a1ae01a5d754a8",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25bcc98828ff4c07"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune all embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linguohui/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "trainer = GCNTrainer(opt, emb_matrix=emb_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T22:49:17.719606Z",
     "start_time": "2024-04-07T22:49:16.694072Z"
    }
   },
   "id": "cd94812420ce6438",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "id2label = dict([(v, k) for k, v in constant.LABEL_TO_ID.items()])\n",
    "dev_score_history = []\n",
    "current_lr = opt['lr']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T22:49:22.814505Z",
     "start_time": "2024-04-07T22:49:22.803474Z"
    }
   },
   "id": "7e3782621f00f367",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "global_start_time = time.time()\n",
    "format_str = ('{}: step {}/{} (epoch {}/{}), loss = {:.6f}, sent_loss = {:.6f}, dep_path_loss = {:.6f} ({:.3f} '\n",
    "              'sec/batch), lr: {:.6f}')\n",
    "max_steps = len(train_batch) * opt['num_epoch']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T22:49:46.877472Z",
     "start_time": "2024-04-07T22:49:46.874839Z"
    }
   },
   "id": "4343235710302177",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linguohui/Projects/definition_extraction/model/gcn.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  terms_out = pool(F.softmax(outputs), terms.unsqueeze(2).byte(), type=pool_type)\n",
      "/Users/linguohui/Projects/definition_extraction/model/gcn.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  defs_out = pool(F.softmax(outputs), defs.unsqueeze(2).byte(), type=pool_type)\n",
      "/Users/linguohui/Projects/definition_extraction/venv/lib/python3.12/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorCompare.cpp:519.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-07 18:50:11.741906: step 20/35400 (epoch 1/100), loss = 1011.164185, sent_loss = 0.683836, dep_path_loss = 17.089998 (0.263 sec/batch), lr: 0.000300\n",
      "2024-04-07 18:50:19.363878: step 40/35400 (epoch 1/100), loss = 730.274231, sent_loss = 0.689742, dep_path_loss = 8.228372 (0.253 sec/batch), lr: 0.000300\n",
      "2024-04-07 18:50:25.702109: step 60/35400 (epoch 1/100), loss = 687.183960, sent_loss = 0.648916, dep_path_loss = 4.087361 (0.380 sec/batch), lr: 0.000300\n",
      "2024-04-07 18:50:32.375247: step 80/35400 (epoch 1/100), loss = 587.915466, sent_loss = 0.621392, dep_path_loss = 5.546593 (0.258 sec/batch), lr: 0.000300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m      8\u001B[0m global_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m----> 9\u001B[0m loss, sent_loss, dep_path_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[1;32m     11\u001B[0m train_sent_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m sent_loss\n",
      "File \u001B[0;32m~/Projects/definition_extraction/model/trainer.py:60\u001B[0m, in \u001B[0;36mGCNTrainer.update\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 60\u001B[0m logits, class_logits, selections, term_def, not_term_def, term_selections \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     63\u001B[0m labels[labels \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/definition_extraction/model/gcn.py:41\u001B[0m, in \u001B[0;36mGCNClassifier.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs):\n\u001B[1;32m     39\u001B[0m     _, masks, _, _, terms, defs, _ \u001B[38;5;241m=\u001B[39m inputs  \u001B[38;5;66;03m# unpack\u001B[39;00m\n\u001B[0;32m---> 41\u001B[0m     outputs, gcn_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgcn_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(torch\u001B[38;5;241m.\u001B[39mcat([outputs, gcn_outputs], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m     44\u001B[0m     pool_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpooling\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/definition_extraction/model/gcn.py:114\u001B[0m, in \u001B[0;36mGCNRelationModel.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    111\u001B[0m l \u001B[38;5;241m=\u001B[39m (masks\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mint64)\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    112\u001B[0m maxlen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(l)\n\u001B[0;32m--> 114\u001B[0m h, pool_mask, gcn_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgcn\u001B[49m\u001B[43m(\u001B[49m\u001B[43madj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;66;03m# pooling\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;66;03m# pool_type = self.opt['pooling']\u001B[39;00m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;66;03m# h_out = pool(h, pool_mask, type=pool_type)\u001B[39;00m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;66;03m# outputs = torch.cat([h_out], dim=1)\u001B[39;00m\n\u001B[1;32m    120\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_mlp(h)\n",
      "File \u001B[0;32m~/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/definition_extraction/model/gcn.py:181\u001B[0m, in \u001B[0;36mGCN.forward\u001B[0;34m(self, adj, inputs)\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;66;03m# rnn layer\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrnn\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 181\u001B[0m     gcn_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrnn_drop(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_with_rnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43membs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmasks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwords\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    183\u001B[0m     gcn_inputs \u001B[38;5;241m=\u001B[39m embs\n",
      "File \u001B[0;32m~/Projects/definition_extraction/model/gcn.py:166\u001B[0m, in \u001B[0;36mGCN.encode_with_rnn\u001B[0;34m(self, rnn_inputs, masks, batch_size)\u001B[0m\n\u001B[1;32m    164\u001B[0m h0, c0 \u001B[38;5;241m=\u001B[39m rnn_zero_state(batch_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrnn_hidden\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrnn_layers\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    165\u001B[0m rnn_inputs \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mrnn\u001B[38;5;241m.\u001B[39mpack_padded_sequence(rnn_inputs, seq_lens, batch_first\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 166\u001B[0m rnn_outputs, (ht, ct) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrnn_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mh0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc0\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m rnn_outputs, _ \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mrnn\u001B[38;5;241m.\u001B[39mpad_packed_sequence(rnn_outputs, batch_first\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m rnn_outputs\n",
      "File \u001B[0;32m~/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/definition_extraction/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:881\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    878\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers,\n\u001B[1;32m    879\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first)\n\u001B[1;32m    880\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 881\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_sizes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    883\u001B[0m output \u001B[38;5;241m=\u001B[39m result[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    884\u001B[0m hidden \u001B[38;5;241m=\u001B[39m result[\u001B[38;5;241m1\u001B[39m:]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# start training\n",
    "for epoch in range(1, opt['num_epoch'] + 1):\n",
    "    train_loss = 0\n",
    "    train_sent_loss = 0\n",
    "    train_dep_path_loss = 0\n",
    "    for i, batch in enumerate(train_batch):\n",
    "        start_time = time.time()\n",
    "        global_step += 1\n",
    "        loss, sent_loss, dep_path_loss = trainer.update(batch)\n",
    "        train_loss += loss\n",
    "        train_sent_loss += sent_loss\n",
    "        train_dep_path_loss += dep_path_loss\n",
    "        if global_step % opt['log_step'] == 0:\n",
    "            duration = time.time() - start_time\n",
    "            print(\n",
    "                format_str.format(\n",
    "                    datetime.now(), global_step, max_steps, epoch,\n",
    "                    opt['num_epoch'], loss, sent_loss, dep_path_loss, duration, current_lr\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # eval on dev\n",
    "    print(\"Evaluating on dev set...\")\n",
    "    predictions = []\n",
    "    dev_loss = 0\n",
    "    for i, batch in enumerate(dev_batch):\n",
    "        preds, _, loss, _ = trainer.predict(batch)\n",
    "        predictions += preds\n",
    "        dev_loss += loss\n",
    "    predictions = [[id2label[l + 1]] for p in predictions for l in p]\n",
    "    train_loss = train_loss / train_batch.num_examples * opt['batch_size']  # avg loss per batch\n",
    "    train_sent_loss = train_sent_loss / train_batch.num_examples * opt['batch_size']  # avg loss per batch\n",
    "    train_dep_path_loss = train_dep_path_loss / train_batch.num_examples * opt['batch_size']  # avg loss per batch\n",
    "    dev_loss = dev_loss / dev_batch.num_examples * opt['batch_size']\n",
    "\n",
    "    dev_p, dev_r, dev_f1 = scorer.score(dev_batch.gold(), predictions, method='macro')\n",
    "    print(\n",
    "        f\"epoch {epoch}: train_loss = {train_loss:.6f}, \"\n",
    "        f\"train_sent_loss = {train_sent_loss:.6f}, \"\n",
    "        f\"train_dep_path_loss = {train_dep_path_loss:.6f}, \"\n",
    "        f\"dev_loss = {dev_loss:.6f}, dev_f1 = {dev_f1:.4f}\"\n",
    "    )\n",
    "    dev_score = dev_f1\n",
    "    file_logger.log(\n",
    "        f\"{epoch}\\t{train_loss:.6f}\\t{train_sent_loss:.6f}\"\n",
    "        f\"\\t{train_dep_path_loss:.6f}\\t{dev_loss:.6f}\"\n",
    "        f\"\\t{dev_score:.4f}\\t{max([dev_score] + dev_score_history):.4f}\"\n",
    "    )\n",
    "\n",
    "    # save\n",
    "    model_file = model_save_dir + f'/checkpoint_epoch_{epoch}.pt'\n",
    "    trainer.save(model_file, epoch)\n",
    "    if epoch == 1 or dev_score > max(dev_score_history):\n",
    "        copyfile(model_file, model_save_dir + '/best_model.pt')\n",
    "    print(\"new best model saved.\")\n",
    "    file_logger.log(\n",
    "        f\"new best model saved at epoch {epoch}: {dev_p * 100:.2f}\\t{dev_r * 100:.2f}\\t{dev_score * 100:.2f}\"\n",
    "    )\n",
    "    if epoch % opt['save_epoch'] != 0:\n",
    "        os.remove(model_file)\n",
    "\n",
    "    # lr schedule\n",
    "    if (\n",
    "            len(dev_score_history) > opt['decay_epoch'] and\n",
    "            dev_score <= dev_score_history[-1] and\n",
    "            opt['optim'] in ['sgd', 'adagrad', 'adadelta']\n",
    "    ):\n",
    "        current_lr *= opt['lr_decay']\n",
    "\n",
    "    trainer.update_lr(current_lr)\n",
    "    dev_score_history += [dev_score]\n",
    "\n",
    "    print(\"Training ended with {} epochs.\".format(epoch))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-07T22:50:03.959959Z"
    }
   },
   "id": "f412c354f4cc0d2f",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2399f1c65794723c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
