{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a75e577969a4ea19"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:42:02.886012Z",
     "start_time": "2024-05-07T14:42:00.122335Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from argparse import Namespace\n",
    "from shutil import (\n",
    "    copyfile,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from data.loader import DataLoader\n",
    "from model.trainer import GCNTrainer\n",
    "from utils import (\n",
    "    scorer,\n",
    "    constant,\n",
    ")\n",
    "from utils.vocab import Vocab\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Parse arguments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f84e7d6f0b68ce09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    data_dir='dataset/definition/textbook',\n",
    "    vocab_dir='dataset/definition/textbook/vocab',\n",
    "    emb_dim=300,\n",
    "    ner_dim=30,\n",
    "    pos_dim=30,\n",
    "    hidden_dim=200,\n",
    "    num_layers=2,\n",
    "    input_dropout=0.5,\n",
    "    gcn_dropout=0.5,\n",
    "    word_dropout=0.04,\n",
    "    topn=10000000000.0,\n",
    "    lower=False,\n",
    "    ratio=1,\n",
    "    only_label=0,\n",
    "    sent_loss=100.0,\n",
    "    dep_path_loss=100.0,\n",
    "    consistency_loss=1.0,\n",
    "    prune_k=-1,\n",
    "    conv_l2=0,\n",
    "    pooling='max',\n",
    "    pooling_l2=0.003,\n",
    "    mlp_layers=2,\n",
    "    no_adj=False,\n",
    "    rnn=True,\n",
    "    rnn_hidden=200,\n",
    "    rnn_layers=1,\n",
    "    rnn_dropout=0.5,\n",
    "    lr=0.0003,\n",
    "    lr_decay=0.9,\n",
    "    decay_epoch=5,\n",
    "    optim='adamax',\n",
    "    num_epoch=10,\n",
    "    batch_size=50,\n",
    "    max_grad_norm=5.0,\n",
    "    log_step=20,\n",
    "    log='logs.txt',\n",
    "    save_dir='./saved_models',\n",
    "    id='0507',\n",
    "    info='',\n",
    "    seed=0,\n",
    "    cuda=torch.cuda.is_available(),\n",
    "    cpu=not torch.cuda.is_available(),\n",
    "    load=False,\n",
    "    model_file=None\n",
    ")\n",
    "opt = vars(args)\n",
    "\n",
    "opt['num_class'] = len(constant.LABEL_TO_ID)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:42:02.890057Z",
     "start_time": "2024-05-07T14:42:02.887553Z"
    }
   },
   "id": "dd72a73236ec9c70",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Set random seed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4134762beb40c57"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:42:02.894486Z",
     "start_time": "2024-05-07T14:42:02.890598Z"
    }
   },
   "id": "f33ebc55d0d55924",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Load vocab"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e7f4322efdd3c41"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab with 26106 words and 300 dims.\n"
     ]
    }
   ],
   "source": [
    "# vocabulary: set of unique words that the dataset contains.\n",
    "vocab = Vocab(os.path.join(opt['vocab_dir'], 'vocab.pkl'))\n",
    "opt['vocab_size'] = vocab.size\n",
    "\n",
    "# word embedding: vector representation of each word in the vocabulary\n",
    "emb_matrix = np.load(os.path.join(opt['vocab_dir'], 'embedding.npy'))\n",
    "\n",
    "print(f\"\"\"Loaded vocab with {vocab.size} words and {emb_matrix.shape[1]} dims.\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:42:02.947560Z",
     "start_time": "2024-05-07T14:42:02.895340Z"
    }
   },
   "id": "f0f49b2cc7a355bb",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11f9e2f2b1a55161"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataset/definition/textbook with batch size 50...\n",
      "354 batches created for dataset/definition/textbook/train.json\n",
      "45 batches created for dataset/definition/textbook/dev.json\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading data from {opt['data_dir']} with batch size {opt['batch_size']}...\")\n",
    "train_batch = DataLoader(os.path.join(opt['data_dir'], 'train.json'), opt, vocab, evaluation=False)\n",
    "dev_batch = DataLoader(os.path.join(opt['data_dir'], 'dev.json'), opt, vocab, evaluation=True)\n",
    "\n",
    "model_save_dir = os.path.join(opt['save_dir'], opt['id'])\n",
    "opt['model_save_dir'] = os.path.join(opt['save_dir'], opt['id'])\n",
    "os.makedirs(model_save_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:42:04.020813Z",
     "start_time": "2024-05-07T14:42:02.950240Z"
    }
   },
   "id": "75c9801be7cc9a90",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25bcc98828ff4c07"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune all embeddings.\n"
     ]
    }
   ],
   "source": [
    "trainer = GCNTrainer(opt, emb_matrix=emb_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:42:04.658766Z",
     "start_time": "2024-05-07T14:42:04.019884Z"
    }
   },
   "id": "cd94812420ce6438",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "id2label = dict([(v, k) for k, v in constant.LABEL_TO_ID.items()])\n",
    "dev_score_history = []\n",
    "current_lr = opt['lr']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:42:04.663242Z",
     "start_time": "2024-05-07T14:42:04.660446Z"
    }
   },
   "id": "7e3782621f00f367",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "global_start_time = time.time()\n",
    "max_steps = len(train_batch) * opt['num_epoch']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:42:04.665659Z",
     "start_time": "2024-05-07T14:42:04.663442Z"
    }
   },
   "id": "4343235710302177",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:42:11: step 20/3540 (epoch 1/10), loss = 912.394592, sent_loss = 0.605355, dep_path_loss = 7.904532 (0.314 sec/batch), lr: 0.000300\n",
      "10:42:16: step 40/3540 (epoch 1/10), loss = 780.796692, sent_loss = 0.650625, dep_path_loss = 8.824707 (0.284 sec/batch), lr: 0.000300\n",
      "10:42:22: step 60/3540 (epoch 1/10), loss = 835.857971, sent_loss = 0.638335, dep_path_loss = 7.909427 (0.279 sec/batch), lr: 0.000300\n",
      "10:42:30: step 80/3540 (epoch 1/10), loss = 571.141479, sent_loss = 0.607847, dep_path_loss = 5.441769 (0.227 sec/batch), lr: 0.000300\n",
      "10:42:37: step 100/3540 (epoch 1/10), loss = 756.993103, sent_loss = 0.586071, dep_path_loss = 4.268195 (0.345 sec/batch), lr: 0.000300\n",
      "10:42:43: step 120/3540 (epoch 1/10), loss = 810.769470, sent_loss = 0.441815, dep_path_loss = 7.167094 (0.320 sec/batch), lr: 0.000300\n",
      "10:42:49: step 140/3540 (epoch 1/10), loss = 594.306335, sent_loss = 0.481428, dep_path_loss = 4.250006 (0.270 sec/batch), lr: 0.000300\n",
      "10:42:55: step 160/3540 (epoch 1/10), loss = 503.317139, sent_loss = 0.540523, dep_path_loss = 4.767273 (0.268 sec/batch), lr: 0.000300\n",
      "10:43:01: step 180/3540 (epoch 1/10), loss = 640.609131, sent_loss = 0.646000, dep_path_loss = 3.321907 (0.310 sec/batch), lr: 0.000300\n",
      "10:43:07: step 200/3540 (epoch 1/10), loss = 727.300964, sent_loss = 0.646927, dep_path_loss = 5.663400 (0.306 sec/batch), lr: 0.000300\n",
      "10:43:13: step 220/3540 (epoch 1/10), loss = 556.973145, sent_loss = 0.318897, dep_path_loss = 6.601409 (0.242 sec/batch), lr: 0.000300\n",
      "10:43:19: step 240/3540 (epoch 1/10), loss = 471.588257, sent_loss = 0.519859, dep_path_loss = 4.323723 (0.198 sec/batch), lr: 0.000300\n",
      "10:43:25: step 260/3540 (epoch 1/10), loss = 751.890137, sent_loss = 0.552178, dep_path_loss = 2.636035 (0.442 sec/batch), lr: 0.000300\n",
      "10:43:31: step 280/3540 (epoch 1/10), loss = 360.864319, sent_loss = 0.371641, dep_path_loss = 2.357398 (0.427 sec/batch), lr: 0.000300\n",
      "10:43:37: step 300/3540 (epoch 1/10), loss = 748.672363, sent_loss = 0.585859, dep_path_loss = 6.079431 (0.282 sec/batch), lr: 0.000300\n",
      "10:43:42: step 320/3540 (epoch 1/10), loss = 428.958649, sent_loss = 0.477434, dep_path_loss = 2.665231 (0.195 sec/batch), lr: 0.000300\n",
      "10:43:49: step 340/3540 (epoch 1/10), loss = 674.718994, sent_loss = 0.445938, dep_path_loss = 4.719592 (0.225 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 53.006%\n",
      "   Recall (micro): 38.563%\n",
      "       F1 (micro): 44.645%\n",
      "epoch 1: train_loss = 34531.108598, train_sent_loss = 27.384392, train_dep_path_loss = 291.068073, dev_loss = 25822.843348, dev_f1 = 0.2335\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_1.pt\n",
      "new best model saved at epoch 1: 29.39\t22.30\t23.35\n",
      "Training ended with 1 epochs.\n",
      "10:44:02: step 360/3540 (epoch 2/10), loss = 563.506714, sent_loss = 0.480843, dep_path_loss = 2.424899 (0.258 sec/batch), lr: 0.000300\n",
      "10:44:07: step 380/3540 (epoch 2/10), loss = 433.913849, sent_loss = 0.356240, dep_path_loss = 4.229744 (0.293 sec/batch), lr: 0.000300\n",
      "10:44:13: step 400/3540 (epoch 2/10), loss = 630.945007, sent_loss = 0.578536, dep_path_loss = 4.226389 (0.284 sec/batch), lr: 0.000300\n",
      "10:44:20: step 420/3540 (epoch 2/10), loss = 523.089417, sent_loss = 0.418914, dep_path_loss = 2.971928 (0.369 sec/batch), lr: 0.000300\n",
      "10:44:26: step 440/3540 (epoch 2/10), loss = 654.481873, sent_loss = 0.434113, dep_path_loss = 4.383318 (0.264 sec/batch), lr: 0.000300\n",
      "10:44:32: step 460/3540 (epoch 2/10), loss = 898.184265, sent_loss = 0.641928, dep_path_loss = 5.024777 (0.347 sec/batch), lr: 0.000300\n",
      "10:44:37: step 480/3540 (epoch 2/10), loss = 656.791809, sent_loss = 0.529760, dep_path_loss = 2.677673 (0.233 sec/batch), lr: 0.000300\n",
      "10:44:43: step 500/3540 (epoch 2/10), loss = 403.092529, sent_loss = 0.401631, dep_path_loss = 3.095726 (0.242 sec/batch), lr: 0.000300\n",
      "10:44:49: step 520/3540 (epoch 2/10), loss = 537.579346, sent_loss = 0.480178, dep_path_loss = 3.499544 (0.256 sec/batch), lr: 0.000300\n",
      "10:44:55: step 540/3540 (epoch 2/10), loss = 574.559692, sent_loss = 0.432548, dep_path_loss = 1.993514 (0.466 sec/batch), lr: 0.000300\n",
      "10:45:01: step 560/3540 (epoch 2/10), loss = 797.654541, sent_loss = 0.395995, dep_path_loss = 3.362179 (0.311 sec/batch), lr: 0.000300\n",
      "10:45:07: step 580/3540 (epoch 2/10), loss = 609.393616, sent_loss = 0.484857, dep_path_loss = 4.620395 (0.247 sec/batch), lr: 0.000300\n",
      "10:45:13: step 600/3540 (epoch 2/10), loss = 752.600220, sent_loss = 0.384401, dep_path_loss = 4.672658 (0.330 sec/batch), lr: 0.000300\n",
      "10:45:19: step 620/3540 (epoch 2/10), loss = 430.841736, sent_loss = 0.517877, dep_path_loss = 2.153951 (0.265 sec/batch), lr: 0.000300\n",
      "10:45:25: step 640/3540 (epoch 2/10), loss = 527.870544, sent_loss = 0.493949, dep_path_loss = 3.158112 (0.243 sec/batch), lr: 0.000300\n",
      "10:45:31: step 660/3540 (epoch 2/10), loss = 338.394409, sent_loss = 0.389372, dep_path_loss = 2.962358 (0.199 sec/batch), lr: 0.000300\n",
      "10:45:37: step 680/3540 (epoch 2/10), loss = 319.414856, sent_loss = 0.562072, dep_path_loss = 3.028313 (0.221 sec/batch), lr: 0.000300\n",
      "10:45:44: step 700/3540 (epoch 2/10), loss = 610.310059, sent_loss = 0.589354, dep_path_loss = 3.263918 (0.281 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 39.248%\n",
      "   Recall (micro): 69.830%\n",
      "       F1 (micro): 50.252%\n",
      "epoch 2: train_loss = 29116.147045, train_sent_loss = 23.984866, train_dep_path_loss = 169.018529, dev_loss = 30430.072691, dev_f1 = 0.3617\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_2.pt\n",
      "new best model saved at epoch 2: 35.82\t38.83\t36.17\n",
      "Training ended with 2 epochs.\n",
      "10:45:55: step 720/3540 (epoch 3/10), loss = 366.595306, sent_loss = 0.364109, dep_path_loss = 1.489219 (0.325 sec/batch), lr: 0.000300\n",
      "10:46:01: step 740/3540 (epoch 3/10), loss = 452.883026, sent_loss = 0.489820, dep_path_loss = 3.081377 (0.283 sec/batch), lr: 0.000300\n",
      "10:46:07: step 760/3540 (epoch 3/10), loss = 549.107300, sent_loss = 0.384442, dep_path_loss = 2.740505 (0.264 sec/batch), lr: 0.000300\n",
      "10:46:15: step 780/3540 (epoch 3/10), loss = 289.831726, sent_loss = 0.324226, dep_path_loss = 2.719594 (0.255 sec/batch), lr: 0.000300\n",
      "10:46:22: step 800/3540 (epoch 3/10), loss = 593.345886, sent_loss = 0.449694, dep_path_loss = 3.846113 (0.255 sec/batch), lr: 0.000300\n",
      "10:46:28: step 820/3540 (epoch 3/10), loss = 604.602417, sent_loss = 0.491514, dep_path_loss = 1.648813 (0.254 sec/batch), lr: 0.000300\n",
      "10:46:34: step 840/3540 (epoch 3/10), loss = 526.741760, sent_loss = 0.325233, dep_path_loss = 1.684861 (0.435 sec/batch), lr: 0.000300\n",
      "10:46:40: step 860/3540 (epoch 3/10), loss = 486.414978, sent_loss = 0.547953, dep_path_loss = 2.228352 (0.426 sec/batch), lr: 0.000300\n",
      "10:46:46: step 880/3540 (epoch 3/10), loss = 481.672028, sent_loss = 0.351008, dep_path_loss = 2.490099 (0.389 sec/batch), lr: 0.000300\n",
      "10:46:52: step 900/3540 (epoch 3/10), loss = 521.140747, sent_loss = 0.434461, dep_path_loss = 3.149649 (0.272 sec/batch), lr: 0.000300\n",
      "10:46:58: step 920/3540 (epoch 3/10), loss = 488.739807, sent_loss = 0.412549, dep_path_loss = 2.009771 (0.313 sec/batch), lr: 0.000300\n",
      "10:47:04: step 940/3540 (epoch 3/10), loss = 443.220581, sent_loss = 0.582567, dep_path_loss = 2.065973 (0.314 sec/batch), lr: 0.000300\n",
      "10:47:10: step 960/3540 (epoch 3/10), loss = 589.676697, sent_loss = 0.424747, dep_path_loss = 3.722376 (0.304 sec/batch), lr: 0.000300\n",
      "10:47:16: step 980/3540 (epoch 3/10), loss = 344.241211, sent_loss = 0.291535, dep_path_loss = 2.114415 (0.175 sec/batch), lr: 0.000300\n",
      "10:47:23: step 1000/3540 (epoch 3/10), loss = 386.478424, sent_loss = 0.491623, dep_path_loss = 2.152272 (0.244 sec/batch), lr: 0.000300\n",
      "10:47:30: step 1020/3540 (epoch 3/10), loss = 375.540619, sent_loss = 0.406367, dep_path_loss = 2.854703 (0.294 sec/batch), lr: 0.000300\n",
      "10:47:37: step 1040/3540 (epoch 3/10), loss = 483.353851, sent_loss = 0.381654, dep_path_loss = 3.007290 (0.249 sec/batch), lr: 0.000300\n",
      "10:47:44: step 1060/3540 (epoch 3/10), loss = 525.727051, sent_loss = 0.425415, dep_path_loss = 1.274648 (0.336 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 43.426%\n",
      "   Recall (micro): 67.739%\n",
      "       F1 (micro): 52.924%\n",
      "epoch 3: train_loss = 26742.946056, train_sent_loss = 22.915348, train_dep_path_loss = 139.210592, dev_loss = 27329.637180, dev_f1 = 0.3851\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_3.pt\n",
      "new best model saved at epoch 3: 42.59\t38.01\t38.51\n",
      "Training ended with 3 epochs.\n",
      "10:47:56: step 1080/3540 (epoch 4/10), loss = 428.545776, sent_loss = 0.569862, dep_path_loss = 2.886519 (0.233 sec/batch), lr: 0.000300\n",
      "10:48:02: step 1100/3540 (epoch 4/10), loss = 511.483704, sent_loss = 0.377470, dep_path_loss = 1.470609 (0.386 sec/batch), lr: 0.000300\n",
      "10:48:08: step 1120/3540 (epoch 4/10), loss = 514.764587, sent_loss = 0.324596, dep_path_loss = 5.265820 (0.247 sec/batch), lr: 0.000300\n",
      "10:48:15: step 1140/3540 (epoch 4/10), loss = 524.675720, sent_loss = 0.326673, dep_path_loss = 2.776085 (0.272 sec/batch), lr: 0.000300\n",
      "10:48:21: step 1160/3540 (epoch 4/10), loss = 469.472595, sent_loss = 0.489822, dep_path_loss = 3.330102 (0.245 sec/batch), lr: 0.000300\n",
      "10:48:28: step 1180/3540 (epoch 4/10), loss = 377.617950, sent_loss = 0.291257, dep_path_loss = 1.332374 (0.523 sec/batch), lr: 0.000300\n",
      "10:48:34: step 1200/3540 (epoch 4/10), loss = 428.007660, sent_loss = 0.531300, dep_path_loss = 2.065896 (0.637 sec/batch), lr: 0.000300\n",
      "10:48:42: step 1220/3540 (epoch 4/10), loss = 569.567932, sent_loss = 0.507590, dep_path_loss = 1.906411 (0.474 sec/batch), lr: 0.000300\n",
      "10:48:48: step 1240/3540 (epoch 4/10), loss = 657.349731, sent_loss = 0.471051, dep_path_loss = 2.277749 (0.353 sec/batch), lr: 0.000300\n",
      "10:48:55: step 1260/3540 (epoch 4/10), loss = 460.227264, sent_loss = 0.462101, dep_path_loss = 1.700109 (0.310 sec/batch), lr: 0.000300\n",
      "10:49:03: step 1280/3540 (epoch 4/10), loss = 550.520508, sent_loss = 0.408957, dep_path_loss = 2.154148 (0.298 sec/batch), lr: 0.000300\n",
      "10:49:11: step 1300/3540 (epoch 4/10), loss = 400.270416, sent_loss = 0.371937, dep_path_loss = 1.930802 (0.358 sec/batch), lr: 0.000300\n",
      "10:49:18: step 1320/3540 (epoch 4/10), loss = 360.445618, sent_loss = 0.408402, dep_path_loss = 2.302228 (0.373 sec/batch), lr: 0.000300\n",
      "10:49:26: step 1340/3540 (epoch 4/10), loss = 437.525696, sent_loss = 0.429020, dep_path_loss = 2.447753 (0.346 sec/batch), lr: 0.000300\n",
      "10:49:33: step 1360/3540 (epoch 4/10), loss = 357.736023, sent_loss = 0.358306, dep_path_loss = 3.045418 (0.313 sec/batch), lr: 0.000300\n",
      "10:49:39: step 1380/3540 (epoch 4/10), loss = 619.174500, sent_loss = 0.451048, dep_path_loss = 2.696248 (0.416 sec/batch), lr: 0.000300\n",
      "10:49:48: step 1400/3540 (epoch 4/10), loss = 602.985840, sent_loss = 0.463353, dep_path_loss = 2.997340 (0.442 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 48.891%\n",
      "   Recall (micro): 65.983%\n",
      "       F1 (micro): 56.166%\n",
      "epoch 4: train_loss = 25133.585254, train_sent_loss = 21.945014, train_dep_path_loss = 121.594908, dev_loss = 23928.424903, dev_f1 = 0.4126\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_4.pt\n",
      "new best model saved at epoch 4: 44.04\t40.30\t41.26\n",
      "Training ended with 4 epochs.\n",
      "10:50:01: step 1420/3540 (epoch 5/10), loss = 375.703033, sent_loss = 0.438127, dep_path_loss = 3.519197 (0.463 sec/batch), lr: 0.000300\n",
      "10:50:08: step 1440/3540 (epoch 5/10), loss = 438.440521, sent_loss = 0.493182, dep_path_loss = 2.068652 (0.302 sec/batch), lr: 0.000300\n",
      "10:50:15: step 1460/3540 (epoch 5/10), loss = 617.873474, sent_loss = 0.487553, dep_path_loss = 1.982606 (0.299 sec/batch), lr: 0.000300\n",
      "10:50:22: step 1480/3540 (epoch 5/10), loss = 346.747314, sent_loss = 0.354983, dep_path_loss = 1.763774 (0.271 sec/batch), lr: 0.000300\n",
      "10:50:29: step 1500/3540 (epoch 5/10), loss = 684.864563, sent_loss = 0.491850, dep_path_loss = 2.572802 (0.343 sec/batch), lr: 0.000300\n",
      "10:50:36: step 1520/3540 (epoch 5/10), loss = 359.726654, sent_loss = 0.333162, dep_path_loss = 2.884997 (0.300 sec/batch), lr: 0.000300\n",
      "10:50:43: step 1540/3540 (epoch 5/10), loss = 372.630981, sent_loss = 0.357990, dep_path_loss = 2.046732 (0.294 sec/batch), lr: 0.000300\n",
      "10:50:49: step 1560/3540 (epoch 5/10), loss = 152.871765, sent_loss = 0.355128, dep_path_loss = 0.585643 (0.413 sec/batch), lr: 0.000300\n",
      "10:50:56: step 1580/3540 (epoch 5/10), loss = 418.066162, sent_loss = 0.416283, dep_path_loss = 2.323652 (0.307 sec/batch), lr: 0.000300\n",
      "10:51:02: step 1600/3540 (epoch 5/10), loss = 330.079132, sent_loss = 0.279447, dep_path_loss = 2.197643 (0.258 sec/batch), lr: 0.000300\n",
      "10:51:10: step 1620/3540 (epoch 5/10), loss = 629.360596, sent_loss = 0.419103, dep_path_loss = 2.675398 (0.244 sec/batch), lr: 0.000300\n",
      "10:51:16: step 1640/3540 (epoch 5/10), loss = 239.401855, sent_loss = 0.291840, dep_path_loss = 0.860483 (0.245 sec/batch), lr: 0.000300\n",
      "10:51:22: step 1660/3540 (epoch 5/10), loss = 489.159821, sent_loss = 0.516110, dep_path_loss = 1.746003 (0.348 sec/batch), lr: 0.000300\n",
      "10:51:28: step 1680/3540 (epoch 5/10), loss = 303.112213, sent_loss = 0.332838, dep_path_loss = 0.900872 (0.242 sec/batch), lr: 0.000300\n",
      "10:51:35: step 1700/3540 (epoch 5/10), loss = 432.246948, sent_loss = 0.283556, dep_path_loss = 1.827996 (0.312 sec/batch), lr: 0.000300\n",
      "10:51:41: step 1720/3540 (epoch 5/10), loss = 633.061523, sent_loss = 0.469857, dep_path_loss = 2.127881 (0.293 sec/batch), lr: 0.000300\n",
      "10:51:47: step 1740/3540 (epoch 5/10), loss = 560.264526, sent_loss = 0.446695, dep_path_loss = 2.237543 (0.281 sec/batch), lr: 0.000300\n",
      "10:51:53: step 1760/3540 (epoch 5/10), loss = 294.376160, sent_loss = 0.340139, dep_path_loss = 0.873079 (0.379 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 48.886%\n",
      "   Recall (micro): 71.900%\n",
      "       F1 (micro): 58.200%\n",
      "epoch 5: train_loss = 23903.737992, train_sent_loss = 20.947962, train_dep_path_loss = 107.920098, dev_loss = 24052.585932, dev_f1 = 0.4360\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_5.pt\n",
      "new best model saved at epoch 5: 43.46\t45.14\t43.60\n",
      "Training ended with 5 epochs.\n",
      "10:52:04: step 1780/3540 (epoch 6/10), loss = 414.660919, sent_loss = 0.389094, dep_path_loss = 2.583892 (0.294 sec/batch), lr: 0.000300\n",
      "10:52:10: step 1800/3540 (epoch 6/10), loss = 483.711060, sent_loss = 0.467754, dep_path_loss = 1.694988 (0.340 sec/batch), lr: 0.000300\n",
      "10:52:15: step 1820/3540 (epoch 6/10), loss = 341.613403, sent_loss = 0.391463, dep_path_loss = 3.403587 (0.234 sec/batch), lr: 0.000300\n",
      "10:52:22: step 1840/3540 (epoch 6/10), loss = 542.814453, sent_loss = 0.299517, dep_path_loss = 0.706957 (0.317 sec/batch), lr: 0.000300\n",
      "10:52:27: step 1860/3540 (epoch 6/10), loss = 343.952942, sent_loss = 0.297052, dep_path_loss = 3.584667 (0.258 sec/batch), lr: 0.000300\n",
      "10:52:35: step 1880/3540 (epoch 6/10), loss = 436.725494, sent_loss = 0.475349, dep_path_loss = 0.651907 (0.340 sec/batch), lr: 0.000300\n",
      "10:52:41: step 1900/3540 (epoch 6/10), loss = 599.741638, sent_loss = 0.347037, dep_path_loss = 2.842612 (0.269 sec/batch), lr: 0.000300\n",
      "10:52:49: step 1920/3540 (epoch 6/10), loss = 492.430359, sent_loss = 0.429785, dep_path_loss = 3.082841 (0.322 sec/batch), lr: 0.000300\n",
      "10:52:55: step 1940/3540 (epoch 6/10), loss = 336.909546, sent_loss = 0.328642, dep_path_loss = 0.559318 (0.317 sec/batch), lr: 0.000300\n",
      "10:53:03: step 1960/3540 (epoch 6/10), loss = 612.941040, sent_loss = 0.382172, dep_path_loss = 3.568127 (0.353 sec/batch), lr: 0.000300\n",
      "10:53:09: step 1980/3540 (epoch 6/10), loss = 596.233521, sent_loss = 0.589198, dep_path_loss = 1.150689 (0.629 sec/batch), lr: 0.000300\n",
      "10:53:16: step 2000/3540 (epoch 6/10), loss = 302.079529, sent_loss = 0.481224, dep_path_loss = 1.141804 (0.317 sec/batch), lr: 0.000300\n",
      "10:53:23: step 2020/3540 (epoch 6/10), loss = 551.085266, sent_loss = 0.403836, dep_path_loss = 2.220805 (0.321 sec/batch), lr: 0.000300\n",
      "10:53:30: step 2040/3540 (epoch 6/10), loss = 384.131592, sent_loss = 0.377392, dep_path_loss = 0.553174 (0.308 sec/batch), lr: 0.000300\n",
      "10:53:37: step 2060/3540 (epoch 6/10), loss = 510.384674, sent_loss = 0.461415, dep_path_loss = 1.106332 (0.424 sec/batch), lr: 0.000300\n",
      "10:53:43: step 2080/3540 (epoch 6/10), loss = 499.226013, sent_loss = 0.487069, dep_path_loss = 2.312689 (0.329 sec/batch), lr: 0.000300\n",
      "10:53:50: step 2100/3540 (epoch 6/10), loss = 385.857697, sent_loss = 0.376779, dep_path_loss = 2.015084 (0.282 sec/batch), lr: 0.000300\n",
      "10:53:57: step 2120/3540 (epoch 6/10), loss = 530.315125, sent_loss = 0.476971, dep_path_loss = 4.662896 (0.263 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 46.661%\n",
      "   Recall (micro): 75.015%\n",
      "       F1 (micro): 57.534%\n",
      "epoch 6: train_loss = 22861.181048, train_sent_loss = 20.269751, train_dep_path_loss = 100.022960, dev_loss = 25941.321165, dev_f1 = 0.4312\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_6.pt\n",
      "Training ended with 6 epochs.\n",
      "10:54:10: step 2140/3540 (epoch 7/10), loss = 585.308105, sent_loss = 0.550348, dep_path_loss = 3.225227 (0.423 sec/batch), lr: 0.000300\n",
      "10:54:16: step 2160/3540 (epoch 7/10), loss = 470.720306, sent_loss = 0.450611, dep_path_loss = 1.367253 (0.298 sec/batch), lr: 0.000300\n",
      "10:54:23: step 2180/3540 (epoch 7/10), loss = 399.229736, sent_loss = 0.476609, dep_path_loss = 1.060517 (0.429 sec/batch), lr: 0.000300\n",
      "10:54:30: step 2200/3540 (epoch 7/10), loss = 302.913361, sent_loss = 0.281682, dep_path_loss = 1.175641 (0.349 sec/batch), lr: 0.000300\n",
      "10:54:36: step 2220/3540 (epoch 7/10), loss = 415.962982, sent_loss = 0.465158, dep_path_loss = 1.025670 (0.363 sec/batch), lr: 0.000300\n",
      "10:54:43: step 2240/3540 (epoch 7/10), loss = 448.254578, sent_loss = 0.364507, dep_path_loss = 3.755495 (0.265 sec/batch), lr: 0.000300\n",
      "10:54:49: step 2260/3540 (epoch 7/10), loss = 353.667877, sent_loss = 0.419818, dep_path_loss = 0.883652 (0.382 sec/batch), lr: 0.000300\n",
      "10:54:56: step 2280/3540 (epoch 7/10), loss = 324.176025, sent_loss = 0.473721, dep_path_loss = 1.634972 (0.238 sec/batch), lr: 0.000300\n",
      "10:55:02: step 2300/3540 (epoch 7/10), loss = 475.343079, sent_loss = 0.401191, dep_path_loss = 1.905400 (0.252 sec/batch), lr: 0.000300\n",
      "10:55:10: step 2320/3540 (epoch 7/10), loss = 502.833649, sent_loss = 0.476029, dep_path_loss = 1.891121 (0.285 sec/batch), lr: 0.000300\n",
      "10:55:19: step 2340/3540 (epoch 7/10), loss = 635.365051, sent_loss = 0.406076, dep_path_loss = 1.556807 (0.454 sec/batch), lr: 0.000300\n",
      "10:55:26: step 2360/3540 (epoch 7/10), loss = 521.935669, sent_loss = 0.382745, dep_path_loss = 2.192344 (0.294 sec/batch), lr: 0.000300\n",
      "10:55:33: step 2380/3540 (epoch 7/10), loss = 433.267273, sent_loss = 0.519035, dep_path_loss = 1.800944 (0.225 sec/batch), lr: 0.000300\n",
      "10:55:40: step 2400/3540 (epoch 7/10), loss = 260.800751, sent_loss = 0.368022, dep_path_loss = 0.721076 (0.354 sec/batch), lr: 0.000300\n",
      "10:55:47: step 2420/3540 (epoch 7/10), loss = 389.307281, sent_loss = 0.309603, dep_path_loss = 2.170793 (0.248 sec/batch), lr: 0.000300\n",
      "10:55:53: step 2440/3540 (epoch 7/10), loss = 374.197388, sent_loss = 0.295165, dep_path_loss = 0.632184 (0.355 sec/batch), lr: 0.000300\n",
      "10:56:00: step 2460/3540 (epoch 7/10), loss = 416.680206, sent_loss = 0.341895, dep_path_loss = 1.314118 (0.527 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 50.165%\n",
      "   Recall (micro): 72.691%\n",
      "       F1 (micro): 59.363%\n",
      "epoch 7: train_loss = 21981.246640, train_sent_loss = 19.829257, train_dep_path_loss = 91.010425, dev_loss = 23866.168416, dev_f1 = 0.4428\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_7.pt\n",
      "new best model saved at epoch 7: 44.17\t45.79\t44.28\n",
      "Training ended with 7 epochs.\n",
      "10:56:13: step 2480/3540 (epoch 8/10), loss = 313.249512, sent_loss = 0.357139, dep_path_loss = 1.005093 (0.424 sec/batch), lr: 0.000300\n",
      "10:56:20: step 2500/3540 (epoch 8/10), loss = 399.880585, sent_loss = 0.348710, dep_path_loss = 1.883203 (0.260 sec/batch), lr: 0.000300\n",
      "10:56:27: step 2520/3540 (epoch 8/10), loss = 562.530579, sent_loss = 0.437259, dep_path_loss = 1.816886 (0.283 sec/batch), lr: 0.000300\n",
      "10:56:34: step 2540/3540 (epoch 8/10), loss = 373.312836, sent_loss = 0.515764, dep_path_loss = 1.688174 (0.354 sec/batch), lr: 0.000300\n",
      "10:56:41: step 2560/3540 (epoch 8/10), loss = 322.974792, sent_loss = 0.359417, dep_path_loss = 1.060293 (0.237 sec/batch), lr: 0.000300\n",
      "10:56:48: step 2580/3540 (epoch 8/10), loss = 320.338135, sent_loss = 0.346515, dep_path_loss = 1.006101 (0.341 sec/batch), lr: 0.000300\n",
      "10:56:54: step 2600/3540 (epoch 8/10), loss = 488.299957, sent_loss = 0.409745, dep_path_loss = 1.659977 (0.277 sec/batch), lr: 0.000300\n",
      "10:57:00: step 2620/3540 (epoch 8/10), loss = 516.285217, sent_loss = 0.345024, dep_path_loss = 3.831334 (0.246 sec/batch), lr: 0.000300\n",
      "10:57:08: step 2640/3540 (epoch 8/10), loss = 397.478790, sent_loss = 0.467352, dep_path_loss = 2.391528 (0.307 sec/batch), lr: 0.000300\n",
      "10:57:15: step 2660/3540 (epoch 8/10), loss = 381.685455, sent_loss = 0.292600, dep_path_loss = 2.971912 (0.342 sec/batch), lr: 0.000300\n",
      "10:57:22: step 2680/3540 (epoch 8/10), loss = 459.225311, sent_loss = 0.572641, dep_path_loss = 1.952897 (0.397 sec/batch), lr: 0.000300\n",
      "10:57:29: step 2700/3540 (epoch 8/10), loss = 421.832336, sent_loss = 0.446927, dep_path_loss = 1.945422 (0.324 sec/batch), lr: 0.000300\n",
      "10:57:38: step 2720/3540 (epoch 8/10), loss = 407.545868, sent_loss = 0.278186, dep_path_loss = 1.092753 (0.381 sec/batch), lr: 0.000300\n",
      "10:57:45: step 2740/3540 (epoch 8/10), loss = 303.746490, sent_loss = 0.285866, dep_path_loss = 2.290623 (0.341 sec/batch), lr: 0.000300\n",
      "10:57:53: step 2760/3540 (epoch 8/10), loss = 327.608704, sent_loss = 0.291892, dep_path_loss = 1.400817 (0.500 sec/batch), lr: 0.000300\n",
      "10:57:59: step 2780/3540 (epoch 8/10), loss = 353.052582, sent_loss = 0.483190, dep_path_loss = 1.618384 (0.273 sec/batch), lr: 0.000300\n",
      "10:58:06: step 2800/3540 (epoch 8/10), loss = 402.869171, sent_loss = 0.448096, dep_path_loss = 0.868966 (0.410 sec/batch), lr: 0.000300\n",
      "10:58:14: step 2820/3540 (epoch 8/10), loss = 379.059082, sent_loss = 0.380847, dep_path_loss = 3.317642 (0.315 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 51.461%\n",
      "   Recall (micro): 71.676%\n",
      "       F1 (micro): 59.909%\n",
      "epoch 8: train_loss = 20921.061201, train_sent_loss = 18.952217, train_dep_path_loss = 85.107649, dev_loss = 22400.348536, dev_f1 = 0.4485\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_8.pt\n",
      "new best model saved at epoch 8: 45.30\t45.49\t44.85\n",
      "Training ended with 8 epochs.\n",
      "10:58:28: step 2840/3540 (epoch 9/10), loss = 264.664001, sent_loss = 0.292936, dep_path_loss = 2.461755 (0.278 sec/batch), lr: 0.000300\n",
      "10:58:35: step 2860/3540 (epoch 9/10), loss = 339.260315, sent_loss = 0.313200, dep_path_loss = 3.252731 (0.259 sec/batch), lr: 0.000300\n",
      "10:58:42: step 2880/3540 (epoch 9/10), loss = 449.205536, sent_loss = 0.429195, dep_path_loss = 2.347862 (0.325 sec/batch), lr: 0.000300\n",
      "10:58:49: step 2900/3540 (epoch 9/10), loss = 420.337433, sent_loss = 0.335180, dep_path_loss = 1.630095 (0.313 sec/batch), lr: 0.000300\n",
      "10:58:55: step 2920/3540 (epoch 9/10), loss = 304.468689, sent_loss = 0.320904, dep_path_loss = 1.580112 (0.233 sec/batch), lr: 0.000300\n",
      "10:59:03: step 2940/3540 (epoch 9/10), loss = 455.913757, sent_loss = 0.347929, dep_path_loss = 0.629876 (0.523 sec/batch), lr: 0.000300\n",
      "10:59:09: step 2960/3540 (epoch 9/10), loss = 265.657501, sent_loss = 0.329140, dep_path_loss = 0.900628 (0.328 sec/batch), lr: 0.000300\n",
      "10:59:16: step 2980/3540 (epoch 9/10), loss = 472.743744, sent_loss = 0.341941, dep_path_loss = 0.611295 (0.421 sec/batch), lr: 0.000300\n",
      "10:59:23: step 3000/3540 (epoch 9/10), loss = 454.047699, sent_loss = 0.444744, dep_path_loss = 2.865821 (0.301 sec/batch), lr: 0.000300\n",
      "10:59:30: step 3020/3540 (epoch 9/10), loss = 295.673706, sent_loss = 0.365513, dep_path_loss = 0.997265 (0.306 sec/batch), lr: 0.000300\n",
      "10:59:36: step 3040/3540 (epoch 9/10), loss = 545.170288, sent_loss = 0.417208, dep_path_loss = 0.862259 (0.313 sec/batch), lr: 0.000300\n",
      "10:59:43: step 3060/3540 (epoch 9/10), loss = 549.874817, sent_loss = 0.421540, dep_path_loss = 1.769690 (0.396 sec/batch), lr: 0.000300\n",
      "10:59:50: step 3080/3540 (epoch 9/10), loss = 335.435638, sent_loss = 0.335925, dep_path_loss = 1.131220 (0.282 sec/batch), lr: 0.000300\n",
      "10:59:57: step 3100/3540 (epoch 9/10), loss = 186.678070, sent_loss = 0.278873, dep_path_loss = 0.622207 (0.303 sec/batch), lr: 0.000300\n",
      "11:00:05: step 3120/3540 (epoch 9/10), loss = 488.850189, sent_loss = 0.371146, dep_path_loss = 0.966559 (0.349 sec/batch), lr: 0.000300\n",
      "11:00:11: step 3140/3540 (epoch 9/10), loss = 522.770874, sent_loss = 0.370489, dep_path_loss = 2.232893 (0.355 sec/batch), lr: 0.000300\n",
      "11:00:19: step 3160/3540 (epoch 9/10), loss = 403.454590, sent_loss = 0.329215, dep_path_loss = 1.176367 (0.484 sec/batch), lr: 0.000300\n",
      "11:00:26: step 3180/3540 (epoch 9/10), loss = 608.348206, sent_loss = 0.376791, dep_path_loss = 1.505385 (0.411 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 52.525%\n",
      "   Recall (micro): 71.666%\n",
      "       F1 (micro): 60.621%\n",
      "epoch 9: train_loss = 20419.439219, train_sent_loss = 18.768274, train_dep_path_loss = 80.376593, dev_loss = 23250.559413, dev_f1 = 0.4534\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_9.pt\n",
      "new best model saved at epoch 9: 45.97\t46.08\t45.34\n",
      "Training ended with 9 epochs.\n",
      "11:00:39: step 3200/3540 (epoch 10/10), loss = 213.236801, sent_loss = 0.319116, dep_path_loss = 1.068916 (0.275 sec/batch), lr: 0.000300\n",
      "11:00:45: step 3220/3540 (epoch 10/10), loss = 340.971375, sent_loss = 0.439007, dep_path_loss = 2.172129 (0.220 sec/batch), lr: 0.000300\n",
      "11:00:52: step 3240/3540 (epoch 10/10), loss = 436.837189, sent_loss = 0.320965, dep_path_loss = 1.873505 (0.338 sec/batch), lr: 0.000300\n",
      "11:01:00: step 3260/3540 (epoch 10/10), loss = 220.188278, sent_loss = 0.349168, dep_path_loss = 0.771458 (0.357 sec/batch), lr: 0.000300\n",
      "11:01:06: step 3280/3540 (epoch 10/10), loss = 581.346008, sent_loss = 0.480531, dep_path_loss = 2.395933 (0.370 sec/batch), lr: 0.000300\n",
      "11:01:13: step 3300/3540 (epoch 10/10), loss = 416.221252, sent_loss = 0.312131, dep_path_loss = 2.285117 (0.335 sec/batch), lr: 0.000300\n",
      "11:01:20: step 3320/3540 (epoch 10/10), loss = 431.784912, sent_loss = 0.325326, dep_path_loss = 0.943317 (0.354 sec/batch), lr: 0.000300\n",
      "11:01:27: step 3340/3540 (epoch 10/10), loss = 333.335480, sent_loss = 0.379708, dep_path_loss = 1.182972 (0.285 sec/batch), lr: 0.000300\n",
      "11:01:33: step 3360/3540 (epoch 10/10), loss = 362.107300, sent_loss = 0.364836, dep_path_loss = 2.159151 (0.306 sec/batch), lr: 0.000300\n",
      "11:01:41: step 3380/3540 (epoch 10/10), loss = 481.191711, sent_loss = 0.283140, dep_path_loss = 4.042581 (0.260 sec/batch), lr: 0.000300\n",
      "11:01:48: step 3400/3540 (epoch 10/10), loss = 251.297424, sent_loss = 0.320505, dep_path_loss = 1.492097 (0.350 sec/batch), lr: 0.000300\n",
      "11:01:55: step 3420/3540 (epoch 10/10), loss = 311.847748, sent_loss = 0.275180, dep_path_loss = 1.426556 (0.368 sec/batch), lr: 0.000300\n",
      "11:02:03: step 3440/3540 (epoch 10/10), loss = 274.449280, sent_loss = 0.316406, dep_path_loss = 0.564024 (0.300 sec/batch), lr: 0.000300\n",
      "11:02:12: step 3460/3540 (epoch 10/10), loss = 265.534576, sent_loss = 0.334162, dep_path_loss = 0.840356 (0.332 sec/batch), lr: 0.000300\n",
      "11:02:21: step 3480/3540 (epoch 10/10), loss = 469.133850, sent_loss = 0.440322, dep_path_loss = 1.022873 (0.502 sec/batch), lr: 0.000300\n",
      "11:02:30: step 3500/3540 (epoch 10/10), loss = 355.886414, sent_loss = 0.275527, dep_path_loss = 2.139962 (0.382 sec/batch), lr: 0.000300\n",
      "11:02:40: step 3520/3540 (epoch 10/10), loss = 374.594879, sent_loss = 0.507032, dep_path_loss = 1.494365 (0.425 sec/batch), lr: 0.000300\n",
      "11:02:46: step 3540/3540 (epoch 10/10), loss = 276.161835, sent_loss = 0.515205, dep_path_loss = 2.231398 (0.194 sec/batch), lr: 0.000300\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 54.940%\n",
      "   Recall (micro): 68.734%\n",
      "       F1 (micro): 61.068%\n",
      "epoch 10: train_loss = 19600.853128, train_sent_loss = 18.135019, train_dep_path_loss = 75.331212, dev_loss = 21886.827202, dev_f1 = 0.4581\n",
      "model saved to ./saved_models/0507/checkpoint_epoch_10.pt\n",
      "new best model saved at epoch 10: 47.47\t45.44\t45.81\n",
      "Training ended with 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "for epoch in range(1, opt['num_epoch'] + 1):\n",
    "    train_loss = 0\n",
    "    train_sent_loss = 0\n",
    "    train_dep_path_loss = 0\n",
    "    for i, batch in enumerate(train_batch):\n",
    "        start_time = time.time()\n",
    "        global_step += 1\n",
    "        loss, sent_loss, dep_path_loss = trainer.update(batch)\n",
    "        train_loss += loss\n",
    "        train_sent_loss += sent_loss\n",
    "        train_dep_path_loss += dep_path_loss\n",
    "        if global_step % opt['log_step'] == 0:\n",
    "            duration = time.time() - start_time\n",
    "            print(\n",
    "                f\"{time.strftime('%H:%M:%S', time.localtime())}: step {global_step}/{max_steps} (epoch {epoch}/{opt['num_epoch']}), loss = {loss:.6f}, sent_loss = {sent_loss:.6f}, dep_path_loss = {dep_path_loss:.6f} ({duration:.3f} sec/batch), lr: {current_lr:.6f}\"\n",
    "            )\n",
    "\n",
    "    # eval on dev\n",
    "    print(\"Evaluating on dev set...\")\n",
    "    predictions = []\n",
    "    dev_loss = 0\n",
    "    for i, batch in enumerate(dev_batch):\n",
    "        preds, _, loss, _ = trainer.predict(batch)\n",
    "        predictions += preds\n",
    "        dev_loss += loss\n",
    "\n",
    "    predictions = [[id2label[l + 1]] for p in predictions for l in p]\n",
    "    train_loss = train_loss / len(train_batch) * opt['batch_size']  # avg loss per batch\n",
    "    train_sent_loss = train_sent_loss / len(train_batch) * opt['batch_size']  # avg loss per batch\n",
    "    train_dep_path_loss = train_dep_path_loss / len(train_batch) * opt['batch_size']  # avg loss per batch\n",
    "    dev_loss = dev_loss / len(dev_batch) * opt['batch_size']\n",
    "\n",
    "    dev_p, dev_r, dev_f1 = scorer.score(dev_batch.gold(), predictions, method='macro')\n",
    "    print(\n",
    "        f\"epoch {epoch}: train_loss = {train_loss:.6f}, \"\n",
    "        f\"train_sent_loss = {train_sent_loss:.6f}, \"\n",
    "        f\"train_dep_path_loss = {train_dep_path_loss:.6f}, \"\n",
    "        f\"dev_loss = {dev_loss:.6f}, dev_f1 = {dev_f1:.4f}\"\n",
    "    )\n",
    "    dev_score = dev_f1\n",
    "\n",
    "    # save\n",
    "    model_file = model_save_dir + f'/checkpoint_epoch_{epoch}.pt'\n",
    "    trainer.save(model_file, epoch)\n",
    "    if epoch == 1 or dev_score > max(dev_score_history):\n",
    "        copyfile(model_file, model_save_dir + '/best_model.pt')\n",
    "\n",
    "        print(f\"new best model saved at epoch {epoch}: {dev_p * 100:.2f}\\t{dev_r * 100:.2f}\\t{dev_score * 100:.2f}\")\n",
    "\n",
    "    dev_score_history += [dev_score]\n",
    "\n",
    "    print(\"Training ended with {} epochs.\".format(epoch))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T15:02:53.152852Z",
     "start_time": "2024-05-07T14:42:04.672090Z"
    }
   },
   "id": "f412c354f4cc0d2f",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T15:02:53.158053Z",
     "start_time": "2024-05-07T15:02:53.152851Z"
    }
   },
   "id": "2399f1c65794723c",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
